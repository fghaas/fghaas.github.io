<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>xahteiwi.eu</title><link href="https://xahteiwi.eu/" rel="alternate"></link><link href="https://xahteiwi.eu/feeds/all.atom.xml" rel="self"></link><id>https://xahteiwi.eu/</id><updated>2022-05-07T00:00:00+00:00</updated><entry><title>Entropy, management, and xkcd 927</title><link href="https://xahteiwi.eu/blog/2022/05/07/entropy/" rel="alternate"></link><published>2022-05-07T00:00:00+00:00</published><updated>2022-05-07T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2022-05-07:/blog/2022/05/07/entropy/</id><summary type="html">&lt;p&gt;As a manager, don’t try to negotiate with the laws of physics.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://xkcd.com/927/"&gt;xkcd 927&lt;/a&gt; is a modern internet classic that is
frequently brought up in conversations to remind people that a proposal
that they’re making will, while being intended to simplify things,
actually make them more complicated.&lt;/p&gt;
&lt;p&gt;Most people quote that strip to satirize or even ridicule the idea of
introducing a “15th standard”, as if the natural order of things was
simplification. Such people are frequently baffled by the amount of
cruft and clutter that accumulates over time in an organization they
work in, and some of them embark on a constant — perhaps career-long —
quest of “streamlining,” “process optimization,” or “reducing
technical debt.”&lt;/p&gt;
&lt;p&gt;If you are one such person, please get ready for some bad news.&lt;/p&gt;
&lt;p&gt;As far as we know, there are three fundamental theories that,
combined, explain the universe as we know it: &lt;a href="https://en.wikipedia.org/wiki/General_relativity"&gt;general
relativity&lt;/a&gt;,
&lt;a href="https://en.wikipedia.org/wiki/Quantum_mechanics"&gt;quantum mechanics&lt;/a&gt;,
and
&lt;a href="https://en.wikipedia.org/wiki/Thermodynamics"&gt;thermodynamics&lt;/a&gt;. Thermodynamics
has a famous &lt;a href="https://en.wikipedia.org/wiki/Second_law_of_thermodynamics"&gt;Second
Law&lt;/a&gt; that
can be stated in various ways — in one modern and simplified form, we
say:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The total entropy of a system never decreases.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;“Entropy,” in this context, is &lt;a href="https://openstax.org/books/physics/pages/12-3-second-law-of-thermodynamics-entropy"&gt;essentially the degree to which the
system is
disorderly&lt;/a&gt;.
In effect, the Second Law states that any system can stay just as
orderly as it is now, or it can become more disorderly, but in can
never again become as orderly as it once was. &lt;strong&gt;The normal state of
the world is that things keep getting more and more disorderly.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There are multiple classic examples of this: you can mix two paints in
a bucket but cannot unmix them, you can open a container of gas in a
vacuum chamber and the gas will disperse but never go back into the
container, you can scramble and cook and egg but never return it to
its original protein structure.&lt;/p&gt;
&lt;p&gt;Sometimes the growth in entropy isn’t noticeable: you can of course
pick up your cluttered desk and put everything neatly away in boxes or
drawers (or the trash), and your office will look nice and clean and
uncluttered thereafter. But, in the process you will have turned so
much of your body’s energy into heat that the overall disorder in the
“system” (consisting of the things in your office, the room, you, all
the gas molecules in the air, and so forth) will have gone up quite
considerably.&lt;/p&gt;
&lt;p&gt;Now, I realize that not all laws of physics can be directly applied on
a macro scale, that is, to organizations, families, or societies. For
example, you’ll have to go through various mind-bends to imagine your
life as a path through gazillions of &lt;a href="https://en.wikipedia.org/wiki/Many-worlds_interpretation"&gt;Everettian many-worlds
bifurcations&lt;/a&gt;.
But I’d posit that the constant growth of entropy is indeed rather
fundamental — after all, growth in entropy is one of our best
definitions of the &lt;a href="https://en.wikipedia.org/wiki/Arrow_of_time#Thermodynamic_arrow_of_time"&gt;passage of
time&lt;/a&gt;.
Escaping the growth of entropy is literally just as impossible as
stopping time.&lt;/p&gt;
&lt;p&gt;What does that mean for each of us, individually? It means, bluntly
speaking, that our lives get objectively and perpetually messier over
time. I don’t know if you’re in a better or worse place than you were
10 or 20 years ago in your life, but I’m pretty sure that you’re in a
more &lt;em&gt;complicated&lt;/em&gt; place now. And many of us might probably &lt;em&gt;want&lt;/em&gt; to
go back to our less-complicated life from back then, but alas,
backwards time travel (and hence entropy reduction, read: “a more
orderly life”) is not an option.&lt;/p&gt;
&lt;p&gt;Now as long as you’re just trying (and failing) to rewind disorder in
your own life, then — as long as you live and work alone — that will
probably not have a harmful effect on anyone. But it gets tricky when
you’re applying the same thinking to living with a spouse, or in a
family. Good luck trying to rewind your life with teenage offspring,
for example, to the presumably simpler time when they were three month
old babies that slept most of the day.&lt;/p&gt;
&lt;p&gt;But let’s also talk about how this affects your work in a management
position.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If you are a manager, it is your job to slow the growth of disorder
in your part of the organization.&lt;/strong&gt; You won’t be able to &lt;em&gt;reduce&lt;/em&gt;
disorder, and any attempt to do so pits you against a most fundamental
law of physics. (Laws of physics are like terrorists: you shouldn’t
attempt to negotiate with them.) However, many managers are exactly
the opposite: they are entropy accelerators; they &lt;em&gt;speed up&lt;/em&gt; the
growth of disorder in the organization.&lt;/p&gt;
&lt;p&gt;You can do better than that.&lt;sup id="fnref:hadfield"&gt;&lt;a class="footnote-ref" href="#fn:hadfield"&gt;1&lt;/a&gt;&lt;/sup&gt; Here are a few suggestions you
can apply when dealing with your management peers, so you can act as
your organization’s entropy decelerator.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Somebody wants to replace multiple existing things with one new
  thing (the original xkcd 927 scenario): the only circumstance under
  which you should agree to this is when you already know &lt;em&gt;for
  certain&lt;/em&gt; that the existing things must go away, within a manageable
  timeframe. For example, the software solutions that your company has
  been buying from one vendor have had such a massive price hike that
  they now break the budget, or the legal ramifications of continuing
  to use them have become untenable. That’s when you have an option of
  possibly replacing two (or three) things with one. Under all other
  circumstances, you can hope to replace one thing with one other, at
  best.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Somebody wants to solve a communications issue by adding more
  channels to your company chat, more categories to your issue
  tracker, more whatever? That’s your cue to stop that dead in its
  tracks. Opening more lanes of communication never simplifies
  anything; it always makes things more complicated. Those new chat
  channels? Tit for tat. They want three new ones, so they must retire
  three. No, not two. Three.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Somebody wants to “open up team communications”, or “flatten the
  organization”, so that everyone’s &lt;a href="%7Bfilename%7Dflat-org-scaling.md"&gt;complete
  graph&lt;/a&gt; has way more edges?
  That’s when you educate them about &lt;span class="math"&gt;\({n(n-1)}\over 2\)&lt;/span&gt;, and what
  quadratic growth means.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Do you notice how &lt;strong&gt;a lot of these involve saying “no” to someone,&lt;/strong&gt;
and that that may place you at odds with the the well-meaning
proponent? Congratulations on your realization that leadership is not
a popularity contest among your management colleagues.&lt;/p&gt;
&lt;p&gt;One word of caution though: even if you fight this good fight — and
trust me, it &lt;em&gt;is&lt;/em&gt; a good fight — you will &lt;em&gt;still&lt;/em&gt; occasionally look
back at when you started working in your organization, and realize
that despite all your efforts it’s a messier place than when you
started. Not just the whole organization, but maybe even your own team
or whatever your little corner of the corporate world is. The part
where &lt;em&gt;you&lt;/em&gt; are responsible for your part of the mess.&lt;/p&gt;
&lt;p&gt;This is especially true if you are just in the middle of leaving an
organization (or a role therein), and are reflecting on the impact of
your tenure: you might fall for the thought of “I tried really hard,
but things still are messier than when I got here.” They always will
be. The point is not to compare today’s degree of disorder to that
when you started. The point is to compare how disorderly it is now, to
how disorderly it would have been if you hadn’t been there.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:hadfield"&gt;
&lt;p&gt;Making a positive contribution to a group in a leadership
role is frequently — and somewhat counter-intuitively — achieved
by simply focusing on not making things worse for
everyone. Canadian astronaut and former
&lt;a href="https://en.wikipedia.org/wiki/International_Space_Station"&gt;ISS&lt;/a&gt;
commander &lt;a href="https://en.wikipedia.org/wiki/Chris_Hadfield"&gt;Chris
Hadfield&lt;/a&gt; calls this
approach “aiming to be a zero” and dedicates a whole chapter in
his excellent &lt;a href="https://www.goodreads.com/book/show/18170143-an-astronaut-s-guide-to-life-on-earth"&gt;Astronaut’s Guide to Life on
Earth&lt;/a&gt;
to this idea. &lt;a class="footnote-backref" href="#fnref:hadfield" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="blog"></category><category term="Work"></category><category term="Communications"></category></entry><entry><title>An experiment</title><link href="https://xahteiwi.eu/blog/2022/05/06/experiment/" rel="alternate"></link><published>2022-05-06T00:00:00+00:00</published><updated>2022-05-06T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2022-05-06:/blog/2022/05/06/experiment/</id><summary type="html">&lt;p&gt;I am launching a small experiment. Would you like to help?&lt;/p&gt;</summary><content type="html">&lt;p&gt;A little while back, I posted on my Twitter and Mastodon feeds&lt;sup id="fnref:crossposter"&gt;&lt;a class="footnote-ref" href="#fn:crossposter"&gt;1&lt;/a&gt;&lt;/sup&gt;
asking people who kept a personal blog to post their RSS or Atom feed
URLs. A surprising number of people responded — many more on Mastodon
than on Twitter, incidentally, though I have about 15 times as many
Twitter as Mastodon followers. You can find the Twitter thread
&lt;a href="https://twitter.com/xahteiwi/status/1515233714162356224"&gt;here&lt;/a&gt; and the
Mastodon thread
&lt;a href="https://mastodon.social/@xahteiwi/108140619829880299"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I now have a very decent aggregated feed, thanks to all who responded!&lt;/p&gt;
&lt;p&gt;Now, normally, when I put a new post out, I chuck out a link to the
post on those two social networks. For some time, I’d like to do
something different, and if you’re inclined, you can help!&lt;/p&gt;
&lt;p&gt;So what I’d ask you to do is subscribe to the &lt;a href="/feeds/all.rss.xml"&gt;RSS
feed&lt;/a&gt; or the &lt;a href="/feeds/all.atom.xml"&gt;Atom feed&lt;/a&gt; for my
site. For the next few things I post, I will &lt;strong&gt;not&lt;/strong&gt; link them on
Twitter or Mastodon — but if you notice them in your feed and find them
share-worthy, I would very much appreciate if &lt;em&gt;you&lt;/em&gt; posted them there.&lt;sup id="fnref:analytics"&gt;&lt;a class="footnote-ref" href="#fn:analytics"&gt;2&lt;/a&gt;&lt;/sup&gt;
Feel free to tag me in them, I’m &lt;code&gt;@xahteiwi&lt;/code&gt; on Twitter and
&lt;code&gt;@xahteiwi@mastodon.social&lt;/code&gt; on Mastodon.&lt;/p&gt;
&lt;p&gt;I’d be really curious to see if it’s feasible in 2022 to reach blog
readers with essentially just an RSS feed, and word-of-mouth.&lt;/p&gt;
&lt;p&gt;So, if you would like to participate, then just add my feed to your
reader, and keep your eyes peeled for the next few articles. Thank you!&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:crossposter"&gt;
&lt;p&gt;If you’re curious about these things: I use &lt;a href="https://lond.com.br/"&gt;Renato
  Cerqueira&lt;/a&gt;’s &lt;a href="https://crossposter.masto.donte.com.br/"&gt;Mastodon Twitter
  Crossposter&lt;/a&gt; to mirror my
  Twitter feed to Mastodon, and vice versa. You can take a look at its
  &lt;a href="https://github.com/renatolond/mastodon-twitter-poster"&gt;GitHub
  project&lt;/a&gt;. &lt;a class="footnote-backref" href="#fnref:crossposter" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:analytics"&gt;
&lt;p&gt;I don’t want to run Google Analytics on this site out of
  concern for your privacy, which is why I don't know where my traffic
  comes from. If you post them and tag me, I have something
  functionally approaching a pingback beacon. &lt;a class="footnote-backref" href="#fnref:analytics" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="blog"></category></entry><entry><title>This site now lives on GitHub</title><link href="https://xahteiwi.eu/blog/2022/05/05/moving-to-github/" rel="alternate"></link><published>2022-05-05T00:00:00+00:00</published><updated>2022-05-05T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2022-05-05:/blog/2022/05/05/moving-to-github/</id><summary type="html">&lt;p&gt;I have moved my site to GitHub Pages. Here's what that means.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I have moved this site to GitHub. It's still available under the same
URL, of course, but it uses &lt;a href="https://pages.github.com/"&gt;GitHub Pages&lt;/a&gt;
for hosting.&lt;/p&gt;
&lt;p&gt;Why did I do this? A few reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;I don't have a &lt;a href="https://xahteiwi.eu/comments/"&gt;comment facility&lt;/a&gt;
  on this site, and I don't intend to add one, but I do want to give
  people the ability to submit corrections or sugggestions. You can do
  that now, by &lt;a href="https://github.com/fghaas/fghaas.github.io/issues"&gt;creating a GitHub
  issue&lt;/a&gt;, sending
  me a pull request, or doing a &lt;a href="https://docs.github.com/en/repositories/working-with-files/managing-files/editing-files"&gt;GitHub
  edit&lt;/a&gt;
  (which is really just a streamlined way of sending a PR from your
  browser).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It gives me the option to use a GitHub Actions workflow to deploy
  the site fully automatically. As you may know I build this site with
  &lt;a href="https://docs.getpelican.com/"&gt;Pelican&lt;/a&gt;, and wiring up a workflow
  that first sets off a Pelican build and then invokes &lt;code&gt;ghp-import&lt;/code&gt;
  (via &lt;code&gt;tox&lt;/code&gt;) was a breeze. You're welcome to &lt;a href="https://github.com/fghaas/fghaas.github.io/blob/main/.github/workflows/deploy.yml"&gt;take a look at the
  implementation&lt;/a&gt;
  if you like. (You can also look at &lt;a href="https://docs.getpelican.com/en/latest/tips.html#publishing-to-github"&gt;the relevant
  section&lt;/a&gt;
  in the Pelican docs, of course.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Overall, this gives me the ability to do quick edits from almost
  anywhere, and also gives someone else (like you!) the ability to
  suggest fixes, which I can then apply almost instantaneously. But
  please don't &lt;em&gt;expect&lt;/em&gt; any such things; I do maintain this site on a
  "when I get around to it" basis.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In short: if you've used this site as a regular or irregular
visitor/reader, not much will change. If however you wanted to chuck
in the occasional fix or correction, you can do that more easily now.&lt;/p&gt;
&lt;p&gt;If at any point I find that GitHub Pages hosting isn't the right thing
to after all, I'll happily rehome the site elsewhere.&lt;/p&gt;
&lt;p&gt;Please be advised that this is still my site, though, and I maintain
editorial control of all content. If you're sending me a PR, please do
so with the understanding that I might decline to merge or publish it,
for any reason at all. If that's not for you, please use your own
platform.&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>The Review Review</title><link href="https://xahteiwi.eu/./blog/2022/01/29/review-review/" rel="alternate"></link><published>2022-01-29T00:00:00+00:00</published><updated>2022-01-29T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2022-01-29:/./blog/2022/01/29/review-review/</id><summary type="html">&lt;p&gt;Musings on source code management, code review, testing, deployment, and collaboration culture.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I wanted to share a few thoughts on something I consider a rather
important topic in our industry: code review and CI/CD tools, and how
they relate.&lt;/p&gt;
&lt;p&gt;This means that I'm talking about&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;source code management:&lt;/strong&gt; where we store our code, and how we
  manage access to it;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;code review:&lt;/strong&gt; how we coordinate changes to our code;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;testing and gating:&lt;/strong&gt; how we make sure that those changes don’t
  break anything;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;deployment:&lt;/strong&gt; how we push changes and updates out to the consumers
  of our code.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In case it’s not obvious, that means I’m talking about a large
fraction of the software engineering cycle. Not all of it; the part
involving “fooling around” (&lt;a href="https://xahteiwi.eu/blog/2021/11/21/creativity/"&gt;creative play&lt;/a&gt;)
is perhaps excluded — but substantially everything where people can be
said to be “developing” in a software engineering organization is
encompassed in these things.&lt;/p&gt;
&lt;p&gt;And there’s a few things that follow from that:&lt;/p&gt;
&lt;p&gt;First, whatever tools we use in order to accomplish these four things,
they simultaneously influence and &lt;em&gt;are&lt;/em&gt; influenced by our
collaboration culture.&lt;/p&gt;
&lt;p&gt;It's ludicrous to presume that tools and culture are independent of
each other, or to categorically declare that tools must be made to fit
processes, not the other way around. That’s not how people
work. Culture and tools always have an influence on each other.&lt;/p&gt;
&lt;p&gt;Second, the scope of these things is continually expanding as the
field evolves. To illustrate, a few years ago a CI/CD platform could
get away with supporting automated unit tests and kicking off an
Ansible playbook to deploy things to VMs. Today, what we expect out of
a continuous deployment pipeline includes support for&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a package registry (for Python packages or Node.js modules, to give
  just two examples),&lt;/li&gt;
&lt;li&gt;a container image registry (for Docker/Podman/OCI containers),&lt;/li&gt;
&lt;li&gt;a secret store,&lt;/li&gt;
&lt;li&gt;the ability to deploy to a Kubernetes cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And that’s just a few examples. I might be forgetting others.&lt;/p&gt;
&lt;p&gt;Third, this is a classic example of where we must apply &lt;em&gt;&lt;a href="https://youtu.be/EbLh7rZ3rhU"&gt;systems
thinking&lt;/a&gt;:&lt;/em&gt; since substantially
everything the organization does is connected to the toolchain, we
&lt;strong&gt;cannot make changes to one part of the system without considering
the consequences for the system as a whole.&lt;/strong&gt; That is not to say that
we cannot make incremental changes, just that we can’t pretend that
anything in the system stands alone.&lt;/p&gt;
&lt;p&gt;To illustrate what I mean, consider the example of an automotive
engineer implementing a design change for an engine. If the design
change makes the engine so much more efficient that it means a range
extension by 10% then that’s excellent. But if in the process the
designer has made it impossible to connect the engine to its battery
(or the fuel line, if we’re talking about obsolescent technology),
then installing the new engine doesn’t just not improve anything — it
renders the vehicle immobile.&lt;/p&gt;
&lt;h2&gt;Responsibility&lt;/h2&gt;
&lt;!-- Note --&gt;
&lt;p&gt;Now, what does that mean about responsibility? Who is ultimately in
charge of the system consisting of source code management and review
tools, and your CI/CD pipeline? The answer is hopefully a no-brainer:
since everything I talk about &lt;em&gt;including&lt;/em&gt; your organizational culture
encompasses substantially all of your engineering organization, the
responsibility rests with whoever is in charge of your engineering
organization (in most companies, that’s often the CTO). And if you’re
a software technology company so your &lt;em&gt;entire&lt;/em&gt; enterprise is
substantially a software engineering organization, it’s your CEO’s or
MD’s responsibility.&lt;/p&gt;
&lt;p&gt;Of course, that person may delegate some of the &lt;em&gt;tasks&lt;/em&gt; and details of
running your source code management and code review and CI/CD
platform, but &lt;em&gt;responsibility&lt;/em&gt; stays with them.&lt;/p&gt;
&lt;p&gt;And that responsibility requires both an understanding &lt;a href="https://xahteiwi.eu/blog/2019/04/21/non-technical/"&gt;of the
technology itself&lt;/a&gt;, &lt;em&gt;and&lt;/em&gt; an understanding
of how it interacts with your engineering culture. A &lt;em&gt;profound&lt;/em&gt;
understanding. &lt;/p&gt;
&lt;p&gt;And I’d go so far as to say if you head up a software engineering
organization and you &lt;em&gt;don’t&lt;/em&gt; have a profound understanding of this
toolchain and its mutual influence on your culture, you should find
another job.&lt;/p&gt;
&lt;p&gt;And if you work &lt;em&gt;in&lt;/em&gt; a software engineering organization and the
person in charge lacks precisely that profound understanding, you
should &lt;em&gt;also&lt;/em&gt; find another job, because you deserve better.&lt;/p&gt;
&lt;p&gt;So having said all that, we can start talking about tools.&lt;/p&gt;
&lt;p&gt;And I’m going to talk about three of them, all of which I use in some
professional capacity on an at-least-weekly basis.&lt;/p&gt;
&lt;!-- .slide: data-timing="20" --&gt;
&lt;h1&gt;GitHub&lt;/h1&gt;
&lt;p&gt;The first one is the toolchain that — I think — a majority of open
source developers will be most familiar with: GitHub, whose
collaboration model is based on the &lt;em&gt;Pull Request&lt;/em&gt; (PR).&lt;/p&gt;
&lt;p&gt;Now the GitHub PR model was strongly influenced by the distributed
development model of the Linux kernel. The kernel project is what Git
was originally written for, so naturally it is also where the original
convention for pull requests emerged.&lt;/p&gt;
&lt;p&gt;In kernel development, during a kernel merge window, subsystem
maintainers fix up a publicly accessible Git tree for Linus to pull
from. They then send a message that follows a conventional format to
the &lt;code&gt;linux-kernel&lt;/code&gt; mailing list (the LKML) outlining the purpose of
the changes they want merged. This email contains a summary of the
changes, and then an enumeration of each commit to be merged. (There’s
a &lt;code&gt;git&lt;/code&gt; subcommand, &lt;code&gt;git request-pull&lt;/code&gt;, to format such a message.)&lt;/p&gt;
&lt;p&gt;The review then proceeds in an email exchange on LKML. Once Linus is
happy with the change, he pulls from the subsystem maintainer’s branch
and informs them that their changes have merged.&lt;/p&gt;
&lt;p&gt;Individual subsystem maintainers replicate this model, perhaps with
small modifications, for contributions to the subsystems they are
responsible for.&lt;/p&gt;
&lt;h2&gt;GitHub Pull Requests (PRs)&lt;/h2&gt;
&lt;p&gt;GitHub replicates some features of the kernel’s model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The collaboration model is generally, “fork and pull”. Individuals
  maintain their own forks of an upstream codebase, and then send pull
  requests when they are ready to review. (However, the review process
  then uses a web interface, rather than a mailing list — in
  principle, a GitHub reviewer can do a complete review within the
  GitHub web interface and source code browser and would never even
  need to check out the repository locally.)&lt;/li&gt;
&lt;li&gt;Each PR generally consists of &lt;em&gt;multiple&lt;/em&gt; commits, which however are
  expected to closely relate and serve a common purpose.&lt;/li&gt;
&lt;li&gt;That common purpose is enumerated in a summary at the top of the
  pull request. GitHub calls this the PR description.&lt;/li&gt;
&lt;li&gt;Submitters can mark a PR as a draft, with which they indicate that
  the PR is not ready to be merged yet. When drafts &lt;a href="https://github.blog/2019-02-14-introducing-draft-pull-requests/"&gt;became
  available&lt;/a&gt;
  in 2019, they replaced an emerging convention in which PR
  descriptions would be prefixed by &lt;code&gt;WIP&lt;/code&gt; &lt;em&gt;(work in progress)&lt;/em&gt; or
  &lt;code&gt;DNM&lt;/code&gt; &lt;em&gt;(do not merge)&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GitHub PRs can be &lt;em&gt;approved,&lt;/em&gt; &lt;em&gt;rejected&lt;/em&gt; or &lt;em&gt;commented on&lt;/em&gt; by
maintainers or other contributors, and an approval can be made a
mandatory requirement for merging, but by default GitHub will let
anyone merge the PR who has write permissions to the repository that
the PR targets. This includes the possibility for a maintainer to
merge the contributor’s remote branch to their own local checkout, and
then pushing the merged branch to he target repo of the PR. Such an
event will automatically close the PR and mark it as merged.&lt;/p&gt;
&lt;h2&gt;GitHub Actions&lt;/h2&gt;
&lt;p&gt;GitHub has, for a long time, allowed maintainers to require that PRs
pass automated testing. However, until rather recently, it relied on
them to run (or interface with) a separate testing infrastructure
outside of GitHub to do that. Typical examples for this included
CircleCI, or Travis, or Jenkins. It was only &lt;a href="https://github.blog/2019-08-08-github-actions-now-supports-ci-cd/"&gt;in
2019&lt;/a&gt;
that GitHub announced automated testing via GitHub Actions.&lt;/p&gt;
&lt;p&gt;At the time of writing however, GitHub Actions workflows are in
widespread use for CI/CD, &lt;em&gt;but&lt;/em&gt; it is still quite common for
GitHub-hosted projects to allow maintainers to circumvent CI/CD tests
and merge directly. When this happens, it often creates a rather
unpleasant situation in which CI/CD testing is only run for
contributions by “outsiders” or “newbies”, whereas maintainers get to
break things with impunity. This means that issues are often not
detected until a casual contributor sends a PR, at which point the
test breaks and leave the contributor confused (and sometimes lead to
the change not even being considered because, well, “it makes the
tests break.”)&lt;/p&gt;
&lt;p&gt;Another thing that comes bundled with GitHub (and GitHub workflow
actions) is the ability to maintain your own package registry &lt;a href="https://docs.github.com/en/packages/managing-github-packages-using-github-actions-workflows/publishing-and-installing-a-package-with-github-actions"&gt;and
push artifacts to it from your
workflow&lt;/a&gt;. Interestingly,
at the time of writing, GitHub’s definition of “packages” includes
container images, Ruby gems, and npm modules &lt;a href="https://docs.github.com/en/packages/working-with-a-github-packages-registry"&gt;among
others&lt;/a&gt;,
but presently does not include Python modules — although you do, of
course, have the option to &lt;a href="https://github.com/marketplace/actions/pypi-publish"&gt;push your packages to PyPI from your
workflow&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;GitLab&lt;/h1&gt;
&lt;p&gt;The equivalent to the GitHub &lt;em&gt;pull request (PR)&lt;/em&gt; is the GitLab &lt;em&gt;merge
request (MR)&lt;/em&gt;. In principle, a GitLab MR is quite similar to a GitHub
PR, albeit with a few noticeable differences:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The “fork and pull” model is less prevalent on GitLab. Instead, it
  is far more common for collaborators to work on one project, and
  then create topic branches within that project for each set of
  changes.&lt;/li&gt;
&lt;li&gt;Since the project repo is shared, this facilitates collaboration on
  a single changeset by multiple people: if two or more people wish to
  collaborate on a change, they simply push additional squash or fixup
  commits on the topic branch. They can &lt;em&gt;also&lt;/em&gt; agree to force-push
  amended commits to the topic branch, in which the GitLab web
  interface will helpfully point out differences between individual
  &lt;em&gt;versions&lt;/em&gt; of a commit (something that GitHub presently cannot do in
  a PR).&lt;/li&gt;
&lt;li&gt;As in a GitHub PR, a GitLab MR is generally expected to include one
  or more commits.&lt;/li&gt;
&lt;li&gt;Also as in a GitHub PR, an MR is expected to contain a summary that
  outlines its purpose.&lt;/li&gt;
&lt;li&gt;GitLab MRs have a Draft status just like GitHub PRs do, and they
  were introduced about the same time in both products, but GitLab had
  a preceding feature called work-in-progress MRs (WIP MRs). GitLab
  has the handy feature that MRs are &lt;em&gt;automatically&lt;/em&gt; marked as drafts
  once any commit with &lt;code&gt;squash:&lt;/code&gt; or &lt;code&gt;fixup:&lt;/code&gt; in the commit message
  ends up in the topic branch — GitLab rightfully infers that the
  branch still needs a squash rebase prior to merge.&lt;/li&gt;
&lt;li&gt;GitLab MRs can be reviewed in full using the web interface alone:
  the review interface and the source code browser are closely
  integrated, just like in GitHub.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;GitLab CI&lt;/h2&gt;
&lt;p&gt;CI/CD has been an intrinsic part of the GitLab review
experience for years, since GitLab includes full CI integration via
the &lt;code&gt;.gitlab-ci.yml&lt;/code&gt; configuration file.&lt;/p&gt;
&lt;p&gt;Since GitLab CI has been around for quite a while, and it has a
multitude of ways to be used, it “feels” more intrinsic to the review
process than GitHub Actions do, which to me still leave an impression
of being bolted on. In addition, GitLab CI comes with multiple options
of using the CI &lt;em&gt;runner:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You can use &lt;em&gt;shared runners,&lt;/em&gt; which GitLab operates for you. These
  are Docker containers that GitLab spins up on your behalf in the
  cloud, and which you share with other GitLab subscription customers.&lt;/li&gt;
&lt;li&gt;You can also host your own runners. You can do that in Docker
  containers, in Kubernetes clusters, in virtual machines, and even on
  bare metal. The runners need no incoming network connectivity; they
  simply connect to a service on your GitLab host and then poll
  whether jobs wait for them.&lt;/li&gt;
&lt;li&gt;You can also specify runners that are exclusive to a project, or to
  a group or subgroup of projects.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GitLab also comes with a &lt;a href="https://docs.gitlab.com/ee/user/packages/package_registry/"&gt;package
registry&lt;/a&gt;,
to which you can push packages from CI pipelines. This differs from
GitHub in such a way that it &lt;a href="https://docs.gitlab.com/ee/user/packages/package_registry/#supported-package-managers"&gt;includes more package different
formats&lt;/a&gt;,
including a private PyPI workalike for Python packages. In addition,
there’s also a separate &lt;a href="https://docs.gitlab.com/ee/user/packages/container_registry/"&gt;container
registry&lt;/a&gt;
for container images.&lt;/p&gt;
&lt;h1&gt;Gerrit/Zuul&lt;/h1&gt;
&lt;p&gt;Now, it feels a bit awkward to call this one “Gerrit/Zuul” when I’ve
called the others just “GitHub” and “GitLab” respectively, and tacitly
included the corresponding CI integrations (GitHub Actions and GitLab
CI, respectively) in them. There are a couple of reasons for that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Zuul is a CI/CD framework that is, in principle, not tied to Gerrit,
  whereas GitHub Actions only apply to GitHub, and GitLab CI only to
  GitLab. Gerrit/Zuul is a particular combination that was largely
  popularized by the OpenStack community, which is why a lot of people
  who are or were part of that community intuitively associate Gerrit
  with Zuul and vice versa.
  &lt;!-- It should be noted that Zuul was not the original CI/CD framework in
  the OpenStack community. It was *developed* (and adopted) by that
  community when it found that it was outgrowing the boundaries of its
  original CI/CD platform (Jenkins). --&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Likewise, Gerrit is not tied to a specific CI/CD framework. It’s
  perfectly feasible to run code reviews in Gerrit and use a different
  CI/CD pipeline (or even none at all).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And Gerrit/Zuul does differ quite notably from GitHub and GitLab,
whose features often map quite closely to each other, and I’d like to
highlight some of those differences.&lt;/p&gt;
&lt;h2&gt;Gerrit reviews&lt;/h2&gt;
&lt;p&gt;The Gerrit review process differs in a few crucial points from the one
we know from GitHub and GitLab:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;You don’t ask someone to pull from a branch or a fork or
  yours. Instead, you run &lt;code&gt;git review&lt;/code&gt; and Gerrit will &lt;em&gt;make a branch
  for you.&lt;/em&gt; Everything else flows from there.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Unlike a GitHub PR and GitLab MR, which both typically contain a
  series of commits to be taken as a whole, a Gerrit &lt;em&gt;change&lt;/em&gt; is
  really just that: one change. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Which, of course, also means that we don’t need a separate summary
  for the change: the summary is the commit message.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It’s still possible to submit a series of commits in the course of a
  Gerrit review. However, Gerrit simply sees those as a series of
  changes that all depend on one another.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dependencies between changes can also be expressed explicitly, by
  including appropriate keywords in commit messages. Crucially, these
  dependencies &lt;em&gt;can cross project boundaries.&lt;/em&gt; That is to say, a
  change in one Git repository can depend on a change in &lt;em&gt;another&lt;/em&gt; Git
  repository, so long as they both use the same Gerrit instance for
  review.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;And we also have the equivalent of a Draft PR/MR; in Gerrit that’s
  called a work-in-progress change.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Because of this, when used in combination with CI such as Zuul, a
Gerrit-reviewed project generally expects CI tests to pass &lt;em&gt;on every
commit,&lt;/em&gt; without exceptions. This is in contrast to many GitHub or
GitLab managed projects, which typically only expect the head commit
of the topic branch associated with a PR/MR to pass CI.&lt;/p&gt;
&lt;p&gt;In Gerrit/Zuul managed projects, it’s also Zuul that merges the
commit. This is also in contrast to projects that live in GitHub or
GitLab: in those, the pipeline run results are generally advisory in
nature, and a successful pipeline run must still be confirmed by a
human clicking a &lt;em&gt;Merge&lt;/em&gt; button (or running a &lt;code&gt;git merge&lt;/code&gt; command
locally, and then pushing to the repository). In addition, even a
failing CI run can generally be overridden by a “core committer” who
has the ability to merge the PR/MR anyway.&lt;/p&gt;
&lt;p&gt;A Gerrit/Zuul project typically has no such shortcuts, meaning the
&lt;em&gt;only&lt;/em&gt; way to get changes into the repo is to pass both peer review,
and the CI pipeline. In my experience, this tends to create a climate
of leadership by example, which has a beneficial effect on both
experienced developers (“seniors” in a corporate setting) and
newcomers (“juniors”).&lt;/p&gt;
&lt;h3&gt;Speculative merging&lt;/h3&gt;
&lt;p&gt;There is one other property that Gerrit/Zuul has that sets it apart
from other review/CI toolchains: &lt;em&gt;speculative merging.&lt;/em&gt; This involves
the &lt;a href="https://zuul-ci.org/docs/zuul/3.10.2/user/gating.html#testing-in-parallel"&gt;parallel execution of CI jobs for interdependent
changes&lt;/a&gt;. With
speculative merging, even complex, long-running CI/CD pipelines don’t
hold up the development process — and this massively enhances project
scalability.&lt;/p&gt;
&lt;h3&gt;No direct repo browser integration&lt;/h3&gt;
&lt;p&gt;Notably, in Gerrit/Zuul there is no close integration with repository
browsing. Gerrit does include the
&lt;a href="https://gerrit.googlesource.com/gitiles/"&gt;Gitiles&lt;/a&gt; plugin for the
purpose, but its user experience is rudimentary at best. A popular
alternative is to deploy Gerrit with &lt;a href="https://gitea.io/en-us/"&gt;Gitea&lt;/a&gt;,
but again, that’s not built-in and your trusted Gerrit/Zuul admin has
to set it up for you. In addition, while source code browsing in
GitHub and GitLab is tightly integrated with project permissions, and
that is also true for Gitiles, there is a certain amount of
administrative duplication to make your Gerrit repository and project
permissions apply to Gitea.&lt;/p&gt;
&lt;h3&gt;No built-in package registries&lt;/h3&gt;
&lt;p&gt;There’s another difference in the Gerrit/Zuul stack when compared to
GitHub and GitLab, and that is its absence of built-in package
registries. Zuul has ready-to-use &lt;em&gt;jobs&lt;/em&gt; for &lt;a href="https://zuul-ci.org/docs/zuul-jobs/docker-image.html"&gt;pushing to a container
registry&lt;/a&gt;, or to
&lt;a href="https://zuul-ci.org/docs/zuul-jobs/python-jobs.html#job-python-upload-pypi"&gt;PyPI&lt;/a&gt;,
but you do have to either push to upstream public registries, or build
your own. Zuul does not come bundled with multitenant private
registries the way GitHub and GitLab do.&lt;/p&gt;
&lt;h3&gt;Administrative complexity&lt;/h3&gt;
&lt;p&gt;In view of the above, there's another thing that you might want to
consider, which in my humble opinion is an important reason why the
Gerrit/Zuul combination has less uptake than it deserves on its
technical merits. And this may sound overly dramatic, but: people like
to be in charge of their own actions, and software developers are
people. And here’s an issue with Zuul: there are quite a few things a
developer can do on their own in GitHub Actions or GitLab CI that
they’d need to ask an admin’s help for in Zuul.&lt;/p&gt;
&lt;p&gt;Creating a relatively standard workflow of building a private
container image, pushing it to your own registry, and then rolling out
that image to a Kubernetes deployment, is something you can do in
GitHub or GitLab as a project owner. With Zuul, you’ll need an admin
at least to set up and manage your container registry. Rerunning a
pipeline, a simple click of a button or API call in GitHub or GitLab,
is something you trigger via a Gerrit keyword (typically &lt;code&gt;recheck&lt;/code&gt;)
for Zuul — but only on the pipelines where &lt;a href="https://zuul-ci.org/docs/zuul/3.11.0/admin/drivers/gerrit.html#reference-pipelines-configuration"&gt;your admin has defined
that
trigger&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;So, which one’s best?&lt;/h1&gt;
&lt;p&gt;So you want to know which one of these &lt;em&gt;you&lt;/em&gt; should choose (or
advocate for)? That’s surprisingly difficult to answer, and greatly
depends on your priorities. And I’ll give you this from four angles.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;When it comes to &lt;em&gt;scalability&lt;/em&gt; — the ability to adapt to massive
  organizational sizes, and/or rapid project growth, or an obscenely
  large number or projects within an organization — the Gerrit/Zuul
  combination wins hands down &lt;strong&gt;if&lt;/strong&gt; you have a competent, responsive,
  and dedicated crew to manage it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When it’s about &lt;em&gt;getting started quickly&lt;/em&gt; — helping a project get
  off the ground with a good, usable, easily manageable review and
  fully integrated CI/CD structure — you can’t beat GitLab.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In terms of &lt;em&gt;beneficial effect on your development culture,&lt;/em&gt;
  Gerrit/Zuul again probably scores best. If you have a team that’s
  great at reviews and commit and CI and doesn’t cut corners, or you
  want to build a team like that, Gerrit/Zuul can really help.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;And when it’s about &lt;em&gt;giving developers the lowest barrier to entry&lt;/em&gt;
  — meaning using tools that they’re most likely already familiar with
  — GitHub is your platform of choice.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</content><category term="blog"></category><category term="Work"></category><category term="CI"></category><category term="Gerrit"></category><category term="GitLab"></category><category term="GitHub"></category><category term="Zuul"></category></entry><entry><title>The Review Review</title><link href="https://xahteiwi.eu/./blog/2022/01/29/review-review/" rel="alternate"></link><published>2022-01-29T00:00:00+00:00</published><updated>2022-01-29T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2022-01-29:/./blog/2022/01/29/review-review/</id><summary type="html">&lt;p&gt;Musings on source code management, code review, testing, deployment, and collaboration culture.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I wanted to share a few thoughts on something I consider a rather
important topic in our industry: code review and CI/CD tools, and how
they relate.&lt;/p&gt;
&lt;p&gt;This means that I'm talking about&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;source code management:&lt;/strong&gt; where we store our code, and how we
  manage access to it;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;code review:&lt;/strong&gt; how we coordinate changes to our code;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;testing and gating:&lt;/strong&gt; how we make sure that those changes don’t
  break anything;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;deployment:&lt;/strong&gt; how we push changes and updates out to the consumers
  of our code.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In case it’s not obvious, that means I’m talking about a large
fraction of the software engineering cycle. Not all of it; the part
involving “fooling around” (&lt;a href="https://xahteiwi.eu/blog/2021/11/21/creativity/"&gt;creative play&lt;/a&gt;)
is perhaps excluded — but substantially everything where people can be
said to be “developing” in a software engineering organization is
encompassed in these things.&lt;/p&gt;
&lt;p&gt;And there’s a few things that follow from that:&lt;/p&gt;
&lt;p&gt;First, whatever tools we use in order to accomplish these four things,
they simultaneously influence and &lt;em&gt;are&lt;/em&gt; influenced by our
collaboration culture.&lt;/p&gt;
&lt;p&gt;It's ludicrous to presume that tools and culture are independent of
each other, or to categorically declare that tools must be made to fit
processes, not the other way around. That’s not how people
work. Culture and tools always have an influence on each other.&lt;/p&gt;
&lt;p&gt;Second, the scope of these things is continually expanding as the
field evolves. To illustrate, a few years ago a CI/CD platform could
get away with supporting automated unit tests and kicking off an
Ansible playbook to deploy things to VMs. Today, what we expect out of
a continuous deployment pipeline includes support for&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a package registry (for Python packages or Node.js modules, to give
  just two examples),&lt;/li&gt;
&lt;li&gt;a container image registry (for Docker/Podman/OCI containers),&lt;/li&gt;
&lt;li&gt;a secret store,&lt;/li&gt;
&lt;li&gt;the ability to deploy to a Kubernetes cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And that’s just a few examples. I might be forgetting others.&lt;/p&gt;
&lt;p&gt;Third, this is a classic example of where we must apply &lt;em&gt;&lt;a href="https://youtu.be/EbLh7rZ3rhU"&gt;systems
thinking&lt;/a&gt;:&lt;/em&gt; since substantially
everything the organization does is connected to the toolchain, we
&lt;strong&gt;cannot make changes to one part of the system without considering
the consequences for the system as a whole.&lt;/strong&gt; That is not to say that
we cannot make incremental changes, just that we can’t pretend that
anything in the system stands alone.&lt;/p&gt;
&lt;p&gt;To illustrate what I mean, consider the example of an automotive
engineer implementing a design change for an engine. If the design
change makes the engine so much more efficient that it means a range
extension by 10% then that’s excellent. But if in the process the
designer has made it impossible to connect the engine to its battery
(or the fuel line, if we’re talking about obsolescent technology),
then installing the new engine doesn’t just not improve anything — it
renders the vehicle immobile.&lt;/p&gt;
&lt;h2&gt;Responsibility&lt;/h2&gt;
&lt;!-- Note --&gt;
&lt;p&gt;Now, what does that mean about responsibility? Who is ultimately in
charge of the system consisting of source code management and review
tools, and your CI/CD pipeline? The answer is hopefully a no-brainer:
since everything I talk about &lt;em&gt;including&lt;/em&gt; your organizational culture
encompasses substantially all of your engineering organization, the
responsibility rests with whoever is in charge of your engineering
organization (in most companies, that’s often the CTO). And if you’re
a software technology company so your &lt;em&gt;entire&lt;/em&gt; enterprise is
substantially a software engineering organization, it’s your CEO’s or
MD’s responsibility.&lt;/p&gt;
&lt;p&gt;Of course, that person may delegate some of the &lt;em&gt;tasks&lt;/em&gt; and details of
running your source code management and code review and CI/CD
platform, but &lt;em&gt;responsibility&lt;/em&gt; stays with them.&lt;/p&gt;
&lt;p&gt;And that responsibility requires both an understanding &lt;a href="https://xahteiwi.eu/blog/2019/04/21/non-technical/"&gt;of the
technology itself&lt;/a&gt;, &lt;em&gt;and&lt;/em&gt; an understanding
of how it interacts with your engineering culture. A &lt;em&gt;profound&lt;/em&gt;
understanding. &lt;/p&gt;
&lt;p&gt;And I’d go so far as to say if you head up a software engineering
organization and you &lt;em&gt;don’t&lt;/em&gt; have a profound understanding of this
toolchain and its mutual influence on your culture, you should find
another job.&lt;/p&gt;
&lt;p&gt;And if you work &lt;em&gt;in&lt;/em&gt; a software engineering organization and the
person in charge lacks precisely that profound understanding, you
should &lt;em&gt;also&lt;/em&gt; find another job, because you deserve better.&lt;/p&gt;
&lt;p&gt;So having said all that, we can start talking about tools.&lt;/p&gt;
&lt;p&gt;And I’m going to talk about three of them, all of which I use in some
professional capacity on an at-least-weekly basis.&lt;/p&gt;
&lt;!-- .slide: data-timing="20" --&gt;
&lt;h1&gt;GitHub&lt;/h1&gt;
&lt;p&gt;The first one is the toolchain that — I think — a majority of open
source developers will be most familiar with: GitHub, whose
collaboration model is based on the &lt;em&gt;Pull Request&lt;/em&gt; (PR).&lt;/p&gt;
&lt;p&gt;Now the GitHub PR model was strongly influenced by the distributed
development model of the Linux kernel. The kernel project is what Git
was originally written for, so naturally it is also where the original
convention for pull requests emerged.&lt;/p&gt;
&lt;p&gt;In kernel development, during a kernel merge window, subsystem
maintainers fix up a publicly accessible Git tree for Linus to pull
from. They then send a message that follows a conventional format to
the &lt;code&gt;linux-kernel&lt;/code&gt; mailing list (the LKML) outlining the purpose of
the changes they want merged. This email contains a summary of the
changes, and then an enumeration of each commit to be merged. (There’s
a &lt;code&gt;git&lt;/code&gt; subcommand, &lt;code&gt;git request-pull&lt;/code&gt;, to format such a message.)&lt;/p&gt;
&lt;p&gt;The review then proceeds in an email exchange on LKML. Once Linus is
happy with the change, he pulls from the subsystem maintainer’s branch
and informs them that their changes have merged.&lt;/p&gt;
&lt;p&gt;Individual subsystem maintainers replicate this model, perhaps with
small modifications, for contributions to the subsystems they are
responsible for.&lt;/p&gt;
&lt;h2&gt;GitHub Pull Requests (PRs)&lt;/h2&gt;
&lt;p&gt;GitHub replicates some features of the kernel’s model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The collaboration model is generally, “fork and pull”. Individuals
  maintain their own forks of an upstream codebase, and then send pull
  requests when they are ready to review. (However, the review process
  then uses a web interface, rather than a mailing list — in
  principle, a GitHub reviewer can do a complete review within the
  GitHub web interface and source code browser and would never even
  need to check out the repository locally.)&lt;/li&gt;
&lt;li&gt;Each PR generally consists of &lt;em&gt;multiple&lt;/em&gt; commits, which however are
  expected to closely relate and serve a common purpose.&lt;/li&gt;
&lt;li&gt;That common purpose is enumerated in a summary at the top of the
  pull request. GitHub calls this the PR description.&lt;/li&gt;
&lt;li&gt;Submitters can mark a PR as a draft, with which they indicate that
  the PR is not ready to be merged yet. When drafts &lt;a href="https://github.blog/2019-02-14-introducing-draft-pull-requests/"&gt;became
  available&lt;/a&gt;
  in 2019, they replaced an emerging convention in which PR
  descriptions would be prefixed by &lt;code&gt;WIP&lt;/code&gt; &lt;em&gt;(work in progress)&lt;/em&gt; or
  &lt;code&gt;DNM&lt;/code&gt; &lt;em&gt;(do not merge)&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GitHub PRs can be &lt;em&gt;approved,&lt;/em&gt; &lt;em&gt;rejected&lt;/em&gt; or &lt;em&gt;commented on&lt;/em&gt; by
maintainers or other contributors, and an approval can be made a
mandatory requirement for merging, but by default GitHub will let
anyone merge the PR who has write permissions to the repository that
the PR targets. This includes the possibility for a maintainer to
merge the contributor’s remote branch to their own local checkout, and
then pushing the merged branch to he target repo of the PR. Such an
event will automatically close the PR and mark it as merged.&lt;/p&gt;
&lt;h2&gt;GitHub Actions&lt;/h2&gt;
&lt;p&gt;GitHub has, for a long time, allowed maintainers to require that PRs
pass automated testing. However, until rather recently, it relied on
them to run (or interface with) a separate testing infrastructure
outside of GitHub to do that. Typical examples for this included
CircleCI, or Travis, or Jenkins. It was only &lt;a href="https://github.blog/2019-08-08-github-actions-now-supports-ci-cd/"&gt;in
2019&lt;/a&gt;
that GitHub announced automated testing via GitHub Actions.&lt;/p&gt;
&lt;p&gt;At the time of writing however, GitHub Actions workflows are in
widespread use for CI/CD, &lt;em&gt;but&lt;/em&gt; it is still quite common for
GitHub-hosted projects to allow maintainers to circumvent CI/CD tests
and merge directly. When this happens, it often creates a rather
unpleasant situation in which CI/CD testing is only run for
contributions by “outsiders” or “newbies”, whereas maintainers get to
break things with impunity. This means that issues are often not
detected until a casual contributor sends a PR, at which point the
test breaks and leave the contributor confused (and sometimes lead to
the change not even being considered because, well, “it makes the
tests break.”)&lt;/p&gt;
&lt;p&gt;Another thing that comes bundled with GitHub (and GitHub workflow
actions) is the ability to maintain your own package registry &lt;a href="https://docs.github.com/en/packages/managing-github-packages-using-github-actions-workflows/publishing-and-installing-a-package-with-github-actions"&gt;and
push artifacts to it from your
workflow&lt;/a&gt;. Interestingly,
at the time of writing, GitHub’s definition of “packages” includes
container images, Ruby gems, and npm modules &lt;a href="https://docs.github.com/en/packages/working-with-a-github-packages-registry"&gt;among
others&lt;/a&gt;,
but presently does not include Python modules — although you do, of
course, have the option to &lt;a href="https://github.com/marketplace/actions/pypi-publish"&gt;push your packages to PyPI from your
workflow&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;GitLab&lt;/h1&gt;
&lt;p&gt;The equivalent to the GitHub &lt;em&gt;pull request (PR)&lt;/em&gt; is the GitLab &lt;em&gt;merge
request (MR)&lt;/em&gt;. In principle, a GitLab MR is quite similar to a GitHub
PR, albeit with a few noticeable differences:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The “fork and pull” model is less prevalent on GitLab. Instead, it
  is far more common for collaborators to work on one project, and
  then create topic branches within that project for each set of
  changes.&lt;/li&gt;
&lt;li&gt;Since the project repo is shared, this facilitates collaboration on
  a single changeset by multiple people: if two or more people wish to
  collaborate on a change, they simply push additional squash or fixup
  commits on the topic branch. They can &lt;em&gt;also&lt;/em&gt; agree to force-push
  amended commits to the topic branch, in which the GitLab web
  interface will helpfully point out differences between individual
  &lt;em&gt;versions&lt;/em&gt; of a commit (something that GitHub presently cannot do in
  a PR).&lt;/li&gt;
&lt;li&gt;As in a GitHub PR, a GitLab MR is generally expected to include one
  or more commits.&lt;/li&gt;
&lt;li&gt;Also as in a GitHub PR, an MR is expected to contain a summary that
  outlines its purpose.&lt;/li&gt;
&lt;li&gt;GitLab MRs have a Draft status just like GitHub PRs do, and they
  were introduced about the same time in both products, but GitLab had
  a preceding feature called work-in-progress MRs (WIP MRs). GitLab
  has the handy feature that MRs are &lt;em&gt;automatically&lt;/em&gt; marked as drafts
  once any commit with &lt;code&gt;squash:&lt;/code&gt; or &lt;code&gt;fixup:&lt;/code&gt; in the commit message
  ends up in the topic branch — GitLab rightfully infers that the
  branch still needs a squash rebase prior to merge.&lt;/li&gt;
&lt;li&gt;GitLab MRs can be reviewed in full using the web interface alone:
  the review interface and the source code browser are closely
  integrated, just like in GitHub.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;GitLab CI&lt;/h2&gt;
&lt;p&gt;CI/CD has been an intrinsic part of the GitLab review
experience for years, since GitLab includes full CI integration via
the &lt;code&gt;.gitlab-ci.yml&lt;/code&gt; configuration file.&lt;/p&gt;
&lt;p&gt;Since GitLab CI has been around for quite a while, and it has a
multitude of ways to be used, it “feels” more intrinsic to the review
process than GitHub Actions do, which to me still leave an impression
of being bolted on. In addition, GitLab CI comes with multiple options
of using the CI &lt;em&gt;runner:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You can use &lt;em&gt;shared runners,&lt;/em&gt; which GitLab operates for you. These
  are Docker containers that GitLab spins up on your behalf in the
  cloud, and which you share with other GitLab subscription customers.&lt;/li&gt;
&lt;li&gt;You can also host your own runners. You can do that in Docker
  containers, in Kubernetes clusters, in virtual machines, and even on
  bare metal. The runners need no incoming network connectivity; they
  simply connect to a service on your GitLab host and then poll
  whether jobs wait for them.&lt;/li&gt;
&lt;li&gt;You can also specify runners that are exclusive to a project, or to
  a group or subgroup of projects.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GitLab also comes with a &lt;a href="https://docs.gitlab.com/ee/user/packages/package_registry/"&gt;package
registry&lt;/a&gt;,
to which you can push packages from CI pipelines. This differs from
GitHub in such a way that it &lt;a href="https://docs.gitlab.com/ee/user/packages/package_registry/#supported-package-managers"&gt;includes more package different
formats&lt;/a&gt;,
including a private PyPI workalike for Python packages. In addition,
there’s also a separate &lt;a href="https://docs.gitlab.com/ee/user/packages/container_registry/"&gt;container
registry&lt;/a&gt;
for container images.&lt;/p&gt;
&lt;h1&gt;Gerrit/Zuul&lt;/h1&gt;
&lt;p&gt;Now, it feels a bit awkward to call this one “Gerrit/Zuul” when I’ve
called the others just “GitHub” and “GitLab” respectively, and tacitly
included the corresponding CI integrations (GitHub Actions and GitLab
CI, respectively) in them. There are a couple of reasons for that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Zuul is a CI/CD framework that is, in principle, not tied to Gerrit,
  whereas GitHub Actions only apply to GitHub, and GitLab CI only to
  GitLab. Gerrit/Zuul is a particular combination that was largely
  popularized by the OpenStack community, which is why a lot of people
  who are or were part of that community intuitively associate Gerrit
  with Zuul and vice versa.
  &lt;!-- It should be noted that Zuul was not the original CI/CD framework in
  the OpenStack community. It was *developed* (and adopted) by that
  community when it found that it was outgrowing the boundaries of its
  original CI/CD platform (Jenkins). --&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Likewise, Gerrit is not tied to a specific CI/CD framework. It’s
  perfectly feasible to run code reviews in Gerrit and use a different
  CI/CD pipeline (or even none at all).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And Gerrit/Zuul does differ quite notably from GitHub and GitLab,
whose features often map quite closely to each other, and I’d like to
highlight some of those differences.&lt;/p&gt;
&lt;h2&gt;Gerrit reviews&lt;/h2&gt;
&lt;p&gt;The Gerrit review process differs in a few crucial points from the one
we know from GitHub and GitLab:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;You don’t ask someone to pull from a branch or a fork or
  yours. Instead, you run &lt;code&gt;git review&lt;/code&gt; and Gerrit will &lt;em&gt;make a branch
  for you.&lt;/em&gt; Everything else flows from there.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Unlike a GitHub PR and GitLab MR, which both typically contain a
  series of commits to be taken as a whole, a Gerrit &lt;em&gt;change&lt;/em&gt; is
  really just that: one change. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Which, of course, also means that we don’t need a separate summary
  for the change: the summary is the commit message.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It’s still possible to submit a series of commits in the course of a
  Gerrit review. However, Gerrit simply sees those as a series of
  changes that all depend on one another.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dependencies between changes can also be expressed explicitly, by
  including appropriate keywords in commit messages. Crucially, these
  dependencies &lt;em&gt;can cross project boundaries.&lt;/em&gt; That is to say, a
  change in one Git repository can depend on a change in &lt;em&gt;another&lt;/em&gt; Git
  repository, so long as they both use the same Gerrit instance for
  review.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;And we also have the equivalent of a Draft PR/MR; in Gerrit that’s
  called a work-in-progress change.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Because of this, when used in combination with CI such as Zuul, a
Gerrit-reviewed project generally expects CI tests to pass &lt;em&gt;on every
commit,&lt;/em&gt; without exceptions. This is in contrast to many GitHub or
GitLab managed projects, which typically only expect the head commit
of the topic branch associated with a PR/MR to pass CI.&lt;/p&gt;
&lt;p&gt;In Gerrit/Zuul managed projects, it’s also Zuul that merges the
commit. This is also in contrast to projects that live in GitHub or
GitLab: in those, the pipeline run results are generally advisory in
nature, and a successful pipeline run must still be confirmed by a
human clicking a &lt;em&gt;Merge&lt;/em&gt; button (or running a &lt;code&gt;git merge&lt;/code&gt; command
locally, and then pushing to the repository). In addition, even a
failing CI run can generally be overridden by a “core committer” who
has the ability to merge the PR/MR anyway.&lt;/p&gt;
&lt;p&gt;A Gerrit/Zuul project typically has no such shortcuts, meaning the
&lt;em&gt;only&lt;/em&gt; way to get changes into the repo is to pass both peer review,
and the CI pipeline. In my experience, this tends to create a climate
of leadership by example, which has a beneficial effect on both
experienced developers (“seniors” in a corporate setting) and
newcomers (“juniors”).&lt;/p&gt;
&lt;h3&gt;Speculative merging&lt;/h3&gt;
&lt;p&gt;There is one other property that Gerrit/Zuul has that sets it apart
from other review/CI toolchains: &lt;em&gt;speculative merging.&lt;/em&gt; This involves
the &lt;a href="https://zuul-ci.org/docs/zuul/3.10.2/user/gating.html#testing-in-parallel"&gt;parallel execution of CI jobs for interdependent
changes&lt;/a&gt;. With
speculative merging, even complex, long-running CI/CD pipelines don’t
hold up the development process — and this massively enhances project
scalability.&lt;/p&gt;
&lt;h3&gt;No direct repo browser integration&lt;/h3&gt;
&lt;p&gt;Notably, in Gerrit/Zuul there is no close integration with repository
browsing. Gerrit does include the
&lt;a href="https://gerrit.googlesource.com/gitiles/"&gt;Gitiles&lt;/a&gt; plugin for the
purpose, but its user experience is rudimentary at best. A popular
alternative is to deploy Gerrit with &lt;a href="https://gitea.io/en-us/"&gt;Gitea&lt;/a&gt;,
but again, that’s not built-in and your trusted Gerrit/Zuul admin has
to set it up for you. In addition, while source code browsing in
GitHub and GitLab is tightly integrated with project permissions, and
that is also true for Gitiles, there is a certain amount of
administrative duplication to make your Gerrit repository and project
permissions apply to Gitea.&lt;/p&gt;
&lt;h3&gt;No built-in package registries&lt;/h3&gt;
&lt;p&gt;There’s another difference in the Gerrit/Zuul stack when compared to
GitHub and GitLab, and that is its absence of built-in package
registries. Zuul has ready-to-use &lt;em&gt;jobs&lt;/em&gt; for &lt;a href="https://zuul-ci.org/docs/zuul-jobs/docker-image.html"&gt;pushing to a container
registry&lt;/a&gt;, or to
&lt;a href="https://zuul-ci.org/docs/zuul-jobs/python-jobs.html#job-python-upload-pypi"&gt;PyPI&lt;/a&gt;,
but you do have to either push to upstream public registries, or build
your own. Zuul does not come bundled with multitenant private
registries the way GitHub and GitLab do.&lt;/p&gt;
&lt;h3&gt;Administrative complexity&lt;/h3&gt;
&lt;p&gt;In view of the above, there's another thing that you might want to
consider, which in my humble opinion is an important reason why the
Gerrit/Zuul combination has less uptake than it deserves on its
technical merits. And this may sound overly dramatic, but: people like
to be in charge of their own actions, and software developers are
people. And here’s an issue with Zuul: there are quite a few things a
developer can do on their own in GitHub Actions or GitLab CI that
they’d need to ask an admin’s help for in Zuul.&lt;/p&gt;
&lt;p&gt;Creating a relatively standard workflow of building a private
container image, pushing it to your own registry, and then rolling out
that image to a Kubernetes deployment, is something you can do in
GitHub or GitLab as a project owner. With Zuul, you’ll need an admin
at least to set up and manage your container registry. Rerunning a
pipeline, a simple click of a button or API call in GitHub or GitLab,
is something you trigger via a Gerrit keyword (typically &lt;code&gt;recheck&lt;/code&gt;)
for Zuul — but only on the pipelines where &lt;a href="https://zuul-ci.org/docs/zuul/3.11.0/admin/drivers/gerrit.html#reference-pipelines-configuration"&gt;your admin has defined
that
trigger&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;So, which one’s best?&lt;/h1&gt;
&lt;p&gt;So you want to know which one of these &lt;em&gt;you&lt;/em&gt; should choose (or
advocate for)? That’s surprisingly difficult to answer, and greatly
depends on your priorities. And I’ll give you this from four angles.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;When it comes to &lt;em&gt;scalability&lt;/em&gt; — the ability to adapt to massive
  organizational sizes, and/or rapid project growth, or an obscenely
  large number or projects within an organization — the Gerrit/Zuul
  combination wins hands down &lt;strong&gt;if&lt;/strong&gt; you have a competent, responsive,
  and dedicated crew to manage it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When it’s about &lt;em&gt;getting started quickly&lt;/em&gt; — helping a project get
  off the ground with a good, usable, easily manageable review and
  fully integrated CI/CD structure — you can’t beat GitLab.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In terms of &lt;em&gt;beneficial effect on your development culture,&lt;/em&gt;
  Gerrit/Zuul again probably scores best. If you have a team that’s
  great at reviews and commit and CI and doesn’t cut corners, or you
  want to build a team like that, Gerrit/Zuul can really help.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;And when it’s about &lt;em&gt;giving developers the lowest barrier to entry&lt;/em&gt;
  — meaning using tools that they’re most likely already familiar with
  — GitHub is your platform of choice.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</content><category term="blog"></category><category term="Work"></category><category term="CI"></category><category term="Gerrit"></category><category term="GitLab"></category><category term="GitHub"></category><category term="Zuul"></category></entry><entry><title>Scaling the flat organization</title><link href="https://xahteiwi.eu/blog/2022/01/16/flat-org-scaling/" rel="alternate"></link><published>2022-01-16T00:00:00+00:00</published><updated>2022-01-16T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2022-01-16:/blog/2022/01/16/flat-org-scaling/</id><summary type="html">&lt;p&gt;“We need a flat organizational structure in order to scale.” Or do we, really?&lt;/p&gt;</summary><content type="html">&lt;p&gt;There’s a common trope in management that goes something like “in
order to better scale the organization as we grow, we need to keep it
flat.” The thrust of the argument is that as the organization grows to
meet customer and demand growth (and with it, growth in head count),
additional levels of corporate hierarchy stifle that growth, and
should thus be avoided.&lt;/p&gt;
&lt;p&gt;For any knowledge-driven organization this is wrong, and just &lt;em&gt;how&lt;/em&gt;
wrong it is can be proven, numerically, with simple high school level
maths. And in this context, “knowledge-driven organization”
encompasses any technology company, any software engineering outfit,
any technology services provider — in short, any organization that
makes its money off the brains of its people.&lt;/p&gt;
&lt;p&gt;Let’s establish a few self-evident facts about knowledge-driven
organizations:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The people who actually “make things happen” are the ones with no
   direct reports. The frontend designers, the infrastructure
   engineers, the backend specialists, the data analysts. Their
   managers (and &lt;em&gt;their&lt;/em&gt; managers, and everyone else all the way up to
   the CEO) are charged with aggregating information, making
   decisions, removing obstacles to productivity, and perhaps
   providing some form of vision and guidance. But it’s individual,
   non-managerial contributors of all specializations that actually
   &lt;em&gt;do&lt;/em&gt; things.&lt;/li&gt;
&lt;li&gt;In doing so, engineers work best in small teams with a great degree
   of autonomy. They will usually benefit from close working
   relationships with a small group of people.&lt;/li&gt;
&lt;li&gt;A manager’s role is thus twofold: remove any obstacles that stand
   in the way of the team accomplishing its goals, and act as an
   interface to other parts of the organization.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;An example&lt;/h2&gt;
&lt;p&gt;With that in mind, let’s consider a hypothetical small company that is
currently structured in teams of 5. There’s always 4 people reporting
to one manager. Currently, that company is made up as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the CEO/founder, Alex (1 person),&lt;/li&gt;
&lt;li&gt;4 team leads (4 people),&lt;/li&gt;
&lt;li&gt;4 employees on each team, all of whom report to the respective team
  lead (in total, 16 people).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, 21 people in all.&lt;/p&gt;
&lt;p&gt;Management theory calls the number of reports per manager in an
organization the &lt;a href="https://en.wikipedia.org/wiki/Span_of_control"&gt;&lt;em&gt;span of
control&lt;/em&gt;&lt;/a&gt;. I don’t like
that term a great deal. For one thing, at four syllables it’s a bit of
a mouthful, particularly if it needs to mentioned frequently. But more
importantly, it’s not an accurate reflection of reality: in a
knowledge-driven organization (like any technology or engineering
company), it’s ludicrous to think that a manager “controls” their
reports like puppets or robots. So, I’ll use a different term for the
remainder of this article: I’m going to call the number of reports per
manager the &lt;strong&gt;width&lt;/strong&gt; of the company.&lt;/p&gt;
&lt;p&gt;Also, I’ll use the term &lt;strong&gt;depth&lt;/strong&gt; for the number of hierarchy levels
that the company has. A sole proprietorship has a depth of zero. A
company with a founder-CEO and a few employees, but no other managers,
has a depth of 1. Alex’ company, with one level of management
reporting to Alex, and everyone else reporting to one of those
managers, currently has a depth of 2.&lt;/p&gt;
&lt;p&gt;So we can say that Alex’ company is currently &lt;em&gt;narrow&lt;/em&gt; and &lt;em&gt;shallow&lt;/em&gt; —
it has small teams, and few management levels.&lt;/p&gt;
&lt;p&gt;Now, the company has just closed a major funding round and several big
customer deals, putting them on a solid growth trajectory. So, Alex
expects the company to double in headcount on an annual basis for the
foreseeable future.&lt;/p&gt;
&lt;p&gt;So the question is: is it better for the organization to stick to the
current width, and add depth as it grows, or should Alex increase its
width, so that it can accomodate more people while retaining a
shallower depth?&lt;/p&gt;
&lt;p&gt;In other words, as the company scales, should it become &lt;em&gt;deeper&lt;/em&gt; while
staying &lt;em&gt;narrow&lt;/em&gt;, or should it grow &lt;em&gt;wider&lt;/em&gt; while staying &lt;em&gt;shallow?&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Fast-forward five years&lt;/h2&gt;
&lt;p&gt;To look at that, Alex mentally fast-forwards five years under the
currently assumed growth model. After five years of doubling in
headcount, the company now has &lt;span class="math"&gt;\(21 \cdot 2^5 = 672\)&lt;/span&gt; employees.&lt;/p&gt;
&lt;p&gt;In this scenario, everyone in the company works still works in a
5-person team, out of which one person is the leader. So every leader
has 4 people that report to them. Let’s look at one employee, Sam. Sam
works in a team with Joe, Jane, Harry and Ruth, and Ruth is the team
lead. Let’s say her title is simply, “Manager”.&lt;/p&gt;
&lt;p&gt;Ruth now has at most 3 peers of her own, and reports to someone who
goes by “Senior Manager,” putting her in another team of no more than
5 at her management level. That Senior Manager has at most 3 peers again, all
of whom report to a Director. A Director also, together with a maximum
of 3 other Directors, reports to a VP, and the 4 VPs work together
under Alex, who is still the CEO.&lt;/p&gt;
&lt;p&gt;Now, I’ll tell you that for 672 people, you’ll not nearly have filled
all those 5-person teams. But try to intuitively guess, without doing
the math, what organizational size this structure would
accommodate. That is to say, with every person in the company being at
most 5 hops away from the CEO, and everyone working in a group of 5,
what’s the maximum company size this model can handle?&lt;/p&gt;
&lt;p&gt;The answer is 1,365.&lt;/p&gt;
&lt;p&gt;Let’s quickly break that down and see how we can plug other numbers in.&lt;/p&gt;
&lt;h2&gt;A gentle bit of maths, part I: team size and hierarchy levels&lt;/h2&gt;
&lt;p&gt;Say we take company’s &lt;em&gt;width&lt;/em&gt;, that is the number of people working
together in any group, &lt;em&gt;excluding&lt;/em&gt; the leader, as &lt;span class="math"&gt;\(x\)&lt;/span&gt;. In our example,
that’s &lt;span class="math"&gt;\(4\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Then, any team’s size (which we’ll call &lt;span class="math"&gt;\(n\)&lt;/span&gt;, for reasons we’ll get to
in a jiffy) is of course &lt;span class="math"&gt;\(x+1=5\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The number of people any Senior Manager is reponsible for is &lt;span class="math"&gt;\((x+1)x +
1 = x^2+x+1 = 21\)&lt;/span&gt; (that is, their Manager’s teams, and themselves).&lt;/p&gt;
&lt;p&gt;The number of people any Director is responsible for is &lt;span class="math"&gt;\(((x+1)x+1)x+1
= x^3+x^2+x+1 = 85\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;You see where this is going. For any additional level of &lt;em&gt;depth&lt;/em&gt;, we
simply need to add another power of &lt;span class="math"&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;And of course &lt;span class="math"&gt;\(1 = x^0\)&lt;/span&gt; — at the zeroth depth level there’s one
single person: the CEO.&lt;/p&gt;
&lt;p&gt;So we can express the number of people in an organization with a width
of &lt;span class="math"&gt;\(x\)&lt;/span&gt; and a depth of &lt;span class="math"&gt;\(y\)&lt;/span&gt; as
&lt;/p&gt;
&lt;div class="math"&gt;$$x^0 + x^1 + x^2 + ... + x^y$$&lt;/div&gt;
&lt;p&gt;or, more briefly:&lt;sup id="fnref:i"&gt;&lt;a class="footnote-ref" href="#fn:i"&gt;1&lt;/a&gt;&lt;/sup&gt; &lt;/p&gt;
&lt;div class="math"&gt;$$\sum_{i=0}^{y} x^{i}$$&lt;/div&gt;
&lt;p&gt;And that, in turn, &lt;a href="https://www.wolframalpha.com/input/?i2d=true&amp;amp;i=Sum%5BPower%5Bx%2Cn%5D%2C%7Bn%2C0%2Cy%7D%5D"&gt;happens to work out
to&lt;/a&gt;&lt;sup id="fnref:indeterminate"&gt;&lt;a class="footnote-ref" href="#fn:indeterminate"&gt;2&lt;/a&gt;&lt;/sup&gt;
&lt;/p&gt;
&lt;div class="math"&gt;$${x^{y+1}-1} \over {x-1}$$&lt;/div&gt;
&lt;p&gt;Plug in the numbers for &lt;span class="math"&gt;\(x=4\)&lt;/span&gt; and &lt;span class="math"&gt;\(y=5\)&lt;/span&gt;, and we get 1,365. &lt;/p&gt;
&lt;h2&gt;A gentle bit of maths, part II: communications in complete graphs&lt;/h2&gt;
&lt;p&gt;Now, what’s our scaling constraint in a knowledge organization? The
number of people you need to constantly be in touch with in order to
accomplish your goals. &lt;/p&gt;
&lt;p&gt;For Sam, those people are principally your Sam’s teammates team
colleagues, including their manager, Ruth. That’s 4 people. However,
it’s not enough for Sam to understand what &lt;em&gt;he&lt;/em&gt; is exchanging with
Jane, Joe, Harry, and Ruth; it’s also imperative for him to understand
what &lt;em&gt;they&lt;/em&gt; communicate about. So, Sam needs to keep himself
appraisedof what Ruth told Harry, or what information Jane gave to
Joe, and how Joe and Harry are coordinating their latest change
(etc.).&lt;/p&gt;
&lt;p&gt;That means that &lt;strong&gt;within a team, communications are a &lt;a href="https://en.wikipedia.org/wiki/Complete_graph"&gt;complete
graph&lt;/a&gt;&lt;/strong&gt;. And for a
complete graph, the number of &lt;em&gt;edges&lt;/em&gt; is given by &lt;/p&gt;
&lt;div class="math"&gt;$${n(n-1)}\over 2$$&lt;/div&gt;
&lt;p&gt;In our case, &lt;span class="math"&gt;\(n\)&lt;/span&gt; is our team size (including the leader), thus
&lt;span class="math"&gt;\(x+1\)&lt;/span&gt; (the reports plus the leader). &lt;/p&gt;
&lt;p&gt;So we can rewrite the complete-graph formula as: 
&lt;/p&gt;
&lt;div class="math"&gt;$${{(x+1)(x+1-1)} \over 2} = {{x(x+1)} \over 2}$$&lt;/div&gt;
&lt;p&gt;So in order for the team to be well informed of everyone’s
actions at all times, a 5-person team must keep track of 10
communications links between people. That’s absolutely doable, though
we must keep in mind that the number of links does not grow linearly
with the number of people in direct communications which each other,
but it grows proportionally to the &lt;em&gt;square&lt;/em&gt; of that number.&lt;/p&gt;
&lt;p&gt;Sam’s manager Ruth, of course, works on &lt;em&gt;two&lt;/em&gt; 5-person teams: Sam’s,
and Ruth’s team of fellow Managers reporting to a Senior Manager. That
means Ruth needs to constantly keep in touch with the people on her
team (including Sam), and also understand what everyone on her team of
Managers is doing. Thus, she keeps track of 20 communications
links. This is also true for her Senior Manager, that Senior Manager’s
Director, and that Director’s VP. It’s only at the very top that the
CEO has the luxury of directly managing only 4 VPs.&lt;sup id="fnref:c-suite"&gt;&lt;a class="footnote-ref" href="#fn:c-suite"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h2&gt;This should be flatter! Or should it?&lt;/h2&gt;
&lt;p&gt;Now, suppose someone tells Alex that in this growth plan the
organization is much too hierarchical, and the organization must thus
lose some of its projected hierarchy levels — that is, reduce its
depth. Of course, the only way to do that while still being able to
manage the same headcount growth is to make the company wider — in
other words, have more people report to one manager than previously
planned.&lt;/p&gt;
&lt;p&gt;So Alex, being a good CEO, opens some spread sheet software and
creates this handy table that simply plugs in values for &lt;span class="math"&gt;\(x\)&lt;/span&gt; and &lt;span class="math"&gt;\(y\)&lt;/span&gt;,
with &lt;span class="math"&gt;\(x\)&lt;/span&gt; (width) in columns and &lt;span class="math"&gt;\(y\)&lt;/span&gt; (depth) in rows.&lt;sup id="fnref:table"&gt;&lt;a class="footnote-ref" href="#fn:table"&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;table class="table table-striped"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;th&gt;4&lt;/th&gt;
&lt;th&gt;5&lt;/th&gt;
&lt;th&gt;6&lt;/th&gt;
&lt;th&gt;7&lt;/th&gt;
&lt;th&gt;8&lt;/th&gt;
&lt;th&gt;9&lt;/th&gt;
&lt;th&gt;10&lt;/th&gt;
&lt;th&gt;11&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;1&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;13&lt;/td&gt;
&lt;td&gt;21&lt;/td&gt;
&lt;td&gt;31&lt;/td&gt;
&lt;td&gt;43&lt;/td&gt;
&lt;td&gt;57&lt;/td&gt;
&lt;td&gt;73&lt;/td&gt;
&lt;td&gt;91&lt;/td&gt;
&lt;td&gt;111&lt;/td&gt;
&lt;td&gt;133&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;3&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;15&lt;/td&gt;
&lt;td&gt;40&lt;/td&gt;
&lt;td&gt;85&lt;/td&gt;
&lt;td&gt;156&lt;/td&gt;
&lt;td&gt;259&lt;/td&gt;
&lt;td&gt;400&lt;/td&gt;
&lt;td&gt;585&lt;/td&gt;
&lt;td&gt;820&lt;/td&gt;
&lt;td&gt;1,111&lt;/td&gt;
&lt;td&gt;1,464&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;4&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;31&lt;/td&gt;
&lt;td&gt;121&lt;/td&gt;
&lt;td&gt;341&lt;/td&gt;
&lt;td&gt;781&lt;/td&gt;
&lt;td&gt;1,555&lt;/td&gt;
&lt;td&gt;2,801&lt;/td&gt;
&lt;td&gt;4,681&lt;/td&gt;
&lt;td&gt;7,381&lt;/td&gt;
&lt;td&gt;11,111&lt;/td&gt;
&lt;td&gt;16,105&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;5&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;63&lt;/td&gt;
&lt;td&gt;364&lt;/td&gt;
&lt;td&gt;1,365&lt;/td&gt;
&lt;td&gt;3,906&lt;/td&gt;
&lt;td&gt;9,331&lt;/td&gt;
&lt;td&gt;19,608&lt;/td&gt;
&lt;td&gt;37,449&lt;/td&gt;
&lt;td&gt;66,430&lt;/td&gt;
&lt;td&gt;111,111&lt;/td&gt;
&lt;td&gt;177,156&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;6&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;127&lt;/td&gt;
&lt;td&gt;1,093&lt;/td&gt;
&lt;td&gt;5,461&lt;/td&gt;
&lt;td&gt;19,531&lt;/td&gt;
&lt;td&gt;55,987&lt;/td&gt;
&lt;td&gt;137,257&lt;/td&gt;
&lt;td&gt;299,593&lt;/td&gt;
&lt;td&gt;597,871&lt;/td&gt;
&lt;td&gt;1,111,111&lt;/td&gt;
&lt;td&gt;1,948,717&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;7&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;255&lt;/td&gt;
&lt;td&gt;3,280&lt;/td&gt;
&lt;td&gt;21,845&lt;/td&gt;
&lt;td&gt;97,656&lt;/td&gt;
&lt;td&gt;335,923&lt;/td&gt;
&lt;td&gt;960,800&lt;/td&gt;
&lt;td&gt;2,396,745&lt;/td&gt;
&lt;td&gt;5,380,840&lt;/td&gt;
&lt;td&gt;11,111,111&lt;/td&gt;
&lt;td&gt;21,435,888&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;8&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;511&lt;/td&gt;
&lt;td&gt;9,841&lt;/td&gt;
&lt;td&gt;87,381&lt;/td&gt;
&lt;td&gt;488,281&lt;/td&gt;
&lt;td&gt;2,015,539&lt;/td&gt;
&lt;td&gt;6,725,601&lt;/td&gt;
&lt;td&gt;19,173,961&lt;/td&gt;
&lt;td&gt;48,427,561&lt;/td&gt;
&lt;td&gt;111,111,111&lt;/td&gt;
&lt;td&gt;235,794,769&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;9&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1,023&lt;/td&gt;
&lt;td&gt;29,524&lt;/td&gt;
&lt;td&gt;349,525&lt;/td&gt;
&lt;td&gt;2,441,406&lt;/td&gt;
&lt;td&gt;12,093,235&lt;/td&gt;
&lt;td&gt;47,079,208&lt;/td&gt;
&lt;td&gt;153,391,689&lt;/td&gt;
&lt;td&gt;435,848,050&lt;/td&gt;
&lt;td&gt;1,111,111,111&lt;/td&gt;
&lt;td&gt;2,593,742,460&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;10&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;2,047&lt;/td&gt;
&lt;td&gt;88,573&lt;/td&gt;
&lt;td&gt;1,398,101&lt;/td&gt;
&lt;td&gt;12,207,031&lt;/td&gt;
&lt;td&gt;72,559,411&lt;/td&gt;
&lt;td&gt;329,554,457&lt;/td&gt;
&lt;td&gt;1,227,133,513&lt;/td&gt;
&lt;td&gt;3,922,632,451&lt;/td&gt;
&lt;td&gt;11,111,111,111&lt;/td&gt;
&lt;td&gt;28,531,167,061&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;For our previous five-year plan, Alex can just look up the cell
matching &lt;span class="math"&gt;\(x=4\)&lt;/span&gt;, &lt;span class="math"&gt;\(y=5\)&lt;/span&gt; and finds our known outcome, a maximum head
count of 1,365.&lt;/p&gt;
&lt;p&gt;Now, Alex looks at what it takes to flatten the organization by
eliminating one hierarchy level, or by two.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If we want to reduce depth by 1, we simply go up one row (thus,
  &lt;span class="math"&gt;\(y=4\)&lt;/span&gt;) and find the value for &lt;span class="math"&gt;\(x\)&lt;/span&gt; that just accommodates 1,365
  people or more. Alex sees that that's &lt;span class="math"&gt;\(x=6\)&lt;/span&gt;, which can accommodate
  1,555 people. That is, increase the width by 2: reorganize from
  teams of 5 to teams of 7. Alex could also pick &lt;span class="math"&gt;\(x=5\)&lt;/span&gt;, that is
  increase the width by only 1, which would land the company at a
  maximum head count of 781. That is well below what &lt;span class="math"&gt;\(x=4\)&lt;/span&gt; can handle,
  but it still lands Alex north of the original growth target of 672.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If we want to reduce depth by 2, we go up two rows (&lt;span class="math"&gt;\(y=3\)&lt;/span&gt;) and do
  the same. We end up at &lt;span class="math"&gt;\(x=11\)&lt;/span&gt;, which means to increase width by 7:
  reorganize from teams of 5 to teams of 12. Thus, we land at a
  maximum of 1,464 people, slightly exceeding the headcount we’re able
  to accommodate if we keep growing with the current structure. We
  could also do &lt;span class="math"&gt;\(x=10\)&lt;/span&gt; or &lt;span class="math"&gt;\(x=9\)&lt;/span&gt;, landing us at maxima well below that
  (1,111 or 820), but still north of 672.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now what does that mean in terms of communication channels each person
has to maintain?&lt;/p&gt;
&lt;p&gt;Again, what we want to keep in mind is the number of edges in a
complete graph connecting &lt;span class="math"&gt;\(n\)&lt;/span&gt; (that is, &lt;span class="math"&gt;\(x+1\)&lt;/span&gt;) points. For regular
employees, we know that that’s &lt;/p&gt;
&lt;div class="math"&gt;$${x(x+1)}\over 2$$&lt;/div&gt;
&lt;p&gt;And for any manager, who is effectively on two teams of size &lt;span class="math"&gt;\(x+1\)&lt;/span&gt;
simultaneously, that’s &lt;/p&gt;
&lt;div class="math"&gt;$$2 \cdot {{x(x+1)}\over 2} = x(x+1)$$&lt;/div&gt;
&lt;p&gt;Which means:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If we want to reduce depth by 1 and go from &lt;span class="math"&gt;\(x=4\)&lt;/span&gt; to
  &lt;span class="math"&gt;\(x=5\)&lt;/span&gt;, every non-manager employee now needs to be aware of 15
  communications links (instead of 10), every manager, of 30 (instead
  of 20).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If instead we go from &lt;span class="math"&gt;\(x=4\)&lt;/span&gt; to &lt;span class="math"&gt;\(x=6\)&lt;/span&gt;, every non-manager employee now
  needs to be aware of 21 communications links, every manager, of 42.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So that’s a least a 50% increase, or even a doubling, of
communications complexity.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;For the elimination of two hierarchy levels (a depth reduction by
  2), we’ll need to move from &lt;span class="math"&gt;\(x=4\)&lt;/span&gt; to at least &lt;span class="math"&gt;\(x=8\)&lt;/span&gt;. At that point,
  every regular employee has at least 36 communications links on their
  teams to deal with; every manager deals with 72.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If instead we go to &lt;span class="math"&gt;\(x=9\)&lt;/span&gt;, every non-manager employee now needs to
  be aware of 45 communications links, every manager, of 90.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;And for &lt;span class="math"&gt;\(x=10\)&lt;/span&gt;, every non-manager employee now needs to
  be aware of 55 communications links, every manager, of 110.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At this point Alex realizes that &lt;strong&gt;making the company wide and
shallow, instead of narrow and deep, is painfully expensive in
communication cost.&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;But what about all those managers we won’t have to pay?&lt;/h2&gt;
&lt;p&gt;A well-meaning advisor interrupts Alex in the middle of planning. He
interjects that Alex is missing a point, namely all the managers that
the company will now no longer need, and the cost savings thus
generated.&lt;/p&gt;
&lt;p&gt;So Alex looks at the table again (width in columns, depth in rows):&lt;/p&gt;
&lt;table class="table table-striped"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;th&gt;4&lt;/th&gt;
&lt;th&gt;5&lt;/th&gt;
&lt;th&gt;6&lt;/th&gt;
&lt;th&gt;7&lt;/th&gt;
&lt;th&gt;8&lt;/th&gt;
&lt;th&gt;9&lt;/th&gt;
&lt;th&gt;10&lt;/th&gt;
&lt;th&gt;11&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;1&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;13&lt;/td&gt;
&lt;td&gt;21&lt;/td&gt;
&lt;td&gt;31&lt;/td&gt;
&lt;td&gt;43&lt;/td&gt;
&lt;td&gt;57&lt;/td&gt;
&lt;td&gt;73&lt;/td&gt;
&lt;td&gt;91&lt;/td&gt;
&lt;td&gt;111&lt;/td&gt;
&lt;td&gt;133&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;3&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;15&lt;/td&gt;
&lt;td&gt;40&lt;/td&gt;
&lt;td&gt;85&lt;/td&gt;
&lt;td&gt;156&lt;/td&gt;
&lt;td&gt;259&lt;/td&gt;
&lt;td&gt;400&lt;/td&gt;
&lt;td&gt;585&lt;/td&gt;
&lt;td&gt;820&lt;/td&gt;
&lt;td&gt;1,111&lt;/td&gt;
&lt;td&gt;1,464&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;4&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;31&lt;/td&gt;
&lt;td&gt;121&lt;/td&gt;
&lt;td&gt;341&lt;/td&gt;
&lt;td&gt;781&lt;/td&gt;
&lt;td&gt;1,555&lt;/td&gt;
&lt;td&gt;2,801&lt;/td&gt;
&lt;td&gt;4,681&lt;/td&gt;
&lt;td&gt;7,381&lt;/td&gt;
&lt;td&gt;11,111&lt;/td&gt;
&lt;td&gt;16,105&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;5&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;63&lt;/td&gt;
&lt;td&gt;364&lt;/td&gt;
&lt;td&gt;1,365&lt;/td&gt;
&lt;td&gt;3,906&lt;/td&gt;
&lt;td&gt;9,331&lt;/td&gt;
&lt;td&gt;19,608&lt;/td&gt;
&lt;td&gt;37,449&lt;/td&gt;
&lt;td&gt;66,430&lt;/td&gt;
&lt;td&gt;111,111&lt;/td&gt;
&lt;td&gt;177,156&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;6&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;127&lt;/td&gt;
&lt;td&gt;1,093&lt;/td&gt;
&lt;td&gt;5,461&lt;/td&gt;
&lt;td&gt;19,531&lt;/td&gt;
&lt;td&gt;55,987&lt;/td&gt;
&lt;td&gt;137,257&lt;/td&gt;
&lt;td&gt;299,593&lt;/td&gt;
&lt;td&gt;597,871&lt;/td&gt;
&lt;td&gt;1,111,111&lt;/td&gt;
&lt;td&gt;1,948,717&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;7&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;255&lt;/td&gt;
&lt;td&gt;3,280&lt;/td&gt;
&lt;td&gt;21,845&lt;/td&gt;
&lt;td&gt;97,656&lt;/td&gt;
&lt;td&gt;335,923&lt;/td&gt;
&lt;td&gt;960,800&lt;/td&gt;
&lt;td&gt;2,396,745&lt;/td&gt;
&lt;td&gt;5,380,840&lt;/td&gt;
&lt;td&gt;11,111,111&lt;/td&gt;
&lt;td&gt;21,435,888&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;8&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;511&lt;/td&gt;
&lt;td&gt;9,841&lt;/td&gt;
&lt;td&gt;87,381&lt;/td&gt;
&lt;td&gt;488,281&lt;/td&gt;
&lt;td&gt;2,015,539&lt;/td&gt;
&lt;td&gt;6,725,601&lt;/td&gt;
&lt;td&gt;19,173,961&lt;/td&gt;
&lt;td&gt;48,427,561&lt;/td&gt;
&lt;td&gt;111,111,111&lt;/td&gt;
&lt;td&gt;235,794,769&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;9&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1,023&lt;/td&gt;
&lt;td&gt;29,524&lt;/td&gt;
&lt;td&gt;349,525&lt;/td&gt;
&lt;td&gt;2,441,406&lt;/td&gt;
&lt;td&gt;12,093,235&lt;/td&gt;
&lt;td&gt;47,079,208&lt;/td&gt;
&lt;td&gt;153,391,689&lt;/td&gt;
&lt;td&gt;435,848,050&lt;/td&gt;
&lt;td&gt;1,111,111,111&lt;/td&gt;
&lt;td&gt;2,593,742,460&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;10&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;2,047&lt;/td&gt;
&lt;td&gt;88,573&lt;/td&gt;
&lt;td&gt;1,398,101&lt;/td&gt;
&lt;td&gt;12,207,031&lt;/td&gt;
&lt;td&gt;72,559,411&lt;/td&gt;
&lt;td&gt;329,554,457&lt;/td&gt;
&lt;td&gt;1,227,133,513&lt;/td&gt;
&lt;td&gt;3,922,632,451&lt;/td&gt;
&lt;td&gt;11,111,111,111&lt;/td&gt;
&lt;td&gt;28,531,167,061&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;What's handy here is that Alex can look at any one table cell, and the
cell &lt;em&gt;directly above it&lt;/em&gt; will contain the total number of managers
(that is, people who have direct reports) for the same width. So,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;for &lt;span class="math"&gt;\(x=4\)&lt;/span&gt;, &lt;span class="math"&gt;\(y=5\)&lt;/span&gt; (our original scenario allowing the company to grow
  to 1,365 people), Alex would have to hire and pay a total of 341
  managers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;for &lt;span class="math"&gt;\(x=6\)&lt;/span&gt;, &lt;span class="math"&gt;\(y=4\)&lt;/span&gt; (the scenario that eliminates one level, and can
  accommodate 1,555 people), Alex’ company will need 259
  managers. That's 82 fewer managers, or a reduction by about 24%.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;for &lt;span class="math"&gt;\(x=5\)&lt;/span&gt;, &lt;span class="math"&gt;\(y=4\)&lt;/span&gt; (the scenario that eliminates one level, but
  accommodates only 781 people), Alex’ company will need 156
  managers. That's 185 fewer managers, or a reduction by about 54%.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;for &lt;span class="math"&gt;\(x=11\)&lt;/span&gt;, &lt;span class="math"&gt;\(y=3\)&lt;/span&gt; (the scenario that eliminates two levels, and can
  accommodate 1,464 people), the company will need 133
  managers. That's 208 fewer managers, or a reduction by about 61%.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;for &lt;span class="math"&gt;\(x=10\)&lt;/span&gt;, &lt;span class="math"&gt;\(y=3\)&lt;/span&gt; (the scenario that eliminates two levels, but
  accommodates only 1,111 people), the company will need 111
  managers. That's 230 fewer managers, or a reduction by about 67%.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;for &lt;span class="math"&gt;\(x=9\)&lt;/span&gt;, &lt;span class="math"&gt;\(y=3\)&lt;/span&gt; (the scenario that eliminates two levels, but
  accommodates only 820 people), the company will need 91
  managers. That's 250 fewer managers, or a reduction by about 73%.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;A gentle bit of maths, part III: how much of our company will be managers?&lt;/h2&gt;
&lt;p&gt;It so happens that we can generalize this. If Alex looks at our table
again, but considers the number of managers proportional to the number
of people in the company, a pattern quickly emerges (again, width
is in columns, depth is in rows):&lt;/p&gt;
&lt;table class="table table-striped"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;2&lt;/th&gt;
&lt;th&gt;3&lt;/th&gt;
&lt;th&gt;4&lt;/th&gt;
&lt;th&gt;5&lt;/th&gt;
&lt;th&gt;6&lt;/th&gt;
&lt;th&gt;7&lt;/th&gt;
&lt;th&gt;8&lt;/th&gt;
&lt;th&gt;9&lt;/th&gt;
&lt;th&gt;10&lt;/th&gt;
&lt;th&gt;11&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;1&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;33.33%&lt;/td&gt;
&lt;td&gt;25.00%&lt;/td&gt;
&lt;td&gt;20.00%&lt;/td&gt;
&lt;td&gt;16.67%&lt;/td&gt;
&lt;td&gt;14.29%&lt;/td&gt;
&lt;td&gt;12.50%&lt;/td&gt;
&lt;td&gt;11.11%&lt;/td&gt;
&lt;td&gt;10.00%&lt;/td&gt;
&lt;td&gt;9.09%&lt;/td&gt;
&lt;td&gt;8.33%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;42.86%&lt;/td&gt;
&lt;td&gt;30.77%&lt;/td&gt;
&lt;td&gt;23.81%&lt;/td&gt;
&lt;td&gt;19.35%&lt;/td&gt;
&lt;td&gt;16.28%&lt;/td&gt;
&lt;td&gt;14.04%&lt;/td&gt;
&lt;td&gt;12.33%&lt;/td&gt;
&lt;td&gt;10.99%&lt;/td&gt;
&lt;td&gt;9.91%&lt;/td&gt;
&lt;td&gt;9.02%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;3&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;46.67%&lt;/td&gt;
&lt;td&gt;32.50%&lt;/td&gt;
&lt;td&gt;24.71%&lt;/td&gt;
&lt;td&gt;19.87%&lt;/td&gt;
&lt;td&gt;16.60%&lt;/td&gt;
&lt;td&gt;14.25%&lt;/td&gt;
&lt;td&gt;12.48%&lt;/td&gt;
&lt;td&gt;11.10%&lt;/td&gt;
&lt;td&gt;9.99%&lt;/td&gt;
&lt;td&gt;9.08%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;4&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;48.39%&lt;/td&gt;
&lt;td&gt;33.06%&lt;/td&gt;
&lt;td&gt;24.93%&lt;/td&gt;
&lt;td&gt;19.97%&lt;/td&gt;
&lt;td&gt;16.66%&lt;/td&gt;
&lt;td&gt;14.28%&lt;/td&gt;
&lt;td&gt;12.50%&lt;/td&gt;
&lt;td&gt;11.11%&lt;/td&gt;
&lt;td&gt;10.00%&lt;/td&gt;
&lt;td&gt;9.09%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;5&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;49.21%&lt;/td&gt;
&lt;td&gt;33.24%&lt;/td&gt;
&lt;td&gt;24.98%&lt;/td&gt;
&lt;td&gt;19.99%&lt;/td&gt;
&lt;td&gt;16.66%&lt;/td&gt;
&lt;td&gt;14.28%&lt;/td&gt;
&lt;td&gt;12.50%&lt;/td&gt;
&lt;td&gt;11.11%&lt;/td&gt;
&lt;td&gt;10.00%&lt;/td&gt;
&lt;td&gt;9.09%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;6&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;49.61%&lt;/td&gt;
&lt;td&gt;33.30%&lt;/td&gt;
&lt;td&gt;25.00%&lt;/td&gt;
&lt;td&gt;20.00%&lt;/td&gt;
&lt;td&gt;16.67%&lt;/td&gt;
&lt;td&gt;14.29%&lt;/td&gt;
&lt;td&gt;12.50%&lt;/td&gt;
&lt;td&gt;11.11%&lt;/td&gt;
&lt;td&gt;10.00%&lt;/td&gt;
&lt;td&gt;9.09%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;7&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;49.80%&lt;/td&gt;
&lt;td&gt;33.32%&lt;/td&gt;
&lt;td&gt;25.00%&lt;/td&gt;
&lt;td&gt;20.00%&lt;/td&gt;
&lt;td&gt;16.67%&lt;/td&gt;
&lt;td&gt;14.29%&lt;/td&gt;
&lt;td&gt;12.50%&lt;/td&gt;
&lt;td&gt;11.11%&lt;/td&gt;
&lt;td&gt;10.00%&lt;/td&gt;
&lt;td&gt;9.09%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;8&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;49.90%&lt;/td&gt;
&lt;td&gt;33.33%&lt;/td&gt;
&lt;td&gt;25.00%&lt;/td&gt;
&lt;td&gt;20.00%&lt;/td&gt;
&lt;td&gt;16.67%&lt;/td&gt;
&lt;td&gt;14.29%&lt;/td&gt;
&lt;td&gt;12.50%&lt;/td&gt;
&lt;td&gt;11.11%&lt;/td&gt;
&lt;td&gt;10.00%&lt;/td&gt;
&lt;td&gt;9.09%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;9&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;49.95%&lt;/td&gt;
&lt;td&gt;33.33%&lt;/td&gt;
&lt;td&gt;25.00%&lt;/td&gt;
&lt;td&gt;20.00%&lt;/td&gt;
&lt;td&gt;16.67%&lt;/td&gt;
&lt;td&gt;14.29%&lt;/td&gt;
&lt;td&gt;12.50%&lt;/td&gt;
&lt;td&gt;11.11%&lt;/td&gt;
&lt;td&gt;10.00%&lt;/td&gt;
&lt;td&gt;9.09%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;10&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;49.98%&lt;/td&gt;
&lt;td&gt;33.33%&lt;/td&gt;
&lt;td&gt;25.00%&lt;/td&gt;
&lt;td&gt;20.00%&lt;/td&gt;
&lt;td&gt;16.67%&lt;/td&gt;
&lt;td&gt;14.29%&lt;/td&gt;
&lt;td&gt;12.50%&lt;/td&gt;
&lt;td&gt;11.11%&lt;/td&gt;
&lt;td&gt;10.00%&lt;/td&gt;
&lt;td&gt;9.09%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;You’ll see that at a depth of 1, the share of managers is obviously &lt;span class="math"&gt;\(1
\over {x+1}\)&lt;/span&gt;, but then as we increase in depth it quickly trends
toward:&lt;sup id="fnref:reciprocal"&gt;&lt;a class="footnote-ref" href="#fn:reciprocal"&gt;5&lt;/a&gt;&lt;/sup&gt; &lt;/p&gt;
&lt;div class="math"&gt;$$1 \over x$$&lt;/div&gt;
&lt;p&gt;The number of managers in Alex’ company is roughly the reciprocal of
the company’s width. In other words, the number of managers is
inversely proportional to width.&lt;/p&gt;
&lt;p&gt;In contrast, the cost of communications is directly proportional to
the &lt;em&gt;square&lt;/em&gt; of the width.&lt;/p&gt;
&lt;p&gt;At this point Alex realizes that &lt;strong&gt;while there are indeed savings to
be made by the elimination of management in a wide-and-shallow
company, they cannot possibly balance the added communication cost.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In other words: the cost in communications inefficiency grows much
faster with width, so much so that it will eat up Alex’ company’s
manager payroll savings several times over.&lt;/p&gt;
&lt;h1&gt;In summary&lt;/h1&gt;
&lt;p&gt;The “flat” (wide) organization scales poorly. Its growth in
communication cost far outpaces its savings in payroll cost. And it
scales progressively worse, the “flatter” (wider) it gets.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:i"&gt;
&lt;p&gt;In this &lt;a href="https://en.wikipedia.org/wiki/Summation#Capital-sigma_notation"&gt;capital-sigma summation
formula&lt;/a&gt;,
&lt;span class="math"&gt;\(i\)&lt;/span&gt; doesn’t mean anything other than it being a counter. The
formula is pronounced, in English, as “sum of &lt;span class="math"&gt;\(x\)&lt;/span&gt; to the &lt;span class="math"&gt;\(i\)&lt;/span&gt;, from
&lt;span class="math"&gt;\(i\)&lt;/span&gt; equals zero to &lt;span class="math"&gt;\(y\)&lt;/span&gt;” (in other words, add up all whole-number
powers of &lt;span class="math"&gt;\(x\)&lt;/span&gt;, from &lt;span class="math"&gt;\(x^0\)&lt;/span&gt; to &lt;span class="math"&gt;\(x^y\)&lt;/span&gt;). &lt;a class="footnote-backref" href="#fnref:i" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:indeterminate"&gt;
&lt;p&gt;You might notice that this expression is
&lt;a href="https://en.wikipedia.org/wiki/Indeterminate_form"&gt;indeterminate&lt;/a&gt;
for &lt;span class="math"&gt;\(x = 1\)&lt;/span&gt;. Now I’d say the idea of a hierarchical company made
up of one-on-one teams (every manager has one report, who in turn
is the manager of one report, and so on) is extremely unrealistic.
But just for completeness’ sake, we can apply &lt;a href="https://www.wolframalpha.com/input/?i2d=true&amp;amp;i=Limit%5BDivide%5BPower%5Bx%2Cy%2B1%5D-1%2Cx-1%5D%2Cx-%3E1%5D"&gt;a
limit&lt;/a&gt;
to show that 
&lt;div class="math"&gt;$$\lim_{x \to 1} {{x^{y+1}-1} \over {x-1}} = {y + 1}$$&lt;/div&gt; 
In other words, such an organization could accommodate a
number of people that is equal to its depth plus 1. &lt;a class="footnote-backref" href="#fnref:indeterminate" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:c-suite"&gt;
&lt;p&gt;This why they might also be able to appoint a CFO, CSO,
CTO or whatever other C-suite functions are appropriate for the
organization. So in the scenario we might end up with a handful
more people than 1,365 for the C-suite and perhaps some number of
staff in their offices. But for the purposes of this discussion
those don’t make a big difference, so we’ll disregard them for
now. &lt;a class="footnote-backref" href="#fnref:c-suite" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:table"&gt;
&lt;p&gt;I encourage you to compare the bottom rows and rightmost
columns of this table to Wikipedia’s &lt;a href="https://en.wikipedia.org/wiki/List_of_largest_employers"&gt;list of largest
employers&lt;/a&gt;. &lt;a class="footnote-backref" href="#fnref:table" title="Jump back to footnote 4 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:reciprocal"&gt;
&lt;p&gt;If you’re curious, that is because the share of
managers in relation to the total number of people in the company
is 
&lt;div class="math"&gt;$${\sum_{i=0}^{y-1} x^{i}} \over {\sum_{i=0}^{y} x^{i}}$$&lt;/div&gt;
That works out to be &lt;div class="math"&gt;$${x^y-1} \over {x^{y+1}-1}$$&lt;/div&gt;
Which, for &lt;span class="math"&gt;\(y=1\)&lt;/span&gt;, is
&lt;div class="math"&gt;$${{x-1} \over {x^2-1}} = {{x-1} \over {(x+1)\cdot(x-1)}} = {1 \over {x+1}}$$&lt;/div&gt;
And for larger values of &lt;span class="math"&gt;\(y\)&lt;/span&gt;, both &lt;span class="math"&gt;\(x^y\)&lt;/span&gt; and
&lt;span class="math"&gt;\(x^{y+1}\)&lt;/span&gt; become so large that the &lt;span class="math"&gt;\(-1\)&lt;/span&gt; part barely matters, so
it’s effectively: 
&lt;div class="math"&gt;$${{x^y-1} \over {x^{y+1}-1}} \approx {x^y \over x^{y+1}} = {1 \over x}$$&lt;/div&gt;
In slightly more formal terms, we can consider &lt;span class="math"&gt;\(1 \over x\)&lt;/span&gt; the 
&lt;em&gt;&lt;a href="https://en.wikipedia.org/wiki/Limit_(mathematics)"&gt;limit&lt;/a&gt;&lt;/em&gt; of the
expression as &lt;span class="math"&gt;\(y\)&lt;/span&gt; goes to infinity:
&lt;div class="math"&gt;$$\lim_{y \to \infty} {{x^y-1} \over {x^{y+1}-1}} = {1 \over x}$$&lt;/div&gt; &lt;a class="footnote-backref" href="#fnref:reciprocal" title="Jump back to footnote 5 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="blog"></category><category term="Work"></category><category term="Communications"></category></entry><entry><title>Voice messages</title><link href="https://xahteiwi.eu/blog/2021/12/05/voice-messages/" rel="alternate"></link><published>2021-12-05T00:00:00+00:00</published><updated>2021-12-05T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-12-05:/blog/2021/12/05/voice-messages/</id><summary type="html">&lt;p&gt;Apparently, some people think you should replace professional textual communications with voice messaging. Here’s why I think that that’s a bad idea.&lt;/p&gt;</summary><content type="html">&lt;p&gt;As of late, I've noticed that when people share one of my articles on
asynchronous communications on Twitter (particularly any from the
&lt;a href="https://xahteiwi.eu/blog/2021/09/30/getting-out-of-meeting-hell/"&gt;Getting out of Meeting
Hell&lt;/a&gt; series, or the one on
&lt;a href="https://xahteiwi.eu/blog/2021/10/27/this-meeting-should-have-been-an-email/"&gt;meetings that should have been an
email&lt;/a&gt;), there's
a reply from a brand account that likes to plug/advertise their
service. That service recommends that synchronous meetings be replaced
by “asynchronous meetings” based on voice messages.&lt;/p&gt;
&lt;p&gt;I’d like to point out that I consider that an utterly terrible idea.&lt;/p&gt;
&lt;p&gt;Let me explain why.&lt;/p&gt;
&lt;h2&gt;Voice is slow&lt;/h2&gt;
&lt;p&gt;First, voice messages suffer from the exact same drawback that
meetings do: they are incredibly slow. Most of us speak at a rate of
&lt;a href="https://en.wikipedia.org/wiki/Speech_tempo"&gt;approximately 4 syllables per
second&lt;/a&gt;.&lt;sup id="fnref:speech-tempo"&gt;&lt;a class="footnote-ref" href="#fn:speech-tempo"&gt;1&lt;/a&gt;&lt;/sup&gt; In
English, that translates to about 120-140 words per minute. That means
that as a listener, you &lt;em&gt;absorb&lt;/em&gt; the content of a voice message at the
same rate. You &lt;em&gt;might&lt;/em&gt; make that a little more efficient by increasing
playback speed, but that’s only feasible to about a 25% speed
increase, which lands you around 150 words per minute.&lt;/p&gt;
&lt;p&gt;In contrast, unless you are dyslexic (I’ll get to that in a bit) you
can &lt;em&gt;read&lt;/em&gt; at 240 words per minute.&lt;/p&gt;
&lt;p&gt;In other words, conveying a certain amount of information by voice
takes nearly twice as long as doing the same in writing. And that’s if
your verbal expression is &lt;em&gt;perfect,&lt;/em&gt; which it never is — any voice
message will come with its fair share of filler words (“uh”, “um”,
“y’know”) and incomplete sentences. &lt;/p&gt;
&lt;p&gt;Add to that the occasional slurred word or phrase, or idioms
unfamiliar to the recipient of the message. If you come across
something that’s unclear while reading, it takes you fractions of a
second to re-read a sentence, and maybe a few seconds to re-read from
the beginning of a paragraph. But in the listening case, it may take
you upward of a minute to go back and re-listen to a passage you
missed or didn’t understand. (Anyone who both reads books and listens
to audiobooks will relate to this.)&lt;/p&gt;
&lt;h2&gt;Voice is more difficult to follow and retrieve&lt;/h2&gt;
&lt;p&gt;Secondly, voice messages are usually much more difficult to understand
for a recipient listening in their second or third language,
particularly if the other person is a native speaker using an accent
that is unfamiliar to them — say, a French person listening to heavily
Scots-accented English or a pronounced Australian twang. Written
messages might still have their ambiguities — as an example, the word
“doubt” meaning “question”, a common substitution in Indian English,
frequently confuses non-Indian English speakers — but those are &lt;em&gt;far&lt;/em&gt;
fewer and easier to resolve for a reader.&lt;/p&gt;
&lt;p&gt;Furthermore, until speech recognition is perfect and automatic
transcription is thus exquisitely faithful, your voice messages aren’t
searchable. You could say that they’re practically
half-off-the-record. Good luck trying to come back to an important bit
of information that someone conveyed via a voice message that you have
only a vague recollection of. Or, worse, trying to establish the
&lt;em&gt;context&lt;/em&gt; in which a decision was made, and having to piece it
together from multiple voice messages.&lt;/p&gt;
&lt;h2&gt;Voice doesn’t convey as much nuance as you think&lt;/h2&gt;
&lt;p&gt;Thirdly, the notion that you ought to be using voice messages to add
“nuance” when you can’t convey such nuance in your writing strikes me
as patently ludicrous.&lt;/p&gt;
&lt;p&gt;When you need to convey emotion or feeling or nuance to a greater
extent than you would be able to in writing, that is &lt;em&gt;absolutely&lt;/em&gt; a
situation in which you should meet with a person face-to-face,
one-on-one, and where that doesn’t permit itself, get on a video
call. At that point, when a written message won’t cut it, a voice
message absolutely won’t.&lt;/p&gt;
&lt;h2&gt;One good use?&lt;/h2&gt;
&lt;p&gt;Now, there may be one useful use of voice messages that I can think
of: they may work for people with dyslexia, for whom consuming a lot
of writing &lt;a href="https://a11yrules.com/podcast/kevin-mar-molinero-talks-about-dyscalculia-and-copy-pasting/"&gt;may cause cognitive
overload&lt;/a&gt;. In
that case, voice messages might be a workable alternative. If so, then
that would make the option to communicate via voice message a very
valid accessibility consideration. That said, I’ve talked to people
who are dyslexic and who said that voice messages are not an adequate
substitute for interactive verbal communication to them — but that’s
of course highly anecdotal, and shouldn’t dismiss the idea outright.&lt;/p&gt;
&lt;p&gt;However: even if voice messages are a good thing for people with
dyslexia, though, I &lt;em&gt;think&lt;/em&gt; that as screen readers continuously
improve, generating speech from text may a be preferable
option. That’s because it retains the searchability advantage for
everyone, and the efficiency advantage for non-dyslexics, while also
accomodating people with dyslexia. But, I want to re-emphasize that
that’s just a hunch, and I may well be completely wrong. If you’re
dyslexic and have thoughts on this, I’d love to hear from you! Please
find me on &lt;a href="https://twitter.com/xahteiwi"&gt;Twitter&lt;/a&gt; or
&lt;a href="https://mastodon.social/@xahteiwi"&gt;Mastodon&lt;/a&gt;.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:speech-tempo"&gt;
&lt;p&gt;Fun useless fact: the rate of 4 syllables per second
is practically universal across spoken languages. How many &lt;em&gt;words&lt;/em&gt;
a native speaker of a particular language speaks in a minute
depends largely on the average number of syllables per word in
that language. &lt;a class="footnote-backref" href="#fnref:speech-tempo" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="blog"></category><category term="Work"></category><category term="Communications"></category><category term="Accessibility"></category></entry><entry><title>Creativity: How we lost it, why that’s bad, and how we get it back</title><link href="https://xahteiwi.eu/blog/2021/11/21/creativity/" rel="alternate"></link><published>2021-11-21T00:00:00+00:00</published><updated>2021-11-21T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-11-21:/blog/2021/11/21/creativity/</id><summary type="html">&lt;p&gt;A summary of how I think we ended up where we are right now, and what we can do to get moving again.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Right now, it’s easy to open a news site and come to the conclusion
that the world as we know it is well and truly fucked. It doesn’t
matter if you’re looking at Covid response, or inaction on climate
change, or corruption, or communications surveillance: it increasingly
looks like we are being governed and managed overwhelmingly by
dunderheads just bumbling along, equipped with less than the most
basic empathy, and lacking the mental faculties required to understand
exponential growth or conditional probability or even percentages. And
people — &lt;em&gt;intelligent&lt;/em&gt; people — are seriously pondering the situation
with utter befuddlement: how the hell did we get here?&lt;/p&gt;
&lt;p&gt;The German writer &lt;a href="https://de.wikipedia.org/wiki/Maximilian_Buddenbohm"&gt;Max
Buddenbohm&lt;/a&gt;
recently asked his followers a question to that effect &lt;a href="https://twitter.com/Buddenbohm/status/1460124921993084929"&gt;on
Twitter&lt;/a&gt;,
which I am taking the liberty to translate:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Do you have a reflected opinion on why everything is so poorly
organized, as in at its core? Historically or sociologically, what’s
the real principal reason? How did this happen?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now it’s perhaps a bit amusing and stereotypically German to complain
of &lt;span class="fraktur"&gt;ſchlechte Organiſation!&lt;/span&gt; in
the middle of a pandemic and global climate cataclysm, but the
sentiment behind the question is sound: it looks as though at every
twist and turn, those empowered to make any kind of decision make the
wrong one, or none at all, or — the worst — aren’t even able to come
up with sensible &lt;em&gt;options&lt;/em&gt; between which to choose.&lt;/p&gt;
&lt;p&gt;And I have a hypothesis: I think the issue at the core of why
everything appears to be going down the tubes is that &lt;strong&gt;we have
systematically drummed creativity out of people,&lt;/strong&gt; for at least fifty
years. And as a result, we collectively have no idea how we can get
ourselves out of a rut.&lt;/p&gt;
&lt;p&gt;Let me swiftly explain what I mean by “creativity.”&lt;/p&gt;
&lt;p&gt;The wonderful &lt;a href="https://en.wikipedia.org/wiki/Ken_Robinson_(educationalist)"&gt;Sir Ken
Robinson&lt;/a&gt;,
who left us much too soon in 2020, described creativity as “the
process of having original ideas that have value.” And in arguing for
the value of creativity, we don’t need to get all hippy-touchy-feely:
creativity — and &lt;em&gt;teaching and learning&lt;/em&gt; creativity — is a simple
economic necessity that is also essential to our survival as a
species.&lt;/p&gt;
&lt;p&gt;If we have no idea what our world will look like ten years — or even
ten &lt;em&gt;months&lt;/em&gt; — from now, then how the hell is any “hard skill” we
acquire today &lt;em&gt;guaranteed&lt;/em&gt; to be useful in future challenges? The
paramount faculty we need to acquire, train, and nurture is the
ability to come up with flexible, intelligent, &lt;em&gt;creative&lt;/em&gt; solutions to
the problems we’ll encounter tomorrow.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;And this we haven’t been doing. From an early age onwards, generation
after generation has been schooled in “the right way” to do things.
And since “the right way” exists only for things we already know, we
are now ensnared in a trap called conformity that is no good at all in
the present situation where so many of us are confronted with things we
haven’t a clue about.&lt;/p&gt;
&lt;p&gt;To illustrate what I mean, allow me to offer an anecdote from my own
personal family experience. When my son, who is now nearly an adult,
was a nine-year-old pupil in his fourth year of primary schooling, he
started to be tasked with writing little stories — it would be an
exaggeration to call them “essays” at that point — in school. And,
given the fact that he was quite an imaginative kid, the first couple
of stories he wrote were truly charming and delightful. But after a
few weeks, something strange happened: his stories were getting rather
bland and boring, and were hardly a reflection of his vivid
imagination anymore. So as his parents, we gently queried about this
mysterious phenomenon — and he was quite happy and forthcoming to
explain the reason. He had observed, he informed us, that the fellow
pupils of his that had got good marks and the teacher’s appreciation
on the first stories they had written were the ones that had turned in
the writing with the fewest spelling and grammar mistakes. And
apparently he resolved then and there to henceforth only turn in
stories that were composed of sentences strung together from words he
already knew how to spell, using constructions that he was already
familiar with — and that he was thus unlikely to stuff up. Of course
that made &lt;em&gt;reading&lt;/em&gt; the stories about as exciting as watching paint
dry, but it kept the teacher happy and thus, off his back.&lt;/p&gt;
&lt;p&gt;And I can attest that this very much goes for my own schooling as
well. It doesn’t matter if we’re talking about my German classes or
English classes or French classes, “correctness” always prevailed over
originality or wit or creativity. I don’t mean to insinuate that
clever writing should get you a free pass to absolutely butcher your
spelling and grammar, but then on the other hand perfect orthography
and punctuation did always make up for abject boredom, and that’s not
quite right either. And this wasn’t restricted to just language
classes: in maths exams there was no extra credit to be had for
arriving at the correct solution of a problem in a novel or
unconventional way. Nay, such brazen nonconformity would net you
either a reprimand from the teacher for not showing the correct &lt;em&gt;path&lt;/em&gt;
to the solution, or at least a snide remark of the “oh you think
you’re very clever don’t you, now sit down and behave” type.&lt;/p&gt;
&lt;p&gt;My English and French and German teachers appear to have been unaware
of &lt;em&gt;another&lt;/em&gt; fact related to their institutional correctness
obsession. Consider this: people who actually make a living from
writing — no matter if it’s fiction or non-fiction — tend to work with
&lt;em&gt;editors,&lt;/em&gt; people whose calling it is to not only correct issues with
orthography or punctuation, but also to helpfully point out plot holes
and suggest the occasional rewrite of dialogue or rearrangement of
chapters. Editors are highly respected by writers and instrumental to
the success of a book but yet, strangely, these people’s names are
normally not printed in bold letters across the book cover, and they
also don’t appear in best seller lists. If my language teachers had
been correct, editors should be celebrity superstars! And they should
hold far greater prestige than the silly authors who only come up with
the storylines but regularly struggle with the placement of a
semicolon.&lt;/p&gt;
&lt;p&gt;And the problem with the idea that errors are awful, and the fact that
that idea is being hammered into our heads from an early age, is that
this has a devastating effect on our creative imagination:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I don’t mean to say that being wrong is the same thing as being
creative. What we do know is: if you’re not prepared to be wrong,
you’ll never come up with anything original.&lt;/p&gt;
&lt;p&gt;— Ken Robinson, “&lt;a href="https://www.ted.com/talks/sir_ken_robinson_do_schools_kill_creativity"&gt;Do schools kill
creativity?&lt;/a&gt;”
(2006)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So, if you want people to be boring and dull and utterly devoid of
originality, then foster a culture where being error-free is
paramount.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;In the business world, some tend to look down on others who have a
tenuous relationship with spelling and grammar and punctuation,
chiding such deficiencies as “unprofessional.” But at the same time,
it’s commonly accepted to be dragged into a meeting and then forced to
listen to someone drone on for an hour in a narcotic monologue
consisting of the recitation of thirty-four wall-of-text slides with
precisely seven bullet points each, in a ferocious assault on
everyone’s attention and consciousness that gives an overdose of
Valium a run for its money. How, pray tell, is it ever “professional”
to steal people’s precious lifetime by boring them out of their
fucking minds? And yet, this is somehow acceptable behavior in the
world of business.&lt;/p&gt;
&lt;p&gt;Let me add another bit of anecdotal first-hand experience: a few years
ago when I was making most of my living as a travelling technical
consultant, I was often brought in to help a team of engineers chart a
path for solving a particular problem using one of the technologies I
knew a little bit about. And in doing so, some decisions frequently
boiled down to two choices, which I was always happy to lay out in
detail: here is option A, it comes with these advantages and
disadvantages, and here’s option B, it comes with &lt;em&gt;those&lt;/em&gt; advantages
and disadvantages. And I would explain to my client that it is now
their &lt;em&gt;business&lt;/em&gt; decision to determine whether the pros of A outweigh
the pros of B &lt;em&gt;for their business,&lt;/em&gt; and whether or not they would be
able to live with the cons of whatever option they chose.&lt;/p&gt;
&lt;p&gt;And inevitably, the reactions to this nearly always fell into one of
two categories.&lt;/p&gt;
&lt;p&gt;The first category was gratitude for me having laid out the options
clearly and distilled the pros and cons of each, informed by my
technical expertise on the matter and my understanding of their
situation. And the business decision was either completely obvious to
them, or they appreciated having a good &lt;em&gt;basis&lt;/em&gt; on which to make a
decision, which they resolved to make in the following days or weeks,
presumably after some more empirical, experimental evaluation.&lt;/p&gt;
&lt;p&gt;And the second category was complete confusion on a person’s face,
followed by the exasperated question, “so what do you recommend?” Or,
worse, “what’s the right way?”&lt;/p&gt;
&lt;p&gt;You can probably guess which category of answers was more likely to
come from managers — or “leaders”, as such people like to be called
in a &lt;a href="https://xahteiwi.eu/blog/2019/04/21/non-technical/"&gt;gross exaggeration of their
capabilities&lt;/a&gt;.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;And now imagine someone having gone through a conventional primary and
secondary education, then continued on to university and from there
into business or the law, or maybe the academic Ph.D. track, while in
parallel having risen through the ranks of that cult of rigidity and
conformism called a political party — and ultimately entering
public office.&lt;/p&gt;
&lt;p&gt;On that note, another illustrative anecdote. Not from myself or my
family but still close to home: you may remember how early in the
Covid-19 pandemic in February 2020, the Tyrolean ski resort of
&lt;a href="https://en.wikipedia.org/wiki/Ischgl#COVID-19_pandemic_hotspot"&gt;Ischgl&lt;/a&gt;
became Central Europe’s &lt;a href="https://www.euractiv.com/section/coronavirus/news/ischgl-oesterreichisches-skiparadies-als-corona-hotspot/"&gt;first major infection
hotspot&lt;/a&gt;,
directly linked to at least 600 cases in Austria and more than twice
as many across Europe. (At the time, 1,800 confirmed Covid cases
seemed like a lot. As I write this, we have about 10 times as
many. &lt;em&gt;Per day.&lt;/em&gt;) The universal understanding of the majority of
observers at the time — and today — was that the situation on the
ground had been horribly botched, and that egregious mistakes were
made that greatly facilitated the spread of Covid-19 across Europe.&lt;/p&gt;
&lt;p&gt;The official in charge of public health in the provincial cabinet then
&lt;a href="https://www.derstandard.at/story/2000115833853/alles-richtig-gemacht-entlarvendes-interview-mit-tirolergesundheitslandesrat-tilg-in-der"&gt;went on national news a couple of weeks
later&lt;/a&gt;
to discuss the events. And, despite the repeated questions from the
exasperated interviewer, voiced with increasing levels of disbelief,
the official kept insisting that the authorities had “done everything
right” and were not to be faulted at all for their actions — and
inactions — in this public health emergency.&lt;/p&gt;
&lt;p&gt;And I don’t even think that this was just hubris or an attempted
cover-up. Rather, it’s a symptom of the exact problem I’m trying to
describe. If you’re applying only &lt;em&gt;what you already know&lt;/em&gt; to a
situation that’s never been here before, you’re failing horribly at
dealing with that situation. But if you’ve been conditioned that
applying “the correct solution” is all you’ll ever have to do in life
to succeed, you eventually end up genuinely believing that that’s
enough.&lt;/p&gt;
&lt;p&gt;And that’s how, in the greatest crisis that humanity has faced in
peacetime in over a century, what we’re stuck with are leaders who,
for the most part, have been so thoroughly molded by the perpetual
vicious cycle of conformism that they now operate with the
decisiveness and agility of a herd of mammoths deep-frozen in
permafrost. They are just shockingly ill-equipped to deal with a
global health crisis affecting a closely interconnected
civilization. And the ones that actually used creative ways to &lt;em&gt;get&lt;/em&gt;
to power turn out to be sociopathic one-trick cronies that could not
apply their skills to something useful if their life depended on it.&lt;/p&gt;
&lt;p&gt;It looks as though &lt;em&gt;systematically,&lt;/em&gt; those who have the &lt;em&gt;power&lt;/em&gt; to
make decisions, at all levels — in business, politics, anywhere —
frequently lack the intellectual, emotional, and empathetic
&lt;strong&gt;creative&lt;/strong&gt; capabilities required to make those decisions. This is
not to say that exceptions to this rule don’t exist — I’m lucky enough
to live in a town where officials from the mayor on down have been
exceptionally creative, empathetic, &lt;em&gt;and successful&lt;/em&gt; in their Covid
response, for example — but I would argue that the rule does stand.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;Now, it would be entirely fair to counter my arguments with the
observation that surely, in the say 1950s or 1930s or 1910s schooling
and education were still more rigid than they are today, and certainly
did not allow for &lt;em&gt;more&lt;/em&gt; creative freedom than they do now. And that
is certainly true, but there is something that children (at least
those lucky enough to &lt;em&gt;go&lt;/em&gt; to school, I am aware that for those who
spent their childhood toiling in the fields or coal mines it was an
entirely different story) had during their schooling in those days
that is a precious rarity today: time and space to let their mind
play.&lt;/p&gt;
&lt;p&gt;John Cleese writes in his &lt;a href="https://www.goodreads.com/en/book/show/50719532-creativity"&gt;excellent book on
creativity&lt;/a&gt;
that &lt;em&gt;mental play&lt;/em&gt; — the ability to let your mind wander and thereby
become open to developing new ideas — is a key element of the creative
process. And this is by no means limited to music or literature or the
arts; some of the examples he lists of mental playfulness leading to
groundbreaking new ideas are from the world of science. Now, it is
essential to be able to keep our mind in that state of playfulness for
some time, because it takes a little while for new ideas to pop into
our head. And so, Cleese observes:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The greatest killer of creativity is interruption. It pulls your
mind away from what you want to be thinking about. [...] It might be
an interruption from outside, like someone coming over and talking
to you, or an email popping up in your inbox. Or it may come from
inside, as when you suddenly remember something you’ve forgotten to
do, or worry that time is running out, or that you don’t think
you’re clever enough to solve whatever problem it is you’re trying
to deal with.&lt;/p&gt;
&lt;p&gt;— John Cleese, “Creativity: A Short and Cheerful Guide” (2020)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And this is the bit that’s incredibly difficult to achieve for most
people born after about 1970, and many born earlier too. That includes
any child alive today, but also their parents and many of their
grandparents. We are &lt;em&gt;constantly&lt;/em&gt; dealing with outside interruptions,
many of them coming from a device we carry in our pockets all day. We
have to fight for our uninterrupted mental play time. A child in the
1950s might just run off to play with friends for the afternoon, and
return home for supper. Without a text from a parent or a snapchat
message from the school bully rudely interrupting halfway
through. It’s perhaps no coincidence that some of those 1950s children
ended up being
&lt;a href="https://en.wikipedia.org/wiki/John_Aaron"&gt;26-year-olds&lt;/a&gt; who could
figure out powering up a disabled spacecraft while it’s on a
free-return trajectory around the Moon, saving the life of a three-man
crew in the process.&lt;/p&gt;
&lt;p&gt;There’s more evidence that even in the world of engineering, allowing
your mind to let go for a bit can lead to creative breakthroughs: &lt;a href="https://appel.nasa.gov/2010/09/20/jim-crocker-on-systems-engineering/"&gt;Jim
Crocker&lt;/a&gt;
was the Ball Aerospace engineer who solved the problem of how exactly
the &lt;a href="https://en.wikipedia.org/wiki/Corrective_Optics_Space_Telescope_Axial_Replacement"&gt;corrective
optics&lt;/a&gt;
on the Hubble Space Telescope should be installed — obviously not a
scenario that anyone accounted for in Hubble’s design.  The ingenious
idea that ended up saving Hubble from being a multibillion dollar
boondoggle &lt;a href="https://www.ball.com/aerospace/newsroom/features/genius-at-work"&gt;came to him in the
shower&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Also, in offices in which we worked with maybe one other colleague in
the room, we had stretches of time where the other person was off
running an errand in town or taking a meeting in a conference
room. And you could close the door and put up a “do not disturb” sign
and do some uninterrupted thinking.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;Around the year 2000, most of that started to change, dramatically.
Open-plan offices, which of course were allegedly introduced to
“facilitate cooperation,” eliminated any room for uninterrupted mental
play at work. Emails replaced typed and printed memos, office workers
transitioned from workstations to laptops. Pagers and cell phones
started to buzz people at home. Around 2010 we progressed to smart
phones, tablets and other portable devices that had the ability to
ping us out of playful thought with an audible notification at any
time of day. &lt;em&gt;Knowledge work became interrupt-driven&lt;/em&gt; — a sentence
that in itself should make anyone shudder that knows anything about
knowledge work at all.&lt;/p&gt;
&lt;p&gt;And it’s no surprise that people who rose to corporate leadership
after being imprinted by an interrupt-driven lifestyle — that is,
people now in their 50s — think that such a thing is &lt;em&gt;normal,&lt;/em&gt; and try
to impress the same thing on their subordinates. That’s how you get to
Slack-driven companies. That’s how you end up in a culture where
people are proud of getting back to any email within 30 minutes (or
less), and expecting the same from everyone. That’s how you end up
with managers who take being signed into a chat (and thereby
&lt;em&gt;constantly&lt;/em&gt; listening for interruptions) as a measure of being
“active”, so much so that they &lt;a href="https://twitter.com/pleia2/status/1456629767743016966"&gt;end up tracking metrics for
it&lt;/a&gt;, and of
course also &lt;a href="https://xahteiwi.eu/blog/2021/11/14/meaningless-metrics-treacherous-targets/"&gt;making it a
target&lt;/a&gt; they
call “engagement” or some other abomination.&lt;/p&gt;
&lt;p&gt;Organizations that do that are at risk of constantly shutting down
creativity, problem-solving, and innovation. What they’re good for is
developing efficient cookie-cutter techniques for optimizing solutions
for &lt;em&gt;yesterday’s&lt;/em&gt; issues. What we need &lt;em&gt;today&lt;/em&gt; — in a global pandemic,
and in the roiling climate crisis that’ll make this pandemic look like
a walk in the park — is people and organizations equipped with the
mindset for the issues of &lt;em&gt;tomorrow.&lt;/em&gt; And a first imperative for
making that happen is to &lt;strong&gt;let people think.&lt;/strong&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;So is everything all doom and gloom? I’d say it isn’t, and there are
indeed some things that make me hopeful. Some of those are related to
a changed approach to creativity in education, some, to a changing
approach to work.&lt;/p&gt;
&lt;p&gt;For example, in my country as of a few years ago it is indeed such
that creativity and originality are accorded at least &lt;em&gt;some&lt;/em&gt; merit in
marking and grading standards. And this is at the secondary school
level, traditionally one of the most rigid and unchanging branches of
education where I live. Much more still is happening at the primary
and preschool level, where I see &lt;em&gt;much&lt;/em&gt; more emphasis on thinking,
creative play, and innovation in my younger kids’ education than I did
in my older ones’.&lt;/p&gt;
&lt;p&gt;And then, there’s the big push towards asynchronous distributed work —
where obviously the &lt;em&gt;asynchronous&lt;/em&gt; part is the bit that matters. Sure,
&lt;a href="https://xahteiwi.eu/blog/2021/10/23/make-my-company-distributed/"&gt;companies suffering from &lt;em&gt;offissification&lt;/em&gt;&lt;/a&gt;
still exist, but for a while, &lt;a href="https://en.wikipedia.org/wiki/Dodo"&gt;so did
dodos&lt;/a&gt;. But an ever-increasing
share of humanity is beginning to understand what it’s like when
you’re no longer shackled to seventeen Slack channels you constantly
need to watch, when you can take a walk in the middle of the day
because you know it’s OK to push something off for an hour to clear
your head and come up with an idea, and when instead of spending an
hour in a meeting &lt;a href="https://xahteiwi.eu/blog/2021/10/27/this-meeting-should-have-been-an-email/"&gt;you can spend 5 minutes reading a memo and use the
other 55 minutes for
thinking&lt;/a&gt;.  And
that’s where things get interesting.&lt;/p&gt;</content><category term="blog"></category><category term="Work"></category><category term="Communications"></category></entry><entry><title>Meaningless Metrics, Treacherous Targets</title><link href="https://xahteiwi.eu/blog/2021/11/14/meaningless-metrics-treacherous-targets/" rel="alternate"></link><published>2021-11-14T00:00:00+00:00</published><updated>2021-11-14T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-11-14:/blog/2021/11/14/meaningless-metrics-treacherous-targets/</id><summary type="html">&lt;p&gt;A quick introduction to Goodhart, Strathern, Campbell, Yankelovich, and McNamara.&lt;/p&gt;</summary><content type="html">&lt;p&gt;A common feature of organizations in the software technology industry
(but certainly not &lt;em&gt;only&lt;/em&gt; in that industry) is their fixation on
metrics, measurements, and quantifiers. I understand that this is
frequently done and advocated for in the spirit of making management
more objective, less arbitrary, more scientific, and perhaps
fairer. But since they say that the road to hell is often paved with
good intentions, here's a quick summary of what we know about about
the undesirable side effects of such an approach.&lt;/p&gt;
&lt;h2&gt;Goodhart’s Law&lt;/h2&gt;
&lt;p&gt;British economist &lt;a href="https://en.wikipedia.org/wiki/Charles_Goodhart"&gt;Charles
Goodhart&lt;/a&gt; wrote in
1975, in an article about British monetary policy:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Any observed statistical regularity will tend to collapse once
pressure is placed upon it for control purposes.&lt;/p&gt;
&lt;p&gt;— Charles Goodhart, “Problems of Monetary Management: the
U.K. Experience” (1975)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That's a mouthful of somewhat niche technical jargon, but let me try
to paraphrase it like this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You collect some data.&lt;/li&gt;
&lt;li&gt;You crunch the numbers using statistics.&lt;/li&gt;
&lt;li&gt;You observe a pattern.&lt;/li&gt;
&lt;li&gt;You distill a value (a “statistical regularity”) from it.&lt;/li&gt;
&lt;li&gt;Someone decides that that value should change: it is too high or too
  low.&lt;/li&gt;
&lt;li&gt;Someone — an individual or a group — is tasked with bringing that
  value up or down, and then keeping it high or low, or rising or
  falling, or above or below a particular threshold.&lt;/li&gt;
&lt;li&gt;That value now is no longer a useful statistical indicator.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What you &lt;em&gt;probably&lt;/em&gt; knew as &lt;em&gt;Goodhart's Law&lt;/em&gt; if you'd heard about it
prior to reading this article is a generalization by anthropologist
&lt;a href="https://en.wikipedia.org/wiki/Marilyn_Strathern"&gt;Marilyn Strathern&lt;/a&gt;,
also from the UK:&lt;sup id="fnref:why-goodhart"&gt;&lt;a class="footnote-ref" href="#fn:why-goodhart"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;When a measure becomes a target, it ceases to be a good measure.&lt;/p&gt;
&lt;p&gt;— Marilyn Strathern, “&lt;a href="https://archive.org/details/ImprovingRatingsAuditInTheBritishUniversitySystem"&gt;'Improving ratings': audit in the British
University
system&lt;/a&gt;”
(1997)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Why is that so? It’s because once you make the measure a target that
has an influence on people (for example, meeting it gets them a bonus,
failing at it gets them a demotion), you have wired them to improve
&lt;em&gt;the measure,&lt;/em&gt; and not necessarily to improve the underlying
conditions that the measure originally arose from. Therefore, they
might opt for gaming the measure, because that gets them to their goal
(a promotion, for example) more quickly and at less effort to them.&lt;/p&gt;
&lt;p&gt;Furthermore, even keeping the option of fudging the numbers aside:
when faced with a choice between doing something that might have a
negative effect on the measure and something else that might have a
negative effect on something &lt;em&gt;other than&lt;/em&gt; the measure, people will
tend to choose the latter. This may lead to situations where people
&lt;em&gt;avoid&lt;/em&gt; an activity with &lt;em&gt;significant&lt;/em&gt; inherent value, just to avoid
depressing a measurement — a concept known as &lt;em&gt;creaming.&lt;/em&gt;&lt;sup id="fnref:creaming"&gt;&lt;a class="footnote-ref" href="#fn:creaming"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;For example, a hospital may be interested in measuring individual
surgeons’ intraoperative death rates: the percentage of a surgeon’s
patients that die in the middle of surgery. On its face, this metric
could help weed out bad surgeons. If a particular surgeon is an
outlier and has &lt;em&gt;way more&lt;/em&gt; patients dying on their operating table
than their peers, it’s possible that that surgeon might be doing
something wrong: they could be incompetent, or frequently intoxicated,
or even be a &lt;a href="https://en.wikipedia.org/wiki/Dr._Death"&gt;Dr. Death&lt;/a&gt; type
serial killer.&lt;/p&gt;
&lt;p&gt;It gets tricky, though, when in the interest of transparency the
hospital doesn’t just fire or retrain incompetent surgeons which it
identifies based on such statistics, but when it “publishes” the
patient mortality data. (I use quotes here because this does not
necessarily mean sharing it with the general public, but perhaps
sharing it with all of the surgical staff.) At that stage, an
individual surgeon's &lt;em&gt;rank&lt;/em&gt; in the statistics will become at least a
matter of pride, status, and prestige, even if it’s not otherwise
rewarded in any way, nor seen as a precondition for continued
employment.&lt;/p&gt;
&lt;p&gt;This, then, will incentivize surgeons to &lt;em&gt;avoid&lt;/em&gt; taking on risky
surgeries where there is a significant chance of the patient dying
mid-surgery — surgeries typically &lt;em&gt;attempted&lt;/em&gt; in the first place to
save the patient’s life, in the course of an immediate major
emergency. Thus, Dr. Alpher who only ever treats torn knee ligaments
might look better in the ranking than Dr. Bethe the polytrauma
specialist, or Dr. Gamow the neurosurgeon who specializes in
particularly challenging malignant brain tumor removal. If there is a
non-negligeable risk of intraoperative death for a particular brain
cancer patient and such an event would be bad for Dr. Gamow’s ranking,
then Dr. Gamow might have an incentive to declare that patient
inoperable — and as a result the patient would &lt;em&gt;certainly&lt;/em&gt; die, just
not in surgery.&lt;sup id="fnref:tyranny"&gt;&lt;a class="footnote-ref" href="#fn:tyranny"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h2&gt;Campbell's Law&lt;/h2&gt;
&lt;p&gt;Although less well known than Goodhart’s law, Campbell’s law is
closely related and, in my humble opinion, just as important.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Donald_T._Campbell"&gt;Donald
T. Campbell&lt;/a&gt;, a
U.S.-based social scientist, wrote in 1976, on the subject of
standardized testing in education:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The more any quantitative social indicator is used for social
decision-making, the more subject it will be to corruption pressures
and the more apt it will be to distort and corrupt the social
processes it is intended to monitor.&lt;/p&gt;
&lt;p&gt;[...]&lt;/p&gt;
&lt;p&gt;Achievement tests may well be valuable indicators of general school
achievement under conditions of normal teaching aimed at general
competence. But when test scores become the goal of the teaching
process, they both lose their value as indicators of educational
status and distort the educational process in undesirable ways.&lt;/p&gt;
&lt;p&gt;— Donald T. Campbell, “Assessing the impact of planned social
change” (1976)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In other words, if you conduct a one-time evaluation of student
achievement across many students in multiple schools, then the fact
that the test is standardized might help in achieving comparable
results. However, as soon as you make the tests a repeat occurrence,
and tie students’ test results to school funding allocations, teacher
salaries, or even just school prestige, you’re undermining their
original purpose: teachers will now spend a significant portion of
their time and effort to ensure that students &lt;em&gt;score well on the
test&lt;/em&gt;, rather than build the competence that the test was originally
designed to measure.&lt;/p&gt;
&lt;p&gt;This is an example of allocating resources (teacher and student time
and effort) to an activity with no inherent value (taking a
standardized test) just to improve a measurement (the test score). And
since the resources are finite, spending them on the activity with no
inherent value (test-taking) makes less of them available to the
inherently valuable activity the indicator is intended to assess
(teaching and learning). This is the “corruption and distortion”
Campbell talks about.&lt;/p&gt;
&lt;h2&gt;The McNamara Fallacy, and the Yankelovich Ladder&lt;/h2&gt;
&lt;p&gt;Closely related to Goodhart’s, Strathern’s and Campbell’s observations
is something called the McNamara Fallacy.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Robert_McNamara"&gt;Robert McNamara&lt;/a&gt;,
U.S. Secretary of Defense during much of the Vietnam war, infamously
believed that he could scientifically measure the progress of the war
by quantitative indicators alone. One of his favourites was &lt;em&gt;body
count,&lt;/em&gt; the number of enemy personnel killed, in comparison to
friendly casualties. The rationale appears to have been, whatever
other factors (qualitative or quantitative) are in play, whichever
side kills more of the other wins the war. Indeed he seems to have
been inclined towards ignoring all non-quantitative indicators of how
the war was going.&lt;/p&gt;
&lt;p&gt;An anecdote
&lt;a href="https://en.wikipedia.org/wiki/McNamara_fallacy#The_Vietnam_War"&gt;told&lt;/a&gt;
by U.S. Air Force general &lt;a href="https://en.wikipedia.org/wiki/Edward_Lansdale"&gt;Edward
Lansdale&lt;/a&gt; alleges that
he (Lansdale) pointed out to McNamara in a briefing that McNamara,
when assessing the progress of the war, failed to take into account
the feelings of the common rural Vietnamese people. McNamara then
allegedly wrote an item saying “feelings of the Vietnamese people” on
his list of things to keep track of in pencil, pondered it for a
moment, and then erased it — reasoning to Lansdale that feelings
cannot be measured, thus must not be important.&lt;sup id="fnref:lansdale"&gt;&lt;a class="footnote-ref" href="#fn:lansdale"&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;This is step 3 on a progressive scale social scientist &lt;a href="https://en.wikipedia.org/wiki/Daniel_Yankelovich"&gt;Daniel
Yankelovich&lt;/a&gt;
described a few years later:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The first step is to measure whatever can be easily measured. This
  is OK as far as it goes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The second step is to disregard that which can’t be easily
  measured or to give it an arbitrary quantitative value. This is
  artificial and misleading.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The third step is to presume that what can’t be measured easily
  really isn’t important. This is blindness.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The fourth step is to say that what can’t be easily measured
  really doesn’t exist. This is suicide.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;— Daniel Yankelovich, “Corporate Priorities: A continuing study of
the new demands on business” (1972).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And it’s somewhat remarkable just how often businesses and
organizations fall into this trap, fifty years later. They might not
end up at step 4, but falling for step 2 or 3 is bad enough.&lt;/p&gt;
&lt;h2&gt;An applied example&lt;/h2&gt;
&lt;p&gt;Let’s now turn to an example from our industry. Something that’s so
important, evidently, that it has given rise to a whole discipline in
our field: &lt;em&gt;site reliability.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Now it’s perhaps a bit amusing that although you can find myriads of
articles describing what &lt;em&gt;site reliability engineering&lt;/em&gt; (SRE) is, a
definition of “site reliability” lives only in a small footnote of the
&lt;a href="https://sre.google/sre-book/preface/#id-gA2u2Iyh4"&gt;Google SRE Book&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For our purposes, reliability is “The probability that [a system]
will perform a required function without failure under stated
conditions for a stated period of time”.&lt;/p&gt;
&lt;p&gt;— Betsy Beyer, Chris Jones, Jennifer Petoff, Niall Murphy, “Site
Reliability Engineering: How Google Runs Production Systems”
(2017)&lt;sup id="fnref:oconnor"&gt;&lt;a class="footnote-ref" href="#fn:oconnor"&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;But, at least there &lt;em&gt;is&lt;/em&gt; a definition, which is good. Now I think it’s
reasonable to say that the following two statements &lt;em&gt;about&lt;/em&gt; site
reliability are probably true:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;In keeping with SRE reflecting a holistic approach to engineering,
   trying to unify a multitude of considerations, site reliability is
   not something we can judge by a single, numerical, universal, and
   useful metric. You can’t measure a single “site reliability score”,
   and then compare hundreds of platforms based on that.&lt;sup id="fnref:score"&gt;&lt;a class="footnote-ref" href="#fn:score"&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Whatever site reliability &lt;em&gt;is&lt;/em&gt; as a whole, it certainly &lt;em&gt;includes&lt;/em&gt;
   a site’s ability to process your data and not mangle it. So, if you
   upload your data into a platform, you want to be able to do
   something useful with it.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;SRE tends to rely on &lt;em&gt;&lt;a href="https://sre.google/sre-book/service-level-objectives/#indicators-o8seIAcZ"&gt;service level
indicators&lt;/a&gt;&lt;/em&gt;
(SLIs) to measure compliance with service level agreements (SLAs),
manage error budgets, and generally keep track of what shape the
site/platform is in.&lt;/p&gt;
&lt;p&gt;So, let’s compare two indicators that differ greatly in their
measurability.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Availability&lt;/em&gt; is exceptionally easy to measure for, say, a REST
   API. You send a request with a defined payload, you measure the
   time it takes to serve your request, you check the status code, you
   check whether the response contains what you expect, and you record
   a data point.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Durability&lt;/em&gt; is &lt;em&gt;much&lt;/em&gt; more difficult to measure at any given point
   in time. Effectively, to properly take a data point for durability
   at the same time as getting one for availability, you’d have to
   read back some data you wrote, say, a year ago, and check its
   content against something like a known hash.&lt;sup id="fnref:hash"&gt;&lt;a class="footnote-ref" href="#fn:hash"&gt;7&lt;/a&gt;&lt;/sup&gt; &lt;em&gt;And also&lt;/em&gt; write some
   data now, travel a year into the future, read it back at that
   point, travel back into the present,&lt;sup id="fnref:timetravel"&gt;&lt;a class="footnote-ref" href="#fn:timetravel"&gt;8&lt;/a&gt;&lt;/sup&gt; and record your
   data point.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now before I continue I’d like to inject another thought to the issue
of data durability: not every platform is a storage solution. In other
words, you don’t always have the option of reading your data back
verbatim. Say for example you’re feeding an inordinate number of data
points into a platform that ingests and aggregates them. You may not
even be interested in the original data some months or years down the
road, so it might be acceptable (and even necessary, as dictated by
cost concerns) to discard the original data immediately after it has
been processed. And that rules out the possibility (or necessity) to
ever read it back exactly as it went in. But you &lt;em&gt;will&lt;/em&gt; be interested
in the statistics that you generate based on the aggregated data.&lt;/p&gt;
&lt;p&gt;And now suppose there is a subtle bug in the &lt;em&gt;implementation&lt;/em&gt; of the
aggregation algorithm. As in, the algorithm itself is perfectly fine,
but there’s a flaw in the implementation. That, too, may render part
of your data unusable or outright invalid, violating data integrity
and durability.&lt;/p&gt;
&lt;p&gt;But the tricky part here is that availability is easy to
measure. &lt;a href="https://www.theregister.com/2018/07/19/data_durability_statements/"&gt;Data durability
isn’t&lt;/a&gt;. Therefore,
availability lends itself to becoming a target (hello, Professor
Strathern), and durability tends to be seen as difficult to measure
and hence less important (hello, Secretary McNamara).&lt;/p&gt;
&lt;p&gt;So now, if you find yourself in charge of a system that you &lt;em&gt;suspect&lt;/em&gt;
has started to corrupt a significant fraction of customer data, data
which customers are pouring into it at an alarming rate, what do you
do?  You’re not sure whether there’s actual corruption yet. The proper
thing to do, if it’s impossible to rule out or fix the data corruption
problem immediately,&lt;sup id="fnref:immediately"&gt;&lt;a class="footnote-ref" href="#fn:immediately"&gt;9&lt;/a&gt;&lt;/sup&gt; is probably to stop intake, and
also ensure that no requests are served that may touch potentially
corrupted data — that is, shut the service down even before you’ve
ascertained corruption. But if you suspect that your next bonus payout
or promotion may rely on you meeting your availability goals, and you
know you’re already shaving it close with your availability error
budget, would you really be inclined to do that?&lt;/p&gt;
&lt;h2&gt;“You can’t manage what you don’t measure”&lt;/h2&gt;
&lt;p&gt;There’s a popular saying in management circles that takes one of the
following forms:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;“If you can’t measure it, you can’t manage it.”&lt;/li&gt;
&lt;li&gt;“You can’t manage what you don’t measure.”&lt;/li&gt;
&lt;li&gt;“You can’t manage what you &lt;em&gt;can’t&lt;/em&gt; measure.”&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Whichever variant you discuss, it is commonly attributed to either
Austrian-American management thinker &lt;a href="https://en.wikipedia.org/wiki/Peter_Drucker"&gt;Peter
Drucker&lt;/a&gt;, or to American
engineer and statistician &lt;a href="https://en.wikipedia.org/wiki/W._Edwards_Deming"&gt;William Edwards
Deming&lt;/a&gt;. Drucker is
seen by many as highly influential in management theory, Deming
developed groundbreaking sampling techniques used on the massive scale
of the United States census. So either of them would be an authority
on management and measurement, lending high credibility to the
statement. &lt;/p&gt;
&lt;p&gt;There’s just a small problem: neither of them appears to ever have
said or written anything to that effect.&lt;/p&gt;
&lt;p&gt;The closest that &lt;a href="https://deming.org/myth-if-you-cant-measure-it-you-cant-manage-it/"&gt;one of them, Deming, ever
wrote&lt;/a&gt;
was:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It is wrong to suppose that if you can’t measure it, you can’t
manage it — a costly myth.&lt;/p&gt;
&lt;p&gt;—  W. Edwards Deming, “The New Economics for Industry, Government,
Education” (1993)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In case you didn’t notice, the point this makes is &lt;em&gt;the exact
opposite&lt;/em&gt; of the popular version of the quote. It’s so wrong that it
comes close to the corruption of the
&lt;a href="https://en.wikipedia.org/wiki/Seneca_the_Younger"&gt;Seneca&lt;/a&gt; lament, “non
vitæ sed scholæ discimus”, “we learn not for life but for school,” of
which you surely learned the inverse... in school.&lt;/p&gt;
&lt;p&gt;Metrics-obsessed managers often take the misquote for gospel. So much
so that they frequently see issues where a qualitative approach is
obviously necessary, and they still try to apply quantification. &lt;/p&gt;
&lt;p&gt;My standard example for this are employee satisfaction surveys.&lt;/p&gt;
&lt;p&gt;Ultimately, what leadership should be interested in learning from
those surveys is how good people feel about working in the
company. There are a number of factors that contribute to this: are
they overloaded, well utilized, or bored? Are people treating each
other with respect and kindness, or malice and contempt? Does everyone
feel that they are doing something meaningful, or do they all hate
their work and are solely in for the money? All these things are
inherently qualitative. And the company could do a great job by hiring
a person trained in sociology or psychology, who sits down with people
for confidential qualitative interviews, and then prepares a
research report with findings and recommendations that management can
act on.&lt;/p&gt;
&lt;p&gt;But no, we have to measure. Make everyone take an online survey where
they rate everything on a scale of 1 to 5. Do you know what that is?
Exactly, step 2 on the Yankelovich ladder. Give that what can’t easily
be measured an arbitrary quantitative value — because that’s what it
is, arbitrary. People from different cultures won’t agree even on what
&lt;a href="https://measuringu.com/scales-cultural-effects/"&gt;a simple 5-step scale really
means&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;And depending on &lt;em&gt;what&lt;/em&gt; version of the faux quote they adhere to, a
manager may even be farther up the ladder:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If they say “you can’t manage what you &lt;em&gt;don’t&lt;/em&gt; measure” (with the
  translation being “I won’t concern myself with anything for which I
  don’t have quantitative data”): that’s step 3, blindness, that which
  isn’t measured isn’t important.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If they insist that “you can’t manage what you &lt;em&gt;can’t&lt;/em&gt; measure”
  (with the translation being “I won’t concern myself with anything
  that isn’t quantifiable”): that’s step 4 (suicide), that which isn’t
  measured doesn’t exist.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;So, what now?&lt;/h2&gt;
&lt;p&gt;Every article and book on bad metrics ends on a positive note, giving
you suggestions for “good” metrics: for example, make them hard to
game, make sure they are defined by competent experts, ensure that
they are in line with inherent ideas of respectability and
professionalism. Honestly, I’ve yet to come across a metric that ticks
all these boxes.&lt;sup id="fnref:game"&gt;&lt;a class="footnote-ref" href="#fn:game"&gt;10&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;So, I am aware that if you are running a platform under an existing
SLA, you &lt;em&gt;will&lt;/em&gt; be running under some metrics of questionable utility
that you cannot get rid of — just because they happen to be industry
standards.&lt;/p&gt;
&lt;p&gt;However, instead of expanding metrics obsession to your entire
organization by introducing ever more counterproductive metrics, I
want to propose a different approach:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Whatever you measure, make the &lt;em&gt;marginal&lt;/em&gt; cost of a measurement
   negligeable.&lt;sup id="fnref:marginal"&gt;&lt;a class="footnote-ref" href="#fn:marginal"&gt;12&lt;/a&gt;&lt;/sup&gt; The cost of adding a new metric should be
   practically zero. The moment someone has to repeatedly spend time
   on collecting and compiling the data, they can’t spend that time on
   doing productive work (and Campbell says hi), so you want to avoid
   that.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;This effectively means that all the systems you care about
   (machines, services, applications) should generate collectable data
   points, everywhere, all the time.&lt;sup id="fnref:privacy"&gt;&lt;a class="footnote-ref" href="#fn:privacy"&gt;11&lt;/a&gt;&lt;/sup&gt; And you probably won’t be
   collecting metrics from anything else. In other words, you are
   &lt;em&gt;just&lt;/em&gt; measuring that which is easily measurable, and you keep
   aware that there a lot of things you don’t measure that are just as
   important. You stay on step one of the Yankelovich ladder.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Now, I’d propose you make the data thus ingested available throughout
   your organization, in machine-readable form and using standardized
   APIs. You want people to actually &lt;em&gt;discover&lt;/em&gt; things from your data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Encourage people to use real, scientific, statistical methods to
   figure out statistical regularities (“indicators”). Offer
   statistics training to people who are interested.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Once someone identifies a statistical regularity, encourage them to
   form an opinion of whether it would be beneficial for it to go up
   or down, formulate a hypothesis on what change to your system would
   have the desired effect, and conduct an experiment. If the
   experiment has no effect, roll back the change and proceed with the
   next hypothesis. If it has an adverse effect, roll back and try the
   opposite. If it has the desired effect, keep the change. Move on to
   discovering the next regularity. Resist the urge to make the
   discovery a target. (Otherwise, Strathern will drop
   by.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Constantly observe and identify things that are important, but not
   measurable. Apply qualitative analysis, emotion, and
   empathy. (Otherwise, McNamara will introduce himself.)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So, is there anything inherently wrong with measuring or measurements?
Nope. But making them targets, introducing arbitrary quantifiers, and
ignoring everything else is.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:why-goodhart"&gt;
&lt;p&gt;The reason the condensed version is called
“Goodhart’s Law” and not “Strathern’s Law” is apparently due to a
coinage by British researcher Keith Hoskin, who wrote a year prior
to Strathern, in a paper she cited:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“Goodhart’s Law” — that every measure which becomes a target becomes
a bad measure — is inexorably, if ruefully, becoming recognized as
one of the overriding laws of our time.&lt;/p&gt;
&lt;p&gt;— Keith Hoskin, “The ‘awful idea of accountability’: inscribing
people into the measurement of objects” (1996)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a class="footnote-backref" href="#fnref:why-goodhart" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:creaming"&gt;
&lt;p&gt;If you think that term sounds a bit odd, I’d agree. I
guess it comes from the idea of milking a cow and then skimming
only the cream, discarding the rest. &lt;a class="footnote-backref" href="#fnref:creaming" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:tyranny"&gt;
&lt;p&gt;The surgery statistics example of creaming is paraphrased
from Jerry Z. Muller, “&lt;a href="https://press.princeton.edu/books/hardcover/9780691174952/the-tyranny-of-metrics"&gt;The Tyranny of
Metrics&lt;/a&gt;”
(2018). &lt;a class="footnote-backref" href="#fnref:tyranny" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:lansdale"&gt;
&lt;p&gt;The Lansdale/McNamara anecdote is paraphrased from &lt;a href="https://en.wikipedia.org/wiki/McNamara_fallacy"&gt;the
Wikipedia article on the McNamara
Fallacy&lt;/a&gt;, which in
turn cites Rufus Phillips and Richard Holbrooke, “Why Vietnam
Matters: An Eyewitness Account of Lessons Not Learned” (2008) as
its source. &lt;a class="footnote-backref" href="#fnref:lansdale" title="Jump back to footnote 4 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:oconnor"&gt;
&lt;p&gt;It should be noted that the SRE book is itself quoting a
definition of reliability found in Patrick P. O’Connor &amp;amp; Andre
Kleyner, “Practical Reliability Engineering” (2012). &lt;a class="footnote-backref" href="#fnref:oconnor" title="Jump back to footnote 5 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:score"&gt;
&lt;p&gt;The irony is not lost on me that by the definition quoted in
the SRE book, such a score absolutely &lt;em&gt;should&lt;/em&gt; exist if its
definition of reliability were adequate: it claims to be a
probability. Probabilities go from 0 to 1. That would make site
reliability a dimensionless quantity between 0 and 1, end of
story. But it goes without saying that such a score would be “an
arbitrary quantitative value”, which would put it on step 2 of the
Yankelovich ladder. &lt;a class="footnote-backref" href="#fnref:score" title="Jump back to footnote 6 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:hash"&gt;
&lt;p&gt;That hash would have to be separately stored &lt;em&gt;outside&lt;/em&gt; the
system. If the hash is stored &lt;em&gt;alongside&lt;/em&gt; the data whose
integrity it’s meant to protect, then it only guards against
unintentional data corruption, but not against deliberate
manipulation. &lt;a class="footnote-backref" href="#fnref:hash" title="Jump back to footnote 7 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:timetravel"&gt;
&lt;p&gt;I wish to point out that the only bit that’s impossible
here is the backwards time travel. The forwards time travel is
fine, we all travel forwards in time all the time, just at a
constant rate of one second per second. &lt;a class="footnote-backref" href="#fnref:timetravel" title="Jump back to footnote 8 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:immediately"&gt;
&lt;p&gt;I’ve run into a few issues of suspected silent data
corruption in my career and I’ve &lt;em&gt;never&lt;/em&gt; been in the situation
where a reliable fix was available immediately. &lt;a class="footnote-backref" href="#fnref:immediately" title="Jump back to footnote 9 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:game"&gt;
&lt;p&gt;In particular, pretty much any real-world metric fails the
“hard to game” test. Said &lt;a href="https://twitter.com/lukasgrossar/status/1267830321057107969"&gt;Lukas Grossar on
Twitter&lt;/a&gt;:
“It always amazes me that people don’t believe that slapping a KPI
onto something won’t lead to people gaming that KPI. We’re
engineers for God sake, making broken stuff work in our favor is
basically our job description.” &lt;a class="footnote-backref" href="#fnref:game" title="Jump back to footnote 10 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:privacy"&gt;
&lt;p&gt;I’d argue that this requires strong privacy guarantees for
your users/customers. Effectively, just don’t collect data that’s
none of your business. &lt;a class="footnote-backref" href="#fnref:privacy" title="Jump back to footnote 11 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:marginal"&gt;
&lt;p&gt;Emphasis on marginal. It’s obvious that the &lt;em&gt;fixed&lt;/em&gt;
cost of building and maintaining an instrumentation platform and
metric system is nonzero. But once you’ve got it set up, the cost
of &lt;em&gt;adding a new metric&lt;/em&gt; should be substantially zero. &lt;a class="footnote-backref" href="#fnref:marginal" title="Jump back to footnote 12 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="blog"></category><category term="Work"></category><category term="Communications"></category></entry><entry><title>Warnock’s Dilemma, Objections, and Acknowledgements</title><link href="https://xahteiwi.eu/blog/2021/10/30/warnock-dilemma/" rel="alternate"></link><published>2021-10-30T00:00:00+00:00</published><updated>2021-10-30T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-10-30:/blog/2021/10/30/warnock-dilemma/</id><summary type="html">&lt;p&gt;“Warnock’s Dilemma” is a classic feature of distributed, asynchronous, online communications. You can’t avoid it, you can’t work around it, but you can deal with it with two simple changes to your communicative behavior.&lt;/p&gt;</summary><content type="html">&lt;p&gt;People skeptical of distributed, asynchronous, written communications
sometimes make they understandable objection that it is often
difficult to interpret the reactions, specifically the &lt;em&gt;absence of&lt;/em&gt;
reactions, to written online communications. &lt;/p&gt;
&lt;p&gt;The reasoning goes like this: if you inform someone of something in a
face-to-face conversation, there is practically no way for them &lt;em&gt;not&lt;/em&gt;
to provide some sort of feedback. Even if the recipient of a verbal
message doesn’t say a word, they usually exhibit some unconscious,
nonverbal reaction, which can carry a whole load of information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The person might smile, light up, and become actively engaged,&lt;/li&gt;
&lt;li&gt;they might express surprise (pleasant or unpleasant),&lt;/li&gt;
&lt;li&gt;they may show signs of dismay or annoyance, or even anger,&lt;/li&gt;
&lt;li&gt;they might just stare or wander off, indicating disconnection or
  indifference,&lt;/li&gt;
&lt;li&gt;or anything in between.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In online, textual communications, people obviously &lt;em&gt;also&lt;/em&gt; exhibit all
those reactions, sitting at their desk, lounging on their couch,
walking with their phone — it’s just that the sender of the message
usually never gets to see them. &lt;/p&gt;
&lt;p&gt;In addition, a face-to-face conversation is a one-to-one communication
mode that we direct our undivided attention to. In contrast, textual
online communications are often many-to-many, and we usually get many
more parallel inputs than we do when we’re speaking to a colleague or
acquaintance or friend.&lt;/p&gt;
&lt;p&gt;That means that while in a face-to-face conversation we’re &lt;em&gt;always&lt;/em&gt;
answering, or at least showing our reaction to what was said, in online
textual communications we must &lt;em&gt;pick and choose&lt;/em&gt; what to react to, and
what to just absorb without providing any kind of feedback to the
message sender.&lt;/p&gt;
&lt;h2&gt;Warnock’s Dilemma&lt;/h2&gt;
&lt;p&gt;In online communities this has been known since at least 2000, when
Bryan Warnock
&lt;a href="https://www.nntp.perl.org/group/perl.bootstrap/2000/08/msg1127.html"&gt;formulated&lt;/a&gt;
it as “the ostrich theory”, although it eventually &lt;a href="https://www.nntp.perl.org/group/perl.perl6.internals/2001/02/msg2562.html"&gt;was
named&lt;/a&gt;
“Warnock’s Dilemma”&lt;sup id="fnref:pentalemma"&gt;&lt;a class="footnote-ref" href="#fn:pentalemma"&gt;1&lt;/a&gt;&lt;/sup&gt; by Dave Mitchell. Writing about
mailing list posts without replies, Bryan wrote:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The problem with no response is that there are five possible
interpretations:&lt;/p&gt;
&lt;p&gt;1) The post is correct, well-written information that needs no
follow-up commentary.  There's nothing more to say except "Yeah,
what he said."&lt;/p&gt;
&lt;p&gt;2) The post is complete and utter nonsense, and no one wants to
waste the energy or bandwidth to even point this out.&lt;/p&gt;
&lt;p&gt;3) No one read the post, for whatever reason.&lt;/p&gt;
&lt;p&gt;4) No one understood the post, but won't ask for clarification, for
whatever reason.&lt;/p&gt;
&lt;p&gt;5) No one cares about the post, for whatever reason.&lt;/p&gt;
&lt;p&gt;— Bryan Warnock, “&lt;a href="https://www.nntp.perl.org/group/perl.bootstrap/2000/08/msg1127.html"&gt;Re: RFCs: two proposals for
change&lt;/a&gt;”,
perl.bootstrap mailing list, 2000-08-07&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In asynchronous and distributed work communications, we have much the
same issue. The beautifully crafted &lt;a href="https://xahteiwi.eu/blog/2021/10/27/this-meeting-should-have-been-an-email/"&gt;five-paragraph
briefing&lt;/a&gt; that
you sent out this morning may have been considered manna from heaven
by your recipients (if you’re a manager, your recipients are usually
your direct reports), and they immediately sprung into action
energized by your electrifying leadership. Or maybe nobody understood
a word of the unintelligible drivel you concocted, but out of respect
or courtesy they are very hesitant to point this out.&lt;/p&gt;
&lt;p&gt;So in my humble opinion, there are two very simple things you can do
as a manager to address Warnock’s Dilemma in your distributed team:
making it a habit to specifically encourage objections, and
establishing a culture of acknowledgements.&lt;/p&gt;
&lt;h2&gt;Encouraging objections&lt;/h2&gt;
&lt;p&gt;The habit I have developed to encourage objections is to not merely
ask the recipients of a message to raise questions if they have them,
but to ask them to poke holes in whatever I’ve been writing.&lt;/p&gt;
&lt;p&gt;To that end, I have standing phrases that I use, such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;“Do you think that sounds reasonable?”&lt;/li&gt;
&lt;li&gt;“Did I overlook something important?”&lt;/li&gt;
&lt;li&gt;“Can you think of a better way to do this?” (Better than my
  suggestion, that is.)&lt;/li&gt;
&lt;li&gt;“I’m pretty sure I’m missing something here, can you pitch in?”&lt;/li&gt;
&lt;li&gt;“Am I way out in left field with this?”&lt;/li&gt;
&lt;li&gt;“How nuts of an idea is this?”&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I might use a variation on one or several of these phrases at the end
of an email, but also in the comments section of a wiki page (or in
individual inline comments), or even in the reply thread of an issue
tracker.&lt;/p&gt;
&lt;p&gt;This serves multiple purposes:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;There are many individual areas of knowledge where someone on my
   team is more of an expert than I am. Obviously, I want those
   people’s ideas on the table.&lt;/li&gt;
&lt;li&gt;It establishes the notion that nobody’s opinions or suggestions on
   technical matters are sacrosanct, and we want to do &lt;em&gt;the right
   thing&lt;/em&gt; in any situation, not follow the hippo.&lt;sup id="fnref:hippo"&gt;&lt;a class="footnote-ref" href="#fn:hippo"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;It encourages others to ask for feedback in the same manner,
   whenever they float ideas or suggestions of their own.&lt;/li&gt;
&lt;li&gt;It establishes that there’s nothing wrong with being wrong from
   time to time.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;So now, on to acknowledgements, that is, what to do when you have &lt;em&gt;no&lt;/em&gt;
objections on something.&lt;/p&gt;
&lt;p&gt;Here’s a general rule that I use: &lt;strong&gt;all communications should be
acknowledged.&lt;/strong&gt; Yes, really. Anything my team sends me, I try to reply
to with at least “ack” or “OK”, but frequently it’s something like
“great, thanks!” — it costs nothing to be kind.&lt;/p&gt;
&lt;p&gt;Likewise, for everything I send &lt;em&gt;to&lt;/em&gt; my team I can count on getting
the same kind of reply back. There’s something I need to pass on from
higher up? Or just something I want everyone to know? Out goes an
email, in come a few “ack” replies over the next few hours. I don’t
even have to specifically ask anyone for acknowledgement anymore, it
just happens.&lt;sup id="fnref:guidelines"&gt;&lt;a class="footnote-ref" href="#fn:guidelines"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;In this context, we deliberately use &lt;em&gt;written&lt;/em&gt; acknowledgements — as
in, somebody actually &lt;em&gt;types&lt;/em&gt; something, even if it’s just the two
letters “OK”. I find Like buttons or thumbs-up or email “read
receipts” (anyone remember those?) oddly perfunctory.&lt;/p&gt;
&lt;p&gt;This has a nice side effect, in combination with encouraging
objections: someone who — while knowing that objections are always
encouraged — acknowledges an idea, opinion, or plan, &lt;em&gt;actually makes
it clear that they are on board with it.&lt;/em&gt;&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:pentalemma"&gt;
&lt;p&gt;To his credit, Dave points out in the same
message that “dilemma” is technically inappropriate as the problem
described includes five choices, not two. It’s properly a
&lt;a href="https://en.wiktionary.org/wiki/pentalemma"&gt;pentalemma&lt;/a&gt;. &lt;a class="footnote-backref" href="#fnref:pentalemma" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:hippo"&gt;
&lt;p&gt;HiPPO: the Highest-Paid Person’s Opinion. Following the
hippo is when you value ideas and opinions by seniority of their
originator, not by correctness or factual merit. &lt;a class="footnote-backref" href="#fnref:hippo" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:guidelines"&gt;
&lt;p&gt;We’ve also codified this in my team’s communications
guidelines. You don’t have something like that? Write them. &lt;a class="footnote-backref" href="#fnref:guidelines" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="blog"></category><category term="Work"></category><category term="Communications"></category></entry><entry><title>This Meeting Should Have Been an Email</title><link href="https://xahteiwi.eu/blog/2021/10/27/this-meeting-should-have-been-an-email/" rel="alternate"></link><published>2021-10-27T00:00:00+00:00</published><updated>2021-10-27T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-10-27:/blog/2021/10/27/this-meeting-should-have-been-an-email/</id><summary type="html">&lt;p&gt;If you believe that it’s just a silly joke or an overused trope, please read this.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Fellow managers, there is an ongoing trope in just about any software
technology or knowledge based organization (and probably others, too)
that goes like this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This meeting should have been an email.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It’s such a well-established meme at this point that you &lt;a href="https://www.redbubble.com/shop/i+survived+another+meeting+that+should+have+been+an+email+mugs"&gt;can buy mugs
saying
so&lt;/a&gt;. Or
&lt;a href="https://www.etsy.com/au/listing/737148259/i-survived-another-meeting-that-could"&gt;cross-stitched “award
certificates”&lt;/a&gt;,
or
&lt;a href="https://www.reddit.com/r/pics/comments/8z31wz/office_participation/"&gt;ribbons&lt;/a&gt;. And
yet, many of you appear to dismiss it as a nerdy joke, and refuse to
take the sentiment behind it seriously.&lt;/p&gt;
&lt;p&gt;And this even though you may &lt;em&gt;agree&lt;/em&gt; that your organization has too
many meetings.  Even that &lt;em&gt;you&lt;/em&gt; are in too many meetings. But you’re
convinced that sadly, sadly you can’t cancel &lt;em&gt;that&lt;/em&gt; meeting. Or that
one. Or the quarterly financials update. Or the update about the
shakeup in the CTO office. Or the meeting explaining at &lt;em&gt;your&lt;/em&gt; level
what the CEO just communicated to everyone via a video message or an
email of their own.&lt;/p&gt;
&lt;p&gt;You can do it. I’m here to help.&lt;/p&gt;
&lt;h2&gt;“Email” means any structured, written communication that allows for feedback&lt;/h2&gt;
&lt;p&gt;Let’s set one thing straight to begin with.&lt;/p&gt;
&lt;p&gt;The standing phrase is “this meeting should have been an email”
because that’s catchy. But that’s not to say that you actually need to
write an email message. What it really means is that to communicate
whatever it is that you’re trying to get across, you use a medium that&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;uses written expression,&lt;/li&gt;
&lt;li&gt;allows you to formulate complex thoughts and reasoning in writing,&lt;/li&gt;
&lt;li&gt;allows people to comment and share feedback, in writing,&lt;/li&gt;
&lt;li&gt;ideally allows for that feedback to subsequently be worked back into
   the original writing.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You’ll see that particularly considering item #4, email isn’t even the
best option available at your disposal. Instead, you can look at the
following, additional options, all of which will probably be available
to you in some form:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a shared flow-text document, like a &lt;a href="https://support.google.com/a/users/answer/9310248?hl=en#6.3"&gt;Google Doc&lt;/a&gt;, a collaboratively edited
  &lt;a href="https://support.microsoft.com/en-us/office/collaborate-on-word-documents-with-real-time-co-authoring-7dd3040c-3f30-4fdd-bab0-8586492a1f1d"&gt;Office 365 Word
  document&lt;/a&gt;,
  or a &lt;a href="https://nextcloud.com/blog/nextcloud-introduces-collaborative-rich-text-editor/"&gt;Nextcloud
  Text&lt;/a&gt;
  document,&lt;/li&gt;
&lt;li&gt;a page in your organization’s wiki, like
  &lt;a href="https://www.mediawiki.org/wiki/MediaWiki"&gt;MediaWiki&lt;/a&gt; or
  &lt;a href="https://www.atlassian.com/software/confluence"&gt;Confluence&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;or even a barebones shared text editor, like
  &lt;a href="https://etherpad.org/"&gt;Etherpad&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So all of these are good.&lt;sup id="fnref:chat"&gt;&lt;a class="footnote-ref" href="#fn:chat"&gt;1&lt;/a&gt;&lt;/sup&gt; All of them are better than a meeting. With
near certainty at least one of them is available at your disposal.&lt;/p&gt;
&lt;h2&gt;Meetings burn people’s time&lt;/h2&gt;
&lt;p&gt;Meetings are gigantic time consumers. And the productivity gains from
switching to well-structured written communications are &lt;strong&gt;enormous&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;To illustrate, allow me to offer some first-hand experience. When I’m
being called to attend a meeting, my colleagues will attest to the
fact that I am a meticulous note-taker. I write meetings up in our
corporate wiki, and I record notes, rather than producing a verbatim
transcript. But I can guarantee you that I will write down every point
that the attendees make that’s worth remembering or referring back
to. This includes some key points that I do record word-for-word. I’ve
been in meetings with 20 attendees of 1 hour in length. My meeting
notes &lt;em&gt;never&lt;/em&gt; go over 2,000 words for such a meeting, and usually
they’re more like 1,000 words. So that means that for a meeting that
burns 20 person-hours &lt;em&gt;just to attend&lt;/em&gt; (that is, not including meeting
prep), what actually gets said can be summarized in 2,000 words, tops.&lt;/p&gt;
&lt;p&gt;Now, consider that &lt;a href="https://www.sciencedirect.com/science/article/abs/pii/S0749596X19300786"&gt;the average silent reading rate for English
speakers&lt;/a&gt;
is approximately 240 words per minute. So people can read a 2,000-word
summary in under 9 minutes, a 1,000 word one in about 4. In other
words, by conveying the information in writing rather than orally, you
can eliminate five-sixths to fourteen-fifteenths of that useless
overhead. Or put differently, &lt;strong&gt;replacing an hourlong meeting with a
well-written briefing gives each and every person 6 to 15 times more
productivity.&lt;/strong&gt; And that’s not even counting the benefits of
eliminating the meeting as a forced synchronization point.&lt;/p&gt;
&lt;h2&gt;But writing things up means more work for me!&lt;/h2&gt;
&lt;p&gt;You may argue that although you understand that putting together a
well-written briefing (instead of calling a meeting) saves everyone
&lt;em&gt;else&lt;/em&gt; time, it takes up more of &lt;em&gt;your&lt;/em&gt; time.&lt;/p&gt;
&lt;p&gt;Let me observe this: If you’ve been convening and chairing meetings of
an hour, and you haven’t been spending &lt;em&gt;about&lt;/em&gt; as much time preparing
for that meeting yourself, then I’m sorry to break it you but you may
not have been a very conscientious meeting chair all along. In fact,
you may have be been rather disrespectful of other people’s time, and
now is a very good time for you to change.&lt;/p&gt;
&lt;p&gt;If however you &lt;em&gt;have&lt;/em&gt; been a conscientious meeting chair and every
one-hour meeting did, in aggregate, consume about one hour of meeting
prep (including scheduling, collecting information, and preparing it
so you have it all ready to go), then rejoice: the onerous
scheduling-and-roping-everyone-in bit is gone, so that saves up a
sizable chunk of &lt;em&gt;your&lt;/em&gt; time, and you can punch out 1,000 to 2,000
words in 30-45 minutes. So, &lt;em&gt;less&lt;/em&gt; work for you. Admittedly, not as
dramatically so for you (the writer) as for your erstwhile attendees
(now readers), but still pretty substantial.&lt;/p&gt;
&lt;p&gt;(Not to mention the fact that &lt;em&gt;team&lt;/em&gt; productivity gains in the
order-of-magnitude range, see above, should make your heart jump with
joy.)&lt;/p&gt;
&lt;h2&gt;OK but how? I don’t know where to start!&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://xahteiwi.eu/resources/presentations/no-we-wont-have-a-video-call-for-that/"&gt;I’ve written about this
before&lt;/a&gt;, but I’d
like to come back to this again: if you’re looking for guidelines on
structuring your writing for what you would otherwise communicate in
your meetings, look at the 5-paragraph briefing format, adapted from
the NATO &lt;a href="https://en.wikipedia.org/wiki/Five_paragraph_order"&gt;5-paragraph field
order&lt;/a&gt;. If you
make it your habit to at least &lt;em&gt;think&lt;/em&gt; about this format, chances are
that your briefing will be pretty damn comprehensive:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Situation&lt;/li&gt;
&lt;li&gt;Objective&lt;/li&gt;
&lt;li&gt;Plan&lt;/li&gt;
&lt;li&gt;Logistics&lt;/li&gt;
&lt;li&gt;Communications&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let’s break these down in a little detail:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Situation is about what position we’re in, and &lt;strong&gt;why&lt;/strong&gt; we set out
   to do what we want to do. You can break this down into three
   sub-points, like the customer’s situation, the situation of your
   own company, any extra help that is available, and the current
   market.&lt;/li&gt;
&lt;li&gt;Objective is &lt;strong&gt;what&lt;/strong&gt; we want to achieve.&lt;/li&gt;
&lt;li&gt;Plan is &lt;strong&gt;how&lt;/strong&gt; we want to achieve it.&lt;/li&gt;
&lt;li&gt;Logistics is about what budget and resources are available, and how
   we can use them.&lt;/li&gt;
&lt;li&gt;Communications is about how we’ll be coordinating among ourselves
   and with others in order to achieve our goal.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Sometimes you want to give not a full briefing, but a simple update,
such as because circumstances have changed. In that case, you may only
include the first three items, and the changes that apply to it.&lt;/p&gt;
&lt;p&gt;It’s good practice to &lt;em&gt;always&lt;/em&gt; include these three (that is,
situation, objective, and plan): to &lt;em&gt;you&lt;/em&gt; it may be clear and obvious
that since the situation has changed, a slight modification of the
plan (or the objective!) is necessary. To others, it might not. So
just always include the current situation, the current objectives, and
the current plan.&lt;/p&gt;
&lt;p&gt;You can also apply this to a problem statement, where it’s just as
useful:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;This is what we’re currently dealing with, and how I see it (that’s
   the &lt;em&gt;situation&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;Here’s why it’s a problem, and why it needs to be fixed (that’s an
   &lt;em&gt;objective&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;This is my suggestion for how it could be fixed (that’s a &lt;em&gt;plan&lt;/em&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;And finally, some poetry&lt;/h2&gt;
&lt;p&gt;And as my final writing tip for improving communications and
eliminating needless meetings, I want to leave you with some
poetry. These lines that just so happen to serve as a perfect mnemonic
for professional briefings.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I keep six honest serving-men:&lt;br/&gt;
(They taught me all I knew)&lt;br/&gt;
Their names are What and Where and When&lt;br/&gt;
And How and Why and Who.  &lt;/p&gt;
&lt;p&gt;— Rudyard Kipling, The Elephant’s Child, 1902&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Strive for all your professional writing to answer most or all of
&lt;em&gt;what,&lt;/em&gt; &lt;em&gt;where,&lt;/em&gt; &lt;em&gt;when,&lt;/em&gt; &lt;em&gt;how,&lt;/em&gt; &lt;em&gt;why,&lt;/em&gt; and &lt;em&gt;who,&lt;/em&gt; and watch your need
for meetings evaporate like morning dew in glistening sunlight.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:chat"&gt;
&lt;p&gt;Please note that interactive chat (like Slack) is not in this
list. It fails the “formulate complex thoughts and reasoning”
test. &lt;a class="footnote-backref" href="#fnref:chat" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="blog"></category><category term="Work"></category><category term="Communications"></category></entry><entry><title>Please, Make My Company Distributed!</title><link href="https://xahteiwi.eu/blog/2021/10/23/make-my-company-distributed/" rel="alternate"></link><published>2021-10-23T00:00:00+00:00</published><updated>2021-10-23T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-10-23:/blog/2021/10/23/make-my-company-distributed/</id><summary type="html">&lt;p&gt;Turning an organization into one that works in a distributed and asynchronous fashion is far from trivial.&lt;/p&gt;</summary><content type="html">&lt;p&gt;After &lt;a href="https://xahteiwi.eu/resources/presentations/no-we-wont-have-a-video-call-for-that/"&gt;No, We Won’t Have a Video Call for
That&lt;/a&gt;, which
covered how productive distributed teams operate, and the &lt;a href="https://xahteiwi.eu/blog/2021/09/30/getting-out-of-meeting-hell/"&gt;Getting out
of Meeting Hell&lt;/a&gt; series,
which focused on how &lt;em&gt;you&lt;/em&gt; as an individual can get to being a member
of a functional distributed team, let’s zoom out a bit.&lt;/p&gt;
&lt;p&gt;Let’s discuss a slightly larger, organizational picture, just in case
you ask yourself this question: “&lt;strong&gt;Why isn’t my organization
distributed and asynchronous?&lt;/strong&gt; And, as companies &lt;a href="https://news.ycombinator.com/item?id=28833394"&gt;bleed talent right
and left&lt;/a&gt; because
competent people run for the competition that &lt;em&gt;does&lt;/em&gt; get distributed
work right, why don’t they wake up and &lt;em&gt;become&lt;/em&gt; like that?  &lt;strong&gt;Can
someone please make my company more distributed and asynchronous?”&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For additional context, let me interject the following observations
from &lt;a href="https://blog.koehntopp.info/"&gt;Kris Köhntopp&lt;/a&gt;, who posted them
&lt;a href="https://twitter.com/isotopp/status/1451497494303711234"&gt;in German on
Twitter&lt;/a&gt; (I am
taking the liberty to translate here; emphasis mine):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;What’s funny is that [what matters to being successful as a
distributed company] are all learnable skills — written
communications, sensible meeting prep and follow-up, correct
definition of objectives and tasks, etc.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;That’s a craft.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;But it appears that organizations prefer to bleed their teams dry by
attrition, rather than to learn, or to hire people that can help
teams to write things down, professionally maintain a wiki, and
teach and drive communications.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And &lt;a href="https://twitter.com/isotopp/status/1451508098779258889"&gt;further
downthread&lt;/a&gt;,
Kris says (again, my translation and emphasis):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This is all definitely feasible, after all there’s remote-first
companies of substantial size and they work.&lt;/p&gt;
&lt;p&gt;They must have &lt;strong&gt;built&lt;/strong&gt; themselves somehow, they didn’t get to
where they are by pure chance.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I agree with all of that (obviously), but things are complicated. So
let’s drill into this a bit.&lt;/p&gt;
&lt;h2&gt;Building is easy. Changing is hard.&lt;/h2&gt;
&lt;p&gt;I’ve founded and bootstrapped a distributed company, and I’ve also
been involved in making a localized company more distributed. Take my
word for it: founding was daunting and scary and stressful, but in
terms of shaping structure and communications — even if you have to
figure it out as you go, as I did with my cofounders&lt;sup id="fnref:invent"&gt;&lt;a class="footnote-ref" href="#fn:invent"&gt;1&lt;/a&gt;&lt;/sup&gt; — it’s &lt;em&gt;easy.&lt;/em&gt;
Changing the communication structure of an established company is
&lt;em&gt;hard.&lt;/em&gt; And slow. Even if you have full support from the top.&lt;/p&gt;
&lt;p&gt;So, if you’re in an organization that wasn’t distributed from the
get-go, do not compare it to one that was.&lt;/p&gt;
&lt;p&gt;Also, do not compare it to one that is two years ahead of yours in
reshaping itself in a distributed and asynchronous manner. Also, if
your company went distributed kicking and screaming at the start of
the pandemic, do not compare it to one where the top leadership made a
conscious decision to be more “remote friendly” or “remote first” or
whatever their preferred term is, long before the pandemic hit. These
organizations are ahead of yours. Their change may be happening just
as slowly as yours, they just started the race earlier and are a
couple of laps ahead of you.&lt;/p&gt;
&lt;p&gt;But your company hasn’t even &lt;em&gt;started&lt;/em&gt; the change to distributed and
async work? You spent the last nearly two years in unfettered meeting
hell?  Your bosses think you’ll now go “back to normal”, because an
office is the only “normal” they know? &lt;a href="https://xahteiwi.eu/blog/2021/10/01/getting-out-of-meeting-hell-employees/"&gt;You know what to
do.&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Hiring people to help: aye, there’s the rub.&lt;/h2&gt;
&lt;p&gt;Now on to the idea of hiring people to help. There’s two ways to look
at that: hiring people as employed &lt;strong&gt;managers&lt;/strong&gt; to work and lead in
the organization in a distributed and async fashion, or hiring people
as management &lt;strong&gt;consultants&lt;/strong&gt; to guide and advise the company in the
distributed and async transition.&lt;/p&gt;
&lt;p&gt;(Please note: the idea of hiring only &lt;em&gt;regular employees&lt;/em&gt; that drive a
distributed and async change “from within” — against the resistance or
inertia of established management — is ludicrous, unethical, and
unworkable.)&lt;/p&gt;
&lt;h3&gt;Hiring distie managers&lt;/h3&gt;
&lt;p&gt;If you make it a priority to hire managers geared toward distributed and
asynchronous work, then if they’re worth their salt I can guarantee you
that one of the first things that they’ll ask in their first interview
is this:&lt;/p&gt;
&lt;p&gt;“What’s &lt;em&gt;my&lt;/em&gt; line manager’s (director’s, VP’s, etc) distributed and
async work experience? How about my lateral peers’?”&lt;/p&gt;
&lt;p&gt;And if the truthful answer is “they’re new to this,” it’s quite likely
that your prospective new management colleague will politely end the
conversation. Their skills are in high demand; they have plenty of
options to go elsewhere. Why should sign they up for a job that’s
going to come with a ton of needless friction?&lt;/p&gt;
&lt;p&gt;And of course, that consideration applies in all management positions,
all the way to the top. So for this to work, in an organization
currently hellbent on localized-synchronized work (I use
&lt;em&gt;offissification&lt;/em&gt; for that state of affairs), it would need at least
its entire
&lt;a href="https://en.wikipedia.org/wiki/Corporate_title#Senior_management"&gt;C-suite&lt;/a&gt;
to come around first. And it would then &lt;em&gt;probably&lt;/em&gt; need to replace at
least one-third of its current managers at all levels, to have any
chance of attracting fresh blood in management.&lt;/p&gt;
&lt;p&gt;You’ll notice that this isn’t exactly easy to do, plus it’ll probably
take longer than you have the patience to put up with it.&lt;/p&gt;
&lt;h3&gt;Hiring management consultants&lt;/h3&gt;
&lt;p&gt;So that leaves the option of hiring people that are &lt;em&gt;not&lt;/em&gt; part of the
organization but are brought in to advise, ideally on all management
levels. These people are called management consultants. And you should
understand that they are commonly &lt;em&gt;loathed&lt;/em&gt; by mid-level line
managers. But let’s leave that aside for now. Let’s assume that you
want to consider the possibility of a management consultant whose
communication skills and empathy and talent are so outstanding that
they are absolutely not hated by anybody.&lt;/p&gt;
&lt;p&gt;Then, please put yourself in that consultant’s shoes. Before they get
anywhere near you, they would have spent countless hours in — you
guessed it — &lt;em&gt;meetings&lt;/em&gt; with the CEO, with top-level management,
possibly with department heads, to get &lt;em&gt;buy-in&lt;/em&gt;. And then, they embark
on a multi-month project where they must use the style of work
currently prevalent in your company, because that’s the only way to
even approach people. So they spend more time in — are you with me —
&lt;em&gt;meetings&lt;/em&gt; to convince and educate people. Oh, and they probably need
to bill by the day or by the hour, in some arbitrary increment that
your bean counters dictate, because otherwise they can’t get
paid. Async work, on your own time and schedule, much?&lt;/p&gt;
&lt;p&gt;So that means that under most circumstances, such a project will
either involve a person who’s actually perfectly fine with localized
and synchronous work, and for this kind of project that’s &lt;em&gt;probably&lt;/em&gt;
not a person you’d want to hire. Or else they’re miserably
unproductive throughout the project, and that doesn’t exactly bode
well for their health &lt;em&gt;nor&lt;/em&gt; your project. (Which means a person
understanding this probably will never start such a consultancy in the
first place.)&lt;/p&gt;
&lt;p&gt;Now, I want to mention that I suppose from the perspective of a
consultant, there is one way to square this circle: charge exorbitant
rates. If you can make a killing working two days a month, and you
actually &lt;em&gt;do&lt;/em&gt; work just two days of meeting hell per month and take
the rest of your time off to recuperate, then that might actually
work. But then it’s less likely — not impossible, but less likely —
that your company will retain their services. Because unlike a
consultant that you bring in to chop heads, monetary gains (that is,
return on investment for the consultant’s fees) are much more
difficult to put in numbers when you’re “only” making everyone’s life
better, and attracting better employees, increasing productivity,
building better products, attracting more customers, and hence making
a bigger profit are mere knock-on effects from that.&lt;sup id="fnref:rational"&gt;&lt;a class="footnote-ref" href="#fn:rational"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h2&gt;So, how do things change, then?&lt;/h2&gt;
&lt;p&gt;It’s my rather firm belief that these things change by evolution, not
on an organizational scale but on one of market and society. &lt;strong&gt;Many of
the companies still stuck in the office mindset will not change,&lt;/strong&gt; at
least not dramatically. They will continue to bleed talent, not
attract much fresh blood, and face fierce competition from companies
that do better and attract good people. Some will undergo a slow and
sometimes painful transition and some will succeed at it. Some will
fail and go under, or become irrelevant.&lt;/p&gt;
&lt;p&gt;But expecting dramatic, sudden change at a large organization is just
not realistic. And if you’re stuck in one that’s still pretending that
this’ll all blow over, your best option is probably to make a change
for yourself, than to try to wait for one in your organization.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:invent"&gt;
&lt;p&gt;This is not to say that we &lt;em&gt;invented&lt;/em&gt; anything, just that
we had to figure out how to make things work for ourselves that
already worked for others. Distributed
companies existed well before my cofounders and I started a
company in 2011. &lt;a href="https://en.wikipedia.org/wiki/MySQL_AB"&gt;MySQL
AB&lt;/a&gt; (incidentally, Kris
Köhntopp’s former employer) established those practices in the
2000-2005 time frame. There is an excellent &lt;a href="https://youtu.be/2xmEgtRhw7o"&gt;November 2011
talk&lt;/a&gt; from ex-MySQL CEO Mårten
Mickos, in which he runs through the entire history of MySQL as an
independent company, until its acquisition by Sun in 2008. &lt;a href="https://youtu.be/2xmEgtRhw7o?t=1653"&gt;Around
the 27-minute mark&lt;/a&gt;, he
starts talking about work in a distributed company. &lt;a class="footnote-backref" href="#fnref:invent" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:rational"&gt;
&lt;p&gt;And &lt;em&gt;even if&lt;/em&gt; there is a demonstrable expected positive
&lt;em&gt;monetary&lt;/em&gt; effect, meaning in terms of numbers it’s an absolute
no-brainer, you should consider that top management &lt;em&gt;are people,&lt;/em&gt;
and people don’t always act rationally. &lt;a class="footnote-backref" href="#fnref:rational" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="blog"></category><category term="Work"></category><category term="Communications"></category></entry><entry><title>No, We Won’t Have a Video Call for That: The Companion Pieces</title><link href="https://xahteiwi.eu/resources/presentations/no-we-wont-have-a-video-call-for-that-the-companion-pieces/" rel="alternate"></link><published>2021-10-23T00:00:00+00:00</published><updated>2021-10-23T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-10-23:/resources/presentations/no-we-wont-have-a-video-call-for-that-the-companion-pieces/</id><summary type="html">&lt;p&gt;&lt;a href="https://xahteiwi.eu/resources/presentations/no-we-wont-have-a-video-call-for-that/"&gt;The original article&lt;/a&gt; continues to prompt a
lot of thoughts and discussions, so I’ve written a a couple of
follow-up pieces:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://xahteiwi.eu/blog/2021/09/30/getting-out-of-meeting-hell/"&gt;Getting out of Meeting
   Hell&lt;/a&gt; is a
   short series about getting from a distributed workplace that
   attempts to duplicate the synchronous nature of an office by
   sticking everyone …&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://xahteiwi.eu/resources/presentations/no-we-wont-have-a-video-call-for-that/"&gt;The original article&lt;/a&gt; continues to prompt a
lot of thoughts and discussions, so I’ve written a a couple of
follow-up pieces:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://xahteiwi.eu/blog/2021/09/30/getting-out-of-meeting-hell/"&gt;Getting out of Meeting
   Hell&lt;/a&gt; is a
   short series about getting from a distributed workplace that
   attempts to duplicate the synchronous nature of an office by
   sticking everyone into video meetings all the time — with usually
   disastrous results — to one that successfully adopts an
   asynchronous way of working. It has suggestions for employees,
   mid-level managers, and executives.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://xahteiwi.eu/blog/2021/10/23/make-my-company-distributed/"&gt;Please, make my company
   distributed!&lt;/a&gt;
   takes a broader view on changing organizations so that they become
   better suited for a distributed and asynchronous style of work, and
   why that’s a lot harder than most people think.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</content><category term="presentations"></category><category term="Conference"></category><category term="Communications"></category><category term="Work"></category></entry><entry><title>Universal tox tests (from just about any CI)</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/universal-tox-tests-from-just-about-any-ci/" rel="alternate"></link><published>2021-10-17T00:00:00+00:00</published><updated>2021-10-17T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-10-17:/resources/hints-and-kinks/universal-tox-tests-from-just-about-any-ci/</id><summary type="html">&lt;p&gt;I like tox. A lot. I use it all the time. This is a quick summary on how to use it in such a way that it becomes a central anchor point that you can use from all your CI systems.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I like &lt;code&gt;tox&lt;/code&gt;. A lot. I use it all the time. This is a quick summary on
how to use it in such a way that it becomes a central anchor point that
you can use from all your CI systems.&lt;/p&gt;
&lt;h2&gt;What’s tox for?&lt;/h2&gt;
&lt;p&gt;Normally &lt;code&gt;tox&lt;/code&gt; is used to run tests for Python projects, and it’s very
well suited for that. You can use it with Python libraries, Django
projects, scripts you use for system automation, whatever. But you can
use it just the same for code that isn’t a Python application or
library itself, but a Python application just happens to come in handy
for testing that code.&lt;/p&gt;
&lt;p&gt;In this example, I’ll describe a super simple use case: using a
barebones &lt;code&gt;tox&lt;/code&gt; configuration that lints YAML configurations. Suppose
you’ve got a Git repo that’s full of YAML files. And you want to make
sure, for example, that all your
&lt;a href="https://yamllint.readthedocs.io/en/stable/rules.html#module-yamllint.rules.truthy"&gt;truthy&lt;/a&gt;
values are &lt;code&gt;true&lt;/code&gt; or &lt;code&gt;false&lt;/code&gt; and never &lt;code&gt;yes&lt;/code&gt;, &lt;code&gt;no&lt;/code&gt;, &lt;code&gt;on&lt;/code&gt; or &lt;code&gt;off&lt;/code&gt;. Or
that your
&lt;a href="https://yamllint.readthedocs.io/en/stable/rules.html#module-yamllint.rules.indentation"&gt;indentation&lt;/a&gt;
is always consistent.&lt;/p&gt;
&lt;h2&gt;&lt;code&gt;tox.ini&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;There first thing you’ll do is create &lt;code&gt;tox.ini&lt;/code&gt;, the central tox
configuration file, in the top level directory of your
repository. Here’s a tiny example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;[tox]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;envlist&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;py{3,36,39}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;skipsdist&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;True&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;[testenv]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;deps&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;yamllint&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;commands&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;yamllint {toxinidir}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That’s it. What this’ll do, when invoked as simply &lt;code&gt;tox&lt;/code&gt;, is&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;create a Python 3 venv,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pip&lt;/code&gt;-install the latest version of
  &lt;a href="https://yamllint.readthedocs.io/en/stable/"&gt;&lt;code&gt;yamllint&lt;/code&gt;&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;invoke the &lt;code&gt;yamllint&lt;/code&gt; command, which will recursively check for all
  &lt;code&gt;.yml&lt;/code&gt;, &lt;code&gt;.yaml&lt;/code&gt;, and &lt;code&gt;.yamllint&lt;/code&gt; files in the directory where the
  &lt;code&gt;tox.ini&lt;/code&gt; file itself lives.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What's helpful here is that &lt;code&gt;tox&lt;/code&gt; does a little bit of magic with the
testenv names. tox
&lt;a href="https://tox.wiki/en/latest/example/basic.html#a-simple-tox-ini-default-environments"&gt;knows&lt;/a&gt;
that if you call a testenv &lt;code&gt;py36&lt;/code&gt;, you want to test with Python 3.6
(more precisely, &lt;a href="https://en.wikipedia.org/wiki/CPython"&gt;CPython&lt;/a&gt;
3.6). &lt;code&gt;py39&lt;/code&gt;, that's Python 3.9. Just &lt;code&gt;py3&lt;/code&gt; means whatever Python
version maps to the &lt;code&gt;python3&lt;/code&gt; binary on your system.&lt;sup id="fnref:python-versions"&gt;&lt;a class="footnote-ref" href="#fn:python-versions"&gt;1&lt;/a&gt;&lt;/sup&gt; &lt;/p&gt;
&lt;h2&gt;Running &lt;code&gt;tox&lt;/code&gt; on every commit&lt;/h2&gt;
&lt;p&gt;Now the first thing you might want to do is run &lt;code&gt;tox&lt;/code&gt; on every commit,
and encourage your collaborators to do the same. You can easily do
that by dropping this tiny shell script&lt;sup id="fnref:shell-script"&gt;&lt;a class="footnote-ref" href="#fn:shell-script"&gt;2&lt;/a&gt;&lt;/sup&gt; into your repo
as a file named &lt;code&gt;pre-commit&lt;/code&gt; in the &lt;code&gt;.githooks&lt;/code&gt; directory:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="ch"&gt;#!/bin/sh&lt;/span&gt;

&lt;span class="nb"&gt;exec&lt;/span&gt; tox -e py3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Add that file to your repository as &lt;code&gt;.githooks/pre-commit&lt;/code&gt;, and make
it executable. Also, add a little note to your README explaining that,
to enable the pre-commit hook, all your collaborators can simply run&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;git config core.hooksPath .githooks
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Easy, right? And once you’ve run that command, every &lt;code&gt;git commit&lt;/code&gt; will
kick off a &lt;code&gt;tox&lt;/code&gt; run and you’ll never commit borked YAML again.&lt;sup id="fnref:py3"&gt;&lt;a class="footnote-ref" href="#fn:py3"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Now of course, using those hooks is entirely optional, and can be
overridden with &lt;code&gt;--no-verify&lt;/code&gt;. So, for those slackers that can’t be
bothered to use them, you also want to check centrally. Here’s where
your CI comes in.&lt;/p&gt;
&lt;h2&gt;Running &lt;code&gt;tox&lt;/code&gt; on every GitHub PR&lt;/h2&gt;
&lt;p&gt;If you collaborate via GitHub, you can run &lt;code&gt;tox&lt;/code&gt; on every PR, with a
simple &lt;a href="https://docs.github.com/en/actions"&gt;GitHub Actions&lt;/a&gt;
workflow. To use it, you’ll need a small addition to your &lt;code&gt;tox.ini&lt;/code&gt;
file:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;[tox]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;envlist: py{3,36,39}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;skipsdist&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;True&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;[gh-actions]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;python&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="na"&gt;3.6: py36&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="na"&gt;3.9: py39&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;[testenv]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;deps&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;yamllint&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;commands&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;yamllint {toxinidir}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And then, you add a workflow to &lt;code&gt;.github/workflows&lt;/code&gt;, say
&lt;code&gt;.github/workflows/tox.yml&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nn"&gt;---&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;Test with tox&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="s"&gt;'on'&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;push&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;pull_request&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nt"&gt;jobs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;build&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;runs-on&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;ubuntu-latest&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;strategy&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;matrix&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;python-version&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;          &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;3.6&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;          &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;3.9&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;steps&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;Checkout&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;uses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;actions/checkout@v2&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;with&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;          &lt;/span&gt;&lt;span class="nt"&gt;submodules&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;true&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;Set up Python ${{ matrix.python-version }}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;uses&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;actions/setup-python@v2&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;with&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;          &lt;/span&gt;&lt;span class="nt"&gt;python-version&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;${{ matrix.python-version }}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;Install dependencies&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;run&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p p-Indicator"&gt;|&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;          &lt;/span&gt;&lt;span class="no"&gt;pip install tox tox-gh-actions&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;Test with tox&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;run&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;tox&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So that sets up your workflow so that it tests with two different
Python versions that you care about, and then runs a test with each of
them.&lt;/p&gt;
&lt;p&gt;It does this via a combination of the information contained in the
&lt;code&gt;[gh-actions]&lt;/code&gt; section of &lt;code&gt;tox.ini&lt;/code&gt;, and the &lt;code&gt;matrix&lt;/code&gt; strategy defined
in the workflow. The &lt;code&gt;tox-gh-action&lt;/code&gt; plugin then pulls that
information together and sets up testenvs as needed.&lt;/p&gt;
&lt;p&gt;And it runs these checks every time you push to a branch (topic branch
or default branch), and also on every pull request.&lt;/p&gt;
&lt;h2&gt;Running &lt;code&gt;tox&lt;/code&gt; from GitLab CI&lt;/h2&gt;
&lt;p&gt;So you’re either using only GitLab and not GitHub, or you’re mirroring
a GitHub repo to a self-hosted GitLab and want to run your pipelines
there as well? Easy. Here’s the exact same functionality for your
&lt;code&gt;.gitlab-ci.yml&lt;/code&gt; file:&lt;sup id="fnref:docker-runners"&gt;&lt;a class="footnote-ref" href="#fn:docker-runners"&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nn"&gt;---&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nt"&gt;py36&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;image&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;python:3.6&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;stage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;build&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;pip install tox&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;tox -e py36&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nt"&gt;py39&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;image&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;python:3.9&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;stage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;build&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;pip install tox&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;tox -e py39&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In &lt;a href="https://docs.gitlab.com/ee/ci/"&gt;GitLab CI&lt;/a&gt; I know of no elegant
&lt;code&gt;matrix&lt;/code&gt; syntax to map the image version to the testenv. But on the
other hand there's a bunch of things that "just happen" in a GitLab CI
pipeline, which you specifically need to define in a GitHub Actions
workflow definition. So overall your &lt;code&gt;.gitlab-ci.yml&lt;/code&gt; ends up shorter
than your GitHub Actions &lt;code&gt;tox.yml&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;Running &lt;code&gt;tox&lt;/code&gt; from Zuul&lt;/h2&gt;
&lt;p&gt;If you’re running a &lt;code&gt;tox&lt;/code&gt; testenv from &lt;a href="https://zuul-ci.org/"&gt;Zuul&lt;/a&gt;,
you would use the built-in tox jobs in your pipeline, as referenced in
&lt;code&gt;.zuul.yaml&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nn"&gt;---&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;project&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;check&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;jobs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;tox-py36&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;tox-py39&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;gate&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;jobs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;tox-py36&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;tox-py39&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here, the &lt;code&gt;tox-py36&lt;/code&gt; and &lt;code&gt;tox-py39&lt;/code&gt; environments are both derivatives
of the base
&lt;a href="https://zuul-ci.org/docs/zuul-jobs/python-jobs.html#job-tox"&gt;tox&lt;/a&gt;
job, which will run with cPython versions 3.6 and 3.9, and by default
invoke testenvs called &lt;code&gt;py36&lt;/code&gt; and &lt;code&gt;py39&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;h2&gt;And now?&lt;/h2&gt;
&lt;p&gt;Now that all of your Python testing standardizes on tox, you can go to
town. Add more tests, add more testenvs, more Python versions,
whatever.&lt;/p&gt;
&lt;p&gt;You might need to make minimal changes, like add one line for each new
Python version you want to support, to all your CI definitions. But if
your project moves from GitHub to GitLab or from GitLab to
Gerrit/Zuul, or your entire company goes on a great big CI migration,
then you'll have one less thing to worry about, because your tests
already run anywhere.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;By the way:&lt;/strong&gt; when you set up your &lt;code&gt;tox.ini&lt;/code&gt; and your CI
configuration files as shown in this article, then &lt;code&gt;yamllint&lt;/code&gt; &lt;em&gt;will&lt;/em&gt;
of course also lint your YAML CI configuration files
themselves. Which comes in handy; I found 4 yamllint warnings and
one error while testing the examples I’ve given here.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:python-versions"&gt;
&lt;p&gt;Testing with multiple Python versions may seem
less than useful when you’re dealing with just one upstream
package, &lt;code&gt;yamllint&lt;/code&gt;. I use that here as an oversimplified
example. As soon as you add your own Python scripts or modules to
the &lt;code&gt;tox&lt;/code&gt; checks, you may very well be interested in multiple
python versions. &lt;a class="footnote-backref" href="#fnref:python-versions" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:shell-script"&gt;
&lt;p&gt;If you're being a purist, you could also invoke the
tox runner from a Python script. I prefer the shell &lt;code&gt;exec&lt;/code&gt;
one-liner. &lt;a class="footnote-backref" href="#fnref:shell-script" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:py3"&gt;
&lt;p&gt;In this case, for testing locally, we're not going to care
about a specific installed Python version. We'll just make sure
that the commit doesn't obviously break anything. In my humble
opinion it's OK to catch version-specific issues in CI, but we
shouldn't feed the CI code that's outright broken. &lt;a class="footnote-backref" href="#fnref:py3" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:docker-runners"&gt;
&lt;p&gt;This example assumes that you’re either using
shared GitLab runners using Docker, or a self-hosted runner on
Kubernetes. &lt;a class="footnote-backref" href="#fnref:docker-runners" title="Jump back to footnote 4 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="hints-and-kinks"></category><category term="CI"></category><category term="Python"></category><category term="GitLab"></category><category term="GitHub"></category><category term="Zuul"></category></entry><entry><title>On Contravictions</title><link href="https://xahteiwi.eu/talk-submissions/devopsdaystlv-2021-contravictions/" rel="alternate"></link><published>2021-10-07T00:00:00+00:00</published><updated>2021-10-07T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-10-07:/talk-submissions/devopsdaystlv-2021-contravictions/</id><summary type="html">&lt;p&gt;A talk I submitted to DevOpsDays Tel Aviv, 2021&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a talk I submitted&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt; to DevOpsDays Tel Aviv 2021, which used
a non-anonymized CfP process via
&lt;a href="https://www.papercall.io/"&gt;PaperCall&lt;/a&gt;. This submission was rejected.&lt;/p&gt;
&lt;h2&gt;Title&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;On Contravictions&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Elevator Pitch&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;You have 300 characters to sell your talk. This is known as the
"elevator pitch". Make it as exciting and enticing as possible.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A contraviction is when a person firmly believes that two objectively
mutually exclusive standpoints are simultaneously true. Being
contravinced makes you extremely vulnerable to manipulation. Here’s
how to spot a contraviction, and what to do about them.&lt;/p&gt;
&lt;h2&gt;Talk Format&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;What format is this talk best suited for?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Talk (~25-40 minutes)&lt;/p&gt;
&lt;h2&gt;Audience Level&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Who is the best target audience for this talk?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;All&lt;/p&gt;
&lt;h2&gt;Description&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;The description will be seen by reviewers during the CFP process and
may eventually be seen by the attendees of the event. You should
make the description of your talk as compelling and exciting as
possible. Remember, you're selling both the organizers of the events
to select your talk, as well as trying to convince attendees your
talk is the one they should see.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;"Contraviction" is a term I use for when a person is firmly convinced
of two sides of an obvious contradiction. This may sound like it would
be an unusual and rare occasion, and yet, once you start looking, they
are all over the place. A few examples:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;At the core of &lt;strong&gt;Nazi ideology&lt;/strong&gt; in Germany in the 1920s and 30s was
  the notion that Jews are engaged in a &lt;em&gt;successful&lt;/em&gt; global conspiracy
  to subjugate all nations including the German nation, and that Jews
  were also, &lt;em&gt;simultaneously,&lt;/em&gt; socially, intellectually, economically,
  and morally inferior to Germans.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;At the core of &lt;strong&gt;religious extremism&lt;/strong&gt; is the belief that God is
  all-forgiving and merciful, and also that as long as a portion of
  humanity ("infidels") displeases God, &lt;em&gt;all&lt;/em&gt; of humanity must suffer
  God's wrath. We see this in contemporary Islamic extremism, but
  Catholicism in the 16th century did no better in the conquest of
  Latin America, nor did Western Christianity do much differently
  during the medieval crusades.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;At the core of &lt;strong&gt;Trumpism&lt;/strong&gt; is the notion that the United States of
  America is the greatest nation on Earth and that there is no better
  nation nor will there ever be, but also that America has been ruined
  by "the liberals" and has slipped into inferiority, so that it is
  necessary to "make America great again."&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In all these examples, both statements can logically be false, or one
of them &lt;em&gt;could&lt;/em&gt; theoretically be true — but if one is true, the other
one &lt;em&gt;must&lt;/em&gt; be false. And yet, people (&lt;em&gt;millions&lt;/em&gt; of people!) hold or
held both of these statements to be true, simultaneously.&lt;/p&gt;
&lt;p&gt;But being contravinced puts people in a very vulnerable position: if
someone gets you to believe both sides of a contradiction, they can
&lt;em&gt;logically&lt;/em&gt; argue &lt;em&gt;anything&lt;/em&gt; to follow from either one side, or the
opposite. Which means they can convince you of anything. And that
never ends well.&lt;/p&gt;
&lt;p&gt;This talk defines contravictions, highlights examples (even devopsy
ones!) and provides suggestions on how to uncover and dismantle
them. Because contravictions have the potential to poison and destroy
discourse, and that’s a cultural issue we all need to deal with —
among friends, family, and coworkers.&lt;/p&gt;
&lt;h2&gt;Notes&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Notes will only be seen by reviewers during the CFP process. This is
where you should explain things such as technical requirements, why
you're the best person to speak on this subject, etc...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Given the fact that the nature of this topic is sensitive and
emotional — yes I, an Austrian, will be talking about Nazi ideology,
in Israel, consider me terrified — I'll need to submit this on the
condition that I'd only want to deliver this talk &lt;em&gt;in person.&lt;/em&gt; If that
does not permit itself on account of the Covid-19 situation or of
travel restrictions, and I would have to rely on a streamed talk and
have no way of reading the room or scanning the audience for body
language feedback (some more details on this topic
&lt;a href="https://xahteiwi.eu/blog/2021/08/24/online-conferences-audience-feedback/"&gt;here&lt;/a&gt;),
then I'd rather not give the talk at all, rather than stream it.&lt;/p&gt;
&lt;p&gt;If this disqualifies the talk (or if you just consider it too
controversial to begin with), no hard feelings at all.&lt;/p&gt;
&lt;h2&gt;Tags&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Tag your talk to make it easier for event organizers to be able to
find. Examples are "ruby, javascript, rails".&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Culture, Communications&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;If you’re curious why this is here, please read
&lt;a href="https://xahteiwi.eu/blog/2019/04/23/talk-submissions/"&gt;this&lt;/a&gt;. &lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="talk-submissions"></category><category term="Conference"></category></entry><entry><title>The Review Review</title><link href="https://xahteiwi.eu/./talk-submissions/review-review/" rel="alternate"></link><published>2021-10-07T00:00:00+00:00</published><updated>2021-10-07T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-10-07:/./talk-submissions/review-review/</id><summary type="html">&lt;p&gt;A talk I submitted to DevOpsDays Tel Aviv 2021 and DevConf.CZ 2022&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a talk I submitted&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt; to
&lt;a href="https://www.devconf.info/cz/"&gt;DevConf.CZ&lt;/a&gt; 2022, which used a
non-anonymized CfP process via &lt;a href="https://cfp.devconf.info"&gt;Red Hat’s CfP
website&lt;/a&gt;. For that conference, it was
selected as the lead talk in the Modern Software Development track.  I
had previously submitted this talk to DevOpsDays Tel Aviv 2021, which
used a non-anonymized CfP process via
&lt;a href="https://www.papercall.io/"&gt;PaperCall&lt;/a&gt;. That submission was rejected.&lt;/p&gt;
&lt;h2&gt;Title&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;The Review Review: comparing code review, testing, staging and
deployment across development collaboration platforms&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Elevator Pitch&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;You have 300 characters to sell your talk. This is known as the
"elevator pitch". Make it as exciting and enticing as possible.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;GitHub, GitLab, Gerrit — what should I choose? What’s the best review
process, the best CI/CD integration, the best deployment facility?
Which should I select for my startup, or consider migrating to? Which
supports good collaboration practices, which bad ones? This talk gives
the run-down.&lt;/p&gt;
&lt;h2&gt;Talk Format&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;What format is this talk best suited for?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Talk (~25-40 minutes)&lt;/p&gt;
&lt;h2&gt;Audience Level&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Who is the best target audience for this talk?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Intermediate&lt;/p&gt;
&lt;h2&gt;Description&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;The description will be seen by reviewers during the CFP process and
may eventually be seen by the attendees of the event. You should
make the description of your talk as compelling and exciting as
possible. Remember, you're selling both the organizers of the events
to select your talk, as well as trying to convince attendees your
talk is the one they should see.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In DevOps, the process of collaborative review, testing, staging, and
deployment to production constitutes a core element of the work we
do. And we generally strive to make this process as effective,
efficient, smooth, and transparent as possible. Achieving that partly
comes from the work culture we shape and inhabit, partly from our
selection of tools — and of course, work culture and work tools
permanently and closely influence each other. This goes for both the
tools that drive review, and the tools that drive CI/CD:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;the &lt;strong&gt;GitHub Pull Request&lt;/strong&gt; process in combination with &lt;strong&gt;GitHub
  Actions&lt;/strong&gt;;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;the &lt;strong&gt;GitLab Merge Request&lt;/strong&gt; process in combination with &lt;strong&gt;GitLab
  CI&lt;/strong&gt;;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;the &lt;strong&gt;Gerrit Review&lt;/strong&gt; process in combination with &lt;strong&gt;Zuul&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;None of these is perfect, all of them have their advantages and
disadvantages under particular circumstances. Some are meant to be
used principally as a service, some are fine to self-host. Some are
adamant about enforcing specific deployment practices, some follow a
more relaxed approach.&lt;/p&gt;
&lt;p&gt;This talk is a summary of the current state of affairs with all these
tools, and contains recommendations on what to use under which
circumstances.&lt;/p&gt;
&lt;h2&gt;Notes&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Notes will only be seen by reviewers during the CFP process. This is
where you should explain things such as technical requirements, why
you're the best person to speak on this subject, etc...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;My team and I have worked with all tools mentioned in a professional
capacity, and I believe I've got a very good understanding of the
relative merits of the systems presented. This does not include a
hard-and-fast recommendation for one particular tool or platform.&lt;/p&gt;
&lt;p&gt;This is a talk that's suitable for both in-person and on-line events.&lt;/p&gt;
&lt;h2&gt;Tags&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Tag your talk to make it easier for event organizers to be able to
find. Examples are "ruby, javascript, rails".&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;GitHub, GitLab, Gerrit, Zuul, CI/CD, Development, DevOps&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;If you’re curious why this is here, please read
&lt;a href="https://xahteiwi.eu/blog/2019/04/23/talk-submissions/"&gt;this&lt;/a&gt;. &lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="talk-submissions"></category><category term="Conference"></category><category term="GitLab"></category><category term="GitHub"></category><category term="Zuul"></category></entry><entry><title>The Review Review</title><link href="https://xahteiwi.eu/./talk-submissions/review-review/" rel="alternate"></link><published>2021-10-07T00:00:00+00:00</published><updated>2021-10-07T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-10-07:/./talk-submissions/review-review/</id><summary type="html">&lt;p&gt;A talk I submitted to DevOpsDays Tel Aviv 2021 and DevConf.CZ 2022&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a talk I submitted&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt; to
&lt;a href="https://www.devconf.info/cz/"&gt;DevConf.CZ&lt;/a&gt; 2022, which used a
non-anonymized CfP process via &lt;a href="https://cfp.devconf.info"&gt;Red Hat’s CfP
website&lt;/a&gt;. For that conference, it was
selected as the lead talk in the Modern Software Development track.  I
had previously submitted this talk to DevOpsDays Tel Aviv 2021, which
used a non-anonymized CfP process via
&lt;a href="https://www.papercall.io/"&gt;PaperCall&lt;/a&gt;. That submission was rejected.&lt;/p&gt;
&lt;h2&gt;Title&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;The Review Review: comparing code review, testing, staging and
deployment across development collaboration platforms&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Elevator Pitch&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;You have 300 characters to sell your talk. This is known as the
"elevator pitch". Make it as exciting and enticing as possible.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;GitHub, GitLab, Gerrit — what should I choose? What’s the best review
process, the best CI/CD integration, the best deployment facility?
Which should I select for my startup, or consider migrating to? Which
supports good collaboration practices, which bad ones? This talk gives
the run-down.&lt;/p&gt;
&lt;h2&gt;Talk Format&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;What format is this talk best suited for?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Talk (~25-40 minutes)&lt;/p&gt;
&lt;h2&gt;Audience Level&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Who is the best target audience for this talk?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Intermediate&lt;/p&gt;
&lt;h2&gt;Description&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;The description will be seen by reviewers during the CFP process and
may eventually be seen by the attendees of the event. You should
make the description of your talk as compelling and exciting as
possible. Remember, you're selling both the organizers of the events
to select your talk, as well as trying to convince attendees your
talk is the one they should see.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In DevOps, the process of collaborative review, testing, staging, and
deployment to production constitutes a core element of the work we
do. And we generally strive to make this process as effective,
efficient, smooth, and transparent as possible. Achieving that partly
comes from the work culture we shape and inhabit, partly from our
selection of tools — and of course, work culture and work tools
permanently and closely influence each other. This goes for both the
tools that drive review, and the tools that drive CI/CD:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;the &lt;strong&gt;GitHub Pull Request&lt;/strong&gt; process in combination with &lt;strong&gt;GitHub
  Actions&lt;/strong&gt;;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;the &lt;strong&gt;GitLab Merge Request&lt;/strong&gt; process in combination with &lt;strong&gt;GitLab
  CI&lt;/strong&gt;;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;the &lt;strong&gt;Gerrit Review&lt;/strong&gt; process in combination with &lt;strong&gt;Zuul&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;None of these is perfect, all of them have their advantages and
disadvantages under particular circumstances. Some are meant to be
used principally as a service, some are fine to self-host. Some are
adamant about enforcing specific deployment practices, some follow a
more relaxed approach.&lt;/p&gt;
&lt;p&gt;This talk is a summary of the current state of affairs with all these
tools, and contains recommendations on what to use under which
circumstances.&lt;/p&gt;
&lt;h2&gt;Notes&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Notes will only be seen by reviewers during the CFP process. This is
where you should explain things such as technical requirements, why
you're the best person to speak on this subject, etc...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;My team and I have worked with all tools mentioned in a professional
capacity, and I believe I've got a very good understanding of the
relative merits of the systems presented. This does not include a
hard-and-fast recommendation for one particular tool or platform.&lt;/p&gt;
&lt;p&gt;This is a talk that's suitable for both in-person and on-line events.&lt;/p&gt;
&lt;h2&gt;Tags&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Tag your talk to make it easier for event organizers to be able to
find. Examples are "ruby, javascript, rails".&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;GitHub, GitLab, Gerrit, Zuul, CI/CD, Development, DevOps&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;If you’re curious why this is here, please read
&lt;a href="https://xahteiwi.eu/blog/2019/04/23/talk-submissions/"&gt;this&lt;/a&gt;. &lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="talk-submissions"></category><category term="Conference"></category><category term="GitLab"></category><category term="GitHub"></category><category term="Zuul"></category></entry><entry><title>Getting out of Meeting Hell: As a top-level executive</title><link href="https://xahteiwi.eu/blog/2021/10/03/getting-out-of-meeting-hell-executives/" rel="alternate"></link><published>2021-10-03T00:00:00+00:00</published><updated>2021-10-03T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-10-03:/blog/2021/10/03/getting-out-of-meeting-hell-executives/</id><summary type="html">&lt;p&gt;A short series on transitioning to distributed work and asynchronous collaboration. This article is on what you can do if you are stuck in meeting hell as a top-level executive, such as a CEO, Managing Director, or Executive Director.&lt;/p&gt;</summary><content type="html">&lt;blockquote&gt;
&lt;p&gt;Please have a look at the
&lt;a href="https://xahteiwi.eu/blog/2021/09/30/getting-out-of-meeting-hell/"&gt;introduction&lt;/a&gt; for
background, for applicable disclaimers, and for information about
the specific environments this series talks about.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This part of this series is for you if you are a chief executive
officer, a managing director, executive director, or whatever else the
top-level role in your organization may be. This means that you have
people who report to you, but you don't report to anyone in the
day-to-day operations of the company — even though you may, of course,
be answerable to your board of directors or your investors, or some
oversight body.&lt;/p&gt;
&lt;p&gt;So, you realize that&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a lot of your company spends a lot of time in useless meetings,&lt;/li&gt;
&lt;li&gt;they're often forced to sit through 90 minutes of staring into
  cameras when they could instead have spent 5 minutes reading an email,&lt;/li&gt;
&lt;li&gt;people's productivity suffers badly because they are constantly
  being interrupted.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And this is badly affecting you, personally, as well. So for the
benefit of yourself and everyone else in the organization, you want to
change things toward being less interrupt-driven, less synchronous,
more productive, and healthier.&lt;/p&gt;
&lt;p&gt;Now, I've got &lt;em&gt;some&lt;/em&gt; bad news for you.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;In contrast to your employees at any level, it is much harder for
   you to pull the &lt;em&gt;Leave&lt;/em&gt; option than it is for them.&lt;/li&gt;
&lt;li&gt;In contrast to most of your mid-level managers, no matter how hard
   you try, you may &lt;em&gt;never&lt;/em&gt; escape being in a lot of meetings, and
   being in a lot of &lt;em&gt;unpleasant&lt;/em&gt; meetings to boot. Chances are, whenever
   stuff is exploding, boiling up, or otherwise going bonkers, you'll
   be roped in to calm things down, make a decision, or soothe a
   high-profile customer who is conniptiously trying to convince you
   that your SLA is akin to the Constitution and that an engineer
   guilty of causing a violation ought to hang for treason.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;But, and this is the good news to balance the bad, if you manage to
pull the &lt;em&gt;rest&lt;/em&gt; of the company out of meeting hell, life is going to
get way better for &lt;em&gt;you,&lt;/em&gt; too.&lt;/p&gt;
&lt;p&gt;So, obviously, there'll be a lot for you to &lt;strong&gt;Learn&lt;/strong&gt;. If you've never
led an organization that was distributed and asynchronous by default,
there's a lot to unpack, understand, and overcome when it comes to
turning one that &lt;em&gt;isn't&lt;/em&gt;, into one that is.&lt;/p&gt;
&lt;p&gt;But your most important role at the top of the organization is this:&lt;/p&gt;
&lt;h2&gt;Lead.&lt;/h2&gt;
&lt;p&gt;And by that I mean lead by example, and also lead by policy.&lt;/p&gt;
&lt;p&gt;Here are a few ways you can lead by example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Write. Particularly when you want to communicate something to the
  whole company. All-hands video streams? &lt;em&gt;[stage whisper]&lt;/em&gt; Everyone
  hates those. Meeting invites saying "we'll anounce something
  important"? Just write an email &lt;em&gt;saying the important thing,&lt;/em&gt; and
  then ask people to send you questions by a deadline. And publicly
  commit &lt;em&gt;yourself&lt;/em&gt; to a deadline by which they can expect answers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Take no shortcuts. If you're setting up communications rules for
  everyone, live by them yourself. &lt;a href="https://xahteiwi.eu/blog/2021/09/16/rules-are-rules/"&gt;There's a bad, hidden cost in
  skirting around them.&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make a point of always giving context when pinging someone in chat.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Quit calling people without warning — you can't convey the &lt;em&gt;context&lt;/em&gt;
  of the call without them answering. A cold call is the ultimate
  &lt;a href="https://fedoraproject.org/wiki/No_naked_pings"&gt;naked ping&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Generally, cut back on synchronous, realtime communications. They
  always interrupt people, and &lt;a href="https://heeris.id.au/2013/this-is-why-you-shouldnt-interrupt-a-programmer/"&gt;interruptions are
  expensive&lt;/a&gt;. Think
  about how much money you'll lose from someone &lt;em&gt;not&lt;/em&gt; having a
  brilliant idea because you pinged them about some technicality in
  the company chat while they were deeply immersed in a complex
  problem. (Also, think about how much money you might &lt;em&gt;have&lt;/em&gt; already
  lost that way.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Insist on agendas being drawn up and meeting notes being kept (and
  both &lt;em&gt;circulated&lt;/em&gt; to anyone who needs the information) for every
  meeting you are asked to attend. Write an agenda for every meeting
  you call or chair. If you have a group that meets regularly, appoint a
  different person from the group as a scribe each time. Do not ask a
  person to volunteer. (If you do, chances are that one person in the
  group will be typecast as the scribe for all such meetings. I call
  such an unfortunate person a &lt;em&gt;scrapegoat.&lt;/em&gt; You don't want
  scrapegoats.)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then, here are ways you can lead by policy:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Hire professional writers. (In the software industry, tech writers
  come to mind.) Not because you want &lt;em&gt;those&lt;/em&gt; people to be
  scrapegoats, but because professional writers can massively move
  your organization forward in efficiency of written expression,
  document organization, and clarity of communications. Make them a
  hiring priority. Pay them handsomely — good tech writers can make
  good money freelancing; you'll need to make them a pretty compelling
  offer to consider giving up some of that freedom.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ram a stake in the ground making clear to everyone you will not
  tolerate corporate surveillance or invasions of privacy. Any attempt
  to introduce an "always on camera" policy should be grounds for
  reprimanding the manager that instigated it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Insist on the procurement of tools that take distributed,
  asynchronous work into account. A video conferencing system that
  values surveillance over privacy is not one your company should
  throw money at. A hiring platform that requires specifying an
  "office location" for every role, and has no provisions for remote
  positions, isn't either. Neither is a chat platform hosted by a
  company whose sole chance at long-term success is to pull &lt;em&gt;all&lt;/em&gt;
  corporate communications into synchronous chat. Yes, these judgments
  require technical expertise. If this is something you don't have
  because you consider yourself a "non-technical" person, &lt;a href="https://xahteiwi.eu/blog/2019/04/21/non-technical/"&gt;I have
  something to read for you&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There's another thing that you &lt;em&gt;might&lt;/em&gt; be inclined toward doing:
declaring meeting-free days, as in making it a policy that no meetings
are to be scheduled on Wednesdays. I think of that as very much a
stop-gap measure that's often done out of sheer despair. Sure, you
want your people to have meeting-free days, but you actually want them
to have &lt;em&gt;meeting days,&lt;/em&gt; with meetingless days being the norm, rather
than the exception. I think you're better off gradually replacing your
meeting-addicted managers with ones that are accustomed to distributed
and asynchronous work.&lt;/p&gt;
&lt;p&gt;Finally, and this may be a bitter pill to swallow: getting to
distributed and asynchronous is infinitely harder if you have built a
"flat" organization. If every one of your managers has 20-30 direct
reports, they will feel utterly overwhelmed at the thought of staying
in asynchronous communication with every one of them, not to mention
the fact that it's damn near impossible for them to convince that many
people at one time to adopt a new way of collaboration.&lt;/p&gt;
&lt;p&gt;This is one of the many, many ways in which &lt;a href="https://getlighthouse.com/blog/flat-organizational-structure-fails/"&gt;flat organizations fail
to
scale&lt;/a&gt;,
but this gives you the opportunity to fix two issues at the same
time. If you've got one manager that's actively promoting meeting hell
that is currently making life miserable for 20 people, you can split
that team up into 4, and hire 3 team leads that know how to work
asynchronously and distributed (or promote people who have that sort
of experience and want to step up). Then, in the one remaining team
with the unreformed meeting addict, things can go three ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The one "traditional" team sees how things go in the other teams,
  and they quickly coax their team lead into doing things the new way, or&lt;/li&gt;
&lt;li&gt;they all ask to be transferred, or&lt;/li&gt;
&lt;li&gt;(the worst-case scenario) the one meeting-addicted manager continues
  to annoy everyone, and they all leave. That's bad, and a failure of
  judgment (that manager should probably have been let go first), but
  losing 4 good people, as difficult as that might be, is probably
  “better” than losing 20.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As a final thought, &lt;em&gt;please&lt;/em&gt; take a moment to put yourself in other
people's shoes, and understand what options &lt;em&gt;they&lt;/em&gt; have with being
stuck in meeting hell. Whether it's your &lt;a href="https://xahteiwi.eu/blog/2021/10/02/getting-out-of-meeting-hell-managers/"&gt;line
managers&lt;/a&gt; or your
regular
&lt;a href="https://xahteiwi.eu/blog/2021/10/01/getting-out-of-meeting-hell-employees/"&gt;employees&lt;/a&gt;, they
both have the option to just chuck in their notice and leave, and
leave they will, if they're sufficiently deep in meeting hell. They
have plenty of opportunities.&lt;/p&gt;
&lt;p&gt;So lead by example, and lead by policy. Do things right, but more
importantly do the right things.&lt;/p&gt;
&lt;hr/&gt;
&lt;blockquote&gt;
&lt;p&gt;This article concludes the series — for now. I am guessing that
people reading this will have opinions, air their grievances, and
share feedback. Those usually give me good thinking material to
dwell on, so I’ll probably have an additional installment based on
reader feedback at some point.&lt;/p&gt;
&lt;/blockquote&gt;</content><category term="blog"></category><category term="Work"></category><category term="Communications"></category></entry><entry><title>Getting out of Meeting Hell: As a mid-level manager</title><link href="https://xahteiwi.eu/blog/2021/10/02/getting-out-of-meeting-hell-managers/" rel="alternate"></link><published>2021-10-02T00:00:00+00:00</published><updated>2021-10-02T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-10-02:/blog/2021/10/02/getting-out-of-meeting-hell-managers/</id><summary type="html">&lt;p&gt;A short series on transitioning to distributed work and asynchronous collaboration. This article is on what you can do if you are stuck in meeting hell as a mid-level manager.&lt;/p&gt;</summary><content type="html">&lt;blockquote&gt;
&lt;p&gt;Please have a look at the
&lt;a href="https://xahteiwi.eu/blog/2021/09/30/getting-out-of-meeting-hell/"&gt;introduction&lt;/a&gt; for
background, for applicable disclaimers, and for information about
the specific environments this series talks about.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This part of this series is for you if you are a manager at any level
of your organization &lt;em&gt;except the very top.&lt;/em&gt; In other words, you have
reports, but you also report to someone. And as such you may be stuck
in meeting hell in two ways:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;With your own team, that is to say, yourself and the people
   reporting to you.&lt;/li&gt;
&lt;li&gt;With your management peers, in other words, the people that manage
   other teams and report to the same director, VP, or whatever other
   fancy titles your company might use.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;And I’ll cover both of those angles, but before I do, I should note
that you, of course, have one option to improve your personal
situation that is &lt;a href="https://xahteiwi.eu/blog/2021/10/01/getting-out-of-meeting-hell-employees/"&gt;also available to your
reports&lt;/a&gt;:
&lt;strong&gt;Leave.&lt;/strong&gt; It’s not the only option you have, and it may not be your
&lt;em&gt;first&lt;/em&gt; option, but an option it is. And, for your personal
development, taking on a management role in a company that does
distributed work and asynchronous communications right might be an
excellent career move.&lt;/p&gt;
&lt;p&gt;If you are a conscientious manager and you feel a sense of
responsibility and obligation to your team, and this makes you
hesitate to consider the option to leave, then that reflects nobly on
your character but know this: that responsibility is contigent on
everyone’s employment in one organization, and it ends the day your
employment contract (or theirs) terminates. That may sound harsh, but
that’s the breaks of the game, and you shouldn’t let that hold you up,
if leaving is the objectively most sensible option for you. There’s no
use burning out over an exaggerated sense of duty.&lt;/p&gt;
&lt;p&gt;In addition, I'd posit that you &lt;em&gt;should&lt;/em&gt; leave your company if it
employs or promotes employee surveillance, keeps voodoo "meeting
engagement metrics", or engages in otherwise harmful or toxic
behavior. I'd argue that in those cases you should also make sure your
direct reports know why you're leaving, to the extent that your
contractual obligations allow you to tell them.&lt;sup id="fnref:non-disparagement"&gt;&lt;a class="footnote-ref" href="#fn:non-disparagement"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;However, if you’ve chosen &lt;em&gt;not&lt;/em&gt; to leave your current organization,
and you want to actually do the hard work for making work
&lt;em&gt;better&lt;/em&gt; for yourself and your distributed team, here is your
paramount obligation:&lt;/p&gt;
&lt;h2&gt;Learn.&lt;/h2&gt;
&lt;p&gt;If there’s anything that the coronavirus pandemic has shown about
organizations making the (admittedly abrupt) transition from localized
to distributed work, it’s this: it’s a challenge for managers much
more than for non-manager employees. You have to make a conscious
effort to learn how distributed work works, and how you manage a
distributed team.&lt;/p&gt;
&lt;p&gt;But, chances are that you won’t be limited to watching talks or
listening to podcasts or reading articles (you might have &lt;a href="https://xahteiwi.eu/resources/presentations/no-we-wont-have-a-video-call-for-that/"&gt;read this
one&lt;/a&gt; before you
landed here). Instead, it’s not unlikely that if you’re doing software
or technology development, some of the people on your team are already
well versed in distributed collaboration and asynchronous
communications. Yes, I am of course talking about open source
contributors. It absolutely does not matter &lt;em&gt;what kind&lt;/em&gt; of open source
software some on your team have worked or helped out on, or whether
it’s in any way related to the products your company builds. Everyone
who’s ever landed a pull request probably has had to learn more about
distributed, async communications than any office dweller did who
never has. Find those people. Talk to them. Learn from them.&lt;/p&gt;
&lt;p&gt;You’ll also have peers in the industry, outside your company. Managers
who’ve already done the work. They can’t do the &lt;em&gt;learning&lt;/em&gt; for you,
but they can you show a few tricks of the trade.&lt;/p&gt;
&lt;p&gt;And I’ll give you one, straight away: in a company stuck in Meeting
Hell, you change things for your team first, and don’t even think
about people at or above your level.  I would not advise taking your
ideas up the chain without the confidence of knowing that what you are
suggesting works in &lt;em&gt;your&lt;/em&gt; team. Mid-level management is unfortunately
often full of “great idea, but it’ll never work here” or “that might
sound nice, but I’m afraid it doesn’t fit our culture.” You want to
run silent, run deep (if you permit me a strained metaphor). When your
team lands its first great big success, &lt;em&gt;that’s&lt;/em&gt; when you casually
want to drop something like “we did this on one meeting a week.”&lt;/p&gt;
&lt;p&gt;So, how can you get there? Here are a few ideas.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Eliminate daily standups.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Limit yourself to one scheduled team meeting a week. Keep it to
  approximately one hour, give or take a few minutes. Schedule it near
  the start of the work week (meaning, in most countries, on Monday).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Have an agenda for your team meeting (and &lt;em&gt;all&lt;/em&gt; other meetings) that
  is available in a collaboratively editable document,
  cross-referencing all open tasks. Have this agenda in a place where
  everyone can find it, and have it ready no later than 15 minutes
  prior to the meeting.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;During the meeting, transform the agenda into your meeting
  notes. This is something a collaboratively editable document (like a
  wiki page or Google Doc) makes easy. Appoint a responsible
  note-taker or scribe, whose job it is to compile the meeting notes,
  edit minor glitches and errors, and then let you know the notes are
  ready for consumption. You may decide that &lt;em&gt;everyone&lt;/em&gt; who is in the
  meeting can co-edit the notes, and this can be very beneficial to
  make sure that even the quiet voices are heard. But it’s the
  scribe’s responsibility to bring them into good shape, and it’s your
  responsibility as the team lead to make sure they’re truthful and
  accurate.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Spend the first 15-20 minutes of the weekly meeting on non-work
  topics. Ask something like "how was your weekend" or "how are things
  going in your part of the world" or anything else that you can think
  of that helps you feel the mood of your team. These things don’t go
  on the meeting record. Always accept when people don't want to give
  an answer. They may have many reasons, none of which are necessarily
  your business. Trust that they'll share whatever they're comfortable
  sharing, even if some weeks that's nothing.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Learn to keep each other appraised of your relative progress and
  status via a simple, central coordination facility, such as a
  virtual Kanban board.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Learn to &lt;a href="https://2018.pycon-au.org/talks/41002-writing-to-be-understood/"&gt;write to be
  understood&lt;/a&gt;,
  and encourage your team to do the same.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Do not attempt to get back to people "immediately", and do not
  expect people to get back to you promptly. A reasonable default
  expectation for reply times is 24 hours. If you need an answer
  faster, you can always send an email (or better still, a comment on
  a card or ticket) with a request like "if I could get this by 1600
  UTC today, that'd be excellent." Bonus points if you add &lt;em&gt;why&lt;/em&gt; you
  need that information quickly, as in "... so I can put this together
  with Kim's performance data and make a decision on which load
  balancing strategy we'll use, which Alex needs to know by tomorrow."&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Establish a convention for marking things as urgent, when
  needed. The word &lt;em&gt;URGENT&lt;/em&gt;, included in capital letters in an email
  subject or a chat message, usually works well. &lt;em&gt;Only&lt;/em&gt; use this if
  things are on fire.&lt;sup id="fnref:not-urgent-by-default"&gt;&lt;a class="footnote-ref" href="#fn:not-urgent-by-default"&gt;2&lt;/a&gt;&lt;/sup&gt; &lt;em&gt;Never&lt;/em&gt; use the urgency
  marker just by itself. (That's a &lt;a href="https://fedoraproject.org/wiki/No_naked_pings"&gt;naked
  ping&lt;/a&gt; on steroids.)
  Also, when someone legitimately uses the marker in communication
  with &lt;em&gt;you,&lt;/em&gt; honour it. When someone uses it for something other than
  a legitimate reason, take them to task.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Get used to referring back to written communication, such as ticket
  comments or the record of a meeting, weeks or months later. This is
  not “pulling out the receipts” or “quoting chapter and verse” at
  someone. It simply serves to establish that yes, we have a written
  record of just about everything, and there is no need to keep these
  things stored in our heads under a banner saying “must not forget”
  (the latter being a major contributor to personal stress).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Don’t attempt to hide your own mistakes and misjudgements. They’re
  on the record. That makes them a learning opportunity.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Gradually establish firm communication rules with your team. Many of
  these won’t need to be autocratically decreed, because they just
  make sense and people tend to intuitively agree on them (like the
  just-mentioned &lt;em&gt;URGENT&lt;/em&gt; marker and the circumstances under which to
  use them). Then, make sure you &lt;a href="https://xahteiwi.eu/blog/2021/09/16/rules-are-rules/"&gt;stick to
  them&lt;/a&gt;. Stick to them yourself, and
  correct others who break them.&lt;sup id="fnref:asshole-filter"&gt;&lt;a class="footnote-ref" href="#fn:asshole-filter"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Importantly, &lt;em&gt;let your team know&lt;/em&gt; that you're working on getting them
&lt;em&gt;all&lt;/em&gt; out of meeting hell. Don't sugarcoat things if you're struggling
while swimming against the company tide, at least temporarily. If they
know you're actively striving to make their work situation better, more
productive &lt;em&gt;and healthier&lt;/em&gt; it may well make the difference between
&lt;a href="https://xahteiwi.eu/blog/2021/10/01/getting-out-of-meeting-hell-employees/"&gt;them leaving&lt;/a&gt; and
staying on board.&lt;/p&gt;
&lt;p&gt;Finally, keep an eye on corporate policy and the messages you get from
company leadership. If they're obviously stuck in 1995, you might as
well go and update your CV. If the people at the top do &lt;a href="https://xahteiwi.eu/blog/2021/10/03/getting-out-of-meeting-hell-executives/"&gt;make an
effort to implement distributed and async friendly
policies&lt;/a&gt;,
however, then things may not change overnight, but there’s hope that
change they will, and your effort will not be for naught.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:non-disparagement"&gt;
&lt;p&gt;By the way: if your non-disparagement clause is
so harsh that you can't talk about &lt;em&gt;anything&lt;/em&gt; negative in the
company, then that's probably an awful company to begin with. &lt;a class="footnote-backref" href="#fnref:non-disparagement" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:not-urgent-by-default"&gt;
&lt;p&gt;Note that the convention of the &lt;em&gt;URGENT&lt;/em&gt;
marker also establishes the convention that things are &lt;em&gt;not&lt;/em&gt;
urgent by default. &lt;a class="footnote-backref" href="#fnref:not-urgent-by-default" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:asshole-filter"&gt;
&lt;p&gt;Failure to enforce sensible collaboration rules may
  result in the inadvertent creation of an &lt;a href="https://siderea.livejournal.com/1230660.html"&gt;asshole
  filter&lt;/a&gt;. “Oh but I
  can't enforce that rule on Bob, because Bob thinks rules aren't for
  him but he's brilliant!” — No. &lt;a href="https://www.brendangregg.com/blog/2017-11-13/brilliant-jerks.html"&gt;Don't tolerate brilliant
  jerks&lt;/a&gt;. &lt;a class="footnote-backref" href="#fnref:asshole-filter" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="blog"></category><category term="Work"></category><category term="Communications"></category></entry><entry><title>Getting out of Meeting Hell: As a regular employee</title><link href="https://xahteiwi.eu/blog/2021/10/01/getting-out-of-meeting-hell-employees/" rel="alternate"></link><published>2021-10-01T00:00:00+00:00</published><updated>2021-10-01T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-10-01:/blog/2021/10/01/getting-out-of-meeting-hell-employees/</id><summary type="html">&lt;p&gt;A short series on transitioning to distributed work and asynchronous collaboration. This article is on what you can do if you are stuck in meeting hell as a regular employee who isn't in a management role.&lt;/p&gt;</summary><content type="html">&lt;blockquote&gt;
&lt;p&gt;Please have a look at the
&lt;a href="https://xahteiwi.eu/blog/2021/09/30/getting-out-of-meeting-hell/"&gt;introduction&lt;/a&gt; for
background, for applicable disclaimers, and for information about
the specific environments this series talks about.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So, you're a regular employee (sometimes called an &lt;em&gt;Individual
Contributor&lt;/em&gt; or IC), who doesn't have a team that reports to you. And
you are in an organization that, although it does have remote
employees or may even have switched to an all-distributed mode on
account of the pandemic, does not adopt basic rules of
distributed work and asynchronous communications.&lt;/p&gt;
&lt;p&gt;You spend more time in meetings than is healthy, your productivity is
severely impacted, you're stressed out from frequent interruptions,
you have trouble getting into a state of
&lt;a href="https://en.wikipedia.org/wiki/Flow_(psychology)"&gt;flow&lt;/a&gt;. You may be
asked to keep your camera on for hours at a time, and you feel that
this badly encroaches on your privacy or sense of personal space. Your
manager or your peers like to
&lt;a href="https://fedoraproject.org/wiki/No_naked_pings"&gt;naked-ping&lt;/a&gt; you or
send you "hey, I need you for a minute" one-liners that &lt;a href="https://heeris.id.au/2013/this-is-why-you-shouldnt-interrupt-a-programmer/"&gt;disrupt your
train of
thought&lt;/a&gt;
for half an hour.&lt;/p&gt;
&lt;p&gt;And your organization (including your peers and direct manager)
tolerate or condone this kind of collaboration.&lt;/p&gt;
&lt;p&gt;If that sounds like your typical day, I have great news for you. You
have at hand an excellent opportunity to improve your personal
situation, be more productive, and communicate better with your peers:&lt;/p&gt;
&lt;h2&gt;Leave.&lt;/h2&gt;
&lt;p&gt;Hand in your notice. Quit. Hightail it outta there. If &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;you want to truly improve your personal situation and work
  effectively in a distributed team, &lt;em&gt;and&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;neither your direct manager nor the top leadership of the
  organization takes any interest in optimizing for distributed and
  asynchronous collaboration,&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;then the way to do that &lt;em&gt;for yourself&lt;/em&gt; is to leave your current
organisation behind, and go elsewhere. There's plenty of employment
opportunities for you to pick up in this industry at this time, and
there are a number of organizations that handle distributed work
better than the one you're currently in.&lt;/p&gt;
&lt;p&gt;Sure, you could consider trying to change the system from within. And
there is a small (I'd say minute, but nonzero) probability that you'll
be successful, and drive real change in your organization. However,
there is an inordinately &lt;em&gt;larger&lt;/em&gt; probability that you'll burn out in
the process — and endangering your health is never a gamble that's
worth taking.&lt;/p&gt;
&lt;p&gt;You may think that that’s a pessimistic view. I think the opposite is
true. You’re not “failing” to drive change in an organization that
resists it, instead you can succeed at pushing change in an
organization that embraces it. Throwing your energy into meaningful
change for the better is the definition of optimism, in my book. And
if the place for that is elsewhere from where you are now, seize that
opportunity!&lt;/p&gt;
&lt;p&gt;However, note that the foregoing is all predicated on the entire
company (including your direct manager) being &lt;em&gt;fine&lt;/em&gt; with synchronous
work and people having their calendar jammed with back-to-back
meetings, with no apparent intent to change. If it’s just you that
wants change, or perhaps only you and people at your level in &lt;em&gt;other&lt;/em&gt;
teams that you can’t reasonably join forces with, I’d argue that you
just shouldn’t be risking your health. In contrast, if your
manager&lt;sup id="fnref:direct-manager"&gt;&lt;a class="footnote-ref" href="#fn:direct-manager"&gt;1&lt;/a&gt;&lt;/sup&gt; and a couple of your peers are on your side —
consider your manager may be in their own
&lt;a href="https://xahteiwi.eu/blog/2021/10/02/getting-out-of-meeting-hell-managers/"&gt;learning&lt;/a&gt; phase
about distributed and async collaboration — then things are a lot less
clean cut, and maybe you’d want to stay on for the ride. Particularly
so if there's an active, supportive push &lt;a href="https://xahteiwi.eu/blog/2021/10/03/getting-out-of-meeting-hell-executives/"&gt;from the
top&lt;/a&gt; of the
organization.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Even if&lt;/em&gt; your manager and some of your peers are on your side, I can
think of a few situations where you should still leave: like when your
company has an “always on camera” policy, or doesn’t allow people to
go audio-only on calls, or promotes &lt;a href="https://docs.microsoft.com/en-us/microsoftteams/teams-analytics-and-reports/teams-reporting-reference"&gt;number crunching on employee
“engagement” in a meeting
app&lt;/a&gt;. Companies
doing that are, in my view, beyond salvation and will never be able to
attain the levels of trust required for a distributed organization to
function.&lt;/p&gt;
&lt;p&gt;So: if you’re stuck in meeting hell with nobody on your side, as a
regular employee with no reports, your best way forward is probably
the way to the exit. If you're stuck in meeting hell &lt;em&gt;now&lt;/em&gt; but there's
a gale blowing the company into async &amp;amp; distributed mode, and/or you
have a very thick-skinned manager that gets it, and will deflect and
absorb any pressure from meeting-addicted higher-ups, you may want to
hang on for the journey.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:direct-manager"&gt;
&lt;p&gt;I’d posit that the only manager that really matters
in this scenario is your &lt;em&gt;direct&lt;/em&gt; line manager. That person would
your make-or-break partner in any transformation of how your team
collaborates. If you and they don’t share views, then don’t expect
to be able to play four-dimensional chess by forming an alliance
with some &lt;em&gt;other&lt;/em&gt; manager who you then expect to influence &lt;em&gt;your&lt;/em&gt;
manager so that &lt;em&gt;everyone&lt;/em&gt; gets better at distributed and async
work. You don’t want to trade being stuck in meeting hell for
being in stuck in meeting hell &lt;em&gt;and corporate politics.&lt;/em&gt; &lt;a class="footnote-backref" href="#fnref:direct-manager" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="blog"></category><category term="Work"></category><category term="Communications"></category></entry><entry><title>Getting out of Meeting Hell: What this is about</title><link href="https://xahteiwi.eu/blog/2021/09/30/getting-out-of-meeting-hell/" rel="alternate"></link><published>2021-09-30T00:00:00+00:00</published><updated>2021-09-30T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-09-30:/blog/2021/09/30/getting-out-of-meeting-hell/</id><summary type="html">&lt;p&gt;A short series on transitioning to distributed work and asynchronous collaboration. This article is the introduction.&lt;/p&gt;</summary><content type="html">&lt;p&gt;In 2020, I presented a talk at &lt;a href="https://www.froscon.de"&gt;FrOSCon&lt;/a&gt;
titled &lt;a href="https://media.ccc.de/v/froscon2020-2605-no_we_won_t_have_a_video_call_for_that"&gt;No, we won’t have a video call for that: Communications for
distributed
teams.&lt;/a&gt;
In early 2021 I put together a full-length writeup of that talk, and
&lt;a href="https://xahteiwi.eu/resources/presentations/no-we-wont-have-a-video-call-for-that/"&gt;published it
here&lt;/a&gt;. And for no
apparent reason that article then &lt;a href="https://news.ycombinator.com/item?id=28636536"&gt;made it to the top of Hacker
News&lt;/a&gt; on one day in
September 2021,&lt;sup id="fnref:newsy"&gt;&lt;a class="footnote-ref" href="#fn:newsy"&gt;1&lt;/a&gt;&lt;/sup&gt; and apparently &lt;a href="https://twitter.com/xahteiwi/status/1442371424543444994"&gt;resonated with quite a few
people&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;And after that, I got a fair number of questions along the lines of
“okay, what you talk about is a spot-on description of how I &lt;em&gt;want&lt;/em&gt; to
work, but how do I get there?” In other words, &lt;strong&gt;what can you do in
order to transition from a team that's stuck in meeting hell, to one
that actually goes fully distributed and embraces asynchronous
communications?&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; I use the shorthand &lt;em&gt;Meeting Hell&lt;/em&gt; for a situation in
which people are forced to be in unnecessary and unproductive video
meetings&lt;sup id="fnref:in-person-meeting"&gt;&lt;a class="footnote-ref" href="#fn:in-person-meeting"&gt;2&lt;/a&gt;&lt;/sup&gt; for an unhealthy fraction of their work
time.&lt;/p&gt;
&lt;p&gt;This is admittedly a mere &lt;em&gt;symptom&lt;/em&gt; of not having adopted
asynchronous and distributed ways of working, but it’s such a
tell-tale sign thereof that it counts as a dead giveaway. Thus, I
think it’s okay to say “I’m stuck in meeting hell” when what someone
means is really “I work in an organization that’s failing badly at
distributed and asynchronous work.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So what I’m doing here is offer &lt;strong&gt;suggestions&lt;/strong&gt; for getting out of that. If&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;you’re one of the people that has 25 meetings a week, or&lt;/li&gt;
&lt;li&gt;you &lt;a href="https://news.ycombinator.com/item?id=28652514"&gt;spend 60% of your work
  week&lt;/a&gt; in standups and
  planning and retro, or&lt;/li&gt;
&lt;li&gt;the only time you have for doing what you actually signed up for &lt;a href="https://news.ycombinator.com/item?id=28653696"&gt;is
  in overtime&lt;/a&gt;,&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;and it’s grinding you down, and you want to work differently, then
this series might be for you.&lt;/p&gt;
&lt;h3&gt;Personal strategies: one size does not fit all&lt;/h3&gt;
&lt;p&gt;I think it’s very important to &lt;strong&gt;differentiate personal strategies&lt;/strong&gt; for
getting to distributed &amp;amp; async, based on your position in the company
or organization. So, I’m going to look at it from three angles:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Your options if you are what some companies call an “Individual
   Contributor”, or IC. In other words, these are for you if you are a
   &lt;strong&gt;regular employee&lt;/strong&gt; (or contractor), and you’re &lt;em&gt;not&lt;/em&gt; personally
   responsible for other people — in other words, you have no reports.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Your options if you are at some level of &lt;strong&gt;management&lt;/strong&gt; that is
   &lt;em&gt;not&lt;/em&gt; top organizational leadership. That is to say, you have
   people that report to you, but you also report to someone.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Your options if you’re a &lt;strong&gt;top-level executive&lt;/strong&gt;, meaning you’re a
   Chief Executive Officer or Managing Director or Executive Director
   or something of the sort. You have people that report to you, but
   you don’t directly report to anyone — even though you may be
   answerable to a Board of Directors or some other oversight body, of
   course.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;These are my views, not self-evident truths&lt;/h3&gt;
&lt;p&gt;Now, I’m only going to talk about my industry (software-driven
technology) because that’s the only industry I feel remotely qualified
to talk about. Also, I have never worked in a company that had more
than 3,000 employees, and I feel most at home in small outfits under
50. I’m reasonably confident that what I talk about is somewhat useful
for companies from 3 to 3,000 people in the software industry. It
&lt;em&gt;may&lt;/em&gt; be applicable elsewhere — larger companies, other industries —
but at any rate, I make no guarantees of any kind. Feel free to adopt
an entirely contrarian position. And, you should also know I am not a
scientist, so none of what I write is informed by rigorous empiricism.&lt;/p&gt;
&lt;p&gt;So, are we cool with that? &lt;strong&gt;My opinion, my thoughts, my views — not
pronouncements of absolute truth.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let’s get started.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:newsy"&gt;
&lt;p&gt;For context: it was at the top for like three hours on a
Saturday morning. So it might have landed there just because
enough people were simultaneously bored enough to give it a
read... &lt;a class="footnote-backref" href="#fnref:newsy" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:in-person-meeting"&gt;
&lt;p&gt;Meeting Hell might &lt;em&gt;also&lt;/em&gt; apply to excessive
in-person meetings in a shared work space, such as an
office. However, I really don't believe my industry will ever go
back to defaulting to office-based work, now that it has shown for
nearly two years that it &lt;em&gt;can&lt;/em&gt; function, in principle, in a
default-distributed mode. Thus, I am using the word "meeting" as
synonymous with "video meeting" in this series, and I wouldn't be
surprised if this eventually became the norm.&lt;/p&gt;
&lt;p&gt;Think of this as
akin to the transition undergone by the word &lt;em&gt;call:&lt;/em&gt; before
the advent of the telephone, a &lt;em&gt;call&lt;/em&gt; was a visit you paid to
someone's house. Then, if you metaphorically "visited" someone by
telephone, that was a &lt;em&gt;telephone call&lt;/em&gt;. Now a &lt;em&gt;call&lt;/em&gt; is always a
phone call, except when explicitly specified as a &lt;em&gt;house call.&lt;/em&gt; &lt;a class="footnote-backref" href="#fnref:in-person-meeting" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="blog"></category><category term="Work"></category><category term="Communications"></category></entry><entry><title>No, We Won’t Have a Video Call for That: Reader Feedback</title><link href="https://xahteiwi.eu/resources/presentations/no-we-wont-have-a-video-call-for-that-reader-feedback/" rel="alternate"></link><published>2021-09-26T00:00:00+00:00</published><updated>2021-09-26T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-09-26:/resources/presentations/no-we-wont-have-a-video-call-for-that-reader-feedback/</id><summary type="html">&lt;p&gt;Communications in distributed teams: a write-up of my talk from FrOSCon 2020, Cloud Edition.&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a short summary of selected reactions to &lt;a href="https://xahteiwi.eu/resources/presentations/no-we-wont-have-a-video-call-for-that/"&gt;the original
article&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Twitter, 2021-04-10&lt;/h3&gt;
&lt;p&gt;On Twitter, &lt;a href="https://musings.danlj.org/about/"&gt;Michael K Johnson&lt;/a&gt; made
&lt;a href="https://twitter.com/mcdanlj/status/1380661700664422406"&gt;an interesting
point&lt;/a&gt; in
response to this article:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;My way of thinking about DMs is a little different, or maybe we
 think differently about confidentiality. Work goes in public,
 meta-work is often about relationships, and I want my reports to be
 100% confident they can bring any question or concern to me.&lt;/p&gt;
&lt;p&gt;So "encrypted email" is not the right metaphor or measuring stick in
my view. DMs are a tool for saying what you aren't comfortable
saying "out loud", but that shouldn't be about the work
itself. Never "how do I do this?" But "advice pls about how to work
with fred?" — yes!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I entirely agree with the sentiments behind this; I still maintain
that chat DMs are not necessarily a good approach for addressing this,
for reason that some chat systems give merely an illusion of
confidentiality. If both participants in a conversation use OTR
encryption over a protocol like IRC or XMPP, inadvertent disclosure to
a third party is highly unlikely. Slack DMs? &lt;a href="https://www.nbcnews.com/better/business/slack-updates-privacy-policy-employers-can-read-private-dms-without-ncna862811"&gt;I wouldn't be so
sure&lt;/a&gt;. If
your report confides in you, you don't want them to have to worry if
their message is &lt;em&gt;really&lt;/em&gt; just between you and them.&lt;/p&gt;
&lt;h3&gt;Hacker News, 2021-09-25&lt;/h3&gt;
&lt;p&gt;On 2021-09-25, &lt;a href="https://news.ycombinator.com/item?id=28636536"&gt;a link to this
article&lt;/a&gt; ended up being
the top post on Hacker News for a few hours. You're very welcome to
read through the 200-odd comments in that thread, but here I'd like to
respond to just a couple. I'm deliberately only picking out ones where I
feel like &lt;em&gt;clarification&lt;/em&gt; on my part is necessary; as far as
differences of opinion are concerned I'll be happy to let those stand.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The article also assumes every one is a native speaker who can write
quickly and clearly in a chat -- in a lot of international projects
this is not the case.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;— &lt;a href="https://news.ycombinator.com/item?id=28651678"&gt;comment&lt;/a&gt; from &lt;code&gt;papaf&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;My native language is German, and neither at the time of presenting
the original talk nor at the time of writing this update did I work
with anyone who is a first-language English speaker.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I have an objection to the author's blanket disregard for "pings" in
chat - while the request could/should be worded a bit more clearly
than just "ping", IMHO they're a valid way of requesting if an
opportunity for synchronous communication is available in the (not
that rare!) cases where asynchronous communication would be
worthless.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;— &lt;a href="https://news.ycombinator.com/item?id=28652633"&gt;comment&lt;/a&gt; from &lt;code&gt;PeterisP&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;My blanket disregard is for &lt;em&gt;naked&lt;/em&gt; pings, not for pings in general.&lt;/p&gt;</content><category term="presentations"></category><category term="Conference"></category><category term="Communications"></category><category term="Work"></category></entry><entry><title>Rules are rules</title><link href="https://xahteiwi.eu/blog/2021/09/16/rules-are-rules/" rel="alternate"></link><published>2021-09-16T00:00:00+00:00</published><updated>2021-09-16T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-09-16:/blog/2021/09/16/rules-are-rules/</id><summary type="html">&lt;p&gt;I have a reputation for being rigid when it comes to communication rules. Here's why I am.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I have a reputation among my colleagues that I am very strict and
rigid about the communications rules I follow for myself, and for my
team. That reputation is entirely deserved, and I am indeed not
particularly flexible in my strong preference for asynchronous,
non-interruptive communication methods. I have discussed
&lt;a href="https://youtu.be/CyzoF7mHEBo"&gt;elsewhere&lt;/a&gt;, and &lt;a href="https://xahteiwi.eu/resources/presentations/no-we-wont-have-a-video-call-for-that/"&gt;at
length&lt;/a&gt;, what
those are and &lt;em&gt;why&lt;/em&gt; I have that strong preference. But I haven't
really outlined why I very rarely allow myself, or others if I can
help it, to deviate from it.&lt;/p&gt;
&lt;p&gt;But Florian, the complaint usually goes, can't you occasionally make
an exception? Sometimes there's something you could easily do to
unblock someone else, if they could only quickly chat you up and ask
you to jump in. You'd be in and out of there in no time.&lt;/p&gt;
&lt;h2&gt;Let's use an analogy here.&lt;/h2&gt;
&lt;p&gt;Suppose you're out of an indispensable food product, say milk or flour
or potatoes or eggs. So you make a quick run to the grocery store, and
because you don't live in a country with proper cycling infrastructure
and the store is out of walking distance, you drive.&lt;/p&gt;
&lt;p&gt;You arrive at the grocery store parking lot, and for some unfathomable
reason it's chock full. Completely packed. Not a single spot
available. Except those two spots right near the store entrance that
are reserved for wheelchair users, which you are not. You don't see a
single car around with a wheelchair plaque or decal. Not even one.&lt;/p&gt;
&lt;p&gt;Now. When you look at the situation, the objectively simplest and most
practical solution is for you to park in a wheelchair spot. You know
exactly how long it takes you to buy a carton of eggs; you'd be in and
out of that place in two minutes. The chance that one car needing a
wheelchair spot arrives in exactly that time is minute, and even then
there would be another one available. The probability of &lt;em&gt;two&lt;/em&gt;
wheelchair users arriving in their cars, simultaneously, in those two
minutes, is infinitesimal. There is an overwhelming probability that
you will vacate the spot again, without it ever being needed by one of
its intended users while you were occupying it. So, why not use it?&lt;/p&gt;
&lt;p&gt;The answer is that if it's OK for &lt;em&gt;you&lt;/em&gt; to break the rule that that
spot is for wheelchair users only, &lt;em&gt;there is absolutely no reason why
it shouldn't also be OK for everyone else.&lt;/em&gt; You're not special, the
same rules apply to you as to everyone else — so if we were to decide
that this rule &lt;em&gt;doesn't&lt;/em&gt; apply to you this very minute, then it also
needn't apply to anyone else under similar circumstances.&lt;/p&gt;
&lt;p&gt;And then, promptly, we're in a situation where everyone flouts the
rules, and an actual wheelchair user can no longer do their grocery
shopping. That's why you, if you are not a wheelchair user, shouldn't
park there, and nobody else that isn't shouldn't either.&lt;/p&gt;
&lt;p&gt;And with interruptive communications — such as pinging someone in a
chat when you could send them an email just the same — it's much the
same way: if you needlessly ping me and I acquiesce, drop the thing
I'm doing, and focus on your interruption instead, it would be unfair
of me to not do the same for somebody else. And I know if &lt;em&gt;everyone&lt;/em&gt;
does this to me, my work day is purely interrupt driven and that's
awful. The same goes for tolerating interruptive communications
towards my team — or, worse, engaging in such interruptive
communications myself.&lt;/p&gt;
&lt;h2&gt;Are there exceptions to this rule?&lt;/h2&gt;
&lt;p&gt;Ah but of course. Let me take you back to the grocery store. Suppose
someone had a heart attack or other major health emergency that struck
them down right as they were exiting the store and walking back to
their car. Would anyone — including a wheelchair-using motorist that
arrived just at that moment to do their shopping — complain if the
ambulance parked across &lt;em&gt;both&lt;/em&gt; wheelchair accessible spots, if that
was the only practical way to get closest to the patient? I hope
not. And caring for the patient and stabilising them for the trip to
the hospital would surely take longer than your two-minute egg
procurement dash that we discussed earlier.&lt;/p&gt;
&lt;p&gt;Again, this has a parallel in interruptive communications in a (much
less dire) regular work situation: stuff is actually on fire? Or
there's something that for some legitimate reason needs doing &lt;em&gt;right
now&lt;/em&gt; that only I or someone on my team can do, or is most comfortable
with? Ping me in chat, use the back channel, give me a ring on my
&lt;em&gt;phone&lt;/em&gt; for cryinoutloud, whatever it takes to get my
attention. Nobody will hold that against you, least of all me. And in
this case that's a rule that I can &lt;em&gt;also&lt;/em&gt; easily apply generally,
treating everyone around me fairly and equitably: when stuff is urgent
and seriously overrides the priority of what's currently being worked
on, you get to interrupt me or, if necessary anyone on my
team. (Though I would prefer that you interrupt me specifically, and I
can decide whether we really need to mobilise another person.)&lt;/p&gt;
&lt;p&gt;Just don't abuse that. If you do, you'll just condition people into
taking your sense of "urgent" with a big pinch of salt.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;&lt;em&gt;Edit, 2021-09-21:&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;My colleague &lt;a href="https://be.linkedin.com/in/evrardjp"&gt;Jean-Philippe Evrard&lt;/a&gt;
has suggested that I refer to another, much more elaborate article on
a similar subject: Siderea's &lt;em&gt;&lt;a href="https://siderea.dreamwidth.org/1209794.html"&gt;The Asshole
Filter&lt;/a&gt;&lt;/em&gt;. I recommend you
give it a read if you're inclined.&lt;/p&gt;</content><category term="blog"></category><category term="Communications"></category><category term="Work"></category></entry><entry><title>How to write a decent job ad</title><link href="https://xahteiwi.eu/blog/2021/08/27/decent-job-ads/" rel="alternate"></link><published>2021-08-27T00:00:00+00:00</published><updated>2021-08-27T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-08-27:/blog/2021/08/27/decent-job-ads/</id><summary type="html">&lt;p&gt;This is a series on writing job ads that people actually get interested in.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Over time I've come to accept that one of the things I'm apparently
reasonably competent at is writing and publishing ads for open
positions, and I've received questions and requests for advice from
other folks who hire people. So I'm going to try and break down what I
consider a decent job ad. Not a perfect one mind you, perhaps not even
a particularly &lt;em&gt;good&lt;/em&gt; one, just a decent one that people will want to
read, pass on, and maybe apply to.&lt;/p&gt;
&lt;h2&gt;A few general notes&lt;/h2&gt;
&lt;p&gt;I try to write an ad in such a way that it answers most of the
questions an applicant might have about the position. And I then
structure it like an imagined conversation between a potential
applicant (asking questions) and me, the hiring manager (answering
them). That's why practically every subheading in the ad is a
question.&lt;/p&gt;
&lt;h2&gt;The structure&lt;/h2&gt;
&lt;p&gt;In my career ads, I give answers to this list of questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What's this gig about? — The ultra-concise summary of the role to be
  filled. One sentence.&lt;sup id="fnref:one-sentence"&gt;&lt;a class="footnote-ref" href="#fn:one-sentence"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;What will I be working on? — Details of the
  systems/processes/responsibilities associated with the role.&lt;/li&gt;
&lt;li&gt;What should I know? — Prerequisite skills and knowledge.&lt;/li&gt;
&lt;li&gt;What can I learn? — Opportunities for acquiring new skills and
  knowledge.&lt;/li&gt;
&lt;li&gt;What communities would I engage with? — People and communities
  &lt;em&gt;outside&lt;/em&gt; your organisation the employee would interact with.&lt;/li&gt;
&lt;li&gt;Who would be my direct manager? — Information about yourself.&lt;/li&gt;
&lt;li&gt;How's work at &lt;em&gt;company?&lt;/em&gt; — Notes on organisational culture.&lt;/li&gt;
&lt;li&gt;What does my team look like? — Notes on team composition and
  culture.&lt;/li&gt;
&lt;li&gt;What does my work week look like? — Information on how the team
  organises its work on a daily/weekly basis.&lt;/li&gt;
&lt;li&gt;Where can I work from? — Information about preferences or
  restrictions regarding the physical location of prospective
  employees.&lt;/li&gt;
&lt;li&gt;Can I work from home?&lt;sup id="fnref:wfh"&gt;&lt;a class="footnote-ref" href="#fn:wfh"&gt;2&lt;/a&gt;&lt;/sup&gt; — Information about your remote work
  policy.&lt;/li&gt;
&lt;li&gt;What timezone would I work in? — Most teams have preferred
  times-of-day when the majority of team members is awake and working,
  which tends to be when most work gets done. Or, else, your team may
  operate 24/7 in shifts, and you're looking to cover a particular
  shift.&lt;/li&gt;
&lt;li&gt;Is travel involved? — Possibly a non-issue in the middle of a
  pandemic, but you might want to establish expectations for when it's
  over.&lt;/li&gt;
&lt;li&gt;What employment conditions apply? — Have standard contractual
  clauses that apply to everyone, like vacation policies or specific
  packages? Might as well list them.&lt;/li&gt;
&lt;li&gt;When would I start? — Don't assume that your applicants are
  available immediately. If people have a notice period in their
  current job to work with, they'll want to know what's the earliest
  and latest date you want the role filled.&lt;/li&gt;
&lt;li&gt;What will I make? — Compensation.&lt;/li&gt;
&lt;li&gt;How do I apply? — Details and deadlines related to the application
  process.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;The details&lt;/h2&gt;
&lt;p&gt;I have a few more details about several of these items, which I'll try
to elaborate on as my time permits. So there should be more
installments in this series, eventually. Hopefully. 🙂&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:one-sentence"&gt;
&lt;p&gt;Can't condense the role description into one
sentence? You'll either have to work on your editing skills, or
define the role better. &lt;a class="footnote-backref" href="#fnref:one-sentence" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:wfh"&gt;
&lt;p&gt;If your answer to this question is "no", I bid you good luck! &lt;a class="footnote-backref" href="#fnref:wfh" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="blog"></category><category term="Hiring"></category></entry><entry><title>Audience feedback on online conference platforms: a speaker's view</title><link href="https://xahteiwi.eu/blog/2021/08/24/online-conferences-audience-feedback/" rel="alternate"></link><published>2021-08-24T00:00:00+00:00</published><updated>2021-08-24T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-08-24:/blog/2021/08/24/online-conferences-audience-feedback/</id><summary type="html">&lt;p&gt;As a speaker, I look for something very specific in online conference platforms.&lt;/p&gt;</summary><content type="html">&lt;p&gt;We are in year 2 of the Covid-19 pandemic, and open-source conferences
are still, for the most part, online-only events. (And I find myself
questioning the judgment of those that put on large in-person
conferences.) I have spoken at several of such conferences, and I'd
like to zero in on one aspect of my &lt;em&gt;personal&lt;/em&gt; experience, &lt;em&gt;as a
speaker,&lt;/em&gt; on some of the conference platforms I worked with.&lt;/p&gt;
&lt;p&gt;Now, I should explain one thing up front. As a speaker, the thing I
care the most about is:&lt;/p&gt;
&lt;h3&gt;Is this talk useful to you?&lt;/h3&gt;
&lt;p&gt;That's it. That's the paramount question. I want you to take something
away from the talk &lt;em&gt;that you find useful.&lt;/em&gt; Whether that's a technical
insight, or a new angle on a problem, or even just entertainment, I
want there to be something in the talk &lt;em&gt;for you.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;And it's incredibly important for me to get a sense of that, as I am
delivering the talk.&lt;/p&gt;
&lt;p&gt;Now in an in-person event, that's easy: all I need is a look across
the room, and I &lt;em&gt;permanently&lt;/em&gt; look across the room. I can tell if
you're making eye contact, or listening intently, or nodding your
head, or even putting on a face that makes it clear that you're
violently disagreeing with me. Sure, if you raise your hand and ask a
question, or heckle me, or laugh at a joke, that drives the point of
your engagement home — but I don't need you to become so &lt;em&gt;explicitly&lt;/em&gt;
engaged, to know &lt;em&gt;that&lt;/em&gt; you are engaged.&lt;/p&gt;
&lt;p&gt;And it is &lt;em&gt;this kind of feedback&lt;/em&gt; (that you might not even realize
you're giving me!) that makes the difference between delivering a
talk, and just speaking into the void. It's also the difference
between delivering a conference talk, even if it's a pre-recorded one,
and just uploading the video on YouTube. If an conference platform
doesn't give me that kind of feedback channel, the work that I put
into writing, rehearsing, and recording/streaming the talk is better
spent with a view toward upload to a video hosting platform, and
engaging with viewers there.&lt;/p&gt;
&lt;p&gt;So, I as a speaker am foremost interested in a single thing about the
conference platform:&lt;/p&gt;
&lt;h3&gt;Is it easy for you to tell me if my talk is useful to you?&lt;/h3&gt;
&lt;p&gt;And I'm not talking about you getting into a chat and saying "this is
useful." That's much too high of a threshold. How often do you sit in
a talk and then &lt;em&gt;tell&lt;/em&gt; the speaker, "hey, that's useful"? Quite
rarely, and only if you find the content &lt;em&gt;especially&lt;/em&gt; actionable or
insightful. Because you normally don't &lt;em&gt;have to&lt;/em&gt; tell me explicitly:
if you're actively listening to me, I can tell. And I know you
wouldn't be listening to me if I talked useless nonsense.&lt;/p&gt;
&lt;p&gt;And this is one of the reasons why I like
&lt;a href="https://venueless.org/en/"&gt;Venueless&lt;/a&gt; so much. Venueless has
implemented an extremely low-threshold feature of showing audience
engagement. You get a handful of emoji like ❤️👏🤣👍🤔 that you, as a
viewer, can click on, and then they appear in the event chat stream
like "emoji rain" from the top of the screen. Just one click, which
also gets anonymized and lost in the crowd — this last bit is
important for people who are shy or reserved, and don't like to stick
their head out. And this makes it so much easier for you to engage,
than having to actually type a sentence (or even a word, or even
&lt;em&gt;typing&lt;/em&gt; an emoji) into a chat channel.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;I can not tell you enough how much of a difference this makes to the
speaker experience.&lt;/em&gt; Add to this that the event chat is &lt;em&gt;not&lt;/em&gt; shackled
to Slack or any other horribly overgrown not-even-really-chat platform
anymore, and you've got a simple, easy-to-use, no-unnecessary-frills
experience that puts you &lt;em&gt;directly&lt;/em&gt; in touch with your audience. I
loved this at &lt;a href="https://2020.pycon.org.au/"&gt;PyCon AU&lt;/a&gt; last year.&lt;/p&gt;
&lt;p&gt;For comparison, I also saw &lt;a href="https://loudswarm.com/"&gt;LoudSwarm&lt;/a&gt; at
&lt;a href="https://2021.djangocon.eu/"&gt;DjangoCon Europe&lt;/a&gt;. The way it was used in
that conference it seemed very tightly tied to Slack, although the
audience was very nice in using emoji reactions very
generously. Still, it wasn't the same quality of feedback that
Venueless provided.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/lukas2511/voctoconf"&gt;Voctoconf&lt;/a&gt;, which I saw at
FrOSCon, allegedly predates Venueless and was excellent in terms of
streaming, but in terms of audience interaction it's essentially
&lt;a href="https://bigbluebutton.org/"&gt;BigBlueButton&lt;/a&gt; on steroids, meaning it's
about on the same level as the LoudSwarm/Slack combination I saw at
DjangoCon.&lt;/p&gt;</content><category term="blog"></category><category term="Conference"></category></entry><entry><title>Add Depth! Stereoscopic imagery for everyone</title><link href="https://xahteiwi.eu/resources/presentations/add-depth-stereoscopic-imagery-for-everyone/" rel="alternate"></link><published>2021-08-21T00:00:00+00:00</published><updated>2021-08-21T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-08-21:/resources/presentations/add-depth-stereoscopic-imagery-for-everyone/</id><summary type="html">&lt;p&gt;My talk from FrOSCon 2021, Cloud Edition.&lt;/p&gt;</summary><content type="html">&lt;p&gt;FrOSCon 2021 was again an online event due to the COVID-19 pandemic
(&lt;a href="https://xahteiwi.eu/resources/presentations/no-we-wont-have-a-video-call-for-that/"&gt;just like the previous year&lt;/a&gt;), and had a
track named &lt;em&gt;Woodwork instead of IT&lt;/em&gt;, showcasing people's hobbies and
interests they had discovered, or rediscovered, during lockdown.&lt;/p&gt;
&lt;p&gt;So I submitted a talk that has absolutely nothing to do with what I do
for work, and instead covered stereography: making, and viewing,
stereoscopic images and videos.&lt;/p&gt;
&lt;p&gt;The talk recording is available from &lt;a href="https://youtu.be/5wh0IDdMvAk"&gt;YouTube&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;And, as always, you can also review my slides, with all my speaker notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rendered slides: &lt;a href="https://fghaas.github.io/add_depth/"&gt;GitHub
  Pages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slide sources (CC-BY-SA): &lt;a href="https://github.com/fghaas/add_depth"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="presentations"></category><category term="Conference"></category></entry><entry><title>Running (Almost) Anything in LXC: Applications Using Your Webcam</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/lxc-webcam/" rel="alternate"></link><published>2021-01-17T00:00:00+00:00</published><updated>2021-01-17T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-01-17:/resources/hints-and-kinks/lxc-webcam/</id><summary type="html">&lt;p&gt;One of the non-open-source applications I sometimes have to run for
work purposes, and which out of principle I run in LXC containers, is
Zoom. Now Zoom is of course an X application, so my previously shared
&lt;a href="https://xahteiwi.eu/resources/hints-and-kinks/lxc-x11/"&gt;considerations&lt;/a&gt; for those apply. It also needs
to process input from my microphone …&lt;/p&gt;</summary><content type="html">&lt;p&gt;One of the non-open-source applications I sometimes have to run for
work purposes, and which out of principle I run in LXC containers, is
Zoom. Now Zoom is of course an X application, so my previously shared
&lt;a href="https://xahteiwi.eu/resources/hints-and-kinks/lxc-x11/"&gt;considerations&lt;/a&gt; for those apply. It also needs
to process input from my microphone, and feed sound into my
headphones, so &lt;a href="https://xahteiwi.eu/resources/hints-and-kinks/lxc-sound/"&gt;that’ll have to work, too&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But a thus-configured LXC container is still missing one other bit:
it’ll have to process the video feed from my webcam. Here’s how to do
that.&lt;/p&gt;
&lt;h2&gt;LXC Configuration&lt;/h2&gt;
&lt;p&gt;In the article on running &lt;a href="https://xahteiwi.eu/resources/hints-and-kinks/lxc-x11/"&gt;X applications in
LXC&lt;/a&gt;, I give the example of sharing a host
&lt;em&gt;directory,&lt;/em&gt; (the one that contains the X.org server sockets). For
sharing a webcam, I need to do the same for a few &lt;em&gt;files&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Now, video capture devices like webcams are represented in Linux by
&lt;em&gt;character devices&lt;/em&gt; named &lt;code&gt;/dev/video0&lt;/code&gt;, &lt;code&gt;/dev/video1&lt;/code&gt; and so
forth. Udev manages these and (on Ubuntu platforms) creates them as
owned by the user &lt;code&gt;root&lt;/code&gt; and the group &lt;code&gt;video&lt;/code&gt; — but it helpfully also
creates POSIX ACL entries for the user currently logged in on the X
console.&lt;/p&gt;
&lt;p&gt;All I thus need to do is &lt;em&gt;mount&lt;/em&gt; these files into the container (yes,
LXC lets you “mount” individual files), like so:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="na"&gt;lxc.mount.entry&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/dev/video0 dev/video0 none bind,optional,create=file&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;lxc.mount.entry&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/dev/video1 dev/video0 none bind,optional,create=file&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;lxc.mount.entry&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/dev/video2 dev/video2 none bind,optional,create=file&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;lxc.mount.entry&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/dev/video3 dev/video2 none bind,optional,create=file&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here, the &lt;code&gt;optional&lt;/code&gt; bit of course means that the container will start
even in case a particular file does not exist in the host at the time
the container receives its &lt;code&gt;lxc-start&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;That, in principle, is all there is to it.&lt;/p&gt;
&lt;h2&gt;Things to consider&lt;/h2&gt;
&lt;p&gt;Be aware that &lt;a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=088ead25524583e2200aa99111bea2f66a86545a"&gt;since early
2018&lt;/a&gt;
(in other words, in kernel 4.16 and later) the Linux kernel’s
&lt;code&gt;uvcvideo&lt;/code&gt; subsystem will create &lt;strong&gt;two&lt;/strong&gt; &lt;code&gt;/dev/video&lt;/code&gt; devices for your
webcam. One of them is the actual video capture device; the second one
is a metadata device node. You can easily tell which is which, with
&lt;code&gt;v4l2-ctl&lt;/code&gt;: only a video capture device will have a non-empty list of
supported formats.&lt;/p&gt;
&lt;p&gt;This is a video capture device:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ v4l2-ctl --list-formats --device /dev/video0
ioctl: VIDIOC_ENUM_FMT
    Type: Video Capture

    &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;: &lt;span class="s1"&gt;'MJPG'&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;Motion-JPEG, compressed&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;: &lt;span class="s1"&gt;'YUYV'&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;YUYV &lt;span class="m"&gt;4&lt;/span&gt;:2:2&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;: &lt;span class="s1"&gt;'H264'&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;H.264, compressed&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And this is the metadata device; note that it lists no video codecs:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ v4l2-ctl --list-formats --device /dev/video1
ioctl: VIDIOC_ENUM_FMT
    Type: Video Capture
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Normally, device nodes &lt;code&gt;/dev/video0&lt;/code&gt; and &lt;code&gt;/dev/video1&lt;/code&gt; will be
occupied by a built-in webcam, your USB webcam will use &lt;code&gt;/dev/video2&lt;/code&gt;
and &lt;code&gt;/dev/video3&lt;/code&gt;, and if you have &lt;em&gt;another&lt;/em&gt; video capture device then
that will be &lt;code&gt;/dev/video4&lt;/code&gt; and &lt;code&gt;/dev/video5&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Thus, perhaps you want your container to see &lt;em&gt;only&lt;/em&gt; your USB webcam,
&lt;em&gt;and&lt;/em&gt; you don’t care about the metadata device. In that case, instead
of the four &lt;code&gt;lxc.mount.entry&lt;/code&gt; lines I gave above, you might use just
one:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="na"&gt;lxc.mount.entry&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/dev/video2 dev/video2 none bind,optional,create=file&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Also, the bind mounts occur at the time you &lt;em&gt;start&lt;/em&gt; the container. Thus,
if you plug in a USB webcam while the container is already running, it
won’t magically become available to the container. There are two ways
to address this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;You start (or restart) your container whenever you need to use a web
   cam (or other video device) that you have just plugged in, &lt;em&gt;or&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;you remove the &lt;code&gt;optional&lt;/code&gt; keyword from your &lt;code&gt;lxc.mount.entry&lt;/code&gt;
   line(s), so that the container will refuse to start unless the
   correct webcam is plugged in.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note further that for the same reason, if you disconnect your USB
webcam &lt;em&gt;while your container is running,&lt;/em&gt; you can’t just plug it
back in and expect it to work. In that case, udev in the host will
have deleted the device node, so the bind mount in your container is
now stale, and your containerized applications won’t be able to use
your capture device anymore. Under those circumstances, you’ll simply
have to restart your container.&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="LXC"></category></entry><entry><title>Fixing powerline flicker on your webcam feed with a udev rule</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/webcam-rolling-shutter-udev/" rel="alternate"></link><published>2021-01-17T00:00:00+00:00</published><updated>2021-01-17T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-01-17:/resources/hints-and-kinks/webcam-rolling-shutter-udev/</id><summary type="html">&lt;p&gt;If you are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;spending a non-trivial amount of time in video calls every week
  (something that, at the time of writing, is true for &lt;strong&gt;a lot&lt;/strong&gt; of
  people due to the COVID-19 pandemic), and also&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;having to use mains-powered artificial lighting in your office (true
  at the time of writing …&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;If you are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;spending a non-trivial amount of time in video calls every week
  (something that, at the time of writing, is true for &lt;strong&gt;a lot&lt;/strong&gt; of
  people due to the COVID-19 pandemic), and also&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;having to use mains-powered artificial lighting in your office (true
  at the time of writing for significant portions of the Northern
  Hemisphere, as it’s winter there),&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;then you may be dealing with an unpleasant effect where your web cam
feed produces a permanent &lt;a href="https://dsp.stackexchange.com/questions/19853/horizontal-banding-flickering-due-to-electronic-rolling-shutters"&gt;horizontal
flicker&lt;/a&gt;
that is due to the electronic rolling shutter interacting with the
(otherwise imperceptible) 50 or 60Hz AC powerline frequency.&lt;/p&gt;
&lt;p&gt;The good news is that most webcams come with a facility to eliminate
that effect, and on a Linux desktop it’s not difficult to permanently
do so.&lt;/p&gt;
&lt;h2&gt;&lt;code&gt;v4l2-ctl&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;The utility you want to use for this purpose is &lt;code&gt;v4l2-ctl&lt;/code&gt;, which on
Ubuntu ships with &lt;a href="https://packages.ubuntu.com/v4l-utils"&gt;the &lt;code&gt;v4l-utils&lt;/code&gt;
package&lt;/a&gt;. &lt;code&gt;v4l2-ctl&lt;/code&gt; allows you
to read and set a bunch of parameters for your webcam. Here’s the set
of parameters available for my &lt;a href="https://www.razer.com/gb-en/streaming-cameras/razer-kiyo/RZ19-02320100-R3U1"&gt;Razer
Kiyo&lt;/a&gt;,
a piece of kit that I highly recommend:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ v4l2-ctl --list-ctrls --device&lt;span class="o"&gt;=&lt;/span&gt;/dev/video0
                     brightness 0x00980900 &lt;span class="o"&gt;(&lt;/span&gt;int&lt;span class="o"&gt;)&lt;/span&gt;    : &lt;span class="nv"&gt;min&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;max&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;255&lt;/span&gt; &lt;span class="nv"&gt;step&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;128&lt;/span&gt; &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;128&lt;/span&gt;
                       contrast 0x00980901 &lt;span class="o"&gt;(&lt;/span&gt;int&lt;span class="o"&gt;)&lt;/span&gt;    : &lt;span class="nv"&gt;min&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;max&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;255&lt;/span&gt; &lt;span class="nv"&gt;step&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;128&lt;/span&gt; &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;128&lt;/span&gt;
                     saturation 0x00980902 &lt;span class="o"&gt;(&lt;/span&gt;int&lt;span class="o"&gt;)&lt;/span&gt;    : &lt;span class="nv"&gt;min&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;max&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;255&lt;/span&gt; &lt;span class="nv"&gt;step&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;128&lt;/span&gt; &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;128&lt;/span&gt;
 white_balance_temperature_auto 0x0098090c &lt;span class="o"&gt;(&lt;/span&gt;bool&lt;span class="o"&gt;)&lt;/span&gt;   : &lt;span class="nv"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;
                           gain 0x00980913 &lt;span class="o"&gt;(&lt;/span&gt;int&lt;span class="o"&gt;)&lt;/span&gt;    : &lt;span class="nv"&gt;min&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;max&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;255&lt;/span&gt; &lt;span class="nv"&gt;step&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;
           power_line_frequency 0x00980918 &lt;span class="o"&gt;(&lt;/span&gt;menu&lt;span class="o"&gt;)&lt;/span&gt;   : &lt;span class="nv"&gt;min&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;max&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt; &lt;span class="nv"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt; &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;
      white_balance_temperature 0x0098091a &lt;span class="o"&gt;(&lt;/span&gt;int&lt;span class="o"&gt;)&lt;/span&gt;    : &lt;span class="nv"&gt;min&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2000&lt;/span&gt; &lt;span class="nv"&gt;max&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7500&lt;/span&gt; &lt;span class="nv"&gt;step&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;10&lt;/span&gt; &lt;span class="nv"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4000&lt;/span&gt; &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4000&lt;/span&gt; &lt;span class="nv"&gt;flags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;inactive
                      sharpness 0x0098091b &lt;span class="o"&gt;(&lt;/span&gt;int&lt;span class="o"&gt;)&lt;/span&gt;    : &lt;span class="nv"&gt;min&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;max&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;255&lt;/span&gt; &lt;span class="nv"&gt;step&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;128&lt;/span&gt; &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;128&lt;/span&gt;
         backlight_compensation 0x0098091c &lt;span class="o"&gt;(&lt;/span&gt;int&lt;span class="o"&gt;)&lt;/span&gt;    : &lt;span class="nv"&gt;min&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;max&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;step&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;
                  exposure_auto 0x009a0901 &lt;span class="o"&gt;(&lt;/span&gt;menu&lt;span class="o"&gt;)&lt;/span&gt;   : &lt;span class="nv"&gt;min&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;max&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="nv"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;
              exposure_absolute 0x009a0902 &lt;span class="o"&gt;(&lt;/span&gt;int&lt;span class="o"&gt;)&lt;/span&gt;    : &lt;span class="nv"&gt;min&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="nv"&gt;max&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2047&lt;/span&gt; &lt;span class="nv"&gt;step&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;127&lt;/span&gt; &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;127&lt;/span&gt;
         exposure_auto_priority 0x009a0903 &lt;span class="o"&gt;(&lt;/span&gt;bool&lt;span class="o"&gt;)&lt;/span&gt;   : &lt;span class="nv"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;
                   pan_absolute 0x009a0908 &lt;span class="o"&gt;(&lt;/span&gt;int&lt;span class="o"&gt;)&lt;/span&gt;    : &lt;span class="nv"&gt;min&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-36000 &lt;span class="nv"&gt;max&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;36000&lt;/span&gt; &lt;span class="nv"&gt;step&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3600&lt;/span&gt; &lt;span class="nv"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;
                  tilt_absolute 0x009a0909 &lt;span class="o"&gt;(&lt;/span&gt;int&lt;span class="o"&gt;)&lt;/span&gt;    : &lt;span class="nv"&gt;min&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;-36000 &lt;span class="nv"&gt;max&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;36000&lt;/span&gt; &lt;span class="nv"&gt;step&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3600&lt;/span&gt; &lt;span class="nv"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;
                 focus_absolute 0x009a090a &lt;span class="o"&gt;(&lt;/span&gt;int&lt;span class="o"&gt;)&lt;/span&gt;    : &lt;span class="nv"&gt;min&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;max&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;255&lt;/span&gt; &lt;span class="nv"&gt;step&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;flags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;inactive
                     focus_auto 0x009a090c &lt;span class="o"&gt;(&lt;/span&gt;bool&lt;span class="o"&gt;)&lt;/span&gt;   : &lt;span class="nv"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;
                  zoom_absolute 0x009a090d &lt;span class="o"&gt;(&lt;/span&gt;int&lt;span class="o"&gt;)&lt;/span&gt;    : &lt;span class="nv"&gt;min&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;100&lt;/span&gt; &lt;span class="nv"&gt;max&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;140&lt;/span&gt; &lt;span class="nv"&gt;step&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;10&lt;/span&gt; &lt;span class="nv"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;100&lt;/span&gt; &lt;span class="nv"&gt;value&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;100&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The value you’re looking for is &lt;code&gt;power_line_frequency&lt;/code&gt;. Its default is
&lt;code&gt;2&lt;/code&gt; (compensating for a 60Hz powerline frequency), which means the
camera should work out of the box and without any powerline flicker in
the Americas and parts of Asia. I am in Europe though, where the mains
frequency is 50Hz, so I need to set this to &lt;code&gt;1&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;v4l2-ctl --device /dev/video0 --set-ctrl&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;power_line_frequency&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;However, it’s rather tedious to run that command every time I want to use the
webcam.&lt;/p&gt;
&lt;h2&gt;udev&lt;/h2&gt;
&lt;p&gt;Thankfully, this process can be automated with a simple udev rule:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;ACTION&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s2"&gt;"add"&lt;/span&gt;, &lt;span class="nv"&gt;SUBSYSTEM&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s2"&gt;"video4linux"&lt;/span&gt;, &lt;span class="nv"&gt;DRIVERS&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s2"&gt;"uvcvideo"&lt;/span&gt;, &lt;span class="nv"&gt;RUN&lt;/span&gt;&lt;span class="o"&gt;+=&lt;/span&gt;&lt;span class="s2"&gt;"/usr/bin/v4l2-ctl --set-ctrl=power_line_frequency=1"&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This way, any camera handled by the &lt;code&gt;uvcvideo&lt;/code&gt; driver (meaning,
practically any contemporary webcam) will have its power line
frequency setting configured to the 50Hz value, eliminating the
banding effect from the rolling shutter.&lt;/p&gt;
&lt;p&gt;Chuck that line into a file in &lt;code&gt;/etc/udev/rules.d&lt;/code&gt;, run &lt;code&gt;sudo udevadm
trigger&lt;/code&gt;, and you should be good to go.&lt;/p&gt;
&lt;h2&gt;Acknowledgments and further reading&lt;/h2&gt;
&lt;p&gt;I got the udev rule suggestion from user
&lt;a href="https://unix.stackexchange.com/users/258991/telcom"&gt;telcoM&lt;/a&gt;’s answer
on &lt;a href="https://unix.stackexchange.com/questions/581867/how-can-i-change-my-webcams-power-line-frequency-setting"&gt;this StackExchange
post&lt;/a&gt;. The
discussion thread on that post has a few additional suggestions,
including some not using udev.&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="udev"></category></entry><entry><title>Running (Almost) Anything in LXC: Sound</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/lxc-sound/" rel="alternate"></link><published>2021-01-16T00:00:00+00:00</published><updated>2021-01-16T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-01-16:/resources/hints-and-kinks/lxc-sound/</id><summary type="html">&lt;p&gt;Some of the &lt;a href="https://xahteiwi.eu/resources/hints-and-kinks/lxc-x11/"&gt;X applications I run in LXC&lt;/a&gt; make
sounds. Now, I find alert sounds horribly distracting so I turn them
off, but for some containerized applications I want to actually play
sound.&lt;/p&gt;
&lt;p&gt;Examples include the &lt;a href="https://www.spotify.com/download/linux/"&gt;Spotify Linux
client&lt;/a&gt; (which I run in its
own LXC container because it …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Some of the &lt;a href="https://xahteiwi.eu/resources/hints-and-kinks/lxc-x11/"&gt;X applications I run in LXC&lt;/a&gt; make
sounds. Now, I find alert sounds horribly distracting so I turn them
off, but for some containerized applications I want to actually play
sound.&lt;/p&gt;
&lt;p&gt;Examples include the &lt;a href="https://www.spotify.com/download/linux/"&gt;Spotify Linux
client&lt;/a&gt; (which I run in its
own LXC container because it’s not open source), and occasionally
things like the latest available &lt;a href="https://shotcut.org/"&gt;Shotcut&lt;/a&gt;
version for video editing.&lt;/p&gt;
&lt;p&gt;You’ll notice that, on face value, that’s a pretty similar problem
compared to getting containerized applications to talk to my X
server. It’s just that rather than applications only being clients to
my X server, I also want them to be clients to my PulseAudio daemon.&lt;/p&gt;
&lt;h2&gt;LXC (Non-)Configuration&lt;/h2&gt;
&lt;p&gt;In the article on running &lt;a href="https://xahteiwi.eu/resources/hints-and-kinks/lxc-x11/"&gt;X applications in
LXC&lt;/a&gt;, I give the example of sharing a host
directory, which contains X.org server sockets.&lt;/p&gt;
&lt;p&gt;In principle, I &lt;em&gt;could&lt;/em&gt; do the same thing with the Unix socket that
PulseAudio runs. However, there’s a small problem with that: the
directory I would have to bind-mount into my container is
&lt;code&gt;/run/1000/pulse&lt;/code&gt;, and you see the difference to bind-mounting
&lt;code&gt;/tmp/.X11-unix&lt;/code&gt;: &lt;code&gt;/tmp&lt;/code&gt; already exists in my container on system
startup — but while &lt;code&gt;/run&lt;/code&gt; also does, &lt;code&gt;/run/1000&lt;/code&gt; does not. I have
experimented with making this work, and I’ll spare you the details but
it’s not as simple as it initially looks. I eventually gave up on that
approach, because there is a much simpler way to do this — and it
doesn’t even require any specific LXC container configuration.&lt;/p&gt;
&lt;p&gt;The trick is to use the PulseAudio &lt;code&gt;native-protocol-tcp&lt;/code&gt; module. When
I load it into my running PulseAudio configuration, like so:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;pactl load-module module-native-protocol-tcp
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;... then a PulseAudio sound server starts listening on a TCP socket on
port 4713.&lt;/p&gt;
&lt;p&gt;I can of course also add this line (minus its &lt;code&gt;pactl&lt;/code&gt; prefix) to my
PulseAudio configuration file, &lt;code&gt;~/config/pulse/default.pa&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;And then, all I need to do is attach to my container, export the
&lt;code&gt;PULSE_SERVER&lt;/code&gt; environment variable set to &lt;code&gt;10.0.3.1&lt;/code&gt; (my IPv4 address
of the host on the &lt;code&gt;lxcbr0&lt;/code&gt; bridge), and launch an application.&lt;/p&gt;
&lt;p&gt;I can do this all in one go, like so (using the Spotify client as an example):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;pactl load-module module-native-protocol-tcp &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
  lxc-start -n focal-spotify &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
  sleep &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
  lxc-attach -n focal-spotify -- &lt;span class="se"&gt;\&lt;/span&gt;
  sudo -Hu florian env &lt;span class="nv"&gt;PULSE_SERVER&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"10.0.3.1"&lt;/span&gt; spotify &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
  lxc-stop -n focal-spotify
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;... and as long as the application links to any PulseAudio client
libraries, it will correctly parse the set &lt;code&gt;PULSE_SERVER&lt;/code&gt; environment
variable as an instruction to connect to the given IP address on its
default port, and send its audio stream there.&lt;/p&gt;
&lt;p&gt;I am then still able to control my volume, control my mix, and mute
the output from my host.&lt;/p&gt;
&lt;p&gt;Of course, you probably want to chuck that long command into a
&lt;code&gt;.desktop&lt;/code&gt; file, or wrap it in a script or function.&lt;/p&gt;
&lt;p&gt;By the way, no I don’t really know why I need that 1-second &lt;code&gt;sleep&lt;/code&gt;
between starting the container and attaching to it, but it works for
me and breaks without it. I presume there is &lt;em&gt;some&lt;/em&gt; initialization
going on in the container that needs just a few tenths of a second to
complete. And I can deal with waiting for my music for one more
second.&lt;/p&gt;
&lt;h2&gt;Things to consider&lt;/h2&gt;
&lt;p&gt;Your Ubuntu desktop will most likely run with
&lt;a href="https://wiki.ubuntu.com/UncomplicatedFirewall"&gt;&lt;code&gt;ufw&lt;/code&gt;&lt;/a&gt; enabled. If
your containerized applications are unable to connect to the
PulseAudio server because your firewall blocks them, you won’t get
sound. Here’s what I do:&lt;/p&gt;
&lt;p&gt;First, I create &lt;code&gt;/etc/ufw/applications.d/pulseaudio&lt;/code&gt;, with this
content:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;[pulseaudio]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;PulseAudio Native Protocol TCP&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;PulseAudio Sound Server &lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;ports&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;4713/tcp&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, I allow traffic incoming via the LXC bridge to connect to that
server:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;sudo ufw allow &lt;span class="k"&gt;in&lt;/span&gt; on lxcbr0 to any app pulseaudio
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Also do consider, of course, that once your system is set up in this
way, not only will your LXC applications be able to play sound through
your speakers, but they will also be able to pick up input from your
microphone. So use this wisely, particularly if the application you
are running does record and process sound.&lt;/p&gt;
&lt;p&gt;Sometimes you totally &lt;strong&gt;want&lt;/strong&gt; your application to record sound,
though, and indeed see the video stream from your webcam, too. Zoom
calls come to mind as one such example. More on this in the next
installment of this series, where I’ll talk about letting your
containerized app use host video input.&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="LXC"></category></entry><entry><title>Running (Almost) Anything in LXC: X applications</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/lxc-x11/" rel="alternate"></link><published>2021-01-09T00:00:00+00:00</published><updated>2021-01-09T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2021-01-09:/resources/hints-and-kinks/lxc-x11/</id><summary type="html">&lt;p&gt;I occasionally want to run X applications in an LXC
container. Sometimes that’s because they’re not open source and I need
to run them for work, like Zoom. Sometimes it’s an open source X
application that doesn’t work splendidly well on the Ubuntu release
that I …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I occasionally want to run X applications in an LXC
container. Sometimes that’s because they’re not open source and I need
to run them for work, like Zoom. Sometimes it’s an open source X
application that doesn’t work splendidly well on the Ubuntu release
that I am using.&lt;/p&gt;
&lt;p&gt;It turns out that this isn’t particularly hard to do — &lt;strong&gt;if you are
running X.org.&lt;/strong&gt; To the best of my knowledge, what I am describing
here cannot be expected to work, reliably, on Wayland. To me that’s no
big loss, because there are several other things that I like to use
(like &lt;a href="https://github.com/autokey/autokey"&gt;Autokey&lt;/a&gt; and
&lt;a href="https://www.openstenoproject.org/plover/"&gt;Plover&lt;/a&gt;) that won’t work on
Wayland, either. So I run GNOME on X by default, anyway.&lt;/p&gt;
&lt;h2&gt;LXC Configuration&lt;/h2&gt;
&lt;p&gt;Compared to the &lt;a href="https://xahteiwi.eu/resources/hints-and-kinks/lxc-basics/"&gt;basic LXC configuration that I have described
before&lt;/a&gt;, there’s only one line that you’ll
need to add:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="na"&gt;lxc.mount.entry&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/tmp/.X11-unix tmp/.X11-unix none bind,optional,create=dir,ro&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now let me explain what this does. &lt;code&gt;/tmp/.X11-unix&lt;/code&gt; is where your X
display sockets will live, and I map it to the same path in the
container. &lt;/p&gt;
&lt;p&gt;If I look into this directory while I’m in an X session myself, I
see one single socket file in there, named &lt;code&gt;X0&lt;/code&gt;, which is owned by my
user account that owns the session.&lt;/p&gt;
&lt;p&gt;And since my standard configuration maps my personal user account (and
&lt;em&gt;only&lt;/em&gt; my personal user account) from the host to the container, that
means that processes running as &lt;code&gt;florian&lt;/code&gt; in the container will be
able to use this socket just like processes owned by &lt;code&gt;florian&lt;/code&gt; in the
host can.&lt;/p&gt;
&lt;p&gt;Now, what’s with the &lt;code&gt;create=dir&lt;/code&gt; and &lt;code&gt;ro&lt;/code&gt; options?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;create=dir&lt;/code&gt; tells LXC to create the mount point in the container if
  it does not exist.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ro&lt;/code&gt; bars processes in the container from creating or deleting any
  files in the directory. You see, my X server always runs in my host
  OS, I only want applications running in the container to connect to
  it, as clients. So there’s no need for applications in the container
  to ever modify this directory. However, you’ll almost certainly be
  running something on your system that will sweep &lt;code&gt;/tmp&lt;/code&gt; on system
  startup
  (&lt;a href="https://www.freedesktop.org/software/systemd/man/systemd-tmpfiles-setup.service.html"&gt;&lt;code&gt;systemd-tmpfiles&lt;/code&gt;&lt;/a&gt;
  will, for example), and if that happened, you’d lose the socket.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With all that set up, any application that runs in the container with
a default &lt;code&gt;$DISPLAY&lt;/code&gt; variable (&lt;code&gt;:0&lt;/code&gt;) in its environment, will connect
to the socket in &lt;code&gt;/tmp/.X11-unix/X0&lt;/code&gt; which is a direct pass-through of
the X server socket in the host.&lt;/p&gt;
&lt;h2&gt;Things to consider&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Since my &lt;a href="https://xahteiwi.eu/resources/hints-and-kinks/lxc-basics/"&gt;default configuration&lt;/a&gt; maps
  &lt;code&gt;/home&lt;/code&gt; in the host to &lt;code&gt;/home&lt;/code&gt; in the container, any application
  running in the container will happily apply the same configuration
  as in the host. So for example, if I start Firefox in the
  container, my Firefox profiles and configuration are all
  there. However, so are any application locks that my application
  creates.&lt;br/&gt;
  Sticking with the Firefox example, I won’t be able to open a
  specific profile in the container that is simultaneously open in the
  host. I can, however, totally use two different profiles
  side-by-side, or the same profile sequentially in first the host,
  then the container or the other way round.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;On a highly customized desktop your application may look different
  in the container than it does in the host. For example, my desktop
  is configured to use
  &lt;a href="https://en.wikipedia.org/wiki/Cantarell_(typeface)"&gt;Cantarell&lt;/a&gt; as
  its sans-serif and &lt;a href="https://sourcefoundry.org/hack/"&gt;Hack&lt;/a&gt; as its
  monospace font. If I neglect to install the &lt;code&gt;fonts-cantarell&lt;/code&gt; and
  &lt;code&gt;fonts-hack&lt;/code&gt; Ubuntu packages in my container, containerized X
  applications will instead fall back to the system default fonts. The
  same consideration applies for GTK themes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I have yet to tell you about pushing sound from the container to the
  host, and about sharing the host’s webcam and microphone with the
  container. More on that in future installments in this series.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</content><category term="hints-and-kinks"></category><category term="LXC"></category></entry><entry><title>Running (Almost) Anything in LXC: The Basics</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/lxc-basics/" rel="alternate"></link><published>2020-12-28T00:00:00+00:00</published><updated>2020-12-28T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2020-12-28:/resources/hints-and-kinks/lxc-basics/</id><summary type="html">&lt;p&gt;LXC is part of my standard Linux desktop toolbox, and I use it
daily. I have done tutorials about this before, one of which you can
find &lt;a href="https://youtu.be/3nUbMREnnns"&gt;on YouTube&lt;/a&gt; (courtesy of
&lt;a href="https://linux.conf.au/"&gt;linux.conf.au&lt;/a&gt;) and
&lt;a href="https://fghaas.github.io/lca2018-lxc/#/1"&gt;GitHub&lt;/a&gt;, but it’s about
time I included this in a series of articles.&lt;/p&gt;
&lt;p&gt;My …&lt;/p&gt;</summary><content type="html">&lt;p&gt;LXC is part of my standard Linux desktop toolbox, and I use it
daily. I have done tutorials about this before, one of which you can
find &lt;a href="https://youtu.be/3nUbMREnnns"&gt;on YouTube&lt;/a&gt; (courtesy of
&lt;a href="https://linux.conf.au/"&gt;linux.conf.au&lt;/a&gt;) and
&lt;a href="https://fghaas.github.io/lca2018-lxc/#/1"&gt;GitHub&lt;/a&gt;, but it’s about
time I included this in a series of articles.&lt;/p&gt;
&lt;p&gt;My motivations for running LXC containers are manifold, but here are
some of the most important ones:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;I want to keep my main system clean of anything that’s not free and
  open source software. There is, however, the odd bit of non-free
  software that I do need to or want to use — Zoom for work, for
  example, or the excellent Spotify Linux client for pleasure.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Even if a piece of Software &lt;em&gt;is&lt;/em&gt; open source, it sometimes does not
  play nicely with the version of my main system that I currently
  use. A recent example is the somewhat premature inclusion of
  pre-release versions of Calibre in Debian and Ubuntu, which means
  that Calibre is currently not playing too nicely on Ubuntu Focal
  (the current LTS at time of writing), but runs just dandy on Bionic,
  which I can handily run in an LXC container.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sometimes the opposite is true as well, that is, some application
  comes in a version that I want to use, except it’s only bundled with
  a future Ubuntu (or Debian) release that I am not yet prepared to
  use. Or else, it’s available only on Fedora or openSUSE, which are
  perfectly fine desktop distributions but just not my preferred ones
  to use on a daily basis. In that case, LXC containers are
  exceedingly useful as well, and are much less hassle than building
  the application in question from source.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here are my general rules for running LXC containers:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;I run my containers as non-root, under my own user account. (If you
   are unfamiliar with this, and would like to learn more about how it
   works and how you need to tweak your system to enable it, please
   see the excellent LXC &lt;a href="https://linuxcontainers.org/lxc/getting-started/#creating-unprivileged-containers-as-a-user"&gt;Getting
   Started&lt;/a&gt;
   guide.)&lt;/li&gt;
&lt;li&gt;I use UID and GID mapping rules so that all of the container’s user
   accounts, including the container’s root, are mapped to subgids and
   subuids of my account — all &lt;strong&gt;except&lt;/strong&gt; my own user account and
   group, with uid and gid 1000.&lt;/li&gt;
&lt;li&gt;I bind-mount the &lt;code&gt;/home&lt;/code&gt; directory into the container. Combined
   with the uid and gid passthrough of my own account, this means that
   &lt;code&gt;florian&lt;/code&gt; in the container can access &lt;code&gt;/home/florian&lt;/code&gt; in any
   container, just like in the host.&lt;/li&gt;
&lt;li&gt;I run all my containers in btrfs subvolumes.&lt;/li&gt;
&lt;li&gt;I maintain a basic container configuration for each Ubuntu release
   I run, and then I duplicate that configuration for a bunch of
   containers using snapshot cloning (&lt;code&gt;lxc-copy -s&lt;/code&gt;), which in
   combination with btrfs makes the clones quite space-efficient.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For example, this is the “container specific configuration” section in
&lt;code&gt;~/.share/lxc/focal/config&lt;/code&gt;, the configuration for my current base
container running Ubuntu Focal:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# Container specific configuration&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;lxc.include&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/etc/lxc/default.conf&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;lxc.idmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;u 0 100000 1000&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;lxc.idmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;g 0 100000 1000&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;lxc.idmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;u 1000 1000 1&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;lxc.idmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;g 1000 1000 1&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;lxc.idmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;u 1001 101001 64535&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;lxc.idmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;g 1001 101001 64535&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;lxc.mount.auto&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;proc sys cgroup&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;lxc.rootfs.path&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;btrfs:/home/florian/.local/share/lxc/focal/rootfs&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;lxc.uts.name&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;focal&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;lxc.mount.entry&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/home home none bind,optional 0 0&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Of this, perhaps the &lt;code&gt;lxc.idmap&lt;/code&gt; settings merit a bit of extra
explanation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;lxc.idmap = u 0 100000 1000&lt;/code&gt; means “map the uid 0 (&lt;code&gt;root&lt;/code&gt;) in the
  container to uid 100000 in the host, and continue up until you’ve
  hit 1,000 mappings”. In other words, map uids 0 to 999 including, to
  100000 to 100999.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lxc.idmap = u 1000 1000 1&lt;/code&gt; means “map the uid 1000 in the container
  to uid 1000 in the host,” (in my case, my user account named
  &lt;code&gt;florian&lt;/code&gt;) “and follow this pattern for just one mapping”. In other
  words, make uid 1000 a pass-through.&lt;/li&gt;
&lt;li&gt;Finally, &lt;code&gt;lxc.idmap = u 1001 101001 64535&lt;/code&gt; means “starting with uid
  1001 in the container, map it to uid 101001 in the host and proceed
  until you’ve hit 64,535 mappings”.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So in total, that’s LXC-ese for “map all possible uids from 0 to 65535
in the container to host subuids shifted by 100,000 &lt;em&gt;except&lt;/em&gt; 1000,
which you shouldn’t map to any subuid. And the same is true for gids,
for the &lt;code&gt;g&lt;/code&gt; idmaps. It’s a rather roundabout way of specifying this,
but it works.&lt;/p&gt;
&lt;p&gt;Now by itself, this already gives me plenty of options for
command-line applications. But since it’s my main workstation that I
run this on, I usually want my applications to be wired up to my
desktop GUI. More on that in the next installment of the series.&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="LXC"></category></entry><entry><title>Add depth! Stereoscopic imagery for everyone</title><link href="https://xahteiwi.eu/talk-submissions/lca-2021-stereoscopy/" rel="alternate"></link><published>2020-11-06T00:00:00+00:00</published><updated>2020-11-06T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2020-11-06:/talk-submissions/lca-2021-stereoscopy/</id><summary type="html">&lt;p&gt;A talk I submitted to linux.conf.au 2021.&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a talk I submitted&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt; to linux.conf.au 2021. It was,
unfortunately, rejected. &lt;/p&gt;
&lt;p&gt;If you run a conference or meetup (on-person or online) where you
think this talk would be a good fit, please let me know! I’d still
love to present it when the opportunity arises.&lt;/p&gt;
&lt;h2&gt;Title&lt;/h2&gt;
&lt;p&gt;Add depth! Stereoscopic imagery for everyone&lt;/p&gt;
&lt;h2&gt;Target Audience&lt;/h2&gt;
&lt;p&gt;User&lt;/p&gt;
&lt;h2&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;This will appear in the conference programme. Up to about 500
words. This field is rendered with the monospace font Hack with
whitespace preserved&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Stereoscopic imagery (photography and videography) is a fascinating
way to create 3-dimensional images of landscapes, unmoving and moving
objects, and of course, people.&lt;/p&gt;
&lt;p&gt;In this talk, we'll cover the basics of stereoscopic imagery and
projection, discover how stereoscopic vision works, and how we can
trick our brains into perceiving depth from two flat images.&lt;/p&gt;
&lt;p&gt;We start with the principles of three-dimensional vision in humans:
how our eyes use the combination of focus and vergence to signal two
slightly different images of our surroundings to our brain, and how
our brain then processes these images to give us the perception of
depth. Then, we discuss the techniques available to play tricks on our
brains in which two slightly (but cleverly) distinct &lt;em&gt;two&lt;/em&gt;-dimensional
images are presented to our eyes in such a way that our mind conjures
up depth where there objectively is none.&lt;/p&gt;
&lt;p&gt;These techniques come in various forms, from very high tech (such as
virtual reality goggles) to very low tech (like mechanical
stereoscopic viewers), but some can deal without any projection
technology at all: this is called freeviewing, and for most people it
is a remarkably simple and low-cost way to enjoy stunning
three-dimensional imagery. We'll cover the parallel-view and crossview
freeviewing techniques.&lt;/p&gt;
&lt;p&gt;We'll then dive into the simple but highly effective steps of making
stereoscopic images, using run-of-the-mill cameras (even cell phones),
and some straightforward image processing in the GIMP.&lt;/p&gt;
&lt;p&gt;Finally, we talk about some neat little tricks to make stereoscopic
videos, with minimal cost and investment. We'll look at how we can
make 3D video with just a GoPro, or a simple drone camera — again
using a free software tool, namely the OpenShot video editor, for
processing.&lt;/p&gt;
&lt;h2&gt;Private Abstract&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;This will only be shown to organisers and reviewers. You should
provide any details about your proposal that you don't want to be
public here. This field is rendered with the monospace font Hack
with whitespace preserved&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This talk does not cover a specific software project; the "Project
URL" below is simply a Flickr album containing a set of stereoscopic
images created with the technique I am describing.&lt;/p&gt;
&lt;p&gt;The fact that LCA is an online event this year would suit this talk
particularly well: when I get to the point of explaining freeviewing
to attendees, I would expect novices to have some difficulty with
&lt;em&gt;one&lt;/em&gt; of the freeviewing techniques, and some, with both. The latter
would have the option of simply backing up the stream and re-watching
the instructions and the test images provided, which is an option that
would not exist in a live talk.&lt;/p&gt;
&lt;p&gt;Accessibility note: Regretfully, this talk will have limited
accessibility for people with vision deficiencies. Specifically, the
3D effects presented will be inaccessible to people with complete loss
of vision in one eye (or both), nystagmus, or strabismus. People with
these conditions will still be able to learn from the techniques
presented in the talk, but will likely be unable to perceive the
demonstrated 3D effects themselves. People with intraocular lens (IOL)
implants might also have difficulty following some of the examples in
the talk.&lt;/p&gt;
&lt;h2&gt;Project URL&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.flickr.com/gp/77872933@N02/SSzK0w"&gt;https://www.flickr.com/gp/77872933@N02/SSzK0w&lt;/a&gt;&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;If you’re curious why this is here, please read
&lt;a href="https://xahteiwi.eu/blog/2019/04/23/talk-submissions/"&gt;this&lt;/a&gt;. &lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="talk-submissions"></category><category term="Conference"></category><category term="Stereoscopy"></category></entry><entry><title>I Don’t Think This Means What You Think It Means: Red Herrings in OpenStack</title><link href="https://xahteiwi.eu/resources/presentations/i-dont-think-this-means-what-you-think-it-means-red-herrings-in-openstack/" rel="alternate"></link><published>2020-10-22T00:00:00+00:00</published><updated>2020-10-22T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2020-10-22:/resources/presentations/i-dont-think-this-means-what-you-think-it-means-red-herrings-in-openstack/</id><summary type="html">&lt;p&gt;My talk from the Open Infrastructure Summit, October 2020.&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a talk of which I had done a previous version at Open Infra
Days Nordic in 2019, but where unfortunately the audio came out really
messed up in the recording. This version is much better.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Talk video: &lt;a href="https://youtu.be/0nughAOezoc"&gt;YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can review my slides, including all speaker notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rendered slides: &lt;a href="https://fghaas.github.io/red-herrings-openstack/"&gt;GitHub
  Pages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slide sources (CC-BY-SA): &lt;a href="https://github.com/fghaas/red-herrings-openstack"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="presentations"></category><category term="Conference"></category><category term="OpenStack"></category></entry><entry><title>What I now know about HAproxied Django database connections, and wish I'd known sooner</title><link href="https://xahteiwi.eu/resources/presentations/what-i-now-know-about-haproxied-django-database-connections-and-wish-id-known-sooner/" rel="alternate"></link><published>2020-09-08T00:00:00+00:00</published><updated>2020-09-08T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2020-09-08:/resources/presentations/what-i-now-know-about-haproxied-django-database-connections-and-wish-id-known-sooner/</id><summary type="html">&lt;p&gt;My talk from PyConline AU 2020.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I’ve been wanting to speak at PyCon.au for a long time now, and
finally did for the 2020 &lt;em&gt;PyConline AU&lt;/em&gt; edition.&lt;/p&gt;
&lt;p&gt;This was a truly wonderful conference, in which the organisers and
attendees collectively bent over backwards and put in a massive effort
to run an event that was just as wonderful as an in-person event would
have been.&lt;/p&gt;
&lt;p&gt;This is a purely technical talk, and covers some very interesting
aspects of dealing with Galera high availability clusters for MySQL
and MariaDB database servers, connecting though them from Django via
an HAProxy load balancer, and then dealing with interesting side
effects of that combination.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Talk video: &lt;a href="https://youtu.be/2qDh7tl-wpg"&gt;YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And, as always, you can also review my slides, with all my speaker notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rendered slides: &lt;a href="https://fghaas.github.io/pyconau2020"&gt;GitHub
  Pages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slide sources (CC-BY-SA): &lt;a href="https://github.com/fghaas/pyconau2020"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="presentations"></category><category term="Conference"></category><category term="Python"></category></entry><entry><title>No, We Won’t Have a Video Call for That!</title><link href="https://xahteiwi.eu/resources/presentations/no-we-wont-have-a-video-call-for-that/" rel="alternate"></link><published>2020-08-22T00:00:00+00:00</published><updated>2020-08-22T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2020-08-22:/resources/presentations/no-we-wont-have-a-video-call-for-that/</id><summary type="html">&lt;p&gt;Communications in distributed teams: a write-up of my talk from FrOSCon 2020, Cloud Edition.&lt;/p&gt;</summary><content type="html">&lt;p&gt;FrOSCon 2020 was an online event due to the COVID-19 pandemic, and
gave me the opportunity to present an extended and heavily updated
version of my &lt;a href="https://xahteiwi.eu/resources/presentations/devopsdays-tel-aviv-2019/"&gt;DevOpsDays 2019&lt;/a&gt; talk.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;I normally make my talks available as a video, and a slide deck with
full speaker notes. In this case though, I consider it fitting to
write the whole thing out, so that you &lt;em&gt;don’t&lt;/em&gt; need to watch a full
length video in 45 minutes, but can read the whole thing in 15.&lt;/p&gt;
&lt;p&gt;You’ll still find links to the recording and deck downpage, as usual.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;No, we won’t have a video call for that!&lt;/p&gt;
&lt;p&gt;Communications for distributed teams&lt;/p&gt;
&lt;p&gt;FrOSCon 2020&lt;/p&gt;
&lt;!-- Note --&gt;
&lt;p&gt;This presentation is a talk presented at &lt;a href="https://www.froscon.de/"&gt;FrOSCon 2020
Cloud Edition&lt;/a&gt;. It is &lt;a href="https://creativecommons.org/licenses/by-sa/4.0/"&gt;CC-BY-SA
4.0&lt;/a&gt; licensed, see
&lt;a href="/LICENSE"&gt;the license&lt;/a&gt; for details.&lt;/p&gt;
&lt;p&gt;Hello and welcome, dear FrOScon people — this is my talk on
communications in distributed teams. My name is Florian, this is the
second time I‘m speaking at FrOScon, and you probably want to know
what the hell qualifies me to talk about this specific issue. So:&lt;/p&gt;
&lt;h3&gt;Why am I talking here?&lt;/h3&gt;
&lt;p&gt;So, why am I talking about &lt;strong&gt;that&lt;/strong&gt;?&lt;/p&gt;
&lt;p&gt;Or rather more precisely, why am &lt;strong&gt;I&lt;/strong&gt; talking about that?&lt;/p&gt;
&lt;p&gt;I turned 40 last year, have been in IT for about 20 years now (19
full-time), and out of that I have worked&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;in 4 successive companies, all of which worked out of offices,
  for 11 years, &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;in a completely distributed company, that I founded, for 6 years,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;and now, for about three years, I have been running a distributed
  team that is a business unit of a company that has existed for 15
  years and throughout that time, has only ever worked from a single
  office.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So I think I might have seen and become aware of some of the rather
interesting challenges that come with this.&lt;/p&gt;
&lt;h3&gt;What changed since last time?&lt;/h3&gt;
&lt;p&gt;I originally wrote and presented this talk for the first time in
December 2019. At the time, you probably had forgotten about SARS, had
no idea what SARS-CoV2 or COVID-19 were, and many of you were probably
working from offices.&lt;/p&gt;
&lt;p&gt;And then something like three months later, everything changed and
suddenly, this talk became much more relevant to a much greater
audience.&lt;/p&gt;
&lt;p&gt;And something else happened: a lot of people suddenly started talking
about working from home and distributed teams, and a lot of those
people who were talking very loudly, had themselves only been working
with or managing distributed teams since March. And a fair amount of
what you could about the subject then, and can still read now, is
complete and utter bullshit.&lt;/p&gt;
&lt;p&gt;So there’s one point I actually &lt;em&gt;didn’t&lt;/em&gt; make in the initial version
of this talk, because I thought it was self-evident. But I have come
to the conclusion that to a lot of people it is not, so to rectify
this omission from last December — and with apologies for that
omission to the wonderful DevOpsDays Tel Aviv crowd, who were my first
audience for this talk, let me make this one thing very clear from the
outset:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Effective distributed collaboration is &lt;strong&gt;not&lt;/strong&gt; pretending to be in
an office while staring into a webcam all day.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You will never be able to capitalize on work as a distributed team
unless you kick some office habits. The key to distributed teams being
effective is &lt;strong&gt;not&lt;/strong&gt; that they happen to not be in the same place, as
you’ll see from the remainder of this talk. So to expect success from
the approach that you take the habits of an office, simply remove the
element of locality, replace every face to face meeting with a video
call and carry on, is ludicrous.&lt;/p&gt;
&lt;p&gt;The good news is that if you do it right, you’ll end up with a far
better team than a local one would ever be, &lt;em&gt;and&lt;/em&gt; everyone has a
chance at far better work-life balance, &lt;em&gt;and&lt;/em&gt; you don’t waste awful
amounts of time and energy and fossil fuels on your commute.&lt;/p&gt;
&lt;h3&gt;What’s in this talk?&lt;/h3&gt;
&lt;p&gt;So you’ll find a few general themes throughout this talk:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;What modes we have &lt;em&gt;available&lt;/em&gt; for communications in teams;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Why distributed teams always collaborate &lt;em&gt;asynchronously,&lt;/em&gt; and what
  communication modes lend themselves to that particularly well;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Why &lt;em&gt;written communication&lt;/em&gt; is so important in distributed teams;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;And why &lt;em&gt;meetings&lt;/em&gt; (like video calls) are a mode of communication
  that effective distributed teams hardly ever need to use — except
  for very specific reasons.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But I do want to state one thing upfront:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This is &lt;em&gt;not science.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Nothing of what I am talking about is steeped in any scientific
rigour. I present anecdotes, not evidence. I might be mistaking
correlation for causation, or the other way round. It’s solely based
on my personal experience, and the experience of others I have talked
to, watched, or read. Everything I say here is subject to debate and
rebuttal, or you can simply have a different opinion.&lt;/p&gt;
&lt;p&gt;But it’s definitely &lt;strong&gt;not&lt;/strong&gt; science.&lt;/p&gt;
&lt;p&gt;Now with all of that said, let me attempt to give a definition of a
distributed team, according to my understanding:&lt;/p&gt;
&lt;p&gt;A distributed team is a &lt;strong&gt;professional&lt;/strong&gt; group whose members do not
rely on proximity in order to &lt;strong&gt;routinely&lt;/strong&gt; collaborate
productively.&lt;/p&gt;
&lt;p&gt;Now this is clearly not an ideal definition, not least because it
defines something by a negative, and an outside factor to boot: it
defines a distributed team by what it &lt;em&gt;does not need&lt;/em&gt; to exist to
function. But it’s the best definition I’ve been able to come up with.&lt;/p&gt;
&lt;p&gt;Now there’s a couple of key words in here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Professional.&lt;/strong&gt; I’m talking about teams that work towards a
  professional goal. This doesn’t necessarily mean that they all work
  in the same company. They could, for example, all work in different
  companies collaborating on a joint project, which is what frequently
  happens in open source software projects. But they’re not pursuing
  their hobby, they’re doing their jobs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Routinely.&lt;/strong&gt; I’m talking about teams that &lt;em&gt;habitually&lt;/em&gt; work in a
  distributed fashion, not the work that goes on in an office-based
  team when one person is having a work-from-home day.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is important to understand that that lack of proximity is not only
spatial, it is temporal as well, because:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Working in a distributed team means &lt;strong&gt;working asynchronously.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If your team is distributed, this is equivalent to saying that it
works in an asynchronous fashion, that is to say, that people will
work on things in parallel, and a capable distributed team will have
just as few synchronization points as absolutely necessary.&lt;/p&gt;
&lt;p&gt;The reason for this is not just working in different timezones, but
also the fact that everyone will have their own daily routine, and/or
have their individual times when they are most productive. Which you
&lt;em&gt;will not attempt to synchronize.&lt;/em&gt; (Doing so would mean setting the
entire team up for failure.)&lt;/p&gt;
&lt;p&gt;Now, this doesn’t come for free, nor does it fall in our lap:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Being productive in a distributed team is a skill
that most people must &lt;strong&gt;learn;&lt;/strong&gt; it is not innate to us.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;People are not born with the ability to work in a distributed
team. Humans function best in groups that collaborate in close
proximity to one another; it is only very recently that technology has
started to enable us to override that to an extent — giving us other
benefits like the ability to work from home, or the ability to hire
people residing anywhere, provided they have internet connectivity.&lt;/p&gt;
&lt;p&gt;So we now &lt;em&gt;can&lt;/em&gt; work in teams despite being continental distances away
from each other but we do have to acquire the skills to do that. And
if we fail to do so, that has a rather grave disadvantage, which is
that...&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Nothing&lt;/strong&gt; has as dire an impact on productivity as &lt;strong&gt;poor
communications.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is a truism that applies to both distributed and non-distributed
teams. Having bad communications will wreck any project, blow any
budget, fail any objective. Now note that the reverse is &lt;em&gt;not true:&lt;/em&gt;
having &lt;em&gt;good&lt;/em&gt; communications does not guarantee success. But having
bad communications does guarantee failure.&lt;/p&gt;
&lt;p&gt;And here is one thing to start with:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A capable distributed team &lt;strong&gt;habitually externalises&lt;/strong&gt; information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Information is generally far less useful when it is only stored in one
person’s head, as opposed to being accessible in a shared system that
everyone trusts and can use. If you take important information out of
your own head and store it in a medium that allows others to easily
find and contextualise it, that’s a win for everyone.&lt;/p&gt;
&lt;p&gt;And since we’re all technology people, we typically have multiple
facilities to externalise, share, and then access information at our
disposal. So let’s see how those compare.&lt;/p&gt;
&lt;h2&gt;Modes of communication in distributed teams&lt;/h2&gt;
&lt;p&gt;A distributed team will habitually use multiple modes of
communication, relying mostly on those that make sharing, finding, and
contextualising information easy, and avoiding those that make it
difficult.&lt;/p&gt;
&lt;p&gt;In many teams, distributed or not, using chat as a default mode of
communication is becoming the norm. Now with an important exception,
which I’ll get to near the end of the talk, this is &lt;strong&gt;not&lt;/strong&gt; a symptom
of having a particularly dynamic or efficient team; it’s the opposite.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Excessively using chat isn’t being efficient.
It’s being lazy.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It’s a symptom of the worst kind of laziness &lt;em&gt;(not malice!)&lt;/em&gt;: in an
attempt to communicate quickly and easily, for yourself, you are really
making things harder for everyone, including yourself.&lt;/p&gt;
&lt;table class="table table-striped"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align="center"&gt;Share&lt;/th&gt;
&lt;th align="center"&gt;Find&lt;/th&gt;
&lt;th&gt;Contextualise&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Chat&lt;/td&gt;
&lt;td align="center"&gt;🙂&lt;/td&gt;
&lt;td align="center"&gt;😐&lt;/td&gt;
&lt;td&gt;🙁&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This is because, while &lt;em&gt;sharing&lt;/em&gt; information in a chat is extremely
easy, it is also a “fire and forget” mode of communications. Chat
makes it difficult to find information after the fact. If you’ve ever
attempted to scour a busy Slack or IRC archive for a discussion on a
specific topic that you only remember to have happened a “few months
ago”, you’ll agree with me here.&lt;/p&gt;
&lt;p&gt;It’s even &lt;em&gt;more&lt;/em&gt; difficult to read a Slack discussion in context, that
is to say in relation to &lt;em&gt;other&lt;/em&gt; discussions on the same topic, days
or weeks earlier or later.&lt;/p&gt;
&lt;p&gt;Let’s compare that to other communication modes:&lt;/p&gt;
&lt;table class="table table-striped"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align="center"&gt;Share&lt;/th&gt;
&lt;th align="center"&gt;Find&lt;/th&gt;
&lt;th&gt;Contextualise&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Chat&lt;/td&gt;
&lt;td align="center"&gt;🙂&lt;/td&gt;
&lt;td align="center"&gt;😐&lt;/td&gt;
&lt;td&gt;🙁&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Email&lt;/td&gt;
&lt;td align="center"&gt;😐&lt;/td&gt;
&lt;td align="center"&gt;😐&lt;/td&gt;
&lt;td&gt;😐&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;Email makes it easy to share information with a person or a group
  from the get-go, but quite difficult to loop people into an ongoing
  discussion after the fact. Finding information later is just as hard
  as with chat, and it’s marginally better at contextualizing
  information than chat (because you get proper threading).&lt;/li&gt;
&lt;/ul&gt;
&lt;table class="table table-striped"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align="center"&gt;Share&lt;/th&gt;
&lt;th align="center"&gt;Find&lt;/th&gt;
&lt;th&gt;Contextualise&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Chat&lt;/td&gt;
&lt;td align="center"&gt;🙂&lt;/td&gt;
&lt;td align="center"&gt;😐&lt;/td&gt;
&lt;td&gt;🙁&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Email&lt;/td&gt;
&lt;td align="center"&gt;😐&lt;/td&gt;
&lt;td align="center"&gt;😐&lt;/td&gt;
&lt;td&gt;😐&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Wiki&lt;/td&gt;
&lt;td align="center"&gt;🙂&lt;/td&gt;
&lt;td align="center"&gt;🙂&lt;/td&gt;
&lt;td&gt;🙂&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Issue tracker&lt;/td&gt;
&lt;td align="center"&gt;🙂&lt;/td&gt;
&lt;td align="center"&gt;🙂&lt;/td&gt;
&lt;td&gt;🙂&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;A wiki and an issue tracker (provided you don’t lock them down with
  silly view permissions), in contrast, both make it &lt;em&gt;very&lt;/em&gt; easy to
  share, find, &lt;strong&gt;and&lt;/strong&gt; contextualise information.&lt;br/&gt;
  Note that “wiki”, in this context, is shorthand for any facility
  that allows you to collaboratively edit long-form documents
  online. That can be an actual wiki like a MediaWiki, but also
  something like Confluence, or even shared Google Docs.&lt;br/&gt;
  Likewise, “issue tracker” can mean RT, OTRS, Jira, Taiga, Bugzilla,
  whatever works for you.&lt;/li&gt;
&lt;/ul&gt;
&lt;table class="table table-striped"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align="center"&gt;Share&lt;/th&gt;
&lt;th align="center"&gt;Find&lt;/th&gt;
&lt;th&gt;Contextualise&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Chat&lt;/td&gt;
&lt;td align="center"&gt;🙂&lt;/td&gt;
&lt;td align="center"&gt;😐&lt;/td&gt;
&lt;td&gt;🙁&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Email&lt;/td&gt;
&lt;td align="center"&gt;😐&lt;/td&gt;
&lt;td align="center"&gt;😐&lt;/td&gt;
&lt;td&gt;😐&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Wiki&lt;/td&gt;
&lt;td align="center"&gt;🙂&lt;/td&gt;
&lt;td align="center"&gt;🙂&lt;/td&gt;
&lt;td&gt;🙂&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Issue tracker&lt;/td&gt;
&lt;td align="center"&gt;🙂&lt;/td&gt;
&lt;td align="center"&gt;🙂&lt;/td&gt;
&lt;td&gt;🙂&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Video call&lt;/td&gt;
&lt;td align="center"&gt;😐&lt;/td&gt;
&lt;td align="center"&gt;🙁&lt;/td&gt;
&lt;td&gt;🙁&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;Video calls are even worse than chat or email, because sharing
  information works but doesn’t scale — you can’t reasonably have more
  than 5-or-so people in a video call, and sharing the recording of a
  full video call is just pointless.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So really, make your wiki and your issue tracker your default mode of
communications, and use the others sparingly. (This isn’t meant to be
a euphemism for “don’t use them”, as we’ll get to in a moment.)&lt;/p&gt;
&lt;h2&gt;Text chat&lt;/h2&gt;
&lt;p&gt;So. Let’s talk about text chat. These days, that frequently means
&lt;a href="https://slack.com/"&gt;Slack&lt;/a&gt;, but what I am talking about also and
equally applies to
&lt;a href="https://en.wikipedia.org/wiki/Internet_Relay_Chat"&gt;IRC&lt;/a&gt;,
&lt;a href="https://mattermost.com/"&gt;Mattermost&lt;/a&gt;, &lt;a href="https://riot.im/"&gt;Riot&lt;/a&gt;, and 
anything similar.&lt;/p&gt;
&lt;p&gt;Is text chat universally useful? No. Is it universally bad? Not that,
either. There is a very specific type of situation in which text chat
is a good thing:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Use &lt;strong&gt;chat&lt;/strong&gt; for collaboration that requires &lt;strong&gt;immediate,
interactive mutual feedback.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Using interactive chat is a good idea for the kind of communication
that requires immediate, interactive mutual feedback from two or more
participants. If that is not the case, chat is not a good idea.&lt;/p&gt;
&lt;p&gt;This means that the only thing that chat is good for is communication
that is required to be &lt;em&gt;synchronous,&lt;/em&gt; and remember, in a distributed
team &lt;em&gt;asychronicity&lt;/em&gt; is the norm. So using interactive chat for
communications needs to be an &lt;em&gt;exceptional&lt;/em&gt; event for a distributed
team; if it is instead a regular occurrence you’ll make everyone on
the team miserable.&lt;/p&gt;
&lt;p&gt;For any interaction that does &lt;em&gt;not&lt;/em&gt; require feedback that is &lt;em&gt;both&lt;/em&gt;
immediate and interactive, email, a wiki, or an issue tracker are &lt;em&gt;far
superior&lt;/em&gt; modes of communication.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The only reason to use &lt;strong&gt;DMs&lt;/strong&gt; for collaboration&lt;br/&gt;
is a need for immediate, interactive mutual feedback&lt;br/&gt;
&lt;strong&gt;and confidentiality.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Using chat direct messages (DMs) as the &lt;em&gt;default&lt;/em&gt; means of
communication is utterly braindead. In order for a chat DM to be
useful, there is precisely one clearly delineated confluence of events
that must occur:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You need immediate feedback from the other person,&lt;/li&gt;
&lt;li&gt;you need mutual back-and-forth with the other person,&lt;/li&gt;
&lt;li&gt;you don’t want others to follow the conversation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I can’t emphasize enough that this combination is perfectly valid —
but it is &lt;em&gt;exceedingly rare.&lt;/em&gt; If you want just a private exchange of
ideas with someone, encrypted email will do. If you want to work on
something together with one person before you share it with others,
restricted view permissions on a wiki page or an issue tracker ticket
will work just fine.&lt;/p&gt;
&lt;p&gt;If you don’t need confidentiality but you do need interactive and
immediate feedback, chances are that you’re working on something
urgent, and it is far more likely you’ll eventually need to poll other
opinions, than that you won’t. So just use a shared channel from the
get-go, that way it’s easier for others to follow the conversation if
needed — and they might be able to point out an incorrect assumption
that one of you has, before you end up chasing a red herring.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A chat ping is a shoulder tap.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;“Pinging” someone in a chat (that is, mentioning their username, which
usually triggers a visual or auditory notification), is exactly like
walking up to a person, interrupting what they are doing, tapping them
on the shoulder, and asking them a question.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;No matter whether it is your intention or not,&lt;/strong&gt; they will feel
compelled to answer, relatively promptly (the only exception is when
you’ve done this so often that you have conditioned your colleagues
to ignore you — congratulations).&lt;/p&gt;
&lt;p&gt;This means that you’ve broken their train of thought, yanked them out
of a potentially complex task, forced them to redo what they did
pre-interruption, or actually have them commit a mistake.&lt;/p&gt;
&lt;p&gt;So pinging someone in a chat is something you should only do if you
are aware of exactly this risk, &lt;em&gt;and&lt;/em&gt; you are convinced that whatever
you’re pinging about is more important. Otherwise, to be very blunt,
you’ll be seen as the asshole.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Want people to hate you? Send naked pings.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A “naked ping” is the action of sending someone a message consisting
only of their username and a marker like “ping”, “hi”, “hey” or
similar.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;&lt;span class="n"&gt;Z&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;johndoe&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;florian&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ping&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;[...]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;56&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="n"&gt;Z&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;florian&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;johndoe&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;I&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;hate&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;you&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Don’t. Just don’t.&lt;/p&gt;
&lt;p&gt;Any person who is versed in the use of chat communications will, when
subjected to this behavior, be inclined to flay you alive. Infinitely
more so if it’s a DM. &lt;strong&gt;Do not do this.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Instead, always provide context. Always always always. Don’t say “can
I ask you a question, instead, &lt;em&gt;ask the question.&lt;/em&gt; If something isn’t
urgent, say something like “no urgency.”&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;00&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;&lt;span class="n"&gt;Z&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;johndoe&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;florian&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;can&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;I&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kd"&gt;get&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;your&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;eyes&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;on&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;PR&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="mi"&gt;1422&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;[...]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;56&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="n"&gt;Z&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;florian&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;johndoe&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;done&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;                   &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;was&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;afk&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bit&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;–&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sick&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;kiddo&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;56&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;58&lt;/span&gt;&lt;span class="n"&gt;Z&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;johndoe&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;florian&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ty&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It should be self-evident why this is better than naked pings, but if
to you it is not, then please read &lt;a href="https://blogs.gnome.org/markmc/2014/02/20/naked-pings/"&gt;Naked
Pings&lt;/a&gt;,
courtesy of Adam Jackson and Mark McLoughlin.&lt;/p&gt;
&lt;h2&gt;Video calls&lt;/h2&gt;
&lt;p&gt;(Zoom, Hangouts, BlueJeans etc.)&lt;/p&gt;
&lt;p&gt;Next, I’d like to talk about video calls. Doesn’t matter what
technology you’re using. Could be Zoom, Google Hangouts, BlueJeans,
Jitsi, whatever.&lt;/p&gt;
&lt;p&gt;And I’d like to address this specifically, given the fact that in the
current pandemic the use of video calls appears to have skyrocketed.&lt;/p&gt;
&lt;p&gt;There’s a very good reason to use video calls: they give you the
ability to pick up on nontextual and nonverbal cues from the call
participants. But that’s really the only good reason to use them.&lt;/p&gt;
&lt;p&gt;Video calls have a significant drawback: until we get reliable
automatic speech recognition and transcription, they are only
half-on-the-record. Hardly anyone goes to the trouble of preparing a
full transcript of a meeting, and if anything, we get perhaps a
summary of points discussed and action items agreed to. So even if we
keep recordings of every video call we attend, it’s practically
impossible to discern, after the fact, what was discussed in a meeting
&lt;em&gt;before&lt;/em&gt; decisions were made.&lt;/p&gt;
&lt;p&gt;It is also practically impossible to &lt;em&gt;find&lt;/em&gt; a discussion point that
you only have a vague recollection of when it was discussed in a video
call, whereas doing so has a much greater probability of success if
a discussion took place on any archived text-based medium.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Every video call needs an agenda.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is, of course, true for any meeting, not just those conducted by
video call.&lt;/p&gt;
&lt;p&gt;A conversation without an agenda is useless. You want people to know
what to expect of the call. You also want to give people the option to
prepare for the call, such as doing some research or pulling together
some documentation. If you fail to circulate those &lt;em&gt;ahead of time,&lt;/em&gt; I
can guarantee that the call will be ineffective, and will likely
result in a repeat performance.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Until machines get intelligent enough to automatically transcribe
and summarise words spoken in a meeting, &lt;strong&gt;write notes and a summary
of every meeting you attend,&lt;/strong&gt; and &lt;strong&gt;circulate them.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Just as important as an agenda to set the &lt;em&gt;purpose&lt;/em&gt; of the meeting, is
a set of notes that describes its &lt;em&gt;outcome&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;Effective distributed teams understand that the &lt;em&gt;record&lt;/em&gt; of a call is
what counts, not the call itself. It is not the spoken word that
matters, but the written one.&lt;/p&gt;
&lt;p&gt;From that follows this consequence:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;To be useful, the write-up of a call &lt;strong&gt;takes more time and effort&lt;/strong&gt;
than the call itself.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If you think that video calls are any less work than chat meetings or
a shared document that’s being edited together or dicussed in
comments, think again. The only way a video call is less work, is when
everyone’s lazy and the call is, therefore, useless. Every meeting
needs notes and a summary, and you need to circulate these notes not
only with everyone who attended the meeting, but with everyone who has
a need-to-know.&lt;/p&gt;
&lt;p&gt;Here’s the standard outline I use for meeting notes:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Meeting title&lt;/li&gt;
&lt;li&gt;Date, time, attendees&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;li&gt;Discussion points (tabular)&lt;/li&gt;
&lt;li&gt;Action items&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Putting an executive summary at the very top is extraordinarily
helpful so people can decide if they&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;should familiarise themselves with what was discussed, immediately,
  and possibly respond if they have objections, or&lt;/li&gt;
&lt;li&gt;only want to be aware of what was decided, or&lt;/li&gt;
&lt;li&gt;just keep in the back of their head that a meeting happened, that
  notes exist, and where they can find them when they need to refer
  back to them.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Once you do meetings right, you no longer need most of them.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The funny thing is that once you adhere to this standard — and I
repeat, having a full and detailed record is &lt;em&gt;the only acceptable
standard&lt;/em&gt; for video meetings – you’ll note that you can actually skip
the meeting altogether, use &lt;em&gt;just&lt;/em&gt; a collaboratively edited document
&lt;em&gt;instead&lt;/em&gt; of your meeting notes, and remove your unnecessary
synchronization point.&lt;/p&gt;
&lt;h3&gt;Video calls for recurring team meetings&lt;/h3&gt;
&lt;p&gt;There is one thing that I do believe video calls are good for, and
that is to use them for &lt;em&gt;recurring&lt;/em&gt; meetings as as an
opportunity to feel the pulse of your team.&lt;/p&gt;
&lt;p&gt;Obviously, a distributed team has &lt;em&gt;few&lt;/em&gt; recurring meetings, because
they are synchronization points, and we’ve already discussed that we
strive to minimize those. So the idea of having daily standups, sprint
planning meetings, and sprint retrospectives is fundamentally
incompatible with distributed teams. &lt;em&gt;Aside: in my humble opinion,
this is also why using Scrum is a terrible idea in distributed teams —
not to mention &lt;a href="https://youtu.be/f-ULT_Ic4qk"&gt;that it’s a terrible idea,
period.&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;However, having perhaps one meeting per week (or maybe even one every
two weeks) in a video call is useful &lt;em&gt;precisely for the aforementioned
reasons&lt;/em&gt; of being able to pick up on nonverbal clues like body
language, posture, facial expressions, and tone. If people are
stressed out or unhappy, it’ll show. If they are relaxed and
productive, that will show too.&lt;/p&gt;
&lt;p&gt;Note that these meetings, which of course do follow the same rules
about agenda and notes, are not strictly &lt;em&gt;necessary&lt;/em&gt; to get the work
done. The team I run has one one-hour meeting a week, but whenever
that meeting conflicts with anything we skip it and divide up our
work via just the circulated coordination notes, and that works
too. The meeting really serves the purpose of syncing emotionally, and
picking up on nonverbal communications.&lt;/p&gt;
&lt;h2&gt;Briefing people&lt;/h2&gt;
&lt;p&gt;Whenever you need to thoroughly &lt;strong&gt;brief a group of people on an
important matter,&lt;/strong&gt; consider using a &lt;strong&gt;5-paragraph format.&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Situation&lt;/li&gt;
&lt;li&gt;Mission&lt;/li&gt;
&lt;li&gt;Execution&lt;/li&gt;
&lt;li&gt;Logistics&lt;/li&gt;
&lt;li&gt;Command and Signal&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This is a format as it is being used by many armed forces; in NATO
parlance it’s called the 5-paragraph field order. Now I’m generally
not a fan of applying military thinking to civilian life — after all
we shouldn’t forget that the military is an institution that kills
people and breaks things, and I say that as a commissioned officer in
my own country’s army —, but in this case it’s actually something that
can very much be applied to professional communications, with some
rather minor modifications:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Situation&lt;/li&gt;
&lt;li&gt;Objective&lt;/li&gt;
&lt;li&gt;Plan&lt;/li&gt;
&lt;li&gt;Logistics&lt;/li&gt;
&lt;li&gt;Communications&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let’s break these down in a little detail:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Situation is about what position we’re in, and &lt;strong&gt;why&lt;/strong&gt; we set out
   to do what we want to do. You can break this down into three
   sub-points, like the customer’s situation, the situation of your
   own company, any extra help that is available, and the current
   market.&lt;/li&gt;
&lt;li&gt;Objective is &lt;strong&gt;what&lt;/strong&gt; we want to achieve.&lt;/li&gt;
&lt;li&gt;Plan is &lt;strong&gt;how&lt;/strong&gt; we want to achieve it.&lt;/li&gt;
&lt;li&gt;Logistics is about what budget and resources are available, and how
   they are used.&lt;/li&gt;
&lt;li&gt;Communications is about how you’ll be coordinating among yourselves
   and with others in order to achieve your goal.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note that people &lt;em&gt;always&lt;/em&gt; have questions on what they’ve just been
briefed about. They just might not think of them straight away. Give
people time to think through what you’ve just briefed them on, and
they will think of good questions. So always have a follow-up round at
a later time (2 hours later, the following day, whatever), for which
you &lt;em&gt;encourage&lt;/em&gt; your group to come back with questions.&lt;/p&gt;
&lt;p&gt;Also, use that same follow-up for checking how your briefing came
across, by gently quizzing people with questions like&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;“by what date do we want to implement X?”, or&lt;/li&gt;
&lt;li&gt;“Joe, what things will you need to coordinate with Jane on?”&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This gives you valuable feedback on the quality of your briefing: if
your team can’t answer these questions, chances are that you weren’t
as clear as you should have been.&lt;/p&gt;
&lt;h2&gt;Pinching the firehose&lt;/h2&gt;
&lt;p&gt;Finally, I want to say a few words about what I like to call pinching
the figurative firehose you might otherwise be forced to drink from:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The amount of incoming information in a distributed team can be
daunting.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;When you work in a distributed team, since everyone is on their own
schedule and everything is asynchronous, you may be dealing with a
constant incoming stream of information — from your colleagues, your
reports, your manager, your customers. &lt;/p&gt;
&lt;p&gt;There is no way to change this, so what you need to do is apply your
own structure to that stream. What follows is not &lt;strong&gt;the&lt;/strong&gt; way to do
that, but &lt;em&gt;one&lt;/em&gt; way, and you may find another works better for
you. But you will need to define and apply &lt;em&gt;some&lt;/em&gt; structure, otherwise
you’ll feel constantly overwhelmed and run the risk of burning out.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Consider using the &lt;strong&gt;“4-D” approach&lt;/strong&gt; when dealing with incoming
information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;(Hat tip to David Allen)&lt;/p&gt;
&lt;p&gt;There’s a defined approach for doing this, which I learned about from
reading &lt;a href="https://en.wikipedia.org/wiki/David_Allen_(author)"&gt;David
Allen&lt;/a&gt;’s &lt;a href="https://www.goodreads.com/book/show/1633.Getting_Things_Done"&gt;Getting
Things
Done&lt;/a&gt;. I
don’t know if Allen invented the 4-D approach or whether someone came
up with it before him, but that’s how I know about it.&lt;/p&gt;
&lt;p&gt;In his book, David Allen suggests to apply one of the following four
actions to any incoming bit of information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Drop&lt;/strong&gt; means read, understand, and then archive. It’s what you use
  for anything that doesn’t require any action on your part.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Delegate&lt;/strong&gt; is for things that do require action, but not from
  you. Make sure that it gets to the right person and is understood by
  &lt;em&gt;them&lt;/em&gt;, and make a note for follow-up.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Defer&lt;/strong&gt; means it needs doing, and it’s you who needs to do it, but
  it doesn’t need doing &lt;em&gt;immediately&lt;/em&gt;. Enter it into your task list
  (to use a very generic term, more on this in a bit), and clear it
  from your inbox.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Do&lt;/strong&gt; are the (typically very few) things that remain that need to
  be done &lt;em&gt;by you, and immediately.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Following this approach does not mean that you’ll never be overwhelmed
by the amount of information that you need to process. But it’ll
greatly reduce that risk.&lt;/p&gt;
&lt;h3&gt;“Drop” rules&lt;/h3&gt;
&lt;p&gt;“Dropping” things doesn’t mean ignoring them. You still have to read
and understand what’s in them, and be able to find them later. So:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Never delete things (except spam).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Only archive them in a way that that keeps them retrievable in the
  future.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If there something isn’t understandable to you, think it through and
  look for clarification.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;“Delegate” rules&lt;/h3&gt;
&lt;p&gt;Delegation obviously requires that there is a person you can delegate
to. This is &lt;em&gt;not necessarily&lt;/em&gt; someone who reports to you; indeed, it
might be someone &lt;strong&gt;you&lt;/strong&gt; report to. (You might be asked to deal with
something that you have no control over, but your manager does.) So:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Find the right person that can get the task done.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Preemptively send them &lt;strong&gt;all&lt;/strong&gt; the information that you think they
  might need (and that you have access to), rather than relying on
  them to ask.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ask them to acknowledge that they have received what they need.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make a note to follow up to see if they need anything else, and
  follow through by seeing the task to completion.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Within your own team, &lt;strong&gt;you only ever delegate tasks, not
responsibility.&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Tasks without follow-up and follow-through are a waste of people’s
time.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Do not delegate, or even define, tasks that you are not prepared to
follow through on. If you handwave “everyone use encrypted email from
now on,” and you’re not even prepared to make that work for your own
email account, you might as well just leave it.&lt;/p&gt;
&lt;p&gt;And if you do proclaim an objective or rule and &lt;em&gt;then&lt;/em&gt; you find yourself
unable to see it through — &lt;em&gt;this happens,&lt;/em&gt; and is no sign of
ineptitude or failure — then loudly and clearly rescind it. It’s far
better for you to visibly backtrack, than to be perceived as someone
whose pronouncements are safe to ignore.&lt;/p&gt;
&lt;h3&gt;“Defer” rules&lt;/h3&gt;
&lt;p&gt;Deferring simply means that because something you need to do doesn’t
need doing &lt;em&gt;immediately,&lt;/em&gt; you can do it at a time that suits your
schedule.&lt;/p&gt;
&lt;p&gt;This means that you’ll need to&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;add the task immediately to some sort of queue (for email, this can
  be a folder named “Needs Reply”),&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;make sure to go through that queue at a later time to prioritize
  (ideally, right after you’re done with your “Do” tasks, which we’ll
  get to in a second),&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;absolutely ensure that you make time to go back and actually do your
  prioritized tasks, at a time you consider convenient.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;“Do” rules&lt;/h3&gt;
&lt;p&gt;And finally, there’ll be your “Do” tasks — stuff that &lt;em&gt;you&lt;/em&gt; need to
do, and do immediately.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Tell people that you’re doing them, because you’ll want to be
  uninterrupted. Update your chat status, put some blocked time in
  your calendar.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make sure you’ll be uninterrupted. For email, turn off all your
  notifications.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Plow through all the undropped, undelegated,
  undeferred items in your inbox until it’s empty.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;But what about the watercooler?&lt;/h2&gt;
&lt;p&gt;The entirety of this talk, up to this point, has focused on
professional communications. And among people unfamiliar or
unexperienced with work in a distributed team, it is often accepted
that teams can communicate well “professionally.” &lt;/p&gt;
&lt;p&gt;However, they frequently ask, “what about watercooler chats? What about
the many informal discussions that happen at work while people are
getting some water or coffee, or sit together over lunch? There’s
always so much communication happening at work that’s informal, but is
extremely beneficial to everyone.”&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Office workers often don’t habitually externalise information. A
distributed team that tries that won’t last a week.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Firstly, many companies where information exchange hinges on coffee or
cafeteria talk simply don’t give a damn about externalising
information. Sure, if 90% of your company’s knowledge is only in
people’s heads, you’re dead without the lunchroom. &lt;/p&gt;
&lt;p&gt;But if the same thing happens in a distributed team, it never gets off
the ground. So, if you have a team that’s functional and productive,
&lt;em&gt;because it habitually externalises information,&lt;/em&gt; the absence of
chit-chat over coffee has zero negative impact on information flow.&lt;/p&gt;
&lt;p&gt;However, you may also be interested in the completely non-work-related
talk that happens over coffee, that simply contributes to people’s
relaxation and well-being.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;People working in distributed teams are often introverts. Or they
simply choose to have their social relationships outside of work.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I know this might shock some people, but there are plenty of people
who can make a terrific contribution to your company, but who dislike
the “social” aspect of work. They might thrive when being left
alone, with as little small-talk as possible, and ample opportunity to
socialize with their friends and family, away from work.&lt;/p&gt;
&lt;p&gt;But if you do have people on your team that enjoy having an entirely
informal conversation every once in a while, there totally is room for
that even in a distributed team. All you need to do is agree on a
signal that means “I’m taking a break and I’d be happy to chat with
anyone who’s inclined, preferably about non work related things” (or
whatever meaning your group agrees on). &lt;/p&gt;
&lt;p&gt;This could be&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a keyword on IRC,&lt;/li&gt;
&lt;li&gt;a message to a specific channel, or&lt;/li&gt;
&lt;li&gt;(if you want to get fancy) a bot that updates your group calendar
  when it receives a message with a particular format.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, as a word of caution, I’ve actually done this with my team
before, and it didn’t catch on — for the simple reason that we almost
never took breaks that happened to overlap. But that doesn’t rule out
that it works on &lt;em&gt;your&lt;/em&gt; team, and also there’s always the remote
possibility that two or more people on your team might like to
schedule their breaks concurrently.&lt;/p&gt;
&lt;p&gt;What you can &lt;em&gt;also&lt;/em&gt; do, of course, is have a channel in which you can
discuss completely random things that are not work related. And if the
rule is that confidential or company-proprietary discussion topics are
off-limits there, the channel might as well be public. It might even
be Twitter.&lt;/p&gt;
&lt;h2&gt;The antithesis: ChatOps&lt;/h2&gt;
&lt;p&gt;I do want to mention one other thing for balance. There is a complete
alternative framework for distributed teams working together, and it’s
what people refer to as ChatOps.&lt;/p&gt;
&lt;p&gt;To the best of my knowledge, the first company to run ChatOps on a
large scale &lt;em&gt;and talk about it publicly&lt;/em&gt; was GitHub, &lt;a href="https://youtu.be/NST3u-GjjFw"&gt;back in
2013&lt;/a&gt; in a
&lt;a href="https://www.rubyfuza.org/"&gt;RubyFuza&lt;/a&gt; talk by &lt;a href="https://twitter.com/jnewland"&gt;Jesse
Newland&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If a distributed team operates on a ChatOps basis, the interactive
text chat is where absolutely everything happens. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Everyone lives in chat all the time, and all issues, alerts and events are
  piped into the chat.&lt;br/&gt;
  Everything is discussed in the chat, and everything is also
  &lt;em&gt;resolved&lt;/em&gt; in the chat.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Such a system relies on heavy use of chat bots. For example, if an
  alert lands in the channel, and the discussion then yields that the
  proper fix to the problem is to run a specific Ansible playbook,
  you send an in-chat bot command that kicks off that playbook, and
  then reports its result.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And this is of course very laudable, because it resolves a major issue
with using chat, which is the classic scenario of something being
discussed in a chat, someone else then going away for a bit and then
coming back saying “I fixed it!”, and nobody else actually
understanding what the problem was. &lt;/p&gt;
&lt;p&gt;If you make everything explicit and in-band, in becomes easy, in
principle, to go back to a previously-solved problem that reappears,
and replay the resolution.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;When does ChatOps make sense? Here’s a hint: It’s called Chat&lt;strong&gt;Ops&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So can this make sense? Yes, absolutely. Under what circumstances
though? I maintain that this is best suited for when your work tends
to be inherently linear with respect to some dimension. For example,
if your primary job is to keep a system operational versus the linear
passage of &lt;em&gt;time,&lt;/em&gt; ChatOps is an excellent approach.&lt;/p&gt;
&lt;p&gt;And keeping complex systems operational over time is the definition
of, you guessed it, ops. So ChatOps may be a very suitable
communication mode for operations, but it’s highly unlikely to be
efficient as a generic mode of communication across distributed teams.&lt;/p&gt;
&lt;p&gt;And even then I posit it’s difficult to get right, since you’ll have
to curb channel sprawl and threading and other things, but’s that’s a
whole ‘nother talk and indeed a talk for another &lt;em&gt;speaker,&lt;/em&gt; because I
don’t lead an ops team.&lt;/p&gt;
&lt;h2&gt;To summarize...&lt;/h2&gt;
&lt;p&gt;So to summarize, here are my key points from this talk, in a nutshell
— please make these your key takeaways.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Distributed teams are better than localized teams — not because
  they’re distributed, but because they’re asynchronous.&lt;/li&gt;
&lt;li&gt;Avoid anything that makes a distributed team run synchronously.&lt;/li&gt;
&lt;li&gt;Use less chat.&lt;/li&gt;
&lt;li&gt;Have fewer meetings.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Write. Things. Down.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="presentations"></category><category term="Conference"></category><category term="Communications"></category><category term="Work"></category></entry><entry><title>No, We Won’t Have a Video Call for That: Slides and Recordings</title><link href="https://xahteiwi.eu/resources/presentations/no-we-wont-have-a-video-call-for-that-slides-and-recordings/" rel="alternate"></link><published>2020-08-22T00:00:00+00:00</published><updated>2020-08-22T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2020-08-22:/resources/presentations/no-we-wont-have-a-video-call-for-that-slides-and-recordings/</id><summary type="html">&lt;p&gt;These are the slides and recordings of the original talk that
ultimately became &lt;a href="https://xahteiwi.eu/resources/presentations/no-we-wont-have-a-video-call-for-that/"&gt;this article&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The talk recording is available from two different sources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Video and audio in multiple formats, for viewing and download: &lt;a href="https://media.ccc.de/v/froscon2020-2605-no_we_won_t_have_a_video_call_for_that"&gt;CCC
  Media
  server&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Streaming: &lt;a href="https://youtu.be/NVnci3tyDa4"&gt;YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And, as always, you can also review my slides, with all …&lt;/p&gt;</summary><content type="html">&lt;p&gt;These are the slides and recordings of the original talk that
ultimately became &lt;a href="https://xahteiwi.eu/resources/presentations/no-we-wont-have-a-video-call-for-that/"&gt;this article&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The talk recording is available from two different sources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Video and audio in multiple formats, for viewing and download: &lt;a href="https://media.ccc.de/v/froscon2020-2605-no_we_won_t_have_a_video_call_for_that"&gt;CCC
  Media
  server&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Streaming: &lt;a href="https://youtu.be/NVnci3tyDa4"&gt;YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And, as always, you can also review my slides, with all my speaker notes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rendered slides: &lt;a href="https://fghaas.github.io/froscon2020/"&gt;GitHub
  Pages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slide sources (CC-BY-SA): &lt;a href="https://github.com/fghaas/froscon2020"&gt;GitHub&lt;/a&gt; &lt;/li&gt;
&lt;/ul&gt;</content><category term="presentations"></category><category term="Conference"></category><category term="Communications"></category><category term="Work"></category></entry><entry><title>Celery to Chew On</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/chewy-celery/" rel="alternate"></link><published>2020-05-06T00:00:00+00:00</published><updated>2020-05-06T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2020-05-06:/resources/hints-and-kinks/chewy-celery/</id><summary type="html">&lt;p&gt;Asynchronous Celery tasks that manipulate a MySQL/Galera database from a Django application can produce very interesting behavior when HAProxy is involved.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Asynchronous Celery tasks that manipulate a MySQL/Galera database from
a Django application can produce very interesting behavior when
HAProxy is involved.&lt;/p&gt;
&lt;!--break--&gt;
&lt;h1&gt;Some basics&lt;/h1&gt;
&lt;p&gt;When you’re running a &lt;a href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt;
application, the following things are all pretty commonplace:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You use &lt;a href="https://en.wikipedia.org/wiki/MySQL"&gt;MySQL&lt;/a&gt; or
  &lt;a href="https://en.wikipedia.org/wiki/MariaDB"&gt;MariaDB&lt;/a&gt; as your &lt;a href="https://docs.djangoproject.com/en/3.0/ref/databases/#mariadb-notes"&gt;Django
  database
  backend&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;You don’t run a single standalone MySQL/MariaDB instance, but a
  &lt;a href="https://galeracluster.com/"&gt;Galera&lt;/a&gt; cluster.&lt;/li&gt;
&lt;li&gt;You run asynchronous tasks in &lt;a href="https://docs.celeryproject.org/en/stable/"&gt;Celery&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This way, if you have a complex operation in your application, you
don’t necessarily have to handle it in your latency-critical request
codepath. Instead, you can have something like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;celery&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Task&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;ComplexOperation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Task&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
   &lt;span class="sd"&gt;"""Task that does very complex things"""&lt;/span&gt;

   &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
      &lt;span class="c1"&gt;# ... lots of interesting things&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;... and then from your view (or management command, or whatever), you
can invoke this like so:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;.tasks&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ComplexOperation&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;some_path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
   &lt;span class="sd"&gt;"""/some_path URL that receives a request for an asynchronous ComplexOperation"""&lt;/span&gt;
   &lt;span class="c1"&gt;# ...&lt;/span&gt;

   &lt;span class="c1"&gt;# Asynchronously process ComplexOperation&lt;/span&gt;
   &lt;span class="n"&gt;ComplexOperation&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;delay&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pk&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;GET&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'id'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

   &lt;span class="c1"&gt;# ...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;What this means is that the code defined in &lt;code&gt;ComplexOperation&lt;/code&gt;’s
&lt;code&gt;run()&lt;/code&gt; method can run asynchronously, while the HTTP request to
&lt;code&gt;/some_path&lt;/code&gt; can immediately return a response. You can then fetch the
asynchronous task’s result in a later request, and present it to the
user.&lt;/p&gt;
&lt;p&gt;(Note that there are other ways to &lt;a href="https://docs.celeryproject.org/en/stable/userguide/calling.html"&gt;invoke Celery
tasks&lt;/a&gt;;
getting into those in detail is not the point of this article.)&lt;/p&gt;
&lt;h1&gt;MySQL/Galera via HAProxy&lt;/h1&gt;
&lt;p&gt;Now, let’s inject another item into the setup. Suppose your
application doesn’t talk to your Galera cluster directly, but via
&lt;a href="https://www.haproxy.org/"&gt;HAProxy&lt;/a&gt;. That’s not exactly unheard of; in
fact it’s &lt;a href="https://galeracluster.com/library/documentation/ha-proxy.html"&gt;an officially documented HA
option&lt;/a&gt;
for Galera.&lt;/p&gt;
&lt;p&gt;If you run a Django application against an HAProxyfied Galera cluster,
and you have rather long-running Celery tasks, you may see occurrences
of &lt;code&gt;OperationalError&lt;/code&gt; exceptions that map to MySQL error 2013, &lt;code&gt;Lost
connection to MySQL server during query&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Error 2013 means that the connection between the client and the server
dropped in the middle of executing a query. This is different from
error 2006, &lt;code&gt;MySQL server has gone away&lt;/code&gt;, which means that the server
has gracefully torn down the connection. 2013 is really an
out-of-nowhere connection drop, which normally only occurs if your
network has gone very wonky.&lt;/p&gt;
&lt;p&gt;With HAProxy however, &lt;em&gt;that&lt;/em&gt; service may be your culprit. An HAProxy
service sets four different &lt;strong&gt;timeout&lt;/strong&gt; values:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;timeout connect&lt;/code&gt;: the time in which a backend server must accept a
  TCP connection, default 5s.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;timeout check&lt;/code&gt;: the time in which a backend server must respond to
  a recurring health check, default 5s.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;timeout server&lt;/code&gt;: how long the server is allowed to take before it
  answers a request, default 50s.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;timeout client&lt;/code&gt;: how long the client is allowed to take before it
  sends the next request, default 50s.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Distilling the timeout problem&lt;/h1&gt;
&lt;p&gt;If you have access to &lt;code&gt;manage.py shell&lt;/code&gt; for your Django application,
here’s a really easy way for you to trigger an adverse effect of this
default configuration. All you have to do is create an object from a
model, so that it fetches data from the database, then wait a bit,
then try to re-fetch. Like so:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="o"&gt;./&lt;/span&gt;&lt;span class="n"&gt;manage&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;py&lt;/span&gt; &lt;span class="n"&gt;shell&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;InteractiveConsole&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;sleep&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;django.contrib.auth&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;get_user_model&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;User&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;get_user_model&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;me&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;User&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;username&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'florian'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;me&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;refresh_from_db&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;55&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;me&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;refresh_from_db&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;Traceback&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;most&lt;/span&gt; &lt;span class="n"&gt;recent&lt;/span&gt; &lt;span class="n"&gt;call&lt;/span&gt; &lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;OperationalError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2013&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'Lost connection to MySQL server during query'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So what happens here?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I open a session to the database with the &lt;code&gt;User.objects.get()&lt;/code&gt; call
  that populates the &lt;code&gt;me&lt;/code&gt; object.&lt;/li&gt;
&lt;li&gt;Then I wait 40 seconds. That’s comfortably short of the 50-second
  HAproxy timeout.&lt;/li&gt;
&lt;li&gt;Now when I run &lt;code&gt;me.refresh_from_db()&lt;/code&gt;, the session is still alive
  and the call completes without error. The timeout clock resets at
  this stage, and I could keep going like this ad infinitum, as long
  as I &lt;code&gt;sleep()&lt;/code&gt; (or keep busy) for less than 50 seconds.&lt;/li&gt;
&lt;li&gt;However, I next wait &lt;em&gt;55&lt;/em&gt; seconds, causing HAProxy to terminate the
  connection.&lt;/li&gt;
&lt;li&gt;And then, &lt;code&gt;refresh_from_db()&lt;/code&gt; breaks immediately with the 2013
  error.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that if I run &lt;code&gt;refresh_from_db()&lt;/code&gt; — or any other operation that
touches the database – &lt;strong&gt;again&lt;/strong&gt;, I get a different error (2016,
expected at this point), but I don’t get my database connection back:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; me.refresh_from_db()
Traceback (most recent call last):
[...]
OperationalError: (2006, 'MySQL server has gone away')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;What I have to do instead is &lt;em&gt;close&lt;/em&gt; my &lt;code&gt;connection&lt;/code&gt; first:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;django.db&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;connection&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;connection&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;... and then, when I run anything else that requires a database query,
Django will happily reconnect for me.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; me.refresh_from_db()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1&gt;HAProxy timeouts getting in the way of your Celery tasks&lt;/h1&gt;
&lt;p&gt;Now how does this relate to a real-world application? Suppose you have
a long-running Celery task with database updates or queries at the
beginning and end of something complicated, like so:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;celery&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Task&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Thing&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;ComplexOperation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Task&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
   &lt;span class="sd"&gt;"""Task that does very complex things"""&lt;/span&gt;

   &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
     &lt;span class="n"&gt;thing&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Thing&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pk&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'pk'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
     &lt;span class="n"&gt;do_something_really_long_and_complicated&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
     &lt;span class="n"&gt;thing&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this case, &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;we retrieve data from the database into memory, populating our
  &lt;code&gt;thing&lt;/code&gt; object,&lt;/li&gt;
&lt;li&gt;then we do something very complex with it — suppose this can
  take on the order of minutes, in the extreme,&lt;/li&gt;
&lt;li&gt;and finally, we take the modified data for our in-memory object, and
  persist it back to the database.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So far, so simple. However, now assume that while you’re executing the
&lt;code&gt;do_something_really_long_and_complicated()&lt;/code&gt; method, something bad
happens to your database. Say you restarted one of your MySQL or
MariaDB processes, or one of your nodes died altogether. Your database
&lt;em&gt;cluster&lt;/em&gt; is still alive, but your &lt;em&gt;session&lt;/em&gt;, which was very much
alive during the call that populated &lt;code&gt;thing&lt;/code&gt;, is dead by the time you
want to make the &lt;code&gt;thing.save()&lt;/code&gt; call.&lt;/p&gt;
&lt;p&gt;Depending on what actually happened, you’d see one of the following
two &lt;code&gt;OperationalError&lt;/code&gt; instances:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Either an immediate &lt;code&gt;2006, MySQL server has gone away&lt;/code&gt; — this is is
  what you’d see if the MySQL server was shut down or
  restarted. That’s a graceful session teardown, and it’s &lt;strong&gt;not&lt;/strong&gt; what
  I want to focus on in this article.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Or, and this is what I want to discuss further here, &lt;code&gt;2013, Lost
  connection to MySQL server during query&lt;/code&gt;. You normally &lt;em&gt;don’t&lt;/em&gt; get
  this as a result of something breaking at the other &lt;em&gt;end&lt;/em&gt; of the
  connection, but rather in between. In our case, that would be
  HAProxy. Let’s look at our code snippet with a few extra comments:&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;celery&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Task&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Thing&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;ComplexOperation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Task&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
   &lt;span class="sd"&gt;"""Task that does very complex things"""&lt;/span&gt;

   &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
     &lt;span class="n"&gt;thing&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Thing&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pk&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'pk'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
     &lt;span class="c1"&gt;# Right here (after the query is complete) is where HAproxy starts its&lt;/span&gt;
     &lt;span class="c1"&gt;# timeout clock&lt;/span&gt;

     &lt;span class="c1"&gt;# Suppose this takes 60 seconds (10 seconds longer than the default &lt;/span&gt;
     &lt;span class="c1"&gt;# HAProxy timeout)&lt;/span&gt;

     &lt;span class="n"&gt;do_something_really_long_and_complicated&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

     &lt;span class="c1"&gt;# Then by the time we get here, HAProxy has torn down the connection,&lt;/span&gt;
     &lt;span class="c1"&gt;# and we get a 2013 error.&lt;/span&gt;
     &lt;span class="n"&gt;thing&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So now that we’ve identified the problem, how do we solve it? Well
that depends greatly on the following questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Are you the developer, meaning you can fix this in code, but you
  can’t change much in the infrastructure?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Or are you a systems person, who can control all aspects of the
  infrastructure, but you don’t have leverage over the code?&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you have control over neither code nor infrastructure, you’re out
of luck. If you call all the shots about both, you get to pick and
choose. But here are your options.&lt;/p&gt;
&lt;h1&gt;Fixing this in code&lt;/h1&gt;
&lt;p&gt;If it’s your codebase, and you want to make it robust so it runs in
any MySQL/Galera environment behind HAProxy, no matter its
configuration, you have a couple of ways to do it.&lt;/p&gt;
&lt;h2&gt;Keep connections shorter&lt;/h2&gt;
&lt;p&gt;One way to do it is do keep your database connections alive for such a
short time that you practically never hit the HAProxy
timeouts. Thankfully, Django auto-reconnects to your database any time
it needs to do something, so the only thing you need to worry about
here is &lt;em&gt;closing&lt;/em&gt; connections — &lt;em&gt;reopening&lt;/em&gt; them is automatic. For
example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;django.db&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;connection&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Thing&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;ComplexOperation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Task&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
   &lt;span class="sd"&gt;"""Task that does very complex things"""&lt;/span&gt;

   &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
     &lt;span class="n"&gt;thing&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Thing&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pk&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'pk'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
     &lt;span class="c1"&gt;# Close connection immediately&lt;/span&gt;
     &lt;span class="n"&gt;connection&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

     &lt;span class="c1"&gt;# Suppose this takes 60 seconds.&lt;/span&gt;
     &lt;span class="n"&gt;do_something_really_long_and_complicated&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

     &lt;span class="c1"&gt;# Here, we just get a new connection.&lt;/span&gt;
     &lt;span class="n"&gt;thing&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Catch OperationalErrors&lt;/h2&gt;
&lt;p&gt;The other option is to just wing it, and catch the errors. Here’s a
deliberately overtrivialized example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;django.db&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;connection&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;django.db.utils&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;OperationalError&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Thing&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;ComplexOperation&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Task&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
   &lt;span class="sd"&gt;"""Task that does very complex things"""&lt;/span&gt;

   &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
     &lt;span class="n"&gt;thing&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Thing&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;objects&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pk&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'pk'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
     &lt;span class="c1"&gt;# Right here (after the query is complete) is where HAproxy starts its&lt;/span&gt;
     &lt;span class="c1"&gt;# timeout clock&lt;/span&gt;

     &lt;span class="c1"&gt;# Suppose this takes 60 seconds.&lt;/span&gt;
     &lt;span class="n"&gt;do_something_really_long_and_complicated&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

     &lt;span class="c1"&gt;# Then by the time we get here, HAProxy has torn down the connection,&lt;/span&gt;
     &lt;span class="c1"&gt;# and we get a 2013 error, which we’ll want to catch.&lt;/span&gt;
     &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
       &lt;span class="n"&gt;thing&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
     &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;OperationalError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
       &lt;span class="c1"&gt;# It’s now necessary to disconnect (and reconnect automatically),&lt;/span&gt;
       &lt;span class="c1"&gt;# because if we don’t then all we do is turn a 2013 into a 2006.&lt;/span&gt;
       &lt;span class="n"&gt;connection&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
       &lt;span class="n"&gt;thing&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now of course, you’d never &lt;em&gt;actually&lt;/em&gt; implement it this way, because
the one-time retry is far too trivial, so you probably want to retry
up to &lt;em&gt;n&lt;/em&gt; times, but with exponential backoff or some such — in
detail, this becomes complicated really quickly. &lt;/p&gt;
&lt;p&gt;You probably also want some logging to catch this. &lt;/p&gt;
&lt;p&gt;In short, you probably don’t want to hand-craft this, but instead rely
on something like the &lt;code&gt;retry()&lt;/code&gt; decorator from
&lt;a href="https://tenacity.readthedocs.io/en/latest/"&gt;tenacity&lt;/a&gt;, which can
conveniently provide all those things, plus the reconnect, without
cluttering your code too much.&lt;/p&gt;
&lt;h1&gt;Fixing this in infrastructure&lt;/h1&gt;
&lt;p&gt;You may be unable to control this sort of thing in your code — because, for
example, it’s a codebase you’re not allowed to touch, or you’re less
than comfortable with the idea of scouring or profiling your code for
long-running codepaths between database queries, and sprinkling
&lt;code&gt;connection.close()&lt;/code&gt; statements around.&lt;/p&gt;
&lt;p&gt;In that case, you can fix your HAProxy configuration instead. Again,
the variables you’ll want to set are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;timeout server&lt;/code&gt; and &lt;/li&gt;
&lt;li&gt;&lt;code&gt;timeout client&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You’ll probably want to set them to an identical value, which should
be the maximum length of your database-manipulating Celery task, and
then ample room to spare.&lt;/p&gt;
&lt;p&gt;The maximum reasonable value that you can set here is that of your
backend server’s &lt;code&gt;wait_timeout&lt;/code&gt; configuration variable, &lt;a href="https://mariadb.com/kb/en/server-system-variables/#wait_timeout"&gt;which
defaults to 8
hours&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;Careful though, while MySQL interprets timeout settings in &lt;em&gt;seconds&lt;/em&gt;
by default, HAProxy &lt;a href="https://cbonte.github.io/haproxy-dconv/1.7/configuration.html#2.4"&gt;defaults to
&lt;em&gt;milliseconds.&lt;/em&gt;&lt;/a&gt;
You’d thus need to translate the &lt;code&gt;28800&lt;/code&gt; default value for MySQL’s
&lt;code&gt;wait_timeout&lt;/code&gt; into a &lt;code&gt;timeout server|client&lt;/code&gt; value of 28000000 for
HAProxy, or else you set the HAProxy timeout to a value of &lt;code&gt;28800s&lt;/code&gt;
(or &lt;code&gt;8h&lt;/code&gt;, if you prefer).&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;Background research contribution credit for this post goes to my &lt;a href="https://www.citynetwork.eu/"&gt;City
Network&lt;/a&gt; colleagues &lt;a href="https://twitter.com/elenalindq"&gt;Elena
Lindqvist&lt;/a&gt; and &lt;a href="https://twitter.com/pdale_se"&gt;Phillip
Dale&lt;/a&gt;, plus &lt;a href="https://twitter.com/zerobanana"&gt;Zane
Bitter&lt;/a&gt; for the tenacity suggestion.&lt;/p&gt;
&lt;p&gt;Also, thanks to &lt;a href="https://twitter.com/muratkochane"&gt;Murat Koç&lt;/a&gt; for
suggesting to clarify the supported time formats in HAProxy.&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Django"></category><category term="MySQL"></category><category term="HAProxy"></category><category term="Celery"></category><category term="Python"></category></entry><entry><title>Paying People</title><link href="https://xahteiwi.eu/blog/2020/02/04/paying-people/" rel="alternate"></link><published>2020-02-04T00:00:00+00:00</published><updated>2020-02-04T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2020-02-04:/blog/2020/02/04/paying-people/</id><summary type="html">&lt;p&gt;Paying people equally is straightforward, right? We all agree on that, and then once we’re talking about people living in different countries, we all disagree on what “equal” really means.&lt;/p&gt;</summary><content type="html">&lt;p&gt;In my now almost 10ish years of first running my own company, and then
managing a team in the company I sold my company to, I have very
frequently struggled with what’s a “fair” way of paying people. &lt;/p&gt;
&lt;p&gt;I’ve come to the conclusion that when it comes to hiring distributed,
and thus hiring people living in different countries, there is no such
thing. At least not one that everyone agrees on to be fair. The best
thing we can hope for is an approximation of fairness.&lt;/p&gt;
&lt;h1&gt;How much do you earn?&lt;/h1&gt;
&lt;p&gt;If I ask you how much you make, you’ll either&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;be very offended at the invasion of your privacy, and refuse to
  answer, or&lt;/li&gt;
&lt;li&gt;give me an answer straight away.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Which it is, is likely going to be determined by your culture and your
upbringing. I am Austrian, I have interacted a lot with Americans, and
now I work with Swedes — I can tell you, there are &lt;em&gt;very&lt;/em&gt; different
views on this.&lt;/p&gt;
&lt;p&gt;Whether or not you choose to answer, you’ll likely have a number in
your head. And again, there are multiple ways you’ll think of that.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It could be your annual salary, before income tax.&lt;/li&gt;
&lt;li&gt;It could be your monthly salary, before income tax and public
  healthcare and pension payments.&lt;/li&gt;
&lt;li&gt;It could be really weird, as in Austria: you’d think of your
  “monthly” salary, but in reality that’s 1/14th rather than 1/12th of
  your annual salary, because you’re paid a double salary in June and
  November.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But whichever it is, you’d probably think of a number, in your home
currency.&lt;/p&gt;
&lt;h1&gt;Equal work, equal pay. Right?&lt;/h1&gt;
&lt;p&gt;I hope we generally agree that two people who do the same (or
equivalent) work should be paid the same. And as long as you’re
comparing two people, living in the same place, whose salary is paid
out in the same currency, that’s easy.&lt;/p&gt;
&lt;p&gt;But what about people from different countries? We can even assume
that those two countries use the same currency, to facilitate the
discussion. (Talking about &lt;em&gt;different&lt;/em&gt; currencies makes things even
more murky, and is perhaps a topic for another article.)&lt;/p&gt;
&lt;p&gt;What’s the actual “worth” of the money you make?&lt;/p&gt;
&lt;p&gt;There’s no correct answer for this. There are two possible approaches,
both of which are “wrong” in a way and “right” in another. Let’s say
we’re talking about two people being paid 3,000 euros a month, one
living in Finland, one in Greece.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;You could say that a euro is a euro. Thus, if you’ve got € 3,000 in
  your hand in Finland, that’s the same as having € 3,000 in Greece.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Or you could look at the question, what does that euro buy? If
  you’ve got € 3,000 in Finland, that will buy you things that, on
  average, you need to spend only about € 2,080 euros on in Greece.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So look at two people, one living in Finland and one in Greece. You
pay them both € 3,000 for the same work. Are you paying them equally,
or not?&lt;/p&gt;
&lt;p&gt;I think you wouldn’t. If I had a person working for me in Finland, and
I paid that person € 3,000, and another person in Greece that also
made € 3,000 for the same work, I’d be massively short-changing the
person in Finland.&lt;/p&gt;
&lt;p&gt;But you can argue that € 3,000 is € 3,000 and that’s the end of the
story. I tend to think that economists are on my side — that’s why the
concept of &lt;a href="https://en.wikipedia.org/wiki/Purchasing_power_parity"&gt;purchasing power
parity&lt;/a&gt; (PPP)
exists —, but you can certainly be of the opposite opinion.&lt;sup id="fnref:inflation"&gt;&lt;a class="footnote-ref" href="#fn:inflation"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;And then there’s the problem that most PPP conversion rates are
per-country. And they may be way off if you compare, say, someone
living in Athens to someone living in
&lt;a href="https://en.wikipedia.org/wiki/%C3%84teritsiputeritsipuolilautatsij%C3%A4nk%C3%A4"&gt;Äteritsiputeritsipuolilautatsijänkä&lt;/a&gt;,
to stick with the Greece and Finland example.&lt;/p&gt;
&lt;p&gt;The fact of the matter is, neither approach is perfect, and I can only
choose one approach or the other. And the approach that I’ve chosen,
in the distributed team that I run, is to make PPP adjustments. Others
opt for a different approach. Neither of these is right, or
wrong. They’re both an attempt to treat your people equally, and
neither is perfect.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:inflation"&gt;
&lt;p&gt;I will put forward one small thought though: if you are
convinced that the money you earn is just that number in your
currency (as in, € 3,000 is € 3,000), then I posit that you should
also stick to that opinion in the face of inflation. Under that
assumption, then € 3,000 next year is still the same € 3,000 it
was this year, regardless of whether inflation was maybe 5%. &lt;a class="footnote-backref" href="#fnref:inflation" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="blog"></category><category term="Work"></category></entry><entry><title>Why do they always lie?</title><link href="https://xahteiwi.eu/blog/2020/02/04/why-do-they-always-lie/" rel="alternate"></link><published>2020-02-04T00:00:00+00:00</published><updated>2020-02-04T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2020-02-04:/blog/2020/02/04/why-do-they-always-lie/</id><summary type="html">&lt;p&gt;When politicians (and their supporters) keep lying even though their lies are easily exposed, it’s a strategy.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Recently I came across a tweet from my Irish OpenStack community
friend &lt;a href="https://twitter.com/nearyd"&gt;Dave Neary&lt;/a&gt;, &lt;a href="https://twitter.com/nearyd/status/1224727999951572993"&gt;in which he wondered
aloud&lt;/a&gt; why a
picture, which was very obviously (and poorly) doctored, made its way
onto Twitter. As if, so goes the reasoning, the creator of the picture
was ass enough to assume that no-one would notice.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It’s so obvious [...] I just don’t understand why you’d bother.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;More generally, you can summarize this befuddlement by rephrasing the
question as follows: “why would anyone, in a political campaign even,
run with a lie that’s so easily called out?”&lt;/p&gt;
&lt;p&gt;This assumes that lying, deception, is something you’d prefer to go
undetected. And generally that’s true, human behavior works exactly
that way: when we lie and deceive — and humans do this all them time
for many reasons, some of them benign — the deception only works if it
isn’t caught.&lt;/p&gt;
&lt;h2&gt;Why do they lie, when it’s so easy to tell?&lt;/h2&gt;
&lt;p&gt;Then, what makes humans lie and spread falsehoods, even when they’re
easily detected?&lt;/p&gt;
&lt;p&gt;I submit that to understand why, you should play a game.&lt;/p&gt;
&lt;p&gt;The game is called &lt;a href="https://ncase.me/trust/"&gt;The Evolution of Trust&lt;/a&gt;,
and its creator is &lt;a href="https://twitter.com/ncasenmare"&gt;Nicky Case&lt;/a&gt;. You
can play it online, it’s available in multiple languages. And it will
take only about 15 minutes to complete. Go play it. No, really do.&lt;/p&gt;
&lt;p&gt;Did you play it? No? Well &lt;a href="https://ncase.me/trust/"&gt;it’s here&lt;/a&gt;. Please
go play it.&lt;/p&gt;
&lt;p&gt;Done? OK. Let’s carry on.&lt;/p&gt;
&lt;h2&gt;What does The Evolution of Trust tell us?&lt;/h2&gt;
&lt;p&gt;The game-theoretical concepts that The Evolution of Trust introduces
tell you three things about its simple game of cooperation and
defection (playing by the rules vs. cheating):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If communications between players are &lt;em&gt;perfect,&lt;/em&gt; then the most
  successful strategy is tit-for-tat (“copycat”).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If communications are &lt;em&gt;imperfect,&lt;/em&gt; then the most successful strategy
  is tit-for-two-tats (or “tit for tat with forgiveness,” or
  “copykitten”) — &lt;em&gt;up to a certain error rate in communications.&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If communications are &lt;em&gt;imperfect beyond that error rate threshold,&lt;/em&gt;
  then the most successful strategy is to always cheat (“cheater”).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now, &lt;em&gt;real&lt;/em&gt; human communications are always messy, so the perfect
communications scenario is out the window. We’re always dealing with
imperfect communications, but we never know how high our error rate
is.&lt;/p&gt;
&lt;p&gt;And most of us are brought up with the Golden Rule and a certain
measure of forgiveness. We tend to be “copykittens.”&lt;/p&gt;
&lt;p&gt;But now put yourself in the shoes of someone who has decided they’ll
take the cheater role. They’ll not play by the rules, they’ll only
ever fend for themselves and their own, everyone else be
damned. They’ve chosen the asshole route.&lt;/p&gt;
&lt;p&gt;Their problem is, they can’t win. Game theory literally tells us that
the forgiveness strategy is superior. &lt;strong&gt;Except if the cheater manages
to increase the error rate beyond the threshold.&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;If you’ve decided you want to be an asshole, lie. It’s your only chance.&lt;/h2&gt;
&lt;p&gt;So once you’ve decided that you’ll not play by the rules, your only
shot at winning is to destroy communications — for everyone.&lt;/p&gt;
&lt;p&gt;And your best shot at that is to lie. Never tell the truth, contradict
objective facts, say the stupidest, dumbest, most blatantly false
things. Small lies, large lies, medium-sized lies. It does not matter
if your lie is exposed, in fact, your lies &lt;em&gt;must&lt;/em&gt; be exposed for your
strategy to work.&lt;/p&gt;
&lt;p&gt;And now you know how to spot someone in politics who has decided to
break the rules. And why you shouldn’t assume they’re stupid, just
because they say objectively stupid things.&lt;/p&gt;</content><category term="blog"></category><category term="Politics"></category></entry><entry><title>Salacious Salad and Omelette</title><link href="https://xahteiwi.eu/blog/2020/01/01/salacious-salad-and-omelette/" rel="alternate"></link><published>2020-01-01T00:00:00+00:00</published><updated>2020-01-01T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2020-01-01:/blog/2020/01/01/salacious-salad-and-omelette/</id><summary type="html">&lt;p&gt;A breakfast experiment that turned out well.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Sometime last year I came across a post on
&lt;a href="https://www.reddit.com/r/food/"&gt;/r/food&lt;/a&gt; that I seem to be unable to
dig up. However, I recall that it had an infographic asserting that
for a salad to be perfect, it had to have&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;something tangy,&lt;/li&gt;
&lt;li&gt;something sweet,&lt;/li&gt;
&lt;li&gt;something crunchy,&lt;/li&gt;
&lt;li&gt;some protein (egg or meat),&lt;/li&gt;
&lt;li&gt;some dairy (yoghurt or cheese).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So I goofed around preparing breakfast one Sunday morning, and out
came this.&lt;/p&gt;
&lt;h2&gt;Ingredients&lt;/h2&gt;
&lt;p&gt;Amounts are per person. Multiply as needed.&lt;/p&gt;
&lt;p&gt;Salad:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A fistful of &lt;a href="https://en.wikipedia.org/wiki/Rocket_leaves"&gt;rocket
  leaves&lt;/a&gt; (arugula).&lt;/li&gt;
&lt;li&gt;Some grapes, the smaller the better.&lt;/li&gt;
&lt;li&gt;A few cherry tomatoes. Best fresh off the vine in the middle of
  summer, even better if you can mix red, yellow, and purple
  varieties.&lt;/li&gt;
&lt;li&gt;A few basil leaves.&lt;/li&gt;
&lt;li&gt;A small amount of your favorite cold cut, say a thin slice or two of
  &lt;a href="https://en.wikipedia.org/wiki/Prosciutto"&gt;prosciutto crudo&lt;/a&gt; or
  &lt;a href="https://en.wikipedia.org/wiki/Bresaola"&gt;bresaola&lt;/a&gt; (or
  &lt;a href="https://en.wikipedia.org/wiki/B%C3%BCndnerfleisch"&gt;Bündnerfleisch&lt;/a&gt;,
  if you want to get super fancy).&lt;/li&gt;
&lt;li&gt;A few thin slices of Parmigiano or Grana Padano. Cutting them off
  the piece with a potato peeler works really well.&lt;/li&gt;
&lt;li&gt;Pinch of black sesame seeds.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Vinaigrette:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1 teaspoon balsamic vinegar&lt;/li&gt;
&lt;li&gt;Pinch of salt&lt;/li&gt;
&lt;li&gt;A few turns of freshly ground black pepper&lt;/li&gt;
&lt;li&gt;Half a teaspoon of mustard&lt;/li&gt;
&lt;li&gt;Half a teaspoon of honey&lt;/li&gt;
&lt;li&gt;A dash of something spicy, if you’re into that sort of thing. Sambal
  oelek or sriracha sauce will work just fine.&lt;/li&gt;
&lt;li&gt;3 teaspoons olive oil&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Omelette:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1 egg&lt;/li&gt;
&lt;li&gt;Pinch of salt&lt;/li&gt;
&lt;li&gt;Butter (for frying)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Equipment&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;1 medium-size bowl&lt;/li&gt;
&lt;li&gt;2 small bowls&lt;/li&gt;
&lt;li&gt;Whisk&lt;/li&gt;
&lt;li&gt;Small frying pan&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Method&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Prepare the tomatoes: using a properly sharp kitchen knife, cut
   them into halves, quarters, or slices. Chuck them into a small bowl
   and sprinkle them rather liberally with salt and black
   pepper. Stack the basil leaves on top of each other and roll them
   up like tobacco leaves for a cigar, then cut the rolls into slices
   as thinly as you can. Throw the thin basil strands into the bowl,
   add some olive oil, and mix thoroughly using a spoon or your
   hands. Let the bowl sit on the countertop for five minutes or so,
   so that the tomatoes start oozing a bit of juice.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make the vinaigrette: in a wide-enough bowl, put in salt, pepper,
   mustard, honey, and balsamic vinegar, and optionally the spicy
   condiment. Whisk to mix nicely, then add olive oil and whisk
   vigorously for 30-60 seconds. The goal is to get an opaque
   emulsion, with the mustard and honey acting as natural
   &lt;a href="https://en.wikipedia.org/wiki/Emulsion#Emulsifiers"&gt;emulsifiers&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Throw the rocket leaves and grapes into the vinaigrette bowl and
   mix thoroughly with (cleanly washed) hands. Let sit for a few
   minutes so that the vinaigrette can infuse the leaves.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Crack egg into a small bowl, beat thoroughly with the whisk so the
   mixture is homogenous. Add a bit of salt.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make sure your serving plate, pieces of meat, cheese shavings, and
   black sesame are close by (if you’re a
   &lt;a href="https://en.wikipedia.org/wiki/Mise_en_place"&gt;mise-en-place&lt;/a&gt;
   enthusiast, you’ve likely done this already) — once the omelette is
   ready, you want to serve things up quickly.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Heat up some butter in the small pan.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pour the beaten egg in and cook your omelet. It will be very thin
   so this should take only a minute, perhaps two.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Throw the omelet on the plate (don’t fold it) and then start
   stacking: rocket and grapes in vinaigrette at the bottom, then
   tomatoes in olive oil and basil, meat, cheese shavings finally
   sesame on top.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Serve.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Nutrition facts&lt;/h2&gt;
&lt;p&gt;No warranty of any kind on these. Values are per serving.&lt;/p&gt;
&lt;table class="table table-striped"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Calories (kcal)&lt;/th&gt;
&lt;th&gt;343&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Total fat (g)&lt;/td&gt;
&lt;td&gt;28.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Saturated fat (g)&lt;/td&gt;
&lt;td&gt;8.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Total carbohydrates (g)&lt;/td&gt;
&lt;td&gt;12.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Sugars (g)&lt;/td&gt;
&lt;td&gt;8.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Protein (g)&lt;/td&gt;
&lt;td&gt;12.9&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</content><category term="blog"></category><category term="Food"></category><category term="Recipe"></category></entry><entry><title>My 2010s</title><link href="https://xahteiwi.eu/blog/2019/12/31/my-2010s/" rel="alternate"></link><published>2019-12-31T00:00:00+00:00</published><updated>2019-12-31T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2019-12-31:/blog/2019/12/31/my-2010s/</id><summary type="html">&lt;p&gt;I guess at the end of a decade, it’s a good time as any to look back.&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is my look back at the decade we’re just finishing up.&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h2&gt;Some stats&lt;/h2&gt;
&lt;p&gt;Besides managing to grow 10 years older, in this decade I founded 1
company, sold 1 company, left 1 company, joined 1 company, folded 0
companies, bankrupted 0 companies, raised precisely €0 of VC, provided
an income to a growing family, kept the bank accounts in the black
throughout, spent 836 days (2 years, 3 months, 2 weeks and 2 days) on
the road, traveled 947,000 kilometers (that’s about the length of a
&lt;a href="https://en.wikipedia.org/wiki/Circumlunar_trajectory"&gt;circumlunar free
return&lt;/a&gt;
trajectory), visited 144 cities in 32 countries (including airport
stopovers), and gave about 72 talks (on average a little over one
every two months) at conferences and events.&lt;/p&gt;
&lt;h2&gt;hastexo&lt;/h2&gt;
&lt;p&gt;More than half the decade (6 years and 1 month, to be precise) is
occupied by my tenure at hastexo, the company I co-founded and led
from inception to acquisition by &lt;a href="https://www.citynetworkhosting.com/"&gt;City
Network&lt;/a&gt;. Coming off an excellent
stint at &lt;a href="https://linbit.com"&gt;Linbit&lt;/a&gt; — where I worked for 4.5 years,
and which I’m pleased to report is still around, alive, independent
and kicking (a rare feat in this industry) — my co-founders Martin,
Andreas and I bootstrapped a company that operationally broke even in
its third month, and earned its founding cost back in six (while
providing us a livelihood out of operational revenue). Though we never
went through any kind of meteoric rise or exponential growth — hardly
a thing in professional service companies devoid of hockey sticks — we
did make good calls in gaining a foothold in the Ceph and OpenStack
communities early on, and quickly established a reputation as
technical experts.&lt;/p&gt;
&lt;p&gt;We parted ways three years in, and if we follow the analogy that that
sort of thing is something like a divorce, this was a particularly
amicable one. All of us are still on good terms, and even occasionally
have the opportunity to collaborate.&lt;/p&gt;
&lt;p&gt;hastexo also enabled me to meet my brilliant colleagues
&lt;a href="https://arbrand.es/"&gt;Adolfo&lt;/a&gt; (with whom I still work) and
&lt;a href="https://twitter.com/syedarmani"&gt;Syed&lt;/a&gt; (who has since done a career
pivot and works in a completely different part of our industry).&lt;/p&gt;
&lt;h2&gt;City Network&lt;/h2&gt;
&lt;p&gt;Making the decision to
&lt;a href="https://www.citynetwork.eu/pressreleases/city-network-shifts-high-gear-hastexo-acquisition/"&gt;sell&lt;/a&gt;
hastexo to &lt;a href="https://www.citynetworkhosting.com/"&gt;City Network&lt;/a&gt; in 2017
is something that I’ve never regretted. I generally get along very
well with the Scandinavian approach to work — something that I had
learned 10 years earlier when I had the pleasure of interacting
regularly with then-independent &lt;a href="https://en.wikipedia.org/wiki/MySQL_AB"&gt;MySQL
AB&lt;/a&gt; —, and City Network is no
exception here.&lt;/p&gt;
&lt;p&gt;Obviously an integration into an acquirer is never entirely devoid of
friction,&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt; particularly when a fully distributed team meets a
previously fully office-driven company, but our colleagues turned out
to be an excellent bunch and I’m on a very good working basis with my
CEO Johan.&lt;/p&gt;
&lt;p&gt;At City Network I’ve also finally succeeded in doing something I’d
always failed at in the years prior, which is to have built a
gender-balanced team. &lt;a href="https://twitter.com/namratasitlani"&gt;Namrata&lt;/a&gt;
and &lt;a href="https://twitter.com/elenalindq"&gt;Elena&lt;/a&gt; are fantastic assets in a
highly professional, highly functional, and &lt;a href="https://twitter.com/search?q=from%3Axahteiwi%20MTIA"&gt;generally
awesome&lt;/a&gt; group.&lt;/p&gt;
&lt;h2&gt;People&lt;/h2&gt;
&lt;p&gt;Apart from the excellent people I get to work with on a daily basis, I
have met an astonishing number of utterly amazing folks in this
decade. In fact, many of them have had so much influence on me that I
find it hard to believe I didn’t even know them a decade ago. It’s
straight-out impossible to list them all, so I’ve representatively
picked three people here.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://twitter.com/liewegas"&gt;Sage Weil&lt;/a&gt; of &lt;a href="https://ceph.io"&gt;Ceph&lt;/a&gt;
fame is possibly the strongest pairing of brilliance and humility
you’ll ever encounter. How many people do you know that &lt;a href="https://www.redhat.com/en/about/press-releases/red-hat-acquire-inktank-provider-ceph"&gt;made fuck-you
money&lt;/a&gt;
from something they thought up in &lt;a href="https://ceph.com/wp-content/uploads/2016/08/weil-thesis.pdf"&gt;their PhD
thesis&lt;/a&gt;,
then took some of that fuck-you money as &lt;a href="https://www.soe.ucsc.edu/news/article/2349"&gt;a donation to their alma
mater&lt;/a&gt; where it endows a
professorship &lt;em&gt;that &lt;a href="https://www.soe.ucsc.edu/news/article/2402"&gt;their PhD advisor now
holds&lt;/a&gt;?&lt;/em&gt;&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3"&gt;3&lt;/a&gt;&lt;/sup&gt; It’s an
absolute privilege to know this guy.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://twitter.com/marcoostini"&gt;Marco Ostini&lt;/a&gt; is, and will always
be, the face of
&lt;a href="https://en.wikipedia.org/wiki/Linux.conf.au"&gt;linux.conf.au&lt;/a&gt; for me,
and I need to mention him here for his own sake and that of the
community he is a part of. When I arrived for &lt;a href="https://2011.linux.conf.au/"&gt;my very first
LCA&lt;/a&gt; in 2011, as a completely
inexperienced traveler, fatigued, jet-lagged and bleary-eyed as all
hell, there was this wonderful Aussietalian with a beaming smile
giving me the warmest of welcomes &lt;em&gt;at half-past midnight&lt;/em&gt; and
cheerfully gave me a lift to the accommodation. LCA 2011 was my best
conference up to that point, ran what &lt;em&gt;still&lt;/em&gt; appears to be &lt;a href="https://youtu.be/NyHJ8Uf03qg"&gt;my most
popular conference talk&lt;/a&gt; (largely thanks
to &lt;a href="https://ourobengr.com/"&gt;Tim Serong&lt;/a&gt;’s live cartooning), and kicked
off a series of LCAs for me that were always a warm fuzzy
shot-up-the-arm of Aussie and Kiwi hospitality in the middle of the
dark European winter. Not to mention the talks. And
Pac-Man. And hugs.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://twitter.com/shar1z"&gt;Sharone Revah Zitzman&lt;/a&gt; has been my
constant and unbroken link to the Israeli cloud, open source, and
DevOps community. Sharone is basically a conference organizing
committee on two feet, and an incredibly nice and welcoming person to
boot. I’ve forged many friendships in the Israeli developer community
that would never have happened were it not for her, and I love coming
back to her neck of the woods for that reason.&lt;/p&gt;
&lt;h2&gt;Me&lt;/h2&gt;
&lt;p&gt;Honestly, I really dislike reading old emails (whether I sent them in
private or to public mailing lists) from the early 2010s, because they
remind me that more than occasionally I was abrasive to the point of
being an outright jerk. I hope that that has improved somewhat.&lt;/p&gt;
&lt;p&gt;I think I did pretty well in the “immersing myself in new technology
and keeping current in it” department. At the start of the decade I
knew next-to-nothing about Ceph, OpenStack hadn’t even started, and
Open edX wasn’t yet under the AGPL. Today I feel kinda-sorta-OK in two
of those, and not-quite-an-idiot in the other, which is about as happy
as I’ll ever be with my limited knowledge of anything.&lt;/p&gt;
&lt;p&gt;I’ve also &lt;em&gt;finally&lt;/em&gt; allowed myself to feel reasonably comfortable
about what I do as a manager, even if it means deviating from
conventional wisdom or established precedent.&lt;/p&gt;
&lt;p&gt;So let’s see what the next decade holds. Happy new year, everyone!&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Yes, I know. It’s arbitrary. Gregorian calendar yada yada, plus
the discussion whether the decade ends at the end of 2019, or the
end of 2020. I don’t care. Now is as good as any time to look back
and reflect. &lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;I should really do a conference talk for startup founders on what
to expect when you’re being acquired one day. &lt;a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;That’s pretty awesome academia bragging rights for the professor,
too. &lt;a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="blog"></category></entry><entry><title>Exceptional Pan Pizza</title><link href="https://xahteiwi.eu/blog/2019/12/30/exceptional-pan-pizza/" rel="alternate"></link><published>2019-12-30T00:00:00+00:00</published><updated>2019-12-30T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2019-12-30:/blog/2019/12/30/exceptional-pan-pizza/</id><summary type="html">&lt;p&gt;My go-to recipe for pan (deep dish) pizza.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I’ve found this to be the pan pizza to end all pan pizzas. It’s my
standard pizza dough recipe, plus some inspiration from &lt;a href="https://youtu.be/uYxB4QBlrx4"&gt;this
video&lt;/a&gt;. The trick with seasoning the pan
is an absolute kicker and makes the crust taste oodles better than
without that seasoning.&lt;/p&gt;
&lt;h2&gt;Ingredients&lt;/h2&gt;
&lt;p&gt;Amounts are for one 26 cm pan that will likely feed 4 adults. Make
several to accommodate a larger crowd, or very hungry people.&lt;/p&gt;
&lt;p&gt;Crust:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;200g plain spelt flour&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;150g wholemeal spelt flour&lt;/li&gt;
&lt;li&gt;150ml warm water&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;10g fresh yeast (alternatively 7 grams dry yeast)&lt;/li&gt;
&lt;li&gt;½ teaspoon honey (optional)&lt;/li&gt;
&lt;li&gt;7g salt&lt;/li&gt;
&lt;li&gt;good splash of olive oil, about 1-2 tablespoons&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sauce:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;200g peeled and chopped canned tomatoes (alternatively a similar
  preparation from homegrown produce)&lt;/li&gt;
&lt;li&gt;Pinch of salt&lt;/li&gt;
&lt;li&gt;1 tablespoon of olive oil&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Toppings:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;100g cheese (mozzarella is canonical, but coarsely grated mild young
  Gouda works surprisingly well and you should give it a shot if you
  have it available)&lt;/li&gt;
&lt;li&gt;spicy sausage, bell peppers, mushrooms, ham, whatever you fancy&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Pan seasoning:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Splash of olive oil&lt;/li&gt;
&lt;li&gt;Tablespoon of cornstarch&lt;/li&gt;
&lt;li&gt;Pinch of salt&lt;/li&gt;
&lt;li&gt;Ground black pepper&lt;/li&gt;
&lt;li&gt;Oregano&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Equipment&lt;/h2&gt;
&lt;p&gt;Required:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One large, thick-bottomed pan with a lid. Can be a cast iron
  skillet, or a non-stick pan, or a thick enamelled frying pan which
  is what I use. What’s important is that the bottom is at least 1cm
  thick, and that the handle can stand being under your oven
  broiler/grill for about 5 minutes.&lt;/li&gt;
&lt;li&gt;Stovetop.&lt;/li&gt;
&lt;li&gt;Oven with broiler/grill.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Optional:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Stand mixer or kitchen appliance with a dough hook. If
  unavailable, your hands will work just fine.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Method&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Prepare a poolish: dissolve the yeast (and honey, if you like) in
   half of the warm water, add flour until the mixture is something
   like porridge. Put in a warm spot&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3"&gt;3&lt;/a&gt;&lt;/sup&gt; and let rise until the volume has
   doubled (15-30 minutes).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Add salt and poolish to the remainder of the flour in a bowl, knead
   and add enough water to make a homogeneous dough. Might take the
   full remaining 150ml, or less, depending on flour. Pour olive oil
   into bowl and and work some in, leaving the sides of the bowl
   nicely greased. Chuck bowl back into warm place and let rise for
   another 15-20 minutes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;While dough rises, season the pan. Pour in olive oil, add
   cornstarch, and rub the mixture with your fingers over the whole
   inside of the pan — both the bottom and the walls.  Sprinkle salt,
   pepper, and oregano into the pan.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Gently spread the dough into a flat round piece roughly the
   diameter of the bottom of the pan. You can use a rolling pin for
   this, but if you do, make sure to grease the rolling pin and
   countertop with olive oil, rather than dusting them with flour like
   you’re perhaps used to.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Let the dough rise one more time, about 15 minutes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Prepare the sauce. Simply mix chopped tomatoes with a good pinch of
   salt and some olive oil.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Spread the sauce &lt;em&gt;all across the dough&lt;/em&gt;, covering the whole
   diameter of the pan. Do not leave any uncovered crust on the
   perimeter. Repeat with cheese and finally, toppings.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Turn burner on medium heat, put the pan on (cover it with a lid),
   and cook for approximately 8-10 minutes. The trapped steam will
   cook the sauce and toppings on top, while the bottom of the pan
   bakes the crust. Preheat your broiler to high heat.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When the cheese on top has started to melt, throw the pan under the
   broiler/grill for about 3 minutes until the cheese gets nice
   patches of golden brown.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Turn pizza out on a round pizza plate. It should easily come off
    the bottom of the pan, though the sides might require some
    scraping if cheese has melted and run down the sides. Cut into
    slices.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dig in.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Nutrition facts&lt;/h2&gt;
&lt;p&gt;No warranty of any kind on these. Values are per serving, counting one
serving as one-quarter of the whole pizza.&lt;/p&gt;
&lt;table class="table table-striped"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Calories (kcal)&lt;/th&gt;
&lt;th&gt;479&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Total fat (g)&lt;/td&gt;
&lt;td&gt;17.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Saturated fat (g)&lt;/td&gt;
&lt;td&gt;6.7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Total carbohydrates (g)&lt;/td&gt;
&lt;td&gt;64.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Sugars (g)&lt;/td&gt;
&lt;td&gt;3.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Protein (g)&lt;/td&gt;
&lt;td&gt;21.1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;In case you’ve never baked with spelt flour before: tastes about
like wheat, but takes on less water. You can modify this recipe to
use wheat flour, in which case you’ll need about 375ml of
water. Also, while a wheat dough normally benefits from a long or
slow rise, I’ve found that not to be true for spelt. &lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;If you’re from the U.S.: yes I know, we Europeans are a bit
weird in that we customarily give some quantities by weight,
others by volume. You’d &lt;em&gt;think&lt;/em&gt; it’d be straightforward that we do
solids by weight and liquids by volume, but it isn’t. (Some
recipes specify sugar by weight, for example, others say use
so-and-so-many tablespoons of sugar.) &lt;a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;My oven has a leavening mode in which I can let a dough rise at
approximately 39°C and near 100% humidity, which is glorious, but
this is in no way a requirement. I’ve let dough rise in a bowl
placed on the floor (we have floor heating), on the running
laundry dryer, or out on the countertop. &lt;a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="blog"></category><category term="Food"></category><category term="Recipe"></category></entry><entry><title>DevOpsDays Tel Aviv 2019</title><link href="https://xahteiwi.eu/resources/presentations/devopsdays-tel-aviv-2019/" rel="alternate"></link><published>2019-12-20T00:00:00+00:00</published><updated>2019-12-20T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2019-12-20:/resources/presentations/devopsdays-tel-aviv-2019/</id><summary type="html">&lt;p&gt;I presented two talks at DevOpsDays Tel Aviv 2019: one 40-minute full-length talk, and a 5-minute Ignite.&lt;/p&gt;</summary><content type="html">&lt;p&gt;This year, &lt;a href="https://devopsdaystlv.com"&gt;DevOpsDays Tel Aviv&lt;/a&gt; accepted
two of my submitted talks:&lt;/p&gt;
&lt;h2&gt;No really, don’t chuck everything in Slack: Communications for distributed teams&lt;/h2&gt;
&lt;p&gt;This is a 40-minute talk that I presented after keynotes on day 2. It
deals with the specific challenges that distributed teams face and
solve, and has a bunch of ready-to-go suggestions to communicate
better as a distributed team.&lt;/p&gt;
&lt;p&gt;I had two surprises in this talk:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;A large number of people still appear to be unfamiliar with the
   term &lt;a href="https://blogs.gnome.org/markmc/2014/02/20/naked-pings/"&gt;naked ping&lt;/a&gt;,
   even though just about everyone is &lt;em&gt;very&lt;/em&gt; familiar with the
   antipattern itself. It resulted in an “oh so &lt;em&gt;that’s&lt;/em&gt; what that’s
   called!” reaction from a significant share of the audience.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I usually try to not throw shade in my talks. But if and when I do
   it’s usually about Scrum, which I continue to consider a patently
   ludicrous idea. I did mention Scrum in a negative manner in my
   talk, and got a rather unexpected round of mid-talk applause. (My
   talks generally tend to be rather matter-of-factly; mid-sentence
   applause is not something I’m used to.) Speaking to a crowd that
   skewed hard toward the software engineering profession, this always
   gets me thinking: engineers understand that Scrum is horrible; when
   will their managers catch on?&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The video for this talk is forthcoming, but for now you can find my
slides (with full speaker notes) on
&lt;a href="https://fghaas.github.io/devopsdaystlv-2019/"&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Five is Fine: A case for small teams&lt;/h2&gt;
&lt;p&gt;This was a 5-minute talk delivered as part of a round of “Ignite”
talks. I use scare quotes because DevOpsDaysTLV uses a somewhat
relaxed Ignite format: you must deliver your talk in 5 minutes, but
you’re not restricted to the exact number of 20 slides, and your
slides also don’t auto-advance every 15 seconds. I did not know this,
so I &lt;em&gt;did&lt;/em&gt; follow the original Ignite format, using reveal.js
autoSlide to advance my slides every 15000 ms.&lt;/p&gt;
&lt;p&gt;These talks were also recorded, and the recording should become
available relatively shortly (I will update this post when they
do). As with the other talk, the slides are available on 
&lt;a href="https://fghaas.github.io/five-is-fine/"&gt;GitHub&lt;/a&gt; and include my notes.&lt;/p&gt;
&lt;p&gt;I’d like to thank &lt;a href="https://twitter.com/wholemilk"&gt;Rachel&lt;/a&gt; for
suggesting that I write this talk.&lt;/p&gt;
&lt;h2&gt;Know a conference that might like these talks?&lt;/h2&gt;
&lt;p&gt;If you organize a conference that might be interested in including
these talks, or you’ve attended one that you &lt;em&gt;think&lt;/em&gt; might, please
&lt;a href="https://twitter.com/xahteiwi"&gt;find me on Twitter&lt;/a&gt; and let me
know. I’ll be happy to submit one of them for consideration. I could
definitely expand the Ignite talk into a full standard-length talk —
doing the reverse for the other one might be a bit challenging,
though.&lt;/p&gt;</content><category term="presentations"></category><category term="Conference"></category></entry><entry><title>Slidecraft updates</title><link href="https://xahteiwi.eu/blog/2019/12/13/slidecraft/" rel="alternate"></link><published>2019-12-13T00:00:00+00:00</published><updated>2019-12-13T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2019-12-13:/blog/2019/12/13/slidecraft/</id><summary type="html">&lt;p&gt;I’ve been doing public talks and presentations rather frequently for the last 10-or-so years, but this year I made significant changes to my process for creating, rehearsing, and presenting talks.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I’ve been doing public talks and presentations rather frequently for
the last 10-or-so years, but this year I made significant changes to
my process for creating, rehearsing, and presenting talks.&lt;/p&gt;
&lt;h2&gt;What I used to do&lt;/h2&gt;
&lt;p&gt;When I started doing talks a while back, I followed an approach that
many of us were at some point either taught, or adopted by emulating
our peers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;I would roughly sketch an outline,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;then I’d create slides (usually on a company or conference template),&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;then I’d add some speaker notes in bullet-point fashion,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;then I’d rehearse the talk,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;and finally I’d refine my content based on whether I was short or
  long in terms of the available time slot.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That’s a very conventional approach, and it tends to focus very much
on getting the slides right.&lt;/p&gt;
&lt;p&gt;Today I do things differently.&lt;/p&gt;
&lt;h2&gt;What I do now&lt;/h2&gt;
&lt;p&gt;I’ve come to the conclusion that what I really want my audience to
focus on is what I am &lt;em&gt;talking&lt;/em&gt; about. So now, I do this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;I still start with a rough — &lt;em&gt;very&lt;/em&gt; rough — outline.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Next though, I write my speaker notes. All of them. Yes, that means
  I write out my &lt;em&gt;entire&lt;/em&gt; talk, and this may well take days.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Then, I do a first practice run. Is there a good natural flow? Will
  it make sense to someone completely unfamiliar with my topic? Is the
  story I’m telling logical?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Then, I edit. This process of alternating rehearsal and edits
  continues until I’m reasonably happy with the whole talk, and I have
  timed it and am happy with my pacing, too.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Only then do I start creating my slides, and I usually completely
  disregard conference templates, for reasons I’ll get to in a moment.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Yes, that means that when I ultimately deliver the talk, I’m actually
reading from my notes. Except when I’m just riffing and ad-libbing
over them. Chances are, unless you know me very well, you’ll be unable
to tell. That’s because I write my notes like I talk, and I pay more
attention to flow and stress and rhythm than I do to grammar and
exactitude. &lt;a href="https://youtu.be/ruehcRDRIgM"&gt;This talk&lt;/a&gt;, just like
&lt;a href="https://youtu.be/ZifNGprBUTA"&gt;this&lt;/a&gt;, and
&lt;a href="https://youtu.be/cRqA-eYYOXE"&gt;this&lt;/a&gt; were all delivered from fully
written speaker notes.&lt;/p&gt;
&lt;p&gt;Fully writing out my talk has also enabled me to greatly reduce my use
of &lt;a href="https://en.wikipedia.org/wiki/Filler_(linguistics)"&gt;fillers&lt;/a&gt; (like
“ah” and “um”), which I used to say excessively and which would make
me cringe at my talk videos.&lt;/p&gt;
&lt;h2&gt;Accessibility&lt;/h2&gt;
&lt;p&gt;Now to explain why I normally disregard conference templates: In
preparing and delivering my talks, I try to put a greater emphasis on
accessibility that I used to before.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;my slides are now all high-contrast. I default to using &lt;a href="https://fghaas.github.io/cookiecutter-presentation/#/3"&gt;black text
  on a white
  background&lt;/a&gt;
  (this is a good default for when I have reason to assume the
  projection equipment will be less than perfect), alternatively I use
  white text on a black background (for darkened rooms).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I try to accommodate people with the most common types of color
  blindness: I use blue — as opposed to red or green – as my highlight
  color, and in
  &lt;a href="https://fghaas.github.io/cephalocon2019-rbdmirror/#/8/2"&gt;charts&lt;/a&gt;, I
  differentiate by both color and line stroke. I also try to refrain
  from using animations. As for slide transitions, I use only fade, no
  motion.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I publish my slides ahead of time, include a QR code at the very
  beginning, and I use reveal.js Multiplex so that my slides advance
  in unison with those one people’s phones, tablets, or laptops. This
  way, people with less-than-perfect vision (or simply seated in an
  unfortunate spot, at the back of the room) can follow along easily
  and and their own preferred zoom level.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Since my speaker notes are fully written out, this means that I can
  also &lt;a href="https://fghaas.github.io/cookiecutter-presentation/#/intro"&gt;include
  them&lt;/a&gt; in
  the published material, so that my notes can act as subtitles for my
  speaking. This can come in handy to people who are hard of hearing,
  or who are simply unaccustomed to my accent or manner of speech.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I’ve rolled these accessibility considerations into my opinionated,
&lt;a href="https://cookiecutter.readthedocs.io/"&gt;Cookiecutter&lt;/a&gt;-based reveal.js
&lt;a href="https://github.com/fghaas/cookiecutter-presentation"&gt;presentation
generator&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;A request&lt;/h2&gt;
&lt;p&gt;If you happen to be visually impaired, or color blind, or hard of
hearing, or you work with people who are – in other words, if you can
make a suggestion for me to improve the accessibility of my slides,
&lt;em&gt;please&lt;/em&gt; &lt;a href="https://github.com/fghaas/cookiecutter-presentation/issues"&gt;file an
issue&lt;/a&gt;
against my Cookiecutter and I’ll try to work that in as best I
can. Thank you!&lt;/p&gt;</content><category term="blog"></category><category term="Conference"></category></entry><entry><title>Ceph Erasure Code Overhead Mathematics</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/ceph-ec-math/" rel="alternate"></link><published>2019-11-30T00:00:00+00:00</published><updated>2019-11-30T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2019-11-30:/resources/hints-and-kinks/ceph-ec-math/</id><summary type="html">&lt;p&gt;In a Ceph cluster, the frequent question, “how much space utilization overhead does my EC profile cause,” can be answered with very simple algebra.&lt;/p&gt;</summary><content type="html">&lt;p&gt;So you’re running a Ceph cluster, and you want to create &lt;a href="https://docs.ceph.com/docs/master/rados/operations/erasure-code/"&gt;pools using
erasure
codes&lt;/a&gt;,
but you’re not quite sure of exactly how much extra space you’re going
to save, and whether or not that’s worth the performance penalty?
Here’s a simple recipe for calculating that space overhead.&lt;/p&gt;
&lt;p&gt;Suppose a RADOS object has a size of &lt;span class="math"&gt;\(S\)&lt;/span&gt;, and because it’s in an EC
pool using the
&lt;a href="https://docs.ceph.com/docs/master/rados/operations/erasure-code-jerasure/"&gt;&lt;code&gt;jerasure&lt;/code&gt;&lt;/a&gt;
or
&lt;a href="https://docs.ceph.com/docs/master/rados/operations/erasure-code-isa/"&gt;&lt;code&gt;isa&lt;/code&gt;&lt;/a&gt;
plugin,&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt; Ceph splits it into &lt;span class="math"&gt;\(k\)&lt;/span&gt; equally-sized chunks. Then the
size of any of its &lt;span class="math"&gt;\(k\)&lt;/span&gt; chunks will be: &lt;/p&gt;
&lt;div class="math"&gt;$$S \over k$$&lt;/div&gt;
&lt;p&gt;In addition, we get &lt;span class="math"&gt;\(m\)&lt;/span&gt; more parity chunks, also of size &lt;span class="math"&gt;\(S \over k\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Thus, the total amount of storage taken by an object of size &lt;span class="math"&gt;\(S\)&lt;/span&gt; is:
&lt;/p&gt;
&lt;div class="math"&gt;$$k \cdot {S \over k} + m \cdot {S \over k}$$&lt;/div&gt;
&lt;p&gt;This of course we can rearrange and reduce to &lt;/p&gt;
&lt;div class="math"&gt;$$S + S \cdot {m \over
k}$$&lt;/div&gt;
&lt;p&gt; or &lt;/p&gt;
&lt;div class="math"&gt;$$S \cdot (1 + {m \over k})$$&lt;/div&gt;
&lt;p&gt;In other words, the overhead (that is, the &lt;strong&gt;additional storage&lt;/strong&gt;
taken up by the EC parity data) is &lt;/p&gt;
&lt;div class="math"&gt;$$S \cdot {m \over k}$$&lt;/div&gt;
&lt;p&gt; or when
expressed as a proportion to &lt;span class="math"&gt;\(S\)&lt;/span&gt;, simply &lt;/p&gt;
&lt;div class="math"&gt;$$m \over k$$&lt;/div&gt;
&lt;p&gt;As an example, an EC profile with &lt;span class="math"&gt;\(k = 8, m=3\)&lt;/span&gt; comes with a storage
overhead of &lt;span class="math"&gt;\(3 \over 8\)&lt;/span&gt; or 37.5%.&lt;/p&gt;
&lt;p&gt;One with &lt;span class="math"&gt;\(k=5, m=2\)&lt;/span&gt; has an overhead of &lt;span class="math"&gt;\(2 \over 5\)&lt;/span&gt;, or 40%. &lt;/p&gt;
&lt;p&gt;And finally, a &lt;em&gt;replicated&lt;/em&gt; (conventional, non-EC) pool with 3
replicas can be thought of as having a degenerate EC profile with
&lt;span class="math"&gt;\(k=1, m=2\)&lt;/span&gt;, resulting in an overhead of &lt;span class="math"&gt;\(2 \over 1\)&lt;/span&gt;, or 200%.&lt;/p&gt;
&lt;p&gt;On a parting note, you should realize that the space utilization
overhead is only one factor by which you should weigh erasure code
profiles against one another. The other is performance. Here, the
general (deliberately oversimplified) rule is that the more chunks you
define — in other words, the higher your &lt;span class="math"&gt;\(k\)&lt;/span&gt; — the higher the
performance penalty you suffer, particularly on reads.&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt; This is due to
the fact that in order to reconstruct the object and serve it to the
application, your client must collect data from &lt;span class="math"&gt;\(k\)&lt;/span&gt; different OSDs and
assemble it locally.&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Thanks to &lt;a href="https://twitter.com/larsmb/"&gt;Lars Marowsky-Bree&lt;/a&gt; for
&lt;a href="https://twitter.com/larsmb/status/1201425069140000773"&gt;reminding me&lt;/a&gt; that
slightly different arithmetics apply to the
&lt;a href="https://docs.ceph.com/docs/master/rados/operations/erasure-code-lrc/"&gt;&lt;code&gt;lrc&lt;/code&gt;&lt;/a&gt;,
&lt;a href="https://docs.ceph.com/docs/master/rados/operations/erasure-code-shec/"&gt;&lt;code&gt;shec&lt;/code&gt;&lt;/a&gt;,
and
&lt;a href="https://docs.ceph.com/docs/master/rados/operations/erasure-code-clay/"&gt;&lt;code&gt;clay&lt;/code&gt;&lt;/a&gt;
plugins. &lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;Thanks to &lt;a href="https://twitter.com/LenzGrimmer"&gt;Lenz Grimmer&lt;/a&gt; for
&lt;a href="https://twitter.com/LenzGrimmer/status/1201418525333700608"&gt;pointing
out&lt;/a&gt;
that the post should make this clear. &lt;a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;If you want to know more about erasure codes and their history,
not limited to their use in Ceph, &lt;a href="https://twitter.com/dabukalam"&gt;Danny
Abukalam&lt;/a&gt; did an &lt;a href="https://youtu.be/aHATgQL18is"&gt;interesting
talk&lt;/a&gt; on the subject at OpenStack
Days Nordic 2019. &lt;a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="hints-and-kinks"></category><category term="Ceph"></category></entry><entry><title>The Little Bag Of Tricks: 10 Things You Might Not Know You Can Do With OpenStack</title><link href="https://xahteiwi.eu/resources/presentations/the-little-bag-of-tricks-10-things-you-might-not-know-you-can-do-with-openstack/" rel="alternate"></link><published>2019-11-05T00:00:00+00:00</published><updated>2019-11-05T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2019-11-05:/resources/presentations/the-little-bag-of-tricks-10-things-you-might-not-know-you-can-do-with-openstack/</id><content type="html">&lt;p&gt;My presentation from the Open Infrastructure Summit 2019 in Shanghai.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;Video: &lt;a href="https://youtu.be/cRqA-eYYOXE"&gt;YouTube&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/openinfrasummit2019-shanghai/"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Use the arrow keys to navigate through the presentation, hit &lt;code&gt;Esc&lt;/code&gt; to
zoom out for an overview, or just advance by hitting the spacebar.&lt;/p&gt;</content><category term="presentations"></category><category term="Conference"></category><category term="OpenStack"></category></entry><entry><title>Using ftrace to trace function calls from qemu-guest-agent</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/ftrace-qemu-ga/" rel="alternate"></link><published>2019-08-21T00:00:00+00:00</published><updated>2019-08-21T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2019-08-21:/resources/hints-and-kinks/ftrace-qemu-ga/</id><summary type="html">&lt;p&gt;When you are using functionality that is buried deep in the Linux
kernel, &lt;a href="https://en.wikipedia.org/wiki/Ftrace"&gt;&lt;code&gt;ftrace&lt;/code&gt;&lt;/a&gt; can be
extremely useful. Here are some suggestions on how to use it, using
the example of tracing function calls from &lt;code&gt;qemu-guest-agent&lt;/code&gt;.&lt;/p&gt;
&lt;!--break--&gt;
&lt;h2&gt;What’s this about?&lt;/h2&gt;
&lt;p&gt;Recently I used, for the first time,
&lt;strong&gt;&lt;a href="https://libvirt.org/"&gt;libvirt&lt;/a&gt;’s functionality …&lt;/strong&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;When you are using functionality that is buried deep in the Linux
kernel, &lt;a href="https://en.wikipedia.org/wiki/Ftrace"&gt;&lt;code&gt;ftrace&lt;/code&gt;&lt;/a&gt; can be
extremely useful. Here are some suggestions on how to use it, using
the example of tracing function calls from &lt;code&gt;qemu-guest-agent&lt;/code&gt;.&lt;/p&gt;
&lt;!--break--&gt;
&lt;h2&gt;What’s this about?&lt;/h2&gt;
&lt;p&gt;Recently I used, for the first time,
&lt;strong&gt;&lt;a href="https://libvirt.org/"&gt;libvirt&lt;/a&gt;’s functionality to indicate to a
virtual guest that it is about to have a point-in-time copy of its
disks — a &lt;em&gt;snapshot&lt;/em&gt; — taken.&lt;/strong&gt; In doing so, it can tell the virtual
machine (VM) to freeze I/O on all its mounted filesystems. &lt;/p&gt;
&lt;p&gt;The rationale behind this is, I hope, obvious: you want the VM to
momentarily stop I/O to its virtual disks, so that you can take a
snapshot when no I/O is in-flight, and the snapshot image can thus be
expected to be internally consistent. The snapshot itself will only
take a second or so, and the minor interruption is a small price to
pay for the added consistency guarantee you get.&lt;/p&gt;
&lt;p&gt;You might be wondering how this works and it is, indeed, a bit
involved.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;First, you’ll need a &lt;strong&gt;virtual serial console&lt;/strong&gt; that allows the
  hypervisor (in the host) to communicate with the guest. This will be
  defined &lt;a href="https://wiki.libvirt.org/page/Qemu_guest_agent#Setting_QEMU_GA_up"&gt;in your libvirt domain
  XML&lt;/a&gt;,
  and in &lt;a href="https://docs.openstack.org/nova/latest/"&gt;OpenStack Nova&lt;/a&gt;,
  this automatically pops up if you are booting your instance off an
  image &lt;a href="https://docs.openstack.org/nova/rocky/admin/configuration/hypervisor-kvm.html#guest-agent-support"&gt;which has the &lt;code&gt;hw_qemu_guest_agent=yes&lt;/code&gt; property
  set&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Then, you’ll need a &lt;strong&gt;daemon&lt;/strong&gt; within the guest that listens for
  commands received over the serial port. This daemon is called
  &lt;code&gt;qemu-guest-agent&lt;/code&gt;, or &lt;code&gt;qemu-ga&lt;/code&gt; for short. All you’ll need for it
  to run is to install the package of that name, which you can do in
  various ways (&lt;code&gt;apt-get install qemu-guest-agent&lt;/code&gt; being the simplest,
  on Ubuntu guests).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;One of the many commands that said daemon supports is
  &lt;a href="https://git.qemu.org/?p=qemu.git;a=blob;f=qga/commands-posix.c;h=dfc05f5b8ab958ef43aca36258e151ee2525ebf5;hb=33f18cf7dca7741d3647d514040904ce83edd73d#l2746"&gt;&lt;code&gt;guest-fsfreeze-freeze&lt;/code&gt;&lt;/a&gt;. When
  it receives that command over the virtual serial link, the daemon
  will &lt;a href="https://git.qemu.org/?p=qemu.git;a=blob;f=qga/commands-posix.c;h=dfc05f5b8ab958ef43aca36258e151ee2525ebf5;hb=33f18cf7dca7741d3647d514040904ce83edd73d#l1295"&gt;loop over your mounted
  filesystems&lt;/a&gt;,
  and issue the &lt;a href="https://elixir.bootlin.com/linux/v5.2/source/fs/ioctl.c#L668"&gt;&lt;strong&gt;&lt;code&gt;FIFREEZE&lt;/code&gt;
  ioctl&lt;/strong&gt;&lt;/a&gt;
  on all of them. This happens in reverse order, meaning your root
  (&lt;code&gt;/&lt;/code&gt;) filesystem is frozen last.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;That ioctl then calls the &lt;a href="https://elixir.bootlin.com/linux/v5.2/source/fs/super.c#L1694"&gt;&lt;strong&gt;&lt;code&gt;freeze_super()&lt;/code&gt; kernel
  function&lt;/strong&gt;&lt;/a&gt;,
  which flushes each filesystem’s superblock, blocks (“freezes”) all
  new I/O to the filesystem, and syncs (flushes) all I/O that is
  currently in flight on that filesystem.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The combined net effect of all of the above is that you get a virtual
machine that is temporarily read-only, with pending I/O piling up,
until you are done taking your snapshot. When that happens, there are
a few more actions that happen:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The hypervisor sends the &lt;code&gt;guest-fsfreeze-thaw&lt;/code&gt; command over the
  virtual serial link.  Now, the daemon will &lt;a href="https://git.qemu.org/?p=qemu.git;a=blob;f=qga/commands-posix.c;h=dfc05f5b8ab958ef43aca36258e151ee2525ebf5;hb=33f18cf7dca7741d3647d514040904ce83edd73d#l1374"&gt;loop over all your
  mounted filesystems
  again&lt;/a&gt;,
  and issue the &lt;a href="https://elixir.bootlin.com/linux/v5.2/source/fs/ioctl.c#L672"&gt;&lt;strong&gt;&lt;code&gt;FITHAW&lt;/code&gt;
  ioctl&lt;/strong&gt;&lt;/a&gt;
  on them. This time, it is taking the mounts in forward order,
  thawing the root filesystem first.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;That ioctl then calls the &lt;a href="https://elixir.bootlin.com/linux/v5.2/source/fs/super.c#L1798"&gt;&lt;strong&gt;&lt;code&gt;thaw_super()&lt;/code&gt; kernel
  function&lt;/strong&gt;&lt;/a&gt;,
  which unblocks (“thaws”) all new I/O to the filesystem, and allows
  the VM to continue normal operations.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now there’s a bit of an issue with that. All of the aforementioned
kernel functions only write &lt;code&gt;printk&lt;/code&gt;’s &lt;a href="https://elixir.bootlin.com/linux/v5.2/source/fs/super.c#L1737"&gt;on
error&lt;/a&gt;,
but they don’t tell you when they succeed. So you can try a snapshot,
then type &lt;code&gt;dmesg&lt;/code&gt; in the guest, and you’ll have no way of telling
whether the whole freeze/thaw dance succeeded, or was never even
attempted.&lt;/p&gt;
&lt;p&gt;But fear not, there’s a way that you can trace exactly what the kernel
is doing!&lt;/p&gt;
&lt;h2&gt;tracefs, and configuring &lt;code&gt;ftrace&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;If your guest runs any modern kernel, then chances are that it will,
by default, mount a virtual &lt;strong&gt;tracefs filesystem&lt;/strong&gt; to the
&lt;code&gt;/sys/kernel/debug/tracing&lt;/code&gt; mount point (although as of kernel 4.1,
this is nominally an alias, with &lt;code&gt;/sys/kernel/tracing&lt;/code&gt; being the
canonical mount point). Regardless of its path, tracefs exposes &lt;a href="https://www.kernel.org/doc/Documentation/trace/ftrace.txt"&gt;the
kernel’s &lt;code&gt;ftrace&lt;/code&gt;
functionality&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So the first thing you’ll tell ftrace, in your guest VM, is the
process for which you’ll want to do function tracing. In our case,
that’s your guest’s &lt;code&gt;qemu-ga&lt;/code&gt;. So, you can do:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;pidof qemu-ga &amp;gt; /sys/kernel/debug/tracing/set_ftrace_pid
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, you’ll want to instruct &lt;code&gt;ftrace&lt;/code&gt; to trace kernel function calls:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"function"&lt;/span&gt; &amp;gt; /sys/kernel/debug/tracing/current_tracer
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And, you’ll want to make sure that we don’t trace only function calls
from &lt;code&gt;qemu-ga&lt;/code&gt; itself, but also from its child processes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"function-fork"&lt;/span&gt; &amp;gt; /sys/kernel/debug/tracing/trace_options
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Let’s see what’s happening!&lt;/h2&gt;
&lt;p&gt;Now you have a guest that’s properly instrumented for tracing kernel
function calls that originate with &lt;code&gt;qemu-ga&lt;/code&gt;. So now, go ahead and
take a snapshot. On OpenStack Nova, you’d do that with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;openstack server image create --name &amp;lt;image-name&amp;gt; &amp;lt;instance-name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, shell back into your guest, and interrogate your trace for
&lt;code&gt;ioctl&lt;/code&gt; calls:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;grep -E &lt;span class="s1"&gt;'(freeze|thaw)_super.*ioctl'&lt;/span&gt; /sys/kernel/debug/tracing/trace
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And voilà:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;         &lt;span class="n"&gt;qemu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ga&lt;/span&gt;&lt;span class="m"&gt;-14574&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;001&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;....&lt;/span&gt;   &lt;span class="m"&gt;264.059109&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;freeze_super&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;&lt;span class="n"&gt;do_vfs_ioctl&lt;/span&gt;
         &lt;span class="n"&gt;qemu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ga&lt;/span&gt;&lt;span class="m"&gt;-14574&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;001&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;....&lt;/span&gt;   &lt;span class="m"&gt;265.837955&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;thaw_super&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;&lt;span class="n"&gt;do_vfs_ioctl&lt;/span&gt;
         &lt;span class="n"&gt;qemu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ga&lt;/span&gt;&lt;span class="m"&gt;-14574&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;001&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;....&lt;/span&gt;   &lt;span class="m"&gt;265.855048&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;thaw_super&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;&lt;span class="n"&gt;do_vfs_ioctl&lt;/span&gt;
         &lt;span class="n"&gt;qemu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ga&lt;/span&gt;&lt;span class="m"&gt;-14574&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;001&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;....&lt;/span&gt;   &lt;span class="m"&gt;265.855084&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;thaw_super&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;&lt;span class="n"&gt;do_vfs_ioctl&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So that’s the &lt;code&gt;FIFREEZE&lt;/code&gt; ioctl that maps to &lt;code&gt;freeze_super()&lt;/code&gt;, and the
&lt;code&gt;FITHAW&lt;/code&gt; ioctl that maps to &lt;code&gt;thaw_super()&lt;/code&gt;. And that’s how you know that
your guest is freezing and thawing I/O as you expect it to!&lt;/p&gt;
&lt;h2&gt;Where to go from here&lt;/h2&gt;
&lt;p&gt;Feel free to dig further into your &lt;code&gt;trace&lt;/code&gt; file (&lt;code&gt;cat&lt;/code&gt; or &lt;code&gt;less&lt;/code&gt; will
help), and play with other &lt;code&gt;ftrace&lt;/code&gt; options. There’s a massive amount
of things you can do with it, as &lt;a href="https://www.kernel.org/doc/Documentation/trace/ftrace.txt"&gt;the
documentation&lt;/a&gt;
explains. You’ll probably also find &lt;a href="https://jvns.ca/blog/2017/03/19/getting-started-with-ftrace/"&gt;this blog
post&lt;/a&gt;
from &lt;a href="https://twitter.com/b0rk"&gt;Julia Evans&lt;/a&gt; useful for exploring
&lt;code&gt;ftrace&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Also, thank &lt;a href="https://twitter.com/srostedt"&gt;Steven Rostedt&lt;/a&gt; when you
see him! He is the primary author of the ftrace framework.&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="libvirt"></category><category term="Linux"></category><category term="ftrace"></category><category term="Qemu"></category></entry><entry><title>Learn Complex Skills, From Anywhere: Combining Django, Ansible and OpenStack to teach any tech skill</title><link href="https://xahteiwi.eu/talk-submissions/lca-2019-openedx/" rel="alternate"></link><published>2019-08-12T00:00:00+00:00</published><updated>2019-08-12T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2019-08-12:/talk-submissions/lca-2019-openedx/</id><summary type="html">&lt;p&gt;A talk I submitted to PyCon AU 2018, linux.conf.au 2019, and PyCon DE 2019.&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a talk I submitted&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt; to three separate conferences:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://2018.pycon-au.org/"&gt;PyCon AU 2018&lt;/a&gt;, via an anonymized CfP
  process using &lt;a href="https://www.papercall.io/"&gt;PaperCall&lt;/a&gt;. This
  submission was rejected.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://2019.linux.conf.au/"&gt;linux.conf.au 2019&lt;/a&gt;, which used a
  non-anonymized CfP process on a custom platform that, &lt;em&gt;I think,&lt;/em&gt; is
  built on &lt;a href="https://symposion.readthedocs.io/"&gt;Symposion&lt;/a&gt;. That
  submission was accepted, and the talk &lt;a href="https://xahteiwi.eu/resources/presentations/learn-complex-skills-from-anywhere-combining-django-ansible-and-openstack-to-teach-any-tech-skill/"&gt;ran in the main conference
  programme&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://de.pycon.org/"&gt;PyCon DE 2019&lt;/a&gt;, via a non-anonymized CfP
  process using &lt;a href="https://pretalx.com/"&gt;pretalx&lt;/a&gt;. This
  submission was rejected.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It’s the linux.conf.au submission that is reflected in this page.&lt;/p&gt;
&lt;h2&gt;Title&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Learn Complex Skills, From Anywhere: Combining Django, Ansible and
OpenStack to teach any tech skill&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Target Audience&lt;/h2&gt;
&lt;p&gt;Community&lt;/p&gt;
&lt;h2&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;This will appear in the conference programme. Up to about 500
words. This field is rendered with the monospace font Hack with
whitespace preserved&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Professional skill-building is challenging, particularly when the
skill to acquire is about distributed, scalable platform
technology. In this talk, I cover an open-source skill-building
platform that is 100% Python: built on Open edX and heavily involving
Django, Ansible, and OpenStack.&lt;/p&gt;
&lt;p&gt;The information technology industry is currently dealing with an
interesting challenge in professional skill-building: almost every new
technology developed in recent years has been complex, distributed,
and built for scale: Kubernetes, Ceph, and OpenStack can serve as just
a few representative examples. Loose coupling, asynchronicity, and
elasticity are just some of the qualities frequently found in such
systems that were entirely absent in many of the systems we built only
a few years ago. As a result, people comfortable with building and
operating these complex systems are hardly found in abundance, and
organisations frequently struggle to adopt these technologies as a
direct result of this scarcity: we are dealing with a skills gap, not
a technology gap.&lt;/p&gt;
&lt;p&gt;This means that we need novel ways to educate professionals on these
technologies. We must provide professional learners with complex,
distributed systems to use as realistic learning environments, and we
must enable them to learn from anywhere, at any time, and on their own
pace. One excellent way of doing this is to use the capabilities of
the Open edX platform to integrate a learning management system with
hands-on, on-demand lab environments that can be just as complex, and
just as distributed, as production systems. This allows anyone
interested to develop a professional skill set on novel technology at
minimal cost, and without the need for costly hardware platforms for
evaluation.&lt;/p&gt;
&lt;p&gt;In this talk, I will give a rapid technical introduction to the core
components of this free and open source (AGPL 3/ASL 2) all-Python
platform:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;edx-platform, the core learning management system (LMS) and content
  management system (CMS), built on Django;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;edx-configuration, the automated deployment facility to roll out the
  Open edX platform, built on Ansible;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;and finally, the Open edX XBlock extension system and its
  integration with OpenStack, also itself an all-Python cloud
  platform, in order to provide on-demand lab environments from both
  private and public cloud environments.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Private Abstract&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;This will only be shown to organisers and reviewers. You should
provide any details about your proposal that you don't want to be
public here. This field is rendered with the monospace font Hack
with whitespace preserved&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I come from a background in technical consulting and instructor-driven
professional education, and together with my team have been building
and deploying Open edX based platforms as described in the talk
since 2015. I believe I have a good understanding on why
instructor-driven training, while desirable, is not accessible to
everyone in need of keeping abreast with technology development, and
that a self-paced, learn-from-anywhere alternative is needed. I am
extremely grateful for the fact that we have an very well-suited
platform for that purpose, and since it has a completely open-source,
Python codebase, it might be of interest to LCA attendees.&lt;/p&gt;
&lt;p&gt;I have done a talk on a similar topic at the LCA 2018 Education
miniconf (video link included below). In the 2018 talk, I focused
primarily on the educational aspects of self-paced, on-line
training. This time, and I think more appropriately for the main
conference track, I would like to dive into the nuts and bolts of the
platform that drives this. As such, the talk should still be appealing
to people engaged in professional education (be it as learners,
tutors, or instructional designers), but will also be insightful to
Python and OpenStack developers, and heavy Ansible users.&lt;/p&gt;
&lt;h2&gt;Video URL&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=E8BhTAjMwa4"&gt;https://www.youtube.com/watch?v=E8BhTAjMwa4&lt;/a&gt; &lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;If you’re curious why this is here, please read
&lt;a href="https://xahteiwi.eu/blog/2019/04/23/talk-submissions/"&gt;this&lt;/a&gt;. &lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="talk-submissions"></category><category term="Conference"></category></entry><entry><title>Team meetings</title><link href="https://xahteiwi.eu/blog/2019/06/06/team-meetings/" rel="alternate"></link><published>2019-06-06T00:00:00+00:00</published><updated>2019-06-06T00:00:00+00:00</updated><author><name>florian</name></author><id>tag:xahteiwi.eu,2019-06-06:/blog/2019/06/06/team-meetings/</id><summary type="html">&lt;p&gt;Distributed teams need to meet in person every once in a while. Here are some thoughts and suggestions on team meetings.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I’ve run a distributed team — nominally the same team, though through
people joining and leaving I am the sole original band member at this
point — for almost 8 years. And about 3 years in was the first time we
were sufficiently spread &lt;em&gt;and&lt;/em&gt; had enough money to spare to warrant
flying everyone to the same place for one week per year. We have been
doing that ever since. Every year, it’s an exceedingly enlightening
and pleasant experience.&lt;/p&gt;
&lt;p&gt;And this year was the first time that we did not one but &lt;strong&gt;two&lt;/strong&gt; team
meetings back to back: first with my core team running education
services at City Network, in the
&lt;a href="https://en.wikipedia.org/wiki/Hellerup"&gt;Hellerup&lt;/a&gt; neighborhood in
&lt;a href="https://en.wikipedia.org/wiki/Copenhagen"&gt;Copenhagen&lt;/a&gt;, and then as
part of the complete City Network all-hands meeting on the island of
Tjärö in the &lt;a href="https://en.wikipedia.org/wiki/Blekinge_archipelago"&gt;Blekinge
archipelago&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So here is how we do these things.&lt;/p&gt;
&lt;h2&gt;Accommodation&lt;/h2&gt;
&lt;p&gt;Except for the very first team meeting we did in 2014 when we put
everyone up in hotel rooms, we’ve always rented a house. I’m a
believer in small team sizes — 5 people being the maximum number of
direct reports a leader can realistically have —, so that means that
we &lt;em&gt;can&lt;/em&gt; still find houses where everyone has a room to themselves,
and nobody has to queue for a shower.&lt;/p&gt;
&lt;p&gt;I consider both of these things extremely important. Many, many people
working in tech are introverts, even more so for people working &lt;em&gt;from
home&lt;/em&gt; in tech. Many of us find the experience of constantly being
around people emotionally draining, and we need solitude to
recharge. Also, privacy. Our personal lives don’t stop while we’re
having a team meeting, so you might want to have a room in which you
can talk about your kid’s health issue with your spouse, without
concern about colleagues overhearing the conversation.&lt;/p&gt;
&lt;p&gt;Price-wise, since this puts us in an accommodation category that can
qualify as a penthouse or mansion, this won’t be significantly cheaper
than hotel accommodation — but it won’t be &lt;em&gt;more&lt;/em&gt; expensive either,
and it’ll be a much nicer experience. Particularly if you also have
the joy of interacting with an exceedingly pleasant, nice, and helpful
person for a host.&lt;/p&gt;
&lt;p&gt;As for &lt;em&gt;who&lt;/em&gt; scouts the accommodation, my rule has always been this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;In case we have a person on the team who lives, or has lived, in the
  city we’re going to, and who thus is very familiar with the locality
  and surroundings, I delegate the search to them. You can never beat
  local personal experience.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Otherwise, I do the scouting on the web, and I usually run it by the
  team — after I have made the booking, but while we can still cancel
  or change.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Arrival&lt;/h2&gt;
&lt;p&gt;Whoever did the scouting for the accommodation travels a day
early, gets the key, settles in, and reports back. This has multiple
purposes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If they are local and so is the host, &lt;em&gt;of course&lt;/em&gt; that’ll facilitate
  matters a lot. Particularly if we’re in a country where that one
  team member speaks the language, and the rest of us don’t.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If there’s something seriously wrong with the property, they can
  still cry foul and we can make other arrangements while we’re not
  all congregated in the same spot. (This has never happened to us,
  but just in case.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;That person is our support backstop who can field issues and
  customer questions, while everyone else is in the air.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;That person can also meet and collect people at the airport or train
  station, if getting to our accommodation is nontrivial or
  difficult. Also, this is particularly helpful when we have a new
  team member who is perhaps less travel experienced.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;First day&lt;/h2&gt;
&lt;p&gt;I normally don’t schedule any formal work sessions for the first
day. People will be jet-lagged and fatigued from travel, we are often
re-meeting in person for the first time in a year, and there is a lot
of catching up to do about family, hobbies, recent travel, and all
sorts of things that are not work. Somebody might be new and we might
see them for the first time ever, in person.&lt;/p&gt;
&lt;p&gt;And then of course people might be delayed in travel, may have had
flights cancelled, or may have missed connections. So that means if
you’re actually &lt;em&gt;planning&lt;/em&gt; the first day to be full of “work”
sessions, you ran a significant chance of your schedule getting
wrecked by a flight delay. So we just don’t do that. Instead, we try
to make the first day as relaxed and as enjoyable as possible,
including a nice first group dinner.&lt;/p&gt;
&lt;p&gt;And then sometimes, as happened this year, a &lt;em&gt;remarkably&lt;/em&gt; serious and
productive discussion over work issues ensues over a glass of wine in
the evening. But that’s not part of the expectation.&lt;/p&gt;
&lt;h2&gt;Work sessions&lt;/h2&gt;
&lt;p&gt;We tend to have half-day work sessions these days, where we focus on
one topic for 3-4 hours straight. These can get intense, and sometimes
heated, but they are nearly always very, very productive.&lt;/p&gt;
&lt;p&gt;We typically use a place like our house’s kitchen (if it’s roomy, and
has a table), or patio (if it’s bearable outside), or sitting room (if
it’s cozy) for work sessions. They are usually quite analog, with
frequently just one person — the assigned record-keeper, often me —
with a laptop open to take notes and record the discussion and its
outcomes. I’ve found that on occasion, when discussing complex issues,
working with a roll of brown paper and thick felt-tip markers
(“sharpies” for you Americans out there) can be &lt;em&gt;much&lt;/em&gt; more useful
than with anything pushing bits.&lt;/p&gt;
&lt;h2&gt;Food&lt;/h2&gt;
&lt;p&gt;I enjoy food, and I’ve never worked with anyone who doesn’t. So we
make that part enjoyable in whatever way we fancy. We might go for
lunch to the neighborhood bagel store that our host recommended for
their excellent pastrami. We might jump on a train to get to a street
food spot, or head out for pizza or tacos or curry.&lt;/p&gt;
&lt;p&gt;And I’m buying. These meetings are for work, my team is traveling for
just that purpose, so whenever we eat together (and we practically
always do), the tab is on me. What I can put on the company and what
comes out of my own pocket is my job to sort out later, but we’re
definitely not going Dutch.&lt;/p&gt;
&lt;h2&gt;Interesting things&lt;/h2&gt;
&lt;p&gt;Our meetings are usually in an interesting city with art,
architecture, and history, and not seeing any of that would be a bit
of a waste. So there’s usually maybe two to three things that we just
go and do. It could be a harbor or river cruise, a visit to a castle
or palace, a bicycle tour criss-crossing the city, or a museum
visit. Depends a bit on the weather and a bit on individual interest.&lt;/p&gt;
&lt;h2&gt;Epilogue: going larger&lt;/h2&gt;
&lt;p&gt;So what works for a 5-person team clearly doesn’t work for a whole
company, not least because you’ll be hard pressed to find a rental
home with 40 bedrooms — I guess such a dwelling would be appropriately
referred to as a palace, and last I checked the Queen wasn’t on
Airbnb.&lt;/p&gt;
&lt;p&gt;But you can take a page out of City Network’s playbook and do
something else, which is to book an island. Yes, you read that right,
immediately after our &lt;em&gt;team&lt;/em&gt; meeting we packed up and boarded a train
to join our &lt;em&gt;company&lt;/em&gt; all-hands meeting, in which we had an island
practically to ourselves. &lt;/p&gt;</content><category term="blog"></category><category term="Philosophy"></category></entry><entry><title>Learn Ceph — For Fun, For Real, For Free!</title><link href="https://xahteiwi.eu/resources/presentations/learn-ceph-for-fun-for-real-for-free/" rel="alternate"></link><published>2019-05-25T00:00:00+00:00</published><updated>2019-05-25T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2019-05-25:/resources/presentations/learn-ceph-for-fun-for-real-for-free/</id><content type="html">&lt;p&gt;My lightning talk from Cephalocon 2019.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;Video:
  &lt;a href="https://youtu.be/oEKJnHAfSiw"&gt;YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="presentations"></category><category term="Conference"></category><category term="Ceph"></category><category term="Open edX"></category></entry><entry><title>Geographical Redundancy with rbd-mirror</title><link href="https://xahteiwi.eu/resources/presentations/geographical-redundancy-with-rbd-mirror/" rel="alternate"></link><published>2019-05-21T00:00:00+00:00</published><updated>2019-05-21T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2019-05-21:/resources/presentations/geographical-redundancy-with-rbd-mirror/</id><content type="html">&lt;p&gt;My presentation from Cephalocon 2019.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Video:
  &lt;a href="https://youtu.be/ZifNGprBUTA"&gt;YouTube&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Slides (with full speaker notes):
  &lt;a href="https://fghaas.github.io/cephalocon2019-rbdmirror/#intro"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Use the &lt;code&gt;PgUp&lt;/code&gt;/&lt;code&gt;PgDown&lt;/code&gt; keys to navigate through the presentation, hit
&lt;code&gt;Esc&lt;/code&gt; to zoom out for an overview, or just advance by hitting the
spacebar.&lt;/p&gt;</content><category term="presentations"></category><category term="Conference"></category><category term="Ceph"></category></entry><entry><title>I Don’t Think This Means What You Think It Means: Red Herrings in OpenStack</title><link href="https://xahteiwi.eu/talk-submissions/oidn-2019-red-herrings/" rel="alternate"></link><published>2019-05-08T00:00:00+00:00</published><updated>2019-05-08T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2019-05-08:/talk-submissions/oidn-2019-red-herrings/</id><summary type="html">&lt;p&gt;A talk I submitted to OpenInfra Days Nordics 2019.&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a talk I proposed&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt; for &lt;a href="https://openinfranordics.com/"&gt;OpenInfra Days
Nordics&lt;/a&gt;, via a non-anonymized CfP
process using &lt;a href="https://www.papercall.io/"&gt;PaperCall&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Title&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;I Don’t Think This Means What You Think It Means: Red Herrings in
OpenStack&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Elevator Pitch&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;You have 300 characters to sell your talk. This is known as the
"elevator pitch". Make it as exciting and enticing as possible.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;OpenStack’s complexity comes with operational challenges. And in
situations where OpenStack misbehaves, it is frequently non-trivial to
find the actual cause of an issue. This talk includes several examples
of red herrings in OpenStack, and suggestions for spotting
and avoiding them.&lt;/p&gt;
&lt;h2&gt;Talk Format&lt;/h2&gt;
&lt;p&gt;Talk (&amp;gt;30-45 minutes)&lt;/p&gt;
&lt;h2&gt;Audience Level&lt;/h2&gt;
&lt;p&gt;All&lt;/p&gt;
&lt;h2&gt;Description&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;This field supports Markdown. The description will be seen by
reviewers during the CFP process and may eventually be seen by the
attendees of the event.&lt;/p&gt;
&lt;p&gt;You should make the description of your talk as compelling and
exciting as possible. Remember, you're selling both the organizers
of the events to select your talk, as well as trying to convince
attendees your talk is the one they should see.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;When working with OpenStack, you deal with an environment that is
inherently complex. As with all complex environments, things sometimes
go wrong or behave unexpectedly. And when &lt;em&gt;that&lt;/em&gt; happens, your
immediate goal is to locate, pinpoint, and then troubleshoot the
issue.&lt;/p&gt;
&lt;p&gt;And then, sometimes, you go down the dead-wrong path, and end up
chasing a red herring for some time, before you find the real
problem. This talk contains examples of such red herrings, enabling
you to recognize and avoid them.&lt;/p&gt;
&lt;p&gt;This talk is both for those who &lt;em&gt;run&lt;/em&gt; an OpenStack cloud, and those
who &lt;em&gt;consume&lt;/em&gt; its functionality as a service. It talks about both red
herrings in OpenStack operations, and red herrings in operating
applications &lt;em&gt;on&lt;/em&gt;  OpenStack. &lt;/p&gt;
&lt;h2&gt;Notes&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;This field supports Markdown. Notes will only be seen by reviewers
during the CFP process. This is where you should explain things such
as technical requirements, why you're the best person to speak on
this subject, etc...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I’ve been working on OpenStack since 2012, have consulted on lots of
private and public cloud deployments using OpenStack, and I work for
the operator of a multi-region global OpenStack Cloud. “I've seen
things you people wouldn't believe. Attack ships on fire off the
shoulder of Orion...”&lt;/p&gt;
&lt;p&gt;In addition to what &lt;strong&gt;I&lt;/strong&gt; have seen, others have seen other things,
which is why I am crowdsourcing the content of this talk. That being
so, the talk proposal &lt;a href="https://xahteiwi.eu/talk-submissions/oidn-2019-red-herrings/"&gt;is
public&lt;/a&gt;,
and I am asking people &lt;a href="https://twitter.com/xahteiwi/status/1126030330937380864"&gt;on
Twitter&lt;/a&gt; to
send me their stories, which I will add to and mix with my own, with
due attribution.&lt;/p&gt;
&lt;p&gt;Just to give one example of what I would like to cover, see &lt;a href="https://xahteiwi.eu/resources/hints-and-kinks/1000-routers-per-tenant-think-again/"&gt;this
article&lt;/a&gt;
on my web site, which talks about how you can run into what looks like
a quota issue in Neutron, but whose cause is in fact buried deep in
&lt;a href="https://tools.ietf.org/html/rfc5798"&gt;RFC 5798&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Tags&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Tag your talk to make it easier for event organizers to be able to
find. Examples are "ruby, javascript, rails".&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;OpenStack, Operations&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;If you’re curious why this is here, please read
&lt;a href="https://xahteiwi.eu/blog/2019/04/23/talk-submissions/"&gt;this&lt;/a&gt;. &lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="talk-submissions"></category><category term="Conference"></category><category term="OpenStack"></category></entry><entry><title>One For All: Using Terraform to manage OpenStack and Kubernetes resources</title><link href="https://xahteiwi.eu/talk-submissions/oidn-2019-terraform/" rel="alternate"></link><published>2019-05-07T00:00:00+00:00</published><updated>2019-05-07T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2019-05-07:/talk-submissions/oidn-2019-terraform/</id><summary type="html">&lt;p&gt;A workshop I submitted to Open Infra Days Nordics 2019.&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a workshop I proposed&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt; for &lt;a href="https://openinfranordics.com/"&gt;OpenInfra Days
Nordics&lt;/a&gt;, via a non-anonymized CfP
process using &lt;a href="https://www.papercall.io/"&gt;PaperCall&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Title&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;One For All: Using Terraform to manage OpenStack and Kubernetes
resources&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Elevator Pitch&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;You have 300 characters to sell your talk. This is known as the
"elevator pitch". Make it as exciting and enticing as possible.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A hands-on introduction to Terraform in an OpenStack and Kubernetes
context. Get the basics (of Terraform), then spin up a Kubernetes
cluster in an OpenStack public cloud (with Terraform), and manage
resources on it (with Terraform).&lt;/p&gt;
&lt;h2&gt;Talk Format&lt;/h2&gt;
&lt;p&gt;Workshop (&amp;gt;60 minutes)&lt;/p&gt;
&lt;h2&gt;Audience Level&lt;/h2&gt;
&lt;p&gt;Intermediate&lt;/p&gt;
&lt;h2&gt;Description&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;This field supports Markdown. The description will be seen by
reviewers during the CFP process and may eventually be seen by the
attendees of the event.&lt;/p&gt;
&lt;p&gt;You should make the description of your talk as compelling and
exciting as possible. Remember, you're selling both the organizers
of the events to select your talk, as well as trying to convince
attendees your talk is the one they should see.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If you are interested in deployment automation for arbitrarily complex
containerized microservice applications, this is for you!&lt;/p&gt;
&lt;p&gt;In this workshop, you will&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;get to know the basics of &lt;a href="https://www.terraform.io/"&gt;Terraform&lt;/a&gt; and
  &lt;a href="https://www.terraform.io/docs/configuration/"&gt;Terraform
  configurations&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;spin up a Kubernetes cluster with Terraform, using the &lt;a href="https://www.terraform.io/docs/providers/openstack/"&gt;OpenStack
  provider&lt;/a&gt; and
  interfacing with &lt;a href="https://docs.openstack.org/magnum/latest/user/"&gt;OpenStack
  Magnum&lt;/a&gt; in a public
  cloud,&lt;/li&gt;
&lt;li&gt;start managing Kubernetes resources from Terraform, using the
  &lt;a href="https://www.terraform.io/docs/providers/kubernetes/"&gt;Kubernetes
  provider&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You'll walk away with a solid understanding of Terraform's
capabilities, enabling you to make an informed decision of whether
Terraform is a suitable deployment automation facility for your
organization's needs.&lt;/p&gt;
&lt;p&gt;Prior Terraform knowledge is not required.&lt;/p&gt;
&lt;h2&gt;Notes&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;This field supports Markdown. Notes will only be seen by reviewers
during the CFP process. This is where you should explain things such
as technical requirements, why you're the best person to speak on
this subject, etc...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;There are no technical requirements other than internet connectivity,
and a web browser (preferably on a laptop, though a reasonably-sized
tablet with a modern browser should work as well).&lt;/p&gt;
&lt;h2&gt;Tags&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Tag your talk to make it easier for event organizers to be able to
find. Examples are "ruby, javascript, rails".&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Terraform, OpenStack, Kubernetes, Magnum&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;If you’re curious why this is here, please read
&lt;a href="https://xahteiwi.eu/blog/2019/04/23/talk-submissions/"&gt;this&lt;/a&gt;. &lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="talk-submissions"></category><category term="Conference"></category><category term="Terraform"></category><category term="OpenStack"></category><category term="Kubernetes"></category></entry><entry><title>Configuring CLI output verbosity with logging and argparse</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/python-cli-logging-options/" rel="alternate"></link><published>2019-05-01T00:00:00+00:00</published><updated>2019-05-01T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2019-05-01:/resources/hints-and-kinks/python-cli-logging-options/</id><summary type="html">&lt;p&gt;Command-line interfaces frequently produce output whose verbosity your users may want to be able to tweak. Here’s a nifty way to do that.&lt;/p&gt;</summary><content type="html">&lt;p&gt;In a Python command-line interface (CLI) utility, you will want to
inform your users about what your program is doing. Your will also
want to give your users the ability to tweak how verbose that output
is. Now there is a de-facto standard convention for doing that, which
most CLIs — Python or otherwise — tend to adhere to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;By default, show messages only about errors and warning conditions.&lt;/li&gt;
&lt;li&gt;Define a &lt;code&gt;-v&lt;/code&gt; or &lt;code&gt;--verbose&lt;/code&gt; option that makes your program also
  show messages that are merely informative in nature.&lt;/li&gt;
&lt;li&gt;Optionally, allow users to repeat the &lt;code&gt;-v&lt;/code&gt; option, making the
  program even more verbose (to include, for example, debug output).&lt;/li&gt;
&lt;li&gt;Conversely, also define a &lt;code&gt;-q&lt;/code&gt; or &lt;code&gt;--quiet&lt;/code&gt; (alternatively
  &lt;code&gt;-s&lt;/code&gt;/&lt;code&gt;--silent&lt;/code&gt;) option that, when set, makes the program suppress
  warnings and show only errors — i.e. the stuff that your program
  shows if it exits with a nonzero exit code.&lt;/li&gt;
&lt;li&gt;Log output that tells users about what the program is doing, as it
  goes along, to the standard error (stderr) stream, whereas the
  output related to the program’s &lt;em&gt;results&lt;/em&gt; goes to standard output
  (stdout). This gives your users the ability to pipe stdout to a file
  or another program, and your progress or status messages won’t
  interfere with that.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And in Python it’s not at all difficult to do that!&lt;/p&gt;
&lt;h2&gt;&lt;code&gt;argparse&lt;/code&gt; options&lt;/h2&gt;
&lt;p&gt;First, we’ll want to define a couple of options &lt;a href="https://docs.python.org/3/library/argparse.html"&gt;for our
&lt;code&gt;argparse.ArgumentParser&lt;/code&gt;
object&lt;/a&gt;, which in the
following snippet I’ve named &lt;code&gt;parser&lt;/code&gt;. Define two options, like so:&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'-v'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'--verbose'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'count'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="n"&gt;dest&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'verbosity'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"verbose output (repeat for increased verbosity)"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'-q'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'--quiet'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'store_const'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="n"&gt;const&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="n"&gt;dest&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'verbosity'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="n"&gt;help&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"quiet output (show errors only)"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;From this, we get two command-line options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;-v&lt;/code&gt; or &lt;code&gt;--verbose&lt;/code&gt;, which can be repeated, sets &lt;code&gt;verbosity&lt;/code&gt;, which
  defaults to 0. &lt;code&gt;action='count'&lt;/code&gt; means that if you invoke your CLI
  with &lt;code&gt;-v&lt;/code&gt;, &lt;code&gt;verbosity&lt;/code&gt; is 1, &lt;code&gt;-vv&lt;/code&gt; sets &lt;code&gt;verbosity&lt;/code&gt; to 2, etc.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;-q&lt;/code&gt; or &lt;code&gt;--quiet&lt;/code&gt; &lt;em&gt;also&lt;/em&gt; sets &lt;code&gt;verbosity&lt;/code&gt;, but to a constant value,
  -1, via &lt;code&gt;store_const&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Setting up the &lt;code&gt;logging&lt;/code&gt; subsystem&lt;/h2&gt;
&lt;p&gt;What we’ll want to do is use &lt;a href="https://docs.python.org/3/library/logging.html"&gt;the &lt;code&gt;logging&lt;/code&gt;
subsystem&lt;/a&gt; to send our
status, progress, and error messages to stderr.&lt;/p&gt;
&lt;p&gt;First, you can translate &lt;code&gt;verbosity&lt;/code&gt; into a logging level understood
by the &lt;code&gt;logging&lt;/code&gt; module. Here’s a little convenience method that
achieves that:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;setup_logging&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;verbosity&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;base_loglevel&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;30&lt;/span&gt;
    &lt;span class="n"&gt;verbosity&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;verbosity&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;loglevel&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;base_loglevel&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;verbosity&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;basicConfig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;loglevel&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="si"&gt;%(message)s&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now what does this do? Python log levels go from 10 (&lt;code&gt;logging.DEBUG&lt;/code&gt;)
to 50 (&lt;code&gt;logging.CRITICAL&lt;/code&gt;) in intervals of 10; our &lt;code&gt;verbosity&lt;/code&gt;
argument goes from -1 (&lt;code&gt;-q&lt;/code&gt;) to 2 (&lt;code&gt;-vv&lt;/code&gt;).&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt; We never want to
suppress error and critical messages, and default to 30
(&lt;code&gt;logging.WARNING&lt;/code&gt;). So we multiply &lt;code&gt;verbosity&lt;/code&gt; by 10, and subtract
that from our base loglevel of 30.&lt;/p&gt;
&lt;p&gt;With &lt;code&gt;-v&lt;/code&gt;, that sets our effective log level to 20 (&lt;code&gt;logging.INFO&lt;/code&gt;);
with &lt;code&gt;-vv&lt;/code&gt;, to 10 (&lt;code&gt;logging.DEBUG&lt;/code&gt;). And with &lt;code&gt;-q&lt;/code&gt;
(i.e. &lt;code&gt;verbosity==-1&lt;/code&gt;), our log level becomes 40 (&lt;code&gt;logging.ERROR&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Now we can use &lt;code&gt;logging.basicConfig()&lt;/code&gt; to configure the logging
subsystem to send unadorned log messages with the desired loglevel or
above, to stderr: &lt;code&gt;basicConfig()&lt;/code&gt;, &lt;a href="https://docs.python.org/3/library/logging.html#logging.basicConfig"&gt;by
default&lt;/a&gt;,
sets up a &lt;code&gt;StreamHandler&lt;/code&gt; whose output stream is &lt;code&gt;sys.stderr&lt;/code&gt;, so it
already does what we want here. And setting &lt;code&gt;format='%(message)s'&lt;/code&gt;
strips the &lt;code&gt;LEVEL:logger:&lt;/code&gt; prefix that &lt;code&gt;basicConfig()&lt;/code&gt; would otherwise
include in the log line (and which is helpful for log files, but not
so much for CLI output).&lt;/p&gt;
&lt;p&gt;From then on, every time your program should write an informational
message to stderr, you just use &lt;code&gt;logging.info()&lt;/code&gt;, for a debug message,
&lt;code&gt;logging.debug()&lt;/code&gt;, and so on.&lt;/p&gt;
&lt;h2&gt;Adding an environment variable&lt;/h2&gt;
&lt;p&gt;In some circumstances you might &lt;em&gt;always&lt;/em&gt; want debug output, and
invoking your CLI with &lt;code&gt;-vv&lt;/code&gt; all the time might not be practical. (CI
systems are an example — you generally want your build logs as verbose
as possible.) You can make your users’ lives easier by optionally
fixing up your logging subsystem with an environment variable, like so:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;setup_logging&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;verbosity&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;base_loglevel&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getenv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'LOGLEVEL'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; 
    &lt;span class="n"&gt;verbosity&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;verbosity&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;loglevel&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;base_loglevel&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;verbosity&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;basicConfig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;loglevel&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="si"&gt;%(message)s&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This way, if you invoke your CLI with &lt;code&gt;LOGLEVEL=10&lt;/code&gt; in its
environment, it will always use debug output. &lt;/p&gt;
&lt;p&gt;Perhaps you’d like to make this even easier, allowing your users to
also set &lt;code&gt;LOGLEVEL&lt;/code&gt; to &lt;code&gt;debug&lt;/code&gt;, &lt;code&gt;INFO&lt;/code&gt;, &lt;code&gt;erRoR&lt;/code&gt; and whatever
else. That you could do like this:&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;setup_logging&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;verbosity&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;base_loglevel&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gettattr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                             &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getenv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'LOGLEVEL'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'WARNING'&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;upper&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt; 
    &lt;span class="n"&gt;verbosity&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;min&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;verbosity&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;loglevel&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;base_loglevel&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;verbosity&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;basicConfig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;loglevel&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="si"&gt;%(message)s&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Parting thought&lt;/h2&gt;
&lt;p&gt;One of the many ways in which using &lt;code&gt;logging&lt;/code&gt; comes in handy in a CLI
is in a catch-all exception handler:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'__main__'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;Exception&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;''&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;exc_info&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;errno&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;AttributeError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This way, unhandled exceptions will show merely the exception message
by default, but if and only if debug logging is enabled, your users
will also see a stack trace.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;This is used
&lt;a href="https://github.com/hastexo/olx-utils/blob/v0.3.0/olxutils/cli.py#L53"&gt;here&lt;/a&gt;. &lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;There is, to the best of my knowledge, no way to limit the
number of repeats for an argument with &lt;code&gt;action='count'&lt;/code&gt;. Hence the
construct with the &lt;code&gt;min()&lt;/code&gt; built-in function. &lt;a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;A variation of this is used
&lt;a href="https://github.com/hastexo/olx-utils/blob/v0.3.0/olxutils/cli.py#L284"&gt;here&lt;/a&gt;. &lt;a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="hints-and-kinks"></category><category term="Python"></category></entry><entry><title>Nonexisticon</title><link href="https://xahteiwi.eu/blog/2019/04/27/nonexisticon/" rel="alternate"></link><published>2019-04-27T00:00:00+00:00</published><updated>2019-04-27T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2019-04-27:/blog/2019/04/27/nonexisticon/</id><summary type="html">&lt;p&gt;I have no experience with, and presently no plans for, running or
organizing a grassroots knowledge-sharing conference. But if I did run
one, and I could shape it exactly as I wanted, this might be what it
would look like. Please be advised that I have no idea what I …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I have no experience with, and presently no plans for, running or
organizing a grassroots knowledge-sharing conference. But if I did run
one, and I could shape it exactly as I wanted, this might be what it
would look like. Please be advised that I have no idea what I am
talking about.&lt;/p&gt;
&lt;!--break--&gt;
&lt;p&gt;Let’s talk about Nonexisticon, the non-existent conference. Just to
benefit your reading flow, dear reader, I am using the indicative
rather than the subjunctive mood, in other words, I use phrases like
“Nonexisticon &lt;em&gt;is&lt;/em&gt;” as opposed to “Nonexisticon &lt;em&gt;would be&lt;/em&gt;”&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt;. I
trust that you are not confused by this, as the name very clearly
implies that the conference does not exist.&lt;/p&gt;
&lt;h2&gt;Unifying Theme&lt;/h2&gt;
&lt;p&gt;Nonexisticon’s theme is freely shared knowledge work. &lt;strong&gt;Nonexisticon
brings together open-data researchers, open-source software and
hardware engineers and designers, Creative Commoners, documentarians,
writers, artists, educators.&lt;/strong&gt; Basically, if you create something with
your mind and you make your creation freely available for anyone to
use, enhance, modify and build upon, you’re welcome at
Nonexisticon.&lt;/p&gt;
&lt;p&gt;Nonexisticon is also a mutually supportive conference, where
corporate-funded or financially secure attendees can commit to
supporting less-privileged ones.&lt;/p&gt;
&lt;h2&gt;Location and Reach&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Nonexisticon is a regional conference.&lt;/strong&gt; “Region” in this context
means an area from which the conference attendees can reasonably
travel to the conference location, using environmentally friendly
transportation modes (such as high-speed rail). Attendance from
outside the region is welcome, but for environmental reasons it is not
encouraged.&lt;/p&gt;
&lt;p&gt;Nonexisticon is typically held on a university campus, or other
suitable facility, in a location well accessible by public
transportation. Cheap accommodation is typically available on-campus.&lt;/p&gt;
&lt;h2&gt;Supporting Organization&lt;/h2&gt;
&lt;p&gt;Nonexisticon is organized by the Nonexisticon Association, a
not-for-profit organization that allows only individual, not corporate
membership. The organization is staffed by volunteers, that is to say,
while it is authorized to reimburse members of the conference team for
expenses incurred and income lost as a direct result of conference
work, it does not pay salaries to its staff.&lt;/p&gt;
&lt;p&gt;Nonexisticon registration includes membership in this organization,
with full voting rights, for a period of two years.&lt;/p&gt;
&lt;h2&gt;Recurrence and Length&lt;/h2&gt;
&lt;p&gt;Any regional Nonexisticon has its own recurrence schedule, but the
conference is never held in the same region more than &lt;strong&gt;once per
year.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Each Nonexisticon has a general theme. Themes can be quite diverse and
are generally broadly defined, so as to attract individuals from many
disciplines and backgrounds (as long as they relate to the unifying
theme of freely shared knowledge work). Examples for conference themes
are “cancer research”, “the Python programming language”, “high-energy
physics”, or “the arts in education.”&lt;/p&gt;
&lt;h2&gt;Conference Committee&lt;/h2&gt;
&lt;p&gt;Nonexisticon is run by a Conference Committee, which is a &lt;strong&gt;group of 5
individuals headed by a Conference Director.&lt;/strong&gt; The Conference
Committee serves for the run-up, duration, and wind-down of one
Nonexisticon, oversees the appointment of the succeeding Committee,
and acts as advisors to the incoming Committee.&lt;/p&gt;
&lt;p&gt;Would-be Conference Committees prepare a bid for the next
Nonexisticon. Bids specify the conference location, dates, venue,
capacity, theme, proposed sponsorship opportunities, and budget. If a
bid is uncontested, the prior Conference Committee merely assesses the
bid for plausibility and compliance with formal criteria, and accepts
the bid (thereby also appointing the new Conference Committee). If
more than one bid exists, the outgoing Conference Committee organizes
an on-line vote among the Association membership, using a preferential
voting system. The winning bid then results in the appointment of the
new Conference Committee.&lt;/p&gt;
&lt;h2&gt;Presentations&lt;/h2&gt;
&lt;p&gt;Nonexisticon is a &lt;strong&gt;single-track conference, with one presentation
slot length available: 30 minutes.&lt;/strong&gt; Nonexisticon typically runs over
the course of &lt;strong&gt;three days,&lt;/strong&gt; with talks scheduled between 09:00 (9am)
and 18:00 (6pm) local time.&lt;/p&gt;
&lt;p&gt;This means that after deducting conference opening and closing
remarks, keynotes, and breaks, &lt;strong&gt;Nonexisticon has 38 talks&lt;/strong&gt;&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt; in
total.&lt;/p&gt;
&lt;p&gt;Q&amp;amp;A time is at the speaker’s discretion; forgoing Q&amp;amp;A entirely is
acceptable.&lt;/p&gt;
&lt;p&gt;All presentations are &lt;strong&gt;open for rating&lt;/strong&gt; by attendees for a short
time period of 5 minutes prior to, and 15 minutes after scheduled
conclusion.&lt;/p&gt;
&lt;p&gt;Presentations are &lt;strong&gt;recorded&lt;/strong&gt; by a professional A/V team, and
publicly released under a permissive license.&lt;/p&gt;
&lt;h2&gt;Presentation Proposals&lt;/h2&gt;
&lt;p&gt;Nonexisticon uses an &lt;strong&gt;anonymized call for proposals (CFP),&lt;/strong&gt;
conducted online, using an open-source conference platform. The
Conference Committee defines the format of the CFP proper, including
the questions posed at submitters. The Conference Committee reviews
all submitted proposals, anonymized, for formal compliance with the
CFP only.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Nonexisticon attendance &lt;em&gt;requires&lt;/em&gt; the submission of a presentation
proposal.&lt;/strong&gt; Thus, conference registration and presentation submission
are one and the same process. The conference registration fee must be
paid in full at the time of registration/submission.&lt;/p&gt;
&lt;p&gt;Nonexisticon limits proposals to one per speaker/attendee. All
presentations are solo; multi-presenter talks and panel discussions
are not permitted.&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h2&gt;Underprivileged Attendee Fund&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Prospective attendees unable to accommodate the registration fee,
conference travel, or accommodation&lt;/strong&gt; may apply, upon registration, to
the Underprivileged Attendee Fund.&lt;sup id="fnref:4"&gt;&lt;a class="footnote-ref" href="#fn:4"&gt;4&lt;/a&gt;&lt;/sup&gt; If accepted (per decision by the
Conference Committee), the speaker/attendee is invited to attend the
conference free of charge, and their submitted presentation is
included in proposal review.&lt;/p&gt;
&lt;p&gt;The Underprivileged Attendee Fund is endowed by&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;corporate conference sponsorship,&lt;/li&gt;
&lt;li&gt;donations to the Nonexisticon Association,&lt;/li&gt;
&lt;li&gt;profits carried over from prior conferences,&lt;/li&gt;
&lt;li&gt;donations from regular speaker-attendees who voluntarily put up
  double the regular application fee upon their own
  registration/proposal submission.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Review process and talk selection&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Talks are selected by all attendees/speakers&lt;/strong&gt; during a time-limited
selection period using a &lt;a href="http://www.deborda.org/faq/voting-systems/what-is-a-modified-borda-count.html"&gt;modified Borda count
(MBC)&lt;/a&gt;
ranking process, as pioneered by the scientific community &lt;a href="https://arxiv.org/abs/0906.1943"&gt;for
allocating observation time on astronomical
telescopes&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In a nutshell, every attendee is assigned a small, randomly selected
set of proposals (about 10, and excluding their own submission) to
review. They then rank these submissions not in an order of
subjectively “best” to “worst”, but from &lt;em&gt;most beneficial to the overall
attendee community&lt;/em&gt; to &lt;em&gt;least beneficial to the overall attendee
community.&lt;/em&gt; This results in an overall preliminary ranking of
submissions, which is then compared to each attendee’s individual
ranking. A high degree of agreement of an individual attendee’s
ranking with the overall preliminary tally results in additional
points for the attendee’s own proposal; the contrary, in subtracted
points. Ultimately, this produces a final, definitive ranking of all
received proposals.&lt;sup id="fnref:5"&gt;&lt;a class="footnote-ref" href="#fn:5"&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;The entire ranking process is automated using open-source software,
and both the preliminary and the final ranking result are publicized
to all attendees/submitters.&lt;/p&gt;
&lt;p&gt;The submitters of the 48 top-ranked presentations (38 plus 10
backup/waitlist presentations) are refunded their registration fee
upon acceptance.&lt;/p&gt;
&lt;p&gt;If an accepted speaker needs to withdraw their talk, the next-ranked
talk automatically moves up, and the speaker’s registration is
simultaneously canceled.&lt;sup id="fnref:6"&gt;&lt;a class="footnote-ref" href="#fn:6"&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h2&gt;Budget and Sponsoring&lt;/h2&gt;
&lt;p&gt;Nonexisticon’s budget calls for a barebones conference (infrastructure
only, no catering, no childcare) to break even solely on
registration fees equivalent to two-thirds of the venue capacity. In
case of registrations being in excess of this threshold, Nonexisticon
funds childcare, refreshments, and catered lunch, in that order.&lt;sup id="fnref:7"&gt;&lt;a class="footnote-ref" href="#fn:7"&gt;7&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Nonexisticon is open to sponsoring. Sponsoring, however, does not buy
presentation slots, nor does it have any bearing on keynote
selection. Sponsors can choose to contribute to infrastructure,
catering, childcare, the Underprivileged Attendee Fund, and social
events. Of these, social events are the only category open
&lt;em&gt;exclusively&lt;/em&gt; to sponsor funding; Nonexisticon does not spend
registration fee revenue on social events.&lt;/p&gt;
&lt;p&gt;If registrations do not meet the two-thirds threshold, and the budget
shortfall cannot be compensated by sponsor contributions or profits
carried over from prior conferences, the conference is cancelled and
registration fees refunded.&lt;/p&gt;
&lt;h2&gt;Keynotes&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Nonexisticon has one keynote, which opens the conference.&lt;/strong&gt; The
Conference Committee extends the keynote speaker invitation by
consensus.&lt;/p&gt;
&lt;p&gt;The closing “keynote” is a reprise of the highest-rated presentation
in the conference.&lt;/p&gt;
&lt;h2&gt;Conference run-up timeline&lt;/h2&gt;
&lt;p&gt;Nonexisticon’s attendee-visible run-up cycle is 6 months.&lt;/p&gt;
&lt;p&gt;Assuming a Nonexisticon is scheduled to run from May 15-17, the
following schedule applies:&lt;/p&gt;
&lt;table class="table table-striped"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Date&lt;/th&gt;
&lt;th&gt;Time to conference&lt;/th&gt;
&lt;th&gt;Event&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Nov 15&lt;/td&gt;
&lt;td&gt;6 months&lt;/td&gt;
&lt;td&gt;Conference Committee appointed. Date, location, and sponsorship opportunities announced.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Dec 15&lt;/td&gt;
&lt;td&gt;5 months&lt;/td&gt;
&lt;td&gt;Registration period / CFP commences.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Jan 15&lt;/td&gt;
&lt;td&gt;4 months&lt;/td&gt;
&lt;td&gt;Registration period / CFP ends, also first sponsorship commitment deadline.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Jan 22&lt;/td&gt;
&lt;td&gt;3 months, 3 weeks&lt;/td&gt;
&lt;td&gt;Conference go/no-go call, based on registration and committed sponsorship.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Jan 29&lt;/td&gt;
&lt;td&gt;3 months, 2 weeks&lt;/td&gt;
&lt;td&gt;Deadline for rejection of submissions, by the conference committee, on formal grounds. Final decision on Underprivileged Attendee Fund applications. First stage of submission review process (anonymized free-form comments on talk submissions) commences.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Feb 15&lt;/td&gt;
&lt;td&gt;3 months&lt;/td&gt;
&lt;td&gt;First stage of submission review process ends, second stage (randomized-subset review and ranking) commences.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mar 1&lt;/td&gt;
&lt;td&gt;2 months, 2 weeks&lt;/td&gt;
&lt;td&gt;Second stage of review ends, final ranking available. Selected speakers for rank 1-38 in final ranking receive notification of acceptance, as do speakers with submissions ranked 39-48 for waitlist/backup talks.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mar 15&lt;/td&gt;
&lt;td&gt;2 months&lt;/td&gt;
&lt;td&gt;Final conference schedule published. Second and final deadline for sponsorships.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr/&gt;
&lt;h3&gt;Disclaimer and acknowledgments&lt;/h3&gt;
&lt;p&gt;I’d like to reiterate that I have no experience whatsoever in running
or putting on a conference, since the only time I’ve contributed to
them as something other than a mere speaker, I’ve sat on proposal
selection committees. So take all of what I wrote above with a
mountain of salt, and consider it nothing more than semi-elaborate
handwaving full of glaring omissions. But if you do want to give me
some feedback, even it is simply telling me &lt;em&gt;why&lt;/em&gt; my ideas are nuts —
as opposed to just &lt;em&gt;that&lt;/em&gt; they are — I’d be most grateful. Find me on
&lt;a href="https://twitter.com/xahteiwi"&gt;Twitter&lt;/a&gt; or
&lt;a href="https://mastodon.social/@xahteiwi"&gt;Mastodon&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;That said, thanks to &lt;a href="https://tom.eastman.nz/"&gt;Tom Eastman&lt;/a&gt; for
&lt;a href="https://twitter.com/tveastman/status/1121515902833311745"&gt;prompting
me&lt;/a&gt; to put
this in writing, to &lt;a href="https://about.me/michael.merrifield"&gt;Professor Mike
Merrifield&lt;/a&gt; for &lt;a href="https://youtu.be/7c0CoXFApnM"&gt;introducing me
to the MBC approach&lt;/a&gt;, and to &lt;a href="http://www.bradyharan.com/"&gt;Brady
Haran&lt;/a&gt; for making the
&lt;a href="https://www.youtube.com/channel/UCoxcjq-8xIDTYp3uz647V5A"&gt;Numberphile&lt;/a&gt;
YouTube channel where I learned about it.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Dear grammar stickler, I am acutely aware that a phrase
including &lt;em&gt;would + infinitive&lt;/em&gt; is not a &lt;em&gt;true&lt;/em&gt; subjunctive
mood, but the use of a modal verb. Feel free to replace all such
instances with a true subjunctive in your head. &lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;Don’t bother to check the talk arithmetic. It doesn’t matter
whether it’s really 36 talks or 41 or 42. I just picked 38 as a
reasonable, concrete number to work with. &lt;a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;Disallowing multiple submissions from one person, and
presentations with multiple speakers, is a necessary consequence
of the talk selection process. Allowing only one submission per
submitter also has the added benefit that prospective speakers can
focus on one single talk and give the proposal their very best
shot. &lt;a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:4"&gt;
&lt;p&gt;Is there a better name for this? &lt;a class="footnote-backref" href="#fnref:4" title="Jump back to footnote 4 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:5"&gt;
&lt;p&gt;If you find this summary insufficient to explain the process but
also don’t feel like plowing through the paper, here’s &lt;a href="https://youtu.be/7c0CoXFApnM"&gt;a video
explanation&lt;/a&gt;, plus &lt;a href="https://youtu.be/bplncn4xC74"&gt;additional
information&lt;/a&gt;. &lt;a class="footnote-backref" href="#fnref:5" title="Jump back to footnote 5 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:6"&gt;
&lt;p&gt;It is admittedly harsh to only be able to pull out of an
accepted talk by pulling out of the conference altogether. I
consider this a necessary evil to ensure that no
attendee/submitter submit their proposal without genuine intent to
present. &lt;a class="footnote-backref" href="#fnref:6" title="Jump back to footnote 6 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:7"&gt;
&lt;p&gt;Of these, I am most on the fence about childcare. Meaning it
would probably be a good idea to always budget for child-care
cost, even if that means a higher registration fee for everyone,
and thus a slightly elevated risk of conference cancellation. &lt;a class="footnote-backref" href="#fnref:7" title="Jump back to footnote 7 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="blog"></category><category term="Conference"></category></entry><entry><title>No, really, don't chuck everything in Slack: communications for distributed teams</title><link href="https://xahteiwi.eu/talk-submissions/lca-2019-slack/" rel="alternate"></link><published>2019-04-24T00:00:00+00:00</published><updated>2019-04-24T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2019-04-24:/talk-submissions/lca-2019-slack/</id><summary type="html">&lt;p&gt;A talk I submitted to linux.conf.au 2019.&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a talk I submitted&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt; to
&lt;a href="https://linux.conf.au/"&gt;linux.conf.au&lt;/a&gt; 2019. The conference uses a
non-anonymized CfP process on a custom platform that, &lt;em&gt;I think,&lt;/em&gt; is
built on &lt;a href="https://symposion.readthedocs.io/"&gt;Symposion&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This talk was accepted as a &lt;em&gt;standby talk,&lt;/em&gt; meaning it was slated to
fill the gap if any other talk had to be cancelled on short notice. I
did prepare the full talk, though it did not end up presenting it at
the conference.&lt;/p&gt;
&lt;p&gt;I also submitted the talk to &lt;a href="https://2019.djangocon.eu"&gt;DjangoCon Europe
2019&lt;/a&gt;, where it was rejected.&lt;/p&gt;
&lt;h2&gt;Title&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;No, really, don't chuck everything in Slack: communications for
distributed teams&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Target Audience&lt;/h2&gt;
&lt;p&gt;Business&lt;/p&gt;
&lt;h2&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;This will appear in the conference programme. Up to about 500
words. This field is rendered with the monospace font Hack with
whitespace preserved&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is a personal story. It does not claim to be rooted in
statistical analysis or scientific rigour, and the evidence presented
is anecdotal. But it might be insightful to anyone joining, leaving,
or interacting with a remote team.&lt;/p&gt;
&lt;p&gt;From 2011 to 2017, I ran a company that had no office. Everyone worked
from home, and apart from an annual one-week face to face meeting, all
our communications were remote. In 2017, I sold my company and
integrated my team into a company that had previously been working
exclusively out of a single office. As one would expect, the
integration was not without friction (they never are), but what
emerged from the experience was a better understanding of the
challenges that come with a mixed office/remote work environment, and
some rules to address them. In this talk, I'll cover:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Typical misconceptions that remoties have about office-workers, and
  vice versa&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Using the right tools for the right type of communications:
  interactive chat, email, wiki, issue trackers, Kanban boards&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Timezones, and communications around scheduling&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The 5-paragraph format, a simple tool I habitually use to make sure
  everyone is on the same page&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Follow-up and follow-through, and how to make sure neither you, nor
  your team, nor your boss loses sight of what needs doing&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Private Abstract&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;This will only be shown to organisers and reviewers. You should
provide any details about your proposal that you don't want to be
public here. This field is rendered with the monospace font Hack
with whitespace preserved&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It's probably good for me to reiterate that this is not a scientific study. :)&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;If you’re curious why this is here, please read
&lt;a href="https://xahteiwi.eu/blog/2019/04/23/talk-submissions/"&gt;this&lt;/a&gt;. &lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="talk-submissions"></category><category term="Conference"></category></entry><entry><title>Talk submissions</title><link href="https://xahteiwi.eu/blog/2019/04/23/talk-submissions/" rel="alternate"></link><published>2019-04-23T00:00:00+00:00</published><updated>2019-04-23T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2019-04-23:/blog/2019/04/23/talk-submissions/</id><summary type="html">&lt;p&gt;I put talk submissions on this site, regardless of whether they get accepted or not. Here’s why.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I have spoken at tech conferences for the better part of a decade, and
up to this point I have only ever published &lt;a href="/category/presentations.html"&gt;my
talks&lt;/a&gt; after I’ve actually presented
them. I’ll change that from here on out, and I’ll instead record any
talk that I &lt;em&gt;submit&lt;/em&gt; to a conference instead, regardless of whether it
ultimately gets accepted or not. I do this for several reasons.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;I’d like to have a record of my talk submissions for my own
   reference purposes.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It’s rather remarkable how many conference talk submission systems
exist that make it rather difficult to retrieve your submitted
abstract a few months or years after the conference. Some event
websites exist specifically for one instance of a particular
conference, so they might be taken down a few months after, and
unaccepted abstracts are usually not accessible publicly — so even
getting them via the &lt;a href="https://archive.org/"&gt;Internet Archive&lt;/a&gt; is
not an option. Others record talk submissions via Google Forms,
into a private Google Sheet, and don’t send an autoreply
containing the full submission.&lt;/p&gt;
&lt;p&gt;So, I use this site for having my own record of talks I submit.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;I don’t want to reinforce the illusion that just because I’m an
    experienced speaker, all talks I submit anywhere get accepted.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I get talks rejected all the time, &lt;em&gt;particularly&lt;/em&gt; from conferences
I’d &lt;em&gt;really&lt;/em&gt; enjoy speaking at. This is normal, and if any of you
reading this are less experienced and find rejections
discouraging, I want you to know that they happen to all of us.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;I am curious about other people’s thoughts.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As a speaker, it is pretty hard to get good feedback on a talk
submission. Very few conferences send you detailed feedback on
rejected talks. And none at all, to the best of my knowledge, send
you qualitative feedback on &lt;em&gt;accepted&lt;/em&gt; ones (other than “congrats,
you’re in!”).&lt;/p&gt;
&lt;p&gt;So I figure that if I publish my submissions here, perhaps a few
people might take a look and chip in some valuable thoughts. And
even though &lt;a href="/comments/"&gt;this site doesn’t do comments&lt;/a&gt;, I am
counting on Twitter and other social networks to spark some.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;If you run a small conference or meetup that I don’t know about,
    I want to give you the opportunity to reach out to me if there’s a
    topic you’d like to hear me talk about.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There’s generally far more topics that I’d &lt;em&gt;like&lt;/em&gt; to do talks on —
and feel reasonably qualified to — than what I often get selected
to speak about. In addition, there are &lt;em&gt;just so many&lt;/em&gt; conferences
and meetups out there that it’s impossible to keep track of all of
them.&lt;/p&gt;
&lt;p&gt;So, if you find a topic here that you’d really like at &lt;em&gt;your&lt;/em&gt;
event that I absolutely don’t have on my radar, do drop me a line.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;If you find any of my talk ideas useful, go ahead and submit your
   own talk like it.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Like almost all content on this site, the talk submissions I
record here are
&lt;a href="https://creativecommons.org/licenses/by-sa/4.0/deed.en"&gt;CC-BY-SA&lt;/a&gt;
licensed, so as long as you include an acknowledgment, and
reciprocate by sharing your own talk, please do consider yourself
encouraged to build your own talk ideas from mine.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;I’ll make one exception from this rule:&lt;/strong&gt; some conferences use an
anonymized talk selection process, where submissions must be devoid of
any information that might be remotely likely to identify the
speaker. If I submit a talk to such a conference, I’ll only put the
abstract up here when the selection process is over, the schedule
stands, and I have received a definitive acceptance or rejection
notice. However, in case I am re-submitting a talk previously given at
(or previously submitted to) a different conference, I won’t be
removing &lt;em&gt;that&lt;/em&gt; article.&lt;/p&gt;
&lt;p&gt;You can find my (continuously updated) list of talk submissions
&lt;a href="/category/talk-submissions.html"&gt;here&lt;/a&gt;, and there’s also an Atom
feed, &lt;a href="/feeds/category/talk-submissions.atom.xml"&gt;here&lt;/a&gt;.&lt;/p&gt;</content><category term="blog"></category><category term="Conference"></category></entry><entry><title>Writing for learners: best practices for creating, developing, and maintaining self-paced learning resources</title><link href="https://xahteiwi.eu/talk-submissions/wtd-prague-2019/" rel="alternate"></link><published>2019-04-23T00:00:00+00:00</published><updated>2019-04-23T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2019-04-23:/talk-submissions/wtd-prague-2019/</id><summary type="html">&lt;p&gt;A talk I submitted to Write The Docs Prague, 2019.&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a talk I submitted&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt; to &lt;a href="https://www.writethedocs.org/conf/"&gt;Write The
Docs&lt;/a&gt; Prague, September
15-17, 2019. The conference uses a non-anonymized CfP process with a
simple Google Form. The CfP page is
&lt;a href="https://www.writethedocs.org/conf/prague/2019/cfp/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Talk title&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Writing for learners: best practices for creating, developing, and
maintaining self-paced learning resources.&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Talk abstract&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;More information here is better. Submitting a single paragraph won't
give us much to go on, but please no walls of text.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This presentation talks about a special kind of tech writing: creating
and maintaining self-paced technical training content. This
encompasses both prose for theoretical background information, and
instructions for hands-on labs.&lt;/p&gt;
&lt;p&gt;In this talk, I’ll go over&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;special challenges (and advantages!) of self-directed over
  instructor-driven training&lt;/li&gt;
&lt;li&gt;video content, and why we don’t do it&lt;/li&gt;
&lt;li&gt;our rules for structuring theoretical content&lt;/li&gt;
&lt;li&gt;our approach for interactive lab instructions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is rooted in 4 years’ experience in writing courseware used for
learning complex technical topics (like OpenStack, Kubernetes, Ceph,
and others) on an Open edX platform.&lt;/p&gt;
&lt;p&gt;You’ll find the concepts discussed in this talk useful if you write
courseware (of course), but I’d say they equally apply whenever you
find yourself writing any content that is instructive, rather than
descriptive.&lt;/p&gt;
&lt;h2&gt;Who and why&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Who is this talk for? What background knowledge or experience do you
expect the audience to have? What is the take away from the talk?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This talk is for anyone who, in a technical context, uses
imperatives. I’ve been at least a part-time tech writer for the better
part of the last 10 years, but I’ve written software documentation for
only 4 of those – the majority of the remainder I’ve written
courseware content instead. &lt;/p&gt;
&lt;p&gt;Writing prose training content and lab instructions comes with its own
unique challenges and its own (explicit or implicit) style
guide. Since as courseware authors we communicate with our learners
exclusively in writing, I believe I have good practices to share with
other documentarians who might occasionally find themselves in the
situation of writing lab instructions and test scenario descriptions,
and I think there are equally many things that can learn from other
talks and speakers.&lt;/p&gt;
&lt;h2&gt;Other Information&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Any other information that might be interesting for us to know about
you? Give a lightning talk last year, speak at a WTD meetup, or
anything else interesting? Add it here.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I’ve never spoken at any Write The Docs conference, though I have done
talks and workshops at multiple instances of linux.conf.au, LinuxCon
(now Open Source Summit), OpenStack Summit (now Open Infrastructure
Summit), the Open edX Conference, and others.&lt;/p&gt;
&lt;p&gt;My team and I maintain City Cloud Academy (academy.citycloud.com),
which runs on Open edX.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;If you’re curious why this is here, please read
&lt;a href="https://xahteiwi.eu/blog/2019/04/23/talk-submissions/"&gt;this&lt;/a&gt;. &lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="talk-submissions"></category><category term="Conference"></category></entry><entry><title>If you’re a leader in tech, “non-technical” is not a free pass</title><link href="https://xahteiwi.eu/blog/2019/04/21/non-technical/" rel="alternate"></link><published>2019-04-21T00:00:00+00:00</published><updated>2019-04-21T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2019-04-21:/blog/2019/04/21/non-technical/</id><summary type="html">&lt;p&gt;There’s a specific use of the term “non-technical,” and that’s applying it to oneself, as a cop-out. If you’re a leader in tech, you don’t get to do that.&lt;/p&gt;</summary><content type="html">&lt;p&gt;The excellent &lt;a href="https://joshsimmons.com/"&gt;Josh Simmons&lt;/a&gt; recently
&lt;a href="https://twitter.com/joshsimmons/status/1111292871594774529"&gt;implored people on
Twitter&lt;/a&gt;
to stop using the term “non-technical” when talking about another
person’s skill set. And as far as that term is often used as a
put-down of others, I am &lt;em&gt;completely&lt;/em&gt; with Josh. Belittling someone
because they work in documentation, corporate leadership, marketing,
middle management, PR, advocacy, legal (etc. etc.), and because you
consider yourself somehow superior because you’re in a “technical”
role — that has got to stop, yesterday.&lt;/p&gt;
&lt;p&gt;However, I would like to amend his plea to also decry the use of the
phrase &lt;em&gt;about oneself,&lt;/em&gt; as a cop-out. I am talking about people in
leadership roles saying “I’m not technical” or “I’m not a tech
person” to allege that they have bigger fish to fry, and cannot be
reasonably &lt;em&gt;expected&lt;/em&gt; to understand technical detail.&lt;/p&gt;
&lt;p&gt;And that has to stop yesterday, too.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Leadership roles exist that &lt;em&gt;require&lt;/em&gt; understanding of technical
detail.&lt;/strong&gt; If you’re the CEO of a tech company, you need to understand
the technology your company makes. If you’re in charge of a product,
you need to understand the technology that makes up that product. And
even if your company’s core business has nothing to do with
technology, but &lt;em&gt;you&lt;/em&gt; are in charge of something that does, you need
to understand that technology.&lt;/p&gt;
&lt;p&gt;Now of course it’s nigh impossible to understand every bit of
technology that you need to make decisions on, in its every intricate
detail. But you &lt;em&gt;will&lt;/em&gt; be faced with decisions that do boil down to
&lt;em&gt;specific&lt;/em&gt; technology details. And then, it is incumbent on you to
know as much as you need to know, to make an &lt;em&gt;informed&lt;/em&gt; decision. This
is a core element of a leadership position, and it makes up at least
part of your income differential versus a person who is a subject
matter expert in their field, but doesn’t manage other people.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Whenever you have an issue to decide on that you don’t understand,
get someone to explain it to you.&lt;/strong&gt; It’s perfectly fine to say “I know
nothing about this bit of technology, please give me your simplest
explanation that will enable me to make a decision.” But you don’t get
to say “I’m not a technical person” and use that as a pass for, and
perpetuation of, your self-inflicted ignorance.&lt;/p&gt;
&lt;p&gt;(By the way, the same is obviously true in reverse. Say you’ve got the
tech-person perspective and someone from legal comes up to you with a
question on licensing or patents or international contract law that
you know zilch about? Same thing. “Please give me your simplest
explanation of this matter that will enable me to make a decision.”)&lt;/p&gt;
&lt;p&gt;There is a recently popular spin on the “it’s OK to be non-technical”
cop-out argument, which is to over-emphasize communication skills over
tech skills. It starts with a truism — a person’s technical skills
provide little benefit unless paired with communications
proficiency. But then this is frequently flipped to claim that
technical understanding can be &lt;em&gt;replaced&lt;/em&gt; with communications skills,
because the former allegedly &lt;em&gt;pales&lt;/em&gt; in importance versus the latter.&lt;/p&gt;
&lt;p&gt;Let me break something to you: &lt;strong&gt;except in the rare case of a job
where someone works entirely on their own and also has no customers,&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt;
communication skills are &lt;em&gt;every&lt;/em&gt; person’s most important skills.&lt;/strong&gt; &lt;em&gt;Yes of
course&lt;/em&gt; your communication skills are more important than your tech
skills, because they’re literally more important than
anything. &lt;/p&gt;
&lt;p&gt;However, &lt;strong&gt;if you’re a great communicator but you don’t know what
you’re talking about, all that makes you is a bullshit peddler.&lt;/strong&gt; And,
if you’re actually incapable of listening to experts who are able and
usually very willing to explain a complex matter to you, maybe you’re
not such a grand communicator after all, either.&lt;/p&gt;
&lt;p&gt;So if you’re in a leadership position that is even remotely
tech-related, and you’ve ever used “I’m not technical” as a free pass
to not understand things, stop. It isn’t.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Yes I am aware that this is exceedingly rare. &lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="blog"></category><category term="Communications"></category></entry><entry><title>Why upload filters don’t work (really simple math!)</title><link href="https://xahteiwi.eu/blog/2019/03/25/upload-filter-math/" rel="alternate"></link><published>2019-03-25T20:00:00+00:00</published><updated>2019-03-25T20:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2019-03-25:/blog/2019/03/25/upload-filter-math/</id><summary type="html">&lt;p&gt;“I can’t figure out how upload filters should work, but I’m not a
technical person — surely someone who is can sort it out!”&lt;/p&gt;
&lt;p&gt;That is a misconception. I’ll be happy to explain, requiring — I
promise! — no technical understanding of what an upload filter is, or
how it …&lt;/p&gt;</summary><content type="html">&lt;p&gt;“I can’t figure out how upload filters should work, but I’m not a
technical person — surely someone who is can sort it out!”&lt;/p&gt;
&lt;p&gt;That is a misconception. I’ll be happy to explain, requiring — I
promise! — no technical understanding of what an upload filter is, or
how it works.&lt;/p&gt;
&lt;!--break--&gt;
&lt;p&gt;The current draft of the EU Directive “on copyright and related
rights in the Digital Single Market”, available
&lt;a href="http://www.europarl.europa.eu/doceo/document/A-8-2018-0245-AM-271-271_EN.pdf"&gt;here&lt;/a&gt;,
(PDF in English), also known as &lt;a href="https://en.wikipedia.org/wiki/Directive_on_Copyright_in_the_Digital_Single_Market"&gt;the &lt;strong&gt;EU Copyright
Directive&lt;/strong&gt;&lt;/a&gt;,
requires in its Article 17 (formerly Article 13), clause 4, that the
service provider undergoes,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;in accordance with high industry standards of professional
diligence, best efforts to ensure the unavailability of specific
works and other subject matter for which the rightholders have
provided the service providers with the relevant and necessary
information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It is obvious that the only way any platform hosting
user-generated content would thus have to intercept any such content
&lt;em&gt;on upload,&lt;/em&gt; failing which it would immediately become potentially liable for a
copyright violation. This would require a technical facility commonly
called an &lt;em&gt;upload filter.&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;We don't need to talk about how upload filters &lt;em&gt;work&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;Now, an upload filter is immensely complex and there are tons of
technical difficulties — the only time this has been attempted on a
large scale is YouTube’s &lt;a href="https://en.wikipedia.org/wiki/Content_ID_(algorithm)"&gt;Content
ID&lt;/a&gt;, and it is
exceedingly unreliable and prone to overblocking. But for the purposes
of this discussion, it doesn’t matter whether implementing an upload
filter is difficult to do.&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Assume for a moment someone has built a magnificent upload
filter. Something that operates on magic pixie dust that catches &lt;em&gt;all&lt;/em&gt;
copyright violations.&lt;/p&gt;
&lt;h2&gt;Interactions&lt;/h2&gt;
&lt;p&gt;Now, let’s call every instance of someone uploading content to the
internet an “interaction”. Every tweet, every Facebook post and
comment, every comment on your favorite news site, every blog post you
write, every picture that you take and post to a WhatsApp group of 50
people or more, every YouTube video and comment — let’s call all of
those “interactions.”&lt;/p&gt;
&lt;p&gt;And let’s make an outrageously overblown assumption: suppose that on
the internet today, 1% of such interactions infringe someone’s
copyright. Again, let me reiterate that this is ludicrously high. The vast
majority of internet interactions today are either completely trivial
and thus irrelevant to copyright, or works of your own, or a perfectly
legal fair-use way of using someone else’s work, such as when you
quote a passage of a book. But purely for the sake of this discussion,
let’s say it’s 1%.&lt;/p&gt;
&lt;p&gt;So then let’s look at 10,000 interactions that completely random
people make on the internet.&lt;/p&gt;
&lt;p&gt;Those would then break down like so:&lt;/p&gt;
&lt;table class="table table-striped"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Total&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Perfectly legal&lt;/td&gt;
&lt;td&gt;9,900&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Infringing copyright&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;Catching copyright violations. Or non-violations.&lt;/h2&gt;
&lt;p&gt;OK. Now, suppose we built a &lt;em&gt;perfect&lt;/em&gt; upload filter, i.e. one that
catches &lt;em&gt;all&lt;/em&gt; copyright infringements. Remember, the Directive calls
for “best effort to ensure the &lt;strong&gt;unavailability&lt;/strong&gt;” (emphasis mine) of
potentially infringing content. It does not allow providers to balance
for freedom of expression or the like, so to err on the side of
caution, they must strive to over- rather than underblock. So a
perfect filter is one that has &lt;strong&gt;no false negatives&lt;/strong&gt; — meaning if
content infringes, it is always caught.&lt;/p&gt;
&lt;p&gt;Now, suppose further that the filter mis-identifies content (meaning,
flags content as infringing when it is not) with a rate of only
2%. That means it has &lt;strong&gt;2% false positives.&lt;/strong&gt; That, now, is
ridiculously low for any automated screening procedure.&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;So that means that out of our 10,000 interactions tracked by our
“perfect” content filter, the numbers break down like this:&lt;/p&gt;
&lt;table class="table table-striped"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Total&lt;/th&gt;
&lt;th&gt;Flagged as legal&lt;/th&gt;
&lt;th&gt;Flagged as infringing&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Perfectly legal&lt;/td&gt;
&lt;td&gt;9,900&lt;/td&gt;
&lt;td&gt;9,802&lt;/td&gt;
&lt;td&gt;198&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Infringing copyright&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Overall&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;10,000&lt;/td&gt;
&lt;td&gt;9,802&lt;/td&gt;
&lt;td&gt;298&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;Congratulations, a coin toss beats your upload filter.&lt;/h2&gt;
&lt;p&gt;That leads us to the question: if you upload something and it gets
flagged, how likely is it that it is &lt;em&gt;actually&lt;/em&gt; infringing any
copyright? Answer: 100 in 298. Roughly one in three. &lt;strong&gt;Yes, that is
worse than a coin toss.&lt;/strong&gt; And remember, this is assuming an
implausibly high rate of infringements overall, and a ludicrously low
false-positive and false-negative rate on your filter.&lt;/p&gt;
&lt;p&gt;Go ahead and play with the numbers, tweak the false-negatives and
false-positives, whatever. &lt;strong&gt;As long as what you’re looking for is
exceedingly rare, automated filters detect it with poor accuracy.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;And if you leave all parameters the same, but consider a probably much
more realistic infringement rate of 1 in 1000, that is, 0.1%, then
things look like this: &lt;/p&gt;
&lt;table class="table table-striped"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Total&lt;/th&gt;
&lt;th&gt;Flagged as legal&lt;/th&gt;
&lt;th&gt;Flagged as infringing&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Perfectly legal&lt;/td&gt;
&lt;td&gt;9,990&lt;/td&gt;
&lt;td&gt;9,800&lt;/td&gt;
&lt;td&gt;200&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Infringing copyright&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Overall&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;10,000&lt;/td&gt;
&lt;td&gt;9,800&lt;/td&gt;
&lt;td&gt;300&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Now there’s a one-in-thirty chance that an upload block is
legitimate. Assuming there is an appeals process, and all false
positives get appealed, then that means the &lt;strong&gt;human&lt;/strong&gt; going through
the appeals will have to undo a block &lt;strong&gt;29 times out of 30.&lt;/strong&gt; &lt;/p&gt;
&lt;h2&gt;A cheap optimization&lt;/h2&gt;
&lt;p&gt;I’d like to propose an optimization here: any website seeking to
implement a content filter should consider to just use a &lt;strong&gt;random
number generator to reject your upload, comment, tweet, or post with a
certain probability that is demonstrably larger than that of an upload
filter.&lt;/strong&gt; I’d posit that that would be by far the safest, cheapest way
to comply with the directive — if it becomes law.&lt;/p&gt;
&lt;p&gt;Of course, everyone who is now in favor of this directive (including
its Article 17) will hate that.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2&gt;Footnotes&lt;/h2&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;It’s also easy to dismiss with a “try harder”
retort, which is completely disingenuous, because it’s akin to
saying, doc, this patient has terminal pancreatic cancer, but you
&lt;em&gt;must&lt;/em&gt; cure her. Inoperable? Terminal? No there’s &lt;em&gt;got&lt;/em&gt; to be a
way. Sometimes there is no way, and it’s OK when an expert tells
you that. &lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;I don’t believe YouTube releases numbers on its ContentID error
rate, but it’s apparently &lt;a href="https://www.techdirt.com/articles/20181214/17272041233/youtubes-100-million-upload-filter-failures-demonstrate-what-disaster-article-13-will-be-internet.shtml"&gt;pretty
bad&lt;/a&gt;
for a system that cost $100M to build. &lt;a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="blog"></category><category term="Politics"></category></entry><entry><title>Article 17: The time to act is now.</title><link href="https://xahteiwi.eu/blog/2019/03/21/copyright-reform/" rel="alternate"></link><published>2019-03-21T17:38:00+00:00</published><updated>2019-03-21T17:38:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2019-03-21:/blog/2019/03/21/copyright-reform/</id><summary type="html">&lt;p&gt;Next Tuesday, the European Parliament is due to vote on something that will impact your life. Yes, yours.&lt;/p&gt;</summary><content type="html">&lt;p&gt;On Tuesday, March 26 at half-past noon Central European Time, the
European Parliament is due to vote on an issue that will definitely
impact your life, no matter if you live in or outside the EU. No, it
has nothing to do with Brexit. Brexit has just managed to monopolise
your attention. The Tuesday vote has much more far-reaching
consequences.&lt;/p&gt;
&lt;h2&gt;What’s going on here?&lt;/h2&gt;
&lt;p&gt;On Tuesday, the EP will vote on a Directive “on copyright and related
rights in the Digital Single Market”, the draft of which you can look
up
&lt;a href="http://www.europarl.europa.eu/doceo/document/A-8-2018-0245-AM-271-271_EN.pdf"&gt;here&lt;/a&gt;
(PDF in English), also known as &lt;a href="https://en.wikipedia.org/wiki/Directive_on_Copyright_in_the_Digital_Single_Market"&gt;the &lt;strong&gt;EU Copyright
Directive&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now this thing attempts to be a 21st-century copyright law, which is
laudable, but it does absolutely awful things: go take a look at &lt;a href="https://youtu.be/CyUh9wOp_Rw"&gt;this
video&lt;/a&gt; to get the quick run-down. It’ll
only take 4 minutes of your time. And as you’ll see from the video,
&lt;strong&gt;this law will have a devastating global impact&lt;/strong&gt; on society at
large. (While completely failing to achieve its ostensible goals, mind
you.)&lt;/p&gt;
&lt;p&gt;What is apparent from the discussion around this directive is that it
isn’t being pushed by exceptionally clueful people. One MEP in favor
of the directive once publicly surmised that he was dealing with a
concerted campaign from Google, &lt;a href="https://twitter.com/schulzeeuropa/status/1096445520770404352"&gt;because lots of the email in his
inbox came from &lt;code&gt;gmail.com&lt;/code&gt;
addresses&lt;/a&gt;. The
&lt;a href="https://en.wikipedia.org/wiki/Committees_of_the_European_Parliament"&gt;rapporteur&lt;/a&gt;
on the directive &lt;a href="https://www.vice.com/de/article/vbw8zy/streit-um-uploadfilter-und-artikel13-wie-axel-voss-das-internet-sieht"&gt;hasn’t subscribed to any YouTube channel and thinks
that there is a Memes section on
Google&lt;/a&gt;,
and when properly roasted on Twitter, someone representing
his party &lt;a href="https://twitter.com/CDU_CSU_EP/status/1108372306101968901"&gt;publicly doubled
down&lt;/a&gt; on
his behalf.&lt;/p&gt;
&lt;p&gt;In the words of Janus Kopfstein:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href="https://motherboard.vice.com/en_us/article/pggamb/dear-congress-it-s-no-longer-ok-to-not-know-how-the-internet-works-5886b6cbc860fd45c9f2dfe3"&gt;It’s no longer OK to not know how the internet
works.&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Yes, he wrote that in 2011, and addressed at the U.S. Congress, but
here we are, with our European representatives still needing that
reminder 8 years on.&lt;/p&gt;
&lt;p&gt;They even tried the oldest trick in the book: once all of Europe
started screaming about Article 13, they renumbered. So &lt;strong&gt;what used to
be Article 13 is now Article 17.&lt;/strong&gt; Don’t get confused; this is just a
ploy by people who print out emails.&lt;/p&gt;
&lt;p&gt;Now luckily, the backers of Article 17 are opposed by a good bunch of
people who are clued in, and have pledged to strike this Directive
down in the EP on Tuesday. &lt;/p&gt;
&lt;h2&gt;OK. So what do I do?&lt;/h2&gt;
&lt;p&gt;You can &lt;a href="https://www.change.org/p/european-parliament-stop-the-censorship-machinery-save-the-internet"&gt;sign a change.org
petition&lt;/a&gt;. It
already has 5 million supporters, and there will likely be many
more. But supporting that petition &lt;strong&gt;is not enough.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You can check out your own MEPs for their status at &lt;a href="https://pledge2019.eu/"&gt;Pledge
2019&lt;/a&gt;. And you can lean on them: Pledge 2019
lets you call the people whose job it is to represent &lt;strong&gt;you&lt;/strong&gt; in the
EP, and if they haven’t pledged to reject the Directive in its current
form, &lt;strong&gt;you can let them know&lt;/strong&gt; (in no uncertain terms) &lt;strong&gt;that you
won’t be voting for them or their party in the upcoming &lt;a href="https://en.wikipedia.org/wiki/2019_European_Parliament_election"&gt;EP
elections&lt;/a&gt;&lt;/strong&gt;
in May.&lt;/p&gt;
&lt;p&gt;Also, there’s &lt;a href="https://saveyourinternet.eu/act/"&gt;Save Your
Internet&lt;/a&gt;. The primary spin your
pro-upload filter reps are trying to put on the discussion is that
the legislation isn’t opposed by an appreciable number of real people,
and that only astroturfing bots want this law struck down. You can
&lt;strong&gt;write an email, send a letter&lt;/strong&gt; (yes, a letter, as in, snail mail), or
&lt;strong&gt;call them.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;And finally, &lt;a href="https://savetheinternet.info/demos"&gt;Save The Internet&lt;/a&gt;
(yes, everyone’s, not just yours). March 23 is a day of pan-European
protest against Article 17. &lt;strong&gt;Find a rally and go.&lt;/strong&gt;&lt;/p&gt;</content><category term="blog"></category><category term="Politics"></category></entry><entry><title>Using coverage with multiple parallel GitLab CI jobs</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/coverage-gitlab-ci/" rel="alternate"></link><published>2019-03-10T00:00:00+00:00</published><updated>2019-03-10T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2019-03-10:/resources/hints-and-kinks/coverage-gitlab-ci/</id><summary type="html">&lt;p&gt;If you ever write unit tests in Python, you are probably familiar with Ned Batchelder’s &lt;code&gt;coverage&lt;/code&gt; tool. This article explains how you can use &lt;code&gt;coverage&lt;/code&gt; in combination with &lt;code&gt;tox&lt;/code&gt; and a GitLab CI pipeline, for coverage reports in your Python code.&lt;/p&gt;</summary><content type="html">&lt;p&gt;If you ever write unit tests in Python, you are probably familiar with
&lt;a href="https://twitter.com/nedbat"&gt;Ned Batchelder&lt;/a&gt;’s &lt;a href="https://coverage.readthedocs.io"&gt;&lt;code&gt;coverage&lt;/code&gt;
tool&lt;/a&gt;. This article explains how you
can use &lt;code&gt;coverage&lt;/code&gt; in combination with &lt;code&gt;tox&lt;/code&gt; and a GitLab CI pipeline,
for coverage reports in your Python code.&lt;/p&gt;
&lt;h2&gt;Running &lt;code&gt;coverage&lt;/code&gt; from &lt;code&gt;tox&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Consider the following rather run-of-the mill &lt;code&gt;tox&lt;/code&gt; configuration
(nothing very spectacular here):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;[tox]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;envlist&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;py{27,35,36,37},flake8&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;[coverage:run]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;parallel&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;True&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;include&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="na"&gt;bin/*&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="na"&gt;my_package/*.py&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="na"&gt;tests/*.py&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;[testenv]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;commands&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="na"&gt;coverage run -m unittest discover tests {posargs}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;deps&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="na"&gt;-rrequirements/setup.txt&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="na"&gt;-rrequirements/test.txt&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;[testenv:flake8]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;deps&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;-rrequirements/flake8.txt&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;commands&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;flake8 {posargs}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this configuration, &lt;code&gt;coverage run&lt;/code&gt; &lt;a href="https://coverage.readthedocs.io/en/latest/cmd.html#execution"&gt;(which, remember, replaces
&lt;code&gt;python&lt;/code&gt;)&lt;/a&gt;
invokes &lt;a href="https://docs.python.org/3/library/unittest.html#test-discovery"&gt;test
auto-discovery&lt;/a&gt;
from the &lt;code&gt;unittest&lt;/code&gt; module. It looks for unit tests in the &lt;code&gt;tests&lt;/code&gt;
subdirectory, runs them, and keeps track of which lines were hit and
missed by your unit tests.&lt;/p&gt;
&lt;p&gt;The only slightly unusual bit is &lt;code&gt;parallel = True&lt;/code&gt; in the
&lt;code&gt;[coverage:run]&lt;/code&gt; section. This instructs &lt;code&gt;coverage&lt;/code&gt; to write its
results not into one file, &lt;code&gt;.coverage&lt;/code&gt;, but into multiple, named
&lt;code&gt;.coverage.&amp;lt;hostname&amp;gt;.&amp;lt;pid&amp;gt;.&amp;lt;randomnumber&amp;gt;&lt;/code&gt; — meaning you get separate
results files for each &lt;code&gt;coverage&lt;/code&gt; run.&lt;/p&gt;
&lt;p&gt;Subsequently, you can combine your coverage data with &lt;code&gt;coverage
combine&lt;/code&gt;, and then do whatever you like with the combined data
(&lt;code&gt;coverage report&lt;/code&gt;, &lt;code&gt;coverage html&lt;/code&gt;, etc.).&lt;/p&gt;
&lt;h2&gt;GitLab CI&lt;/h2&gt;
&lt;p&gt;Now there’s a bit of a difficulty with GitLab CI, which is that your
individual &lt;code&gt;tox&lt;/code&gt; &lt;code&gt;testenv&lt;/code&gt;s will all run in completely different
container instances. That means that you’ll run your &lt;code&gt;py27&lt;/code&gt; tests in
one container, &lt;code&gt;py35&lt;/code&gt; in another, and so forth. But you can use GitLab
CI &lt;a href="https://docs.gitlab.com/ee/user/project/pipelines/job_artifacts.html"&gt;job
artifacts&lt;/a&gt;
to pass your coverage data between one stage and another.&lt;/p&gt;
&lt;p&gt;Here’s your &lt;code&gt;build&lt;/code&gt; stage, which stores your &lt;code&gt;coverage&lt;/code&gt; data in
short-lived artifacts:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nt"&gt;image&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;python&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nt"&gt;py27&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;image&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;'python:2.7'&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;stage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;build&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;pip install tox&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;tox -e py27,flake8&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;artifacts&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;paths&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;.coverage*&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;expire_in&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;5 minutes&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nt"&gt;py35&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;image&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;'python:3.5'&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;stage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;build&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;pip install tox&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;tox -e py35,flake8&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;artifacts&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;paths&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;.coverage*&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;expire_in&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;5 minutes&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nt"&gt;py36&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;image&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;'python:3.6'&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;stage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;build&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;pip install tox&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;tox -e py36,flake8&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;artifacts&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;paths&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;.coverage*&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;expire_in&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;5 minutes&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nt"&gt;py37&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;image&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;'python:3.7'&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;stage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;build&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;pip install tox&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;tox -e py37,flake8&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;artifacts&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;paths&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;.coverage*&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;expire_in&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;5 minutes&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And here’s the &lt;code&gt;test&lt;/code&gt; stage, with a single job that&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;combines your coverage data,&lt;/li&gt;
&lt;li&gt;runs &lt;code&gt;coverage report&lt;/code&gt; and parses the output — this is what goes into
  the &lt;em&gt;coverage&lt;/em&gt; column of your GitLab job report,&lt;/li&gt;
&lt;li&gt;runs &lt;code&gt;coverage html&lt;/code&gt; and stores the resulting &lt;code&gt;htmlcov&lt;/code&gt; directory
  into an artifact that you can download from GitLab for a week.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nt"&gt;coverage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;stage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;test&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;script&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;pip install coverage&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;python -m coverage combine&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;python -m coverage html&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;python -m coverage report&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;coverage&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;'/TOTAL.*\s+(\d+%)$/'&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;artifacts&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;paths&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;htmlcov&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;expire_in&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;1 week&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content><category term="hints-and-kinks"></category><category term="Python"></category><category term="CI"></category><category term="GitLab"></category></entry><entry><title>Building a nested CLI parser from a dictionary</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/python-argparse-from-dictionary/" rel="alternate"></link><published>2019-03-09T00:00:00+00:00</published><updated>2019-03-09T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2019-03-09:/resources/hints-and-kinks/python-argparse-from-dictionary/</id><summary type="html">&lt;p&gt;Here’s a nice way to initialize a CLI argument parser in Python, with arbitrary levels of subcommands.&lt;/p&gt;</summary><content type="html">&lt;p&gt;If you’ve ever built a command-line interface in Python, you are
surely familiar with the &lt;code&gt;argparse&lt;/code&gt; module, which is part of the Python
standard library. It contains the &lt;code&gt;ArgumentParser&lt;/code&gt; class, instances
of which are typically invoked from the CLI’s &lt;code&gt;main()&lt;/code&gt; method.&lt;/p&gt;
&lt;p&gt;The canonical way of doing this is explained in considerable detail in
&lt;a href="https://docs.python.org/3/library/argparse.html"&gt;the standard library
documentation&lt;/a&gt;. However,
the standard way is quite repetitive, and you end up invoking
&lt;code&gt;parser.add_argument()&lt;/code&gt; &lt;em&gt;a lot,&lt;/em&gt; as you populate your parent parser
and subparsers with options.&lt;/p&gt;
&lt;p&gt;Here’s a more concise way:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# If you must run this on Python 2. You really shouldn't!&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;__future__&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;print_function&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;argparse&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ArgumentParser&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;yaml&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;

&lt;span class="c1"&gt;# Using YAML here only for illustrative purposes, as it's a bit&lt;/span&gt;
&lt;span class="c1"&gt;# easier to read. You probably just want to use a dictionary outright.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# More at the bottom of this article.&lt;/span&gt;
&lt;span class="c1"&gt;# Yes, go read the bottom of this article.&lt;/span&gt;
&lt;span class="c1"&gt;#&lt;/span&gt;
&lt;span class="c1"&gt;# Want to just blindly copy and paste this snippet? Fine, this is for you.&lt;/span&gt;
&lt;span class="k"&gt;assert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;PARSER_CONFIG_YAML&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"""&lt;/span&gt;
&lt;span class="s2"&gt;options:&lt;/span&gt;
&lt;span class="s2"&gt;  - 'flags': ['-V', '--version']&lt;/span&gt;
&lt;span class="s2"&gt;    action: version&lt;/span&gt;
&lt;span class="s2"&gt;    help: 'show version'&lt;/span&gt;
&lt;span class="s2"&gt;    version: '0.01'&lt;/span&gt;
&lt;span class="s2"&gt;subcommands:&lt;/span&gt;
&lt;span class="s2"&gt;- foo:&lt;/span&gt;
&lt;span class="s2"&gt;    options:&lt;/span&gt;
&lt;span class="s2"&gt;      - 'flags': ['-c', '--config']&lt;/span&gt;
&lt;span class="s2"&gt;        'help': 'YAML configuration file'&lt;/span&gt;
&lt;span class="s2"&gt;        dest: config&lt;/span&gt;
&lt;span class="s2"&gt;- bar:&lt;/span&gt;
&lt;span class="s2"&gt;    options:&lt;/span&gt;
&lt;span class="s2"&gt;      - 'flags': ['-o', '--output']&lt;/span&gt;
&lt;span class="s2"&gt;        'help': 'output file'&lt;/span&gt;
&lt;span class="s2"&gt;        dest: output&lt;/span&gt;
&lt;span class="s2"&gt;- baz:&lt;/span&gt;
&lt;span class="s2"&gt;    subcommands:&lt;/span&gt;
&lt;span class="s2"&gt;      - 'spam-eggs':&lt;/span&gt;
&lt;span class="s2"&gt;          options:&lt;/span&gt;
&lt;span class="s2"&gt;            - 'flags': ['-i', '--input']&lt;/span&gt;
&lt;span class="s2"&gt;              'help': 'input file'&lt;/span&gt;
&lt;span class="s2"&gt;              dest: input&lt;/span&gt;
&lt;span class="s2"&gt;"""&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;CLI&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

        &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;walk_config&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dictionary&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
            &lt;span class="sd"&gt;"""Walk a dictionary and populate an ArgumentParser."""&lt;/span&gt;

            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s1"&gt;'options'&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;dictionary&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;opt&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;dictionary&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'options'&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
                    &lt;span class="n"&gt;args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;opt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'flags'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                    &lt;span class="n"&gt;kwargs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;opt&lt;/span&gt;
                    &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_argument&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s1"&gt;'subcommands'&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;dictionary&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;subs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_subparsers&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dest&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'action'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;subcommand&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;dictionary&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'subcommands'&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
                    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;cmd&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;opts&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;subcommand&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
                        &lt;span class="n"&gt;sub&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;subs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add_parser&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cmd&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                        &lt;span class="n"&gt;walk_config&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;opts&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sub&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="n"&gt;config&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;yaml&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;safe_load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;PARSER_CONFIG_YAML&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="n"&gt;parser&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ArgumentParser&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;walk_config&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parser&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;parser&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;foo&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"This is the foo subcommand, "&lt;/span&gt;
              &lt;span class="s2"&gt;"invoked with '-c &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;'."&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;bar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"This is the bar subcommand, "&lt;/span&gt;
              &lt;span class="s2"&gt;"invoked with '-o &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;'."&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;baz&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"This is the baz subcommand"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;spam_eggs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"This is the baz spam-eggs subcommand, "&lt;/span&gt;
              &lt;span class="s2"&gt;"invoked with '-i &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;'."&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;opts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parser&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse_args&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:])&lt;/span&gt;
        &lt;span class="nb"&gt;getattr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;opts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'action'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'-'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'_'&lt;/span&gt;&lt;span class="p"&gt;))(&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;opts&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'__main__'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;CLI&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And now, if you want to add a new option, you add it to the
top-level or the subcommand’s &lt;code&gt;options&lt;/code&gt; list, and add it to your
subcommand method.&lt;/p&gt;
&lt;p&gt;And if you want to add a new subcommand, you just add that at the
level you like, and add a method that is named like your subcommand
— with any hyphens in the subcommand being replaced with underscores in
the method name.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2&gt;Notes&lt;/h2&gt;
&lt;p&gt;When using PyYAML, do not use versions affected by
&lt;a href="https://nvd.nist.gov/vuln/detail/CVE-2017-18342"&gt;CVE-2017-18342&lt;/a&gt;. Really,
you shouldn’t be using YAML at all for this purpose; you should just
use a straight-up dictionary. If you want something just &lt;em&gt;a little&lt;/em&gt;
more readable, you might also consider JSON (for which there is &lt;a href="https://docs.python.org/3/library/json.html"&gt;a
parser&lt;/a&gt; in the standard
library), or perhaps &lt;a href="https://pypi.org/project/toml/"&gt;TOML&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Also, yes there are smarter ways to define your program’s version;
more on that perhaps in a later post.&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Python"></category></entry><entry><title>Learn Complex Skills, From Anywhere: Combining Django, Ansible and OpenStack to teach any tech skill</title><link href="https://xahteiwi.eu/resources/presentations/learn-complex-skills-from-anywhere-combining-django-ansible-and-openstack-to-teach-any-tech-skill/" rel="alternate"></link><published>2019-01-23T00:00:00+00:00</published><updated>2019-01-23T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2019-01-23:/resources/presentations/learn-complex-skills-from-anywhere-combining-django-ansible-and-openstack-to-teach-any-tech-skill/</id><content type="html">&lt;p&gt;My presentation from linux.conf.au 2019.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;Video: &lt;a href="https://youtu.be/B1ic5o9geqw"&gt;YouTube&lt;/a&gt;, &lt;a href="http://mirror.linux.org.au/pub/linux.conf.au/2019/c3/Wednesday/Learn_Complex_Skills_From_Anywhere_Combining_Django_Ansible_and_OpenStack_to_teach_any_tech_skill.mp4"&gt;Linux Australia
  (MP4)&lt;/a&gt;,
  &lt;a href="http://mirror.linux.org.au/pub/linux.conf.au/2019/c3/Wednesday/Learn_Complex_Skills_From_Anywhere_Combining_Django_Ansible_and_OpenStack_to_teach_any_tech_skill.webm"&gt;Linux Australia (WebM)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides (with full speaker notes): &lt;a href="https://fghaas.github.io/lca2019/"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Use the arrow keys to navigate through the presentation, hit &lt;code&gt;Esc&lt;/code&gt; to
zoom out for an overview, or just advance by hitting the spacebar.&lt;/p&gt;</content><category term="presentations"></category><category term="Conference"></category><category term="Open edX"></category><category term="OpenStack"></category><category term="Django"></category><category term="Ansible"></category><category term="linux.conf.au"></category></entry><entry><title>1,000 routers per tenant? Think again!</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/1000-routers-per-tenant-think-again/" rel="alternate"></link><published>2018-12-08T00:00:00+00:00</published><updated>2018-12-08T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2018-12-08:/resources/hints-and-kinks/1000-routers-per-tenant-think-again/</id><summary type="html">&lt;p&gt;When you allow one of your OpenStack tenants a large number of routers, they may not be getting as many as you think they will.&lt;/p&gt;</summary><content type="html">&lt;h2&gt;Neutron quotas&lt;/h2&gt;
&lt;p&gt;As with all other OpenStack services, Neutron uses a fairly extensive
quota system. An OpenStack admin can give a tenant&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt; a quota limit
on networks, routers, port, subnets, IPv6 subnetpools, and many other
object types.&lt;/p&gt;
&lt;p&gt;Most OpenStack deployments set the default per-tenant quota at 10
routers. &lt;strong&gt;However, nothing stops an admin from setting a much higher
router quota, including one above 255. When such a quota change has
been applied to your tenant, you’re in for a surprise.&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;HA routers&lt;/h2&gt;
&lt;p&gt;Way back in the OpenStack Juno release, we got high-availability
support for Neutron routers. This means that, assuming you have more
than one network gateway node that can host them, your virtual routers
will work in an automated active/backup configuration. &lt;/p&gt;
&lt;p&gt;In effect, what Neutron does for you is that for every subnet that is
plugged into the router — and for which it therefore acts as the
default gateway — the gateway address binds to a keepalived-backed
VRRP interface. On one of the network nodes that interface is active,
and on the others it’s in standby. &lt;strong&gt;If your network node goes down,
keepalived makes sure that the subnets’ default gateway IPs come up on
the other node.&lt;/strong&gt; The keepalived configuration is completely
abstracted away from the user; the Neutron L3 agent happily takes care
of all of it.&lt;/p&gt;
&lt;p&gt;In addition, in case a network node is up but has lost upstream
network connectivity itself, whereas another is still available that
retains it, HA routers also fail over in order to ensure connectivity
for your VMs.&lt;/p&gt;
&lt;h2&gt;The catch: one HA router network per tenant&lt;/h2&gt;
&lt;p&gt;In order to enable HA routers, Neutron creates &lt;em&gt;one&lt;/em&gt; administrative
network per tenant, over which it runs VRRP traffic. In order to tell
apart all the keepalived instances that it manages on that network, it
assigns each an individual Virtual Router ID or VRID.&lt;/p&gt;
&lt;p&gt;And here’s the problem: &lt;strong&gt;&lt;a href="https://tools.ietf.org/html/rfc5798"&gt;RFC
5798&lt;/a&gt; defines the VRID to be an
8-bit integer.&lt;/strong&gt; That means that if you use HA routers, then setting a
router quota over 255 is useless — Neutron will run out of VRIDs in
the administrative network, before your tenant can ever hit the quota.&lt;/p&gt;
&lt;p&gt;And this is a hard limit; there’s really not much that Neutron can do
about this — apart from starting to spin up additional administrative
networks once it runs out of VRIDs in the first one, but that likely
would be a pretty involved change. &lt;strong&gt;Thus, at least for the time
being, if you want more than 255 &lt;em&gt;highly-available&lt;/em&gt; virtual routers,
you’ll have to spread them across multiple tenants.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;What’s more is that Neutron is not very forthcoming about this
limitation itself: an attempt to create an HA router beyond the limit
simply leads to an &lt;code&gt;Unknown&lt;/code&gt; error from the Neutron API endpoint.&lt;/p&gt;
&lt;h2&gt;Wait, what if I really don’t &lt;em&gt;need&lt;/em&gt; HA routers?&lt;/h2&gt;
&lt;p&gt;Well, firstly you probably do want them, really. But that aside,
let’s assume for a moment that you actually don’t. Or rather, that
it’s more important for you to have more than 255 routers in a single
tenant, than for any of them to be highly available. So you create
routers with the &lt;code&gt;ha&lt;/code&gt; flag set to &lt;code&gt;False&lt;/code&gt;, simple, right?&lt;/p&gt;
&lt;p&gt;It turns out that you probably won’t be able to do that. And that’s
not because you can’t change a router’s &lt;code&gt;ha&lt;/code&gt; flag without first
temporarily disabling it — that’s not going to hurt you much if you’ve
already decided you don’t need HA; in such a case a brief router blip
will be acceptable. Instead, it’s because (at the time of writing)
&lt;strong&gt;the default Neutron policy restricts setting the &lt;code&gt;ha&lt;/code&gt; flag on a
router to admins only.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;So &lt;em&gt;if&lt;/em&gt; you want to be able to disable a router’s HA capability,
you’ll first need to convince your cloud service provider to override
the following default entries in Neutron’s &lt;code&gt;policy.json&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;"create_router:ha"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"rule:admin_only"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;"get_router:ha"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"rule:admin_only"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;"update_router:ha"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"rule:admin_only"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;... and instead set them as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;"create_router:ha"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"rule:admin_or_owner"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;"get_router:ha"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"rule:admin_or_owner"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;"update_router:ha"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"rule:admin_or_owner"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If your cloud service provider deploys Neutron with
&lt;a href="https://docs.openstack.org/openstack-ansible/latest/"&gt;OpenStack-Ansible&lt;/a&gt;,
they can define this in the &lt;a href="https://docs.openstack.org/openstack-ansible-os_neutron/latest/"&gt;following
variable&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nt"&gt;neutron_policy_overrides&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;"create_router:ha"&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"rule:admin_or_owner"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;"get_router:ha"&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"rule:admin_or_owner"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;"update_router:ha"&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"rule:admin_or_owner"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once the policy has been overridden in this manner, you should be able
to create a new router with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;openstack router create --no-ha &amp;lt;name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And modify an existing router’s high-availability flag with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;openstack router &lt;span class="nb"&gt;set&lt;/span&gt; --disable &amp;lt;name&amp;gt;
openstack router &lt;span class="nb"&gt;set&lt;/span&gt; --no-ha &amp;lt;name&amp;gt;
openstack router &lt;span class="nb"&gt;set&lt;/span&gt; --enable &amp;lt;name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;&lt;em&gt;Is&lt;/em&gt; my router HA, really?&lt;/h2&gt;
&lt;p&gt;In relation to what I described above, you may want to &lt;em&gt;find out&lt;/em&gt;
whether one of your routers is configured to be highly available in
the first place. You’d expect to easily be able to do this with an
&lt;code&gt;openstack router show&lt;/code&gt; command:&lt;/p&gt;
&lt;p&gt;Alas, what you see in the example above &lt;em&gt;is&lt;/em&gt; indeed a highly-available
router, &lt;strong&gt;so why does it clearly report its &lt;code&gt;ha&lt;/code&gt; flag as being
&lt;code&gt;False&lt;/code&gt;?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Well, that’s another consequence of that default Neutron policy, in
combination with rather unintuitive behavior by the &lt;code&gt;openstack&lt;/code&gt;
command line client. You see, this part of the aforementioned policy&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;"get_router:ha"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"rule:admin_only"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;... means you’re not even allowed to &lt;em&gt;query&lt;/em&gt; the &lt;code&gt;ha&lt;/code&gt; flag if you’re
not an admin, and when the &lt;code&gt;openstack&lt;/code&gt; client is asked to display a
boolean value that the user is not allowed to even read, then it
always displays &lt;code&gt;False&lt;/code&gt;.&lt;/p&gt;
&lt;hr/&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;I’m very sorry, I still can’t force myself to call a tenant it a
“project”, as I find that term profoundly illogical: the proper
term for the concept being discussed here is multitenancy, not
multiprojectcy. &lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="hints-and-kinks"></category><category term="OpenStack"></category></entry><entry><title>The Little Bag O’Tricks: 10 Things You Might Not Know You Can Do With OpenStack</title><link href="https://xahteiwi.eu/resources/presentations/the-little-bag-otricks-10-things-you-might-not-know-you-can-do-with-openstack/" rel="alternate"></link><published>2018-10-10T00:00:00+00:00</published><updated>2018-10-10T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2018-10-10:/resources/presentations/the-little-bag-otricks-10-things-you-might-not-know-you-can-do-with-openstack/</id><summary type="html">&lt;p&gt;My presentation from OpenStack Days Nordic 2018 in Stockholm. Actually
talks about 11, not 10 OpenStack capabilities you might not know
about.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;Video: &lt;a href="https://youtu.be/3hUoVi_AWCU"&gt;YouTube&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/osdn2018/"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Use the arrow keys to navigate through the presentation, hit &lt;code&gt;Esc&lt;/code&gt; to
zoom out for an overview, or just advance by hitting the spacebar …&lt;/p&gt;</summary><content type="html">&lt;p&gt;My presentation from OpenStack Days Nordic 2018 in Stockholm. Actually
talks about 11, not 10 OpenStack capabilities you might not know
about.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;Video: &lt;a href="https://youtu.be/3hUoVi_AWCU"&gt;YouTube&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/osdn2018/"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Use the arrow keys to navigate through the presentation, hit &lt;code&gt;Esc&lt;/code&gt; to
zoom out for an overview, or just advance by hitting the spacebar.&lt;/p&gt;</content><category term="presentations"></category><category term="Conference"></category><category term="OSDN"></category><category term="OpenStack"></category></entry><entry><title>Working from home, with little kids in the house</title><link href="https://xahteiwi.eu/blog/2018/02/18/working-from-home-with-little-kids/" rel="alternate"></link><published>2018-02-18T00:00:00+00:00</published><updated>2018-02-18T00:00:00+00:00</updated><author><name>florian</name></author><id>tag:xahteiwi.eu,2018-02-18:/blog/2018/02/18/working-from-home-with-little-kids/</id><summary type="html">&lt;p&gt;I very much prefer working from home to working from an office. But with little kids in the house, that’s a nontrivial endeavor.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I’ve worked exclusively from home&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt; for the last 6½ years, and
when I first started, my older kids were 7 and 6 years old. For the
last 3 years after the arrival of our two younger children, though,
I’ve worked from home &lt;strong&gt;with infants/toddlers in the house,&lt;/strong&gt; and
that’s a wholly different ball game.&lt;/p&gt;
&lt;h2&gt;The basic rules of working from home&lt;/h2&gt;
&lt;p&gt;If you’ve dealt with the idea of working from home, or have
done it before, then you’re surely familiar with a few basic rules to
follow:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Make sure that you have a &lt;em&gt;home office,&lt;/em&gt; that is a working space to
  yourself that allows you to close a door and be undisturbed when you
  need it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set aside some time to go outside. Office workers have a commute
  that ensures they get out of the house; as a home worker you’re
  running a certain risk of turning into a hermit. Make sure you run
  errands, take walks, go for runs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Keep tabs on your working hours. Home workers are frequently at risk
  of working too much or too long, which puts a strain on yourself,
  your significant other, and your family.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Maintain relationships with others who work from home. Chat with
  them, call them, invite them over for dinner if they live close
  by. Working from home is still not a common thing to do in general
  (however common it might be in the tech industry), so exchanging
  thoughts with people in the same boat is a good thing.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Be ready to try out working-from-home strategies that have worked
  for others. Fortunately for all of us, there are quite a few people
  who talk about the experience publicly — for example,
  &lt;a href="https://twitter.com/johndalton"&gt;John Dalton&lt;/a&gt; did so in a
  &lt;a href="https://youtu.be/qFWkDPTjjEM"&gt;45-minute talk&lt;/a&gt; at linux.conf.au
  2018.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Now, the challenging part: &lt;em&gt;little&lt;/em&gt; kids&lt;/h2&gt;
&lt;p&gt;If anyone reading this wants to pre-emptively freak out and berate me
for being an irresponsible or unloving parent, you are politely asked
to chill and if incapable of doing so, to GTFO. I absolutely love
being around my children, and I wouldn’t even &lt;em&gt;think&lt;/em&gt; to trade my job
for an office-dwelling one. Being able to work from home is generally
a wonderful privilege, and so is being around my kids.&lt;/p&gt;
&lt;p&gt;You need to be aware of two things: one, working from home with a
family is different from working from home when you’re alone or living
with an adult partner or roomie. Two, working from home with a family
with little children is &lt;em&gt;very&lt;/em&gt; different from a family with school-age
kids. School-age children don’t permanently need an adult in the room,
they spend a significant amount of their time outside the house,
they’re usually not particularly prone to tantrums, and in the event
that you really, really need some quiet, they can be asked to give you
that for a limited amount of time. Kids under two?  Good luck with
that.&lt;/p&gt;
&lt;p&gt;If you’re not striking a balance here, here’s what’s likely to
happen: you’ll think that you are a completely inadequate parent, or a
terrible employee, or both. So, never lose sight of the fact that
you’re probably a wonderful parent and a highly productive employee —
but that you can do &lt;em&gt;anything,&lt;/em&gt; but not &lt;em&gt;everything.&lt;/em&gt;&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;My most important piece of advice here is that you &lt;strong&gt;should not attempt
to &lt;em&gt;simultaneously&lt;/em&gt; be a primary parent and an employee.&lt;/strong&gt; (Please
note the emphasis on “simultaneously.”)&lt;/p&gt;
&lt;p&gt;I think it’s fundamentally impossible to be a mindful parent of your
kids, and &lt;em&gt;at the same time&lt;/em&gt; a productive knowledge worker. And the
repeated attempt will lead to frustration and burnout. Of course, you
can split your day in half with your significant other, if for example
you happen to be a night owl and they are not, and you can put in a
full day of work between 1pm and 9pm (but do ensure you get enough
sleep, which is probably a topic for another post). Or you could rise
early and start working at 6 while your other half drops your kids off
at daycare, from whence you pick them up at 2. But whatever it is that
you decide, please don’t fool yourself into thinking that you can work
productively, and be a good parent for your kids at the very same
time.&lt;/p&gt;
&lt;h2&gt;Productivity tips during work hours&lt;/h2&gt;
&lt;p&gt;So, we’ve established that work time and parenting time shouldn’t
overlap. So what can you do while you’re at work, and your kids are in
the house (under the supervision of your spouse or partner, or other
trusted guardian)? Spoiler: “please, kids, be quiet for a bit” isn’t
going to work. Not with toddlers. And sound-proofing your room is
quite expensive, and also remarkably ineffective for the deep bass
&lt;em&gt;whooomp&lt;/em&gt; of an exuberant kid jumping off a couch upstairs.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;I find myself being able to focus extremely well if I &lt;strong&gt;play
&lt;a href="https://en.wikipedia.org/wiki/Pink_noise"&gt;pink noise&lt;/a&gt; through my
headphones.&lt;/strong&gt;&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3"&gt;3&lt;/a&gt;&lt;/sup&gt; It drowns out practically all background noise, and
is uniform enough that my brain eventually drops it as an input, and I
barely notice it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I also habitually &lt;strong&gt;close my door&lt;/strong&gt; when I need to work. Obviously, my
family knows that they can call on me when something urgent comes up,
but little kids rightfully take an open door as an invitation. And as
much as I would like to be able to tolerate interruptions of my
thinking flow to play with a little one for a few minutes, and then
immediately pick up where I left off,
&lt;a href="http://heeris.id.au/2013/this-is-why-you-shouldnt-interrupt-a-programmer/"&gt;I am not.&lt;/a&gt;&lt;sup id="fnref:4"&gt;&lt;a class="footnote-ref" href="#fn:4"&gt;4&lt;/a&gt;&lt;/sup&gt;
So, this is a classic trade-off: I can either enjoy the interaction
with my kids and then deal with the frustration that comes with not
getting things done, or I can get things done and regret that I didn’t
spend more time with my kids. There’s no right answer. The wrong
answer that I choose is that my door stays closed.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Striking a balance (or trying to)&lt;/h2&gt;
&lt;p&gt;There are a few things I do to try and balance my in-house family
absence (I’m dead serious, that’s what working from home is):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;When I’m home, &lt;strong&gt;I don’t miss lunch.&lt;/strong&gt;&lt;sup id="fnref:5"&gt;&lt;a class="footnote-ref" href="#fn:5"&gt;5&lt;/a&gt;&lt;/sup&gt; I can’t say that I’ve &lt;em&gt;never&lt;/em&gt;
  missed lunch because I have done so when a customer’s or colleague’s
  environment had just reached the
  &lt;a href="https://en.wikipedia.org/wiki/Halt_and_Catch_Fire"&gt;HCF instruction&lt;/a&gt;,
  but I won’t miss lunch for a meeting that can also be scheduled to
  an hour earlier or later.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Also, &lt;strong&gt;tucking the little ones in&lt;/strong&gt; is my job every night.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;I don’t travel when it would mean being absent for a child’s
  birthday.&lt;/strong&gt; Which is actually not that easy to do when you’re on the
  conference circuit, travel about 100 days per year, and you have a
  big family — thus far, if my math is right I’ve successfully
  navigated 28 kids’ birthdays.&lt;sup id="fnref:6"&gt;&lt;a class="footnote-ref" href="#fn:6"&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Am I succeeding?&lt;/h2&gt;
&lt;p&gt;Let’s be real: &lt;strong&gt;I have no way of knowing.&lt;/strong&gt; Whether I’m being a
decent parent will ultimately be judged by my children when they’ve
grown up. Whether I’ve had a successful career is something I’ll
decide upon my retirement.&lt;/p&gt;
&lt;p&gt;But hey, such is life. And thus far it looks like I don’t
suck at it. I hope. 🙂 &lt;/p&gt;
&lt;hr/&gt;
&lt;h3&gt;Footnotes&lt;/h3&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on my blog on &lt;code&gt;fghaas.github.io&lt;/code&gt; (now defunct).&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Well, not &lt;em&gt;just&lt;/em&gt; from home. Throughout the last few years I’ve
traveled rather extensively, so I’ve also worked from planes,
airport lounges, trains, hotel rooms, customer offices, cafes and
parks. What I mean is that I haven’t had to go to an office on a
daily basis, since 2011. &lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;Hat tip to
&lt;a href="https://en.wikipedia.org/wiki/David_Allen_(author)"&gt;David Allen&lt;/a&gt;,
whose &lt;a href="http://a.co/iZhglcP"&gt;Getting Things Done&lt;/a&gt; is not the
ultimate fount of all self-management wisdom, but definitely a
good source to have read at least once. &lt;a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;On a Linux box with &lt;a href="https://en.wikipedia.org/wiki/SoX"&gt;SoX&lt;/a&gt;,
you can generate an Ogg Vorbis file containing 25 minutes of pink
noise with
&lt;code&gt;sox -n pinknoise.ogg synth 25:00 pinknoise&lt;/code&gt;
— the 25-minute length may come in handy if you’re using
&lt;a href="https://en.wikipedia.org/wiki/Pomodoro_Technique"&gt;Pomodoro&lt;/a&gt;. As
with music, I play my pink noise from
&lt;a href="https://audacious-media-player.org/"&gt;Audacious&lt;/a&gt; with the
&lt;a href="https://specifications.freedesktop.org/mpris-spec/latest/"&gt;MPRIS&lt;/a&gt;-2
plugin enabled, which allows me to pause and play from
&lt;a href="https://wiki.gnome.org/Projects/GnomeShell"&gt;gnome-shell&lt;/a&gt; with the
&lt;a href="https://extensions.gnome.org/extension/55/media-player-indicator/"&gt;Media Player Indicator&lt;/a&gt;
extension. &lt;a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:4"&gt;
&lt;p&gt;I do not consider myself a programmer. But the issue described
in the cartoon applies to any knowledge worker. In fact, it
probably applies to &lt;em&gt;any&lt;/em&gt; worker, it’s just that I’ve been doing
knowledge work for the entirety of my career, and can’t comment
authoritatively on anything else. &lt;a class="footnote-backref" href="#fnref:4" title="Jump back to footnote 4 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:5"&gt;
&lt;p&gt;For those of you who grew up outside central Europe: over here,
lunch (not dinner) is traditionally considered the “big” meal of
the day. &lt;a class="footnote-backref" href="#fnref:5" title="Jump back to footnote 5 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:6"&gt;
&lt;p&gt;I also took uninterrupted travel breaks of 6 and 10 weeks,
respectively, when our younger kids were born. (When the older
ones arrived, I was traveling way less overall, so those travel
schedule adjustments were easy at the time.) &lt;a class="footnote-backref" href="#fnref:6" title="Jump back to footnote 6 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="blog"></category><category term="Philosophy"></category></entry><entry><title>More recommendations for Ceph and OpenStack</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/more-recommendations-ceph-openstack/" rel="alternate"></link><published>2017-08-03T00:00:00+00:00</published><updated>2017-08-03T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2017-08-03:/resources/hints-and-kinks/more-recommendations-ceph-openstack/</id><summary type="html">&lt;p&gt;Our series on best practices for Ceph and OpenStack continues.&lt;/p&gt;</summary><content type="html">&lt;p&gt;A few months ago, we
&lt;a href="https://xahteiwi.eu/resources/hints-and-kinks/dos-donts-ceph-openstack/"&gt;shared our Dos and Don'ts&lt;/a&gt;,
as they relate to Ceph and OpenStack. Since that post has proved quite
popular, here are a few additional considerations for your Ceph-backed
OpenStack cluster.&lt;/p&gt;
&lt;h2&gt;Do configure your images for VirtIO-SCSI&lt;/h2&gt;
&lt;p&gt;By default, RBD-backed Nova instances use the &lt;code&gt;virtio-blk&lt;/code&gt; driver to
expose RBD images to the guest -- either as ephemeral drives, or as
persistent volumes. In this default configuration, VirtIO presents a
virtual PCI device to the guest that represents the paravirtual I/O
bus, and devices are named &lt;code&gt;/dev/vda&lt;/code&gt;, &lt;code&gt;/dev/vdb&lt;/code&gt;, and so
forth. VirtIO block devices are lightweight and efficient, but they
come with a drawback: they don't support the &lt;code&gt;discard&lt;/code&gt; operation.&lt;/p&gt;
&lt;p&gt;Not being able to use &lt;code&gt;discard&lt;/code&gt; means the guest cannot mount a
filesystem with &lt;code&gt;mount -o discard&lt;/code&gt;, and it also cannot clean up freed
blocks on a filesystem with &lt;code&gt;fstrim&lt;/code&gt;. This can be a security concern
for your users, who might want to be able to really, actually &lt;em&gt;delete&lt;/em&gt;
data from within the guest (after overwriting it, presumably). It can
also be an operational concern for you as the cluster operator.&lt;/p&gt;
&lt;p&gt;This is because not supporting &lt;code&gt;discard&lt;/code&gt; also means that RADOS objects
owned by the corresponding RBD image and never &lt;em&gt;removed&lt;/em&gt; during the
image's lifetime -- they persist until the whole image is deleted. So
your cluster may carry the overhead of perhaps tens of thousands of
RADOS objects that no-one actually cares about.&lt;/p&gt;
&lt;p&gt;Thankfully, there is an alternative VirtIO disk driver that &lt;em&gt;does&lt;/em&gt;
support &lt;code&gt;discard&lt;/code&gt;: the paravirtualized VirtIO SCSI controller,
&lt;code&gt;virtio-scsi&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Enabling the VirtIO SCSI controller is something you do by setting a
couple of Glance &lt;strong&gt;image properties,&lt;/strong&gt; namely &lt;code&gt;hw_scsi_model&lt;/code&gt; and
&lt;code&gt;hw_disk_bus&lt;/code&gt;. You do so by running the following &lt;code&gt;openstack&lt;/code&gt; commands
on your image:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;openstack image &lt;span class="nb"&gt;set&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
  --property &lt;span class="nv"&gt;hw_scsi_model&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;virtio-scsi &lt;span class="se"&gt;\&lt;/span&gt;
  --property &lt;span class="nv"&gt;hw_disk_bus&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;scsi &lt;span class="se"&gt;\&lt;/span&gt;
  &amp;lt;name or ID of your image&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, if you boot an instance from this image, you'll see that its
block device names switch from &lt;code&gt;/dev/vdX&lt;/code&gt; to &lt;code&gt;/dev/sdX&lt;/code&gt;, and you also
get everything else you expect from a SCSI stack. For example, there's
&lt;code&gt;/proc/scsi/scsi&lt;/code&gt;, you can extract information about your bus,
controller, and LUs with &lt;code&gt;lsscsi&lt;/code&gt; command, and so on.&lt;/p&gt;
&lt;p&gt;It's important to note that this &lt;em&gt;image&lt;/em&gt; property is inherited by the
&lt;em&gt;instance&lt;/em&gt; booted from that image, which also passes it on to all
&lt;em&gt;volumes&lt;/em&gt; that you may subsequently attach to that instance. Thus,
&lt;code&gt;openstack server add volume&lt;/code&gt; will now add &lt;code&gt;/dev/sdb&lt;/code&gt;, not &lt;code&gt;/dev/vdb&lt;/code&gt;,
and you will automatically get the benefits of &lt;code&gt;discard&lt;/code&gt; on your
volumes, as well.&lt;/p&gt;
&lt;h2&gt;Do set disk I/O limits on your Nova flavors&lt;/h2&gt;
&lt;p&gt;In a Ceph cluster that acts as backing storage for OpenStack,
naturally many OpenStack VMs share the bandwidth and IOPS of your
whole cluster. When that happens, occasionally you may have a VM
that’s very busy (meaning it produces a lot of I/O), which the Ceph
cluster will attempt to process to the best of its abilities. In doing
so, since RBD has no built-in QoS guarantees
(&lt;a href="http://tracker.ceph.com/projects/ceph/wiki/Add_QoS_capacity_to_librbd"&gt;yet&lt;/a&gt;),
it might cause &lt;em&gt;other&lt;/em&gt; VMs to suffer from reduced throughput,
increased latency, or both.&lt;/p&gt;
&lt;p&gt;The trouble with this is that it’s almost impossible for your users to
calculate and reckon with. They’ll see a VM that sustains, say, 10,000
IOPS at times, and then drop to 2,000 with no warning or
explanation. It is much smarter to pre-emptively &lt;em&gt;limit&lt;/em&gt; Ceph RBD
performance from the hypervisor, and luckily, OpenStack Nova
absolutely allows you to do that. This concept is known as &lt;strong&gt;instance
resource quotas&lt;/strong&gt;, and you set them via flavor properties. For
example, an you may want to limit a specific flavor to 1,500 IOPS and
a maximum throughput of 100 MB/s:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;openstack flavor &lt;span class="nb"&gt;set&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
  --property quota:disk_total_bytes_sec&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$((&lt;/span&gt;&lt;span class="m"&gt;100&lt;/span&gt;&amp;lt;&amp;lt;&lt;span class="m"&gt;20&lt;/span&gt;&lt;span class="k"&gt;))&lt;/span&gt;
  --property quota:disk_total_iops_sec&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1500&lt;/span&gt;
  m1.medium
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In the background, these settings are handed through to libvirt and
ultimately fed into cgroup limitations for Qemu/KVM, when a VM with
this flavor spins up. So these limits aren’t specific to RBD, but they
come in particularly handy when dealing with RBD.&lt;/p&gt;
&lt;p&gt;Obviously, since flavors can be public, but can also be limited to
specific tenants, you can set relatively low instance resource quotas
in public flavors, and then make flavors with higher resource quotas
available to select tenants only.&lt;/p&gt;
&lt;h2&gt;Do differentiate Cinder volume types by disk I/O limits&lt;/h2&gt;
&lt;p&gt;In addition to setting I/O limits on flavors for VMs, you can also
influence the I/O characteristics of volumes. You do so by specifying
distinct Cinder volume &lt;em&gt;types&lt;/em&gt;. Volume types are frequently used to
enable users to select a specific Cinder backend — say, to stick
volumes either on a NetApp box or on RBD, but it’s perfectly OK if you
define multiple volume types using the same backend. You can then set
characteristics like maximum IOPS or maximum throughput via Cinder QoS
specifications. A QoS specification akin to the Nova flavor decribed
above — limiting throughput to 100 MB/s and 1,500 IOPS would be
created like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;openstack volume qos create &lt;span class="se"&gt;\&lt;/span&gt;
  --consumer front-end
  --property &lt;span class="nv"&gt;total_bytes_sec&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$((&lt;/span&gt;&lt;span class="m"&gt;100&lt;/span&gt;&amp;lt;&amp;lt;&lt;span class="m"&gt;20&lt;/span&gt;&lt;span class="k"&gt;))&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
  --property &lt;span class="nv"&gt;total_iops_sec&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1500&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
  &lt;span class="s2"&gt;"100MB/s-1500iops"&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You would then create a corresponding volume type, and associate the
QoS spec with it:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;openstack volume &lt;span class="nb"&gt;type&lt;/span&gt; create &lt;span class="se"&gt;\&lt;/span&gt;
  --public &lt;span class="se"&gt;\&lt;/span&gt;
  &lt;span class="s2"&gt;"100MB/s-1500iops"&lt;/span&gt;
openstack volume qos associate &lt;span class="se"&gt;\&lt;/span&gt;
  &lt;span class="s2"&gt;"100MB/s-1500iops"&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
  &lt;span class="s2"&gt;"100MB/s-1500iops"&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Again, as with Nova flavors, you can make volume types public, but you
can also limit them to specific tenants.&lt;/p&gt;
&lt;h2&gt;Don't forget about suspend files&lt;/h2&gt;
&lt;p&gt;When you &lt;strong&gt;suspend&lt;/strong&gt; a Nova/libvirt/KVM instance, what really happens
is what libvirt calls a &lt;strong&gt;managed save&lt;/strong&gt;: the instance's entire memory
is written to a file, and then KVM process shuts down. This is
actually quite neat because it means that the VM does not consume any
CPU cycles nor memory until it restarts, and it will continue right
where it left off, even if the compute node is rebooted in the
interim.&lt;/p&gt;
&lt;p&gt;You should understand that these savefiles are not compressed in any
way: if your instance has 16GB of RAM, that's a 16GB file that
instance suspension drops into &lt;code&gt;/var/lib/nova/save&lt;/code&gt;. This can add up
pretty quickly: if a single compute node hosts something like 10
suspended instances, their combined save file size can easily exceed 
100 GB. Obviously, this can put you in a really bad spot if this fills
up your &lt;code&gt;/var&lt;/code&gt; (or worse, &lt;code&gt;/&lt;/code&gt;) filesystem.&lt;/p&gt;
&lt;p&gt;Of course, if you already have a Ceph cluster, you can put it to good
use here too: just deep-mount a CephFS file system into that
spot. Here's an Ansible playbook snippet that you may use as
inspiration:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nn"&gt;---&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;hosts&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;compute-nodes&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;vars&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;ceph_mons&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;ceph-mon01&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;ceph-mon02&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;ceph-mon03&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;cephfs_client&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;cephfs&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;cephfs_secret&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"{{&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;vaulted_cephfs_secret&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;}}"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;tasks&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"install&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph-fs-common&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;package"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;apt&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;ceph-fs-common&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;state&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;installed&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"create&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;directory"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;dest&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;/etc/ceph&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;owner&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;root&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;group&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;root&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;mode&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;'0755'&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;state&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;directory&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"create&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;cephfs&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;secretfile"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;dest&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;/etc/ceph/cephfs.secret&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;owner&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;root&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;group&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;root&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;mode&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;'0600'&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;content&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;'{{&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;cephfs_secret&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;}}'&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"mount&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;savefile&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;directory"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;mount&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;fstype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;ceph&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;path&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;/var/lib/nova/save&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;src&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"{{&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph_mons&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;|&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;join(',')&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;}}:/nova/save/{{&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;ansible_hostname&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;}}"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;opts&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"name={{&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;cephfs_client&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;}},secretfile=/etc/ceph/cephfs.secret"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;state&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;mounted&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"fix&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;savefile&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;directory&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;ownership"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;path&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;/var/lib/nova/save&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;owner&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;libvirt-qemu&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;group&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;kvm&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;state&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;directory&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;hr/&gt;
&lt;h2&gt;Got more?&lt;/h2&gt;
&lt;p&gt;Do you have Ceph/OpenStack hints of your own? Leave them in the
comments below and we’ll include them in the next installment.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="OpenStack"></category><category term="Ceph"></category></entry><entry><title>Importing an existing Ceph RBD image into Glance</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/importing-rbd-into-glance/" rel="alternate"></link><published>2017-02-17T00:00:00+00:00</published><updated>2017-02-17T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2017-02-17:/resources/hints-and-kinks/importing-rbd-into-glance/</id><summary type="html">&lt;p&gt;As an OpenStack/Ceph operator, you may sometimes want to forgo uploading a new image using the Glance API, because the process can be inefficient and time-consuming. Here's a faster way.&lt;/p&gt;</summary><content type="html">&lt;p&gt;The normal process of uploading an image into Glance is
straightforward: you use &lt;code&gt;glance image-create&lt;/code&gt; or &lt;code&gt;openstack image
create&lt;/code&gt;, or the Horizon dashboard. Whichever process you choose, you
select a local file, which you upload into the Glance image store.&lt;/p&gt;
&lt;p&gt;This process can be unpleasantly time-consuming when your Glance
service is backed with Ceph RBD, for a practical reason. When using
the &lt;code&gt;rbd&lt;/code&gt; image store, you're expected to use &lt;code&gt;raw&lt;/code&gt; images, which have
interesting characteristics.&lt;/p&gt;
&lt;h2&gt;Raw images and sparse files&lt;/h2&gt;
&lt;p&gt;Most people will take an existing vendor cloud image, which is
typically available in the &lt;code&gt;qcow2&lt;/code&gt; format, and convert it using the
&lt;code&gt;qemu-img&lt;/code&gt; utility, like so:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ wget -O ubuntu-xenial.qcow2 &lt;span class="se"&gt;\&lt;/span&gt;
  https://cloud-images.ubuntu.com/xenial/current/xenial-server-cloudimg-amd64-disk1.img
$ qemu-img convert -p -f qcow2 -O raw ubuntu-xenial.qcow2 ubuntu-xenial.raw
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;On face value, the result looks innocuous enough:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ qemu-img info ubuntu-xenial.qcow2 
image: ubuntu-xenial.qcow2
file format: qcow2
virtual size: &lt;span class="m"&gt;2&lt;/span&gt;.2G &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;2361393152&lt;/span&gt; bytes&lt;span class="o"&gt;)&lt;/span&gt;
disk size: 308M
cluster_size: &lt;span class="m"&gt;65536&lt;/span&gt;
Format specific information:
    compat: &lt;span class="m"&gt;0&lt;/span&gt;.10
    refcount bits: &lt;span class="m"&gt;16&lt;/span&gt;

$ qemu-img info ubuntu-xenial.raw
image: ubuntu-xenial.raw
file format: raw
virtual size: &lt;span class="m"&gt;2&lt;/span&gt;.2G &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;2361393152&lt;/span&gt; bytes&lt;span class="o"&gt;)&lt;/span&gt;
disk size: 1000M
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As you can see, in both cases the virtual image size differs starkly
from the actual file size. In &lt;code&gt;qcow2&lt;/code&gt;, this is due to the
copy-on-write nature of the file format and zlib compression; for the
&lt;code&gt;raw&lt;/code&gt; image, we're dealing with a sparse file:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ ls -lh ubuntu-xenial.qcow2
-rw-rw-r-- &lt;span class="m"&gt;1&lt;/span&gt; florian florian 308M Feb &lt;span class="m"&gt;17&lt;/span&gt; &lt;span class="m"&gt;10&lt;/span&gt;:05 ubuntu-xenial.qcow2
$ du -h  ubuntu-xenial.qcow2
308M    ubuntu-xenial.qcow2
$ ls -lh info ubuntu-xenial.raw
-rw-r--r-- &lt;span class="m"&gt;1&lt;/span&gt; florian florian &lt;span class="m"&gt;2&lt;/span&gt;.2G Feb &lt;span class="m"&gt;17&lt;/span&gt; &lt;span class="m"&gt;10&lt;/span&gt;:16 ubuntu-xenial.raw
$ du -h  ubuntu-xenial.raw
1000M   ubuntu-xenial.raw
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So, while the &lt;code&gt;qcow2&lt;/code&gt; file's physical and logical sizes match, the
&lt;code&gt;raw&lt;/code&gt; file looks much larger in terms of filesystem metadata, as
opposed to its actual storage utilization. That's because in a sparse
file, "holes" (essentially, sequences of null bytes) aren't actually
written to the filesystem. Instead, the filesystems just records the
position and length of each "hole", and when we read from the "holes"
in the file, the read would just return null bytes again.&lt;/p&gt;
&lt;p&gt;The trouble with sparse files is that RESTful web services, like
Glance, don't know too much about them. So, if we were to import that
raw file with &lt;code&gt;openstack image-create --file my_cloud_image.raw&lt;/code&gt;, the
command line client would upload null bytes with happy abandon, which
would greatly lengthen the process.&lt;/p&gt;
&lt;h2&gt;Importing images into RBD with &lt;code&gt;qemu-img convert&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Luckily for us, &lt;code&gt;qemu-img&lt;/code&gt; also allows us to upload &lt;em&gt;directly&lt;/em&gt; into
RBD. All you need to do is make sure the image goes into the correct
pool, and is reasonably named. Glance names uploaded images by their
image ID, which is a universally unique identifier (UUID), so let's
follow Glance's precedent.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;IMAGE_ID&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;uuidgen&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;POOL&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"glance-images"&lt;/span&gt;  &lt;span class="c1"&gt;# replace with your Glance pool name&lt;/span&gt;

qemu-img convert &lt;span class="se"&gt;\&lt;/span&gt;
  -f qcow2 -O raw &lt;span class="se"&gt;\&lt;/span&gt;
  my_cloud_image.raw &lt;span class="se"&gt;\&lt;/span&gt;
  rbd:&lt;span class="nv"&gt;$POOL&lt;/span&gt;/&lt;span class="nv"&gt;$IMAGE_ID&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Creating the clone baseline snapshot&lt;/h2&gt;
&lt;p&gt;Glance expects a snapshot named &lt;code&gt;snap&lt;/code&gt; to exist on any image that is
subsequently cloned by Cinder or Nova, so let's create that as
well:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;rbd snap create &lt;span class="nv"&gt;$POOL&lt;/span&gt;/&lt;span class="nv"&gt;$IMAGE_ID&lt;/span&gt;@snap
rbd snap protect &lt;span class="nv"&gt;$POOL&lt;/span&gt;/&lt;span class="nv"&gt;$IMAGE_ID&lt;/span&gt;@snap
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Making Glance aware of the image&lt;/h2&gt;
&lt;p&gt;Finally, we can let Glance know about this image. Now, there's a catch
to this: this trick &lt;em&gt;only&lt;/em&gt; works with the Glance v1 API, and thus you
&lt;em&gt;must&lt;/em&gt; use the &lt;code&gt;glance&lt;/code&gt; client to do it. Your Glance is v2 only?
Sorry. Insist on using the &lt;code&gt;openstack&lt;/code&gt; client? Out of luck.&lt;/p&gt;
&lt;p&gt;What's special about this invocation of the &lt;code&gt;glance&lt;/code&gt; client are simply
the pre-populated &lt;code&gt;location&lt;/code&gt; and &lt;code&gt;id&lt;/code&gt; fields. The &lt;code&gt;location&lt;/code&gt; is composed of the following segments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the fixed string &lt;code&gt;rbd://&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;your Ceph cluster UUID (you get this from &lt;code&gt;ceph fsid&lt;/code&gt;),&lt;/li&gt;
&lt;li&gt;a forward slash (&lt;code&gt;/&lt;/code&gt;),&lt;/li&gt;
&lt;li&gt;the name of the pool that the image is stored in,&lt;/li&gt;
&lt;li&gt;the name of your image (which you previously created with &lt;code&gt;uuidgen&lt;/code&gt;),&lt;/li&gt;
&lt;li&gt;another forward slash (&lt;code&gt;/&lt;/code&gt;, not &lt;code&gt;@&lt;/code&gt; as you might expect),&lt;/li&gt;
&lt;li&gt;and finally, the name of your snapshot (&lt;code&gt;snap&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Other than that, the &lt;code&gt;glance&lt;/code&gt; client invocation is pretty
straightforward for a v1 API call:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;CLUSTER_ID&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;ceph fsid&lt;span class="sb"&gt;`&lt;/span&gt;
glance --os-image-api-version &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
  image-create &lt;span class="se"&gt;\&lt;/span&gt;
  --disk-format raw &lt;span class="se"&gt;\&lt;/span&gt;
  --id &lt;span class="nv"&gt;$IMAGE_ID&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
  --location rbd://&lt;span class="nv"&gt;$CLUSTER_ID&lt;/span&gt;/&lt;span class="nv"&gt;$POOL&lt;/span&gt;/&lt;span class="nv"&gt;$IMAGE_ID&lt;/span&gt;/snap
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Of course, you might add other options, like &lt;code&gt;--private&lt;/code&gt; or
&lt;code&gt;--protected&lt;/code&gt; or &lt;code&gt;--name&lt;/code&gt;, but the above options are the bare minimum.&lt;/p&gt;
&lt;h2&gt;And that's it!&lt;/h2&gt;
&lt;p&gt;Now you can happily fire up VMs, or clone your image into a volume and
fire a VM up from that.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Ceph"></category><category term="OpenStack"></category></entry><entry><title>Replacing the built-in Open edX forum with a suitable alternative</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/replace-edx-forum/" rel="alternate"></link><published>2017-02-02T00:00:00+00:00</published><updated>2017-02-02T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2017-02-02:/resources/hints-and-kinks/replace-edx-forum/</id><summary type="html">&lt;p&gt;Open edX comes with a built-in
&lt;a href="http://edx.readthedocs.io/projects/open-edx-building-and-running-a-course/en/latest/manage_live_course/discussions.html"&gt;discussion forum&lt;/a&gt;
service. Many Open edX users find this service less than optimal: it
is the only edX service to require Ruby, it depends on a Ruby version
that is outdated and
&lt;a href="https://github.com/edx/configuration/issues/3589"&gt;no longer receives security updates (although a fix for that is on …&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Open edX comes with a built-in
&lt;a href="http://edx.readthedocs.io/projects/open-edx-building-and-running-a-course/en/latest/manage_live_course/discussions.html"&gt;discussion forum&lt;/a&gt;
service. Many Open edX users find this service less than optimal: it
is the only edX service to require Ruby, it depends on a Ruby version
that is outdated and
&lt;a href="https://github.com/edx/configuration/issues/3589"&gt;no longer receives security updates (although a fix for that is on the way),&lt;/a&gt;
it and generally feels like overkill to many users.&lt;/p&gt;
&lt;p&gt;Thankfully, since the Open edX Eucalyptus release it's been quite easy
to replace the course forum with an alternative. Here at hastexo,
we're fans of &lt;a href="//www.disqus.com"&gt;Disqus&lt;/a&gt; (you may have noticed we also
use it around out web site), so let's see what we can do to drop the
Open edX Forum and replace it with Disqus.&lt;/p&gt;
&lt;h2&gt;Step 1: Locate your course's &lt;code&gt;policy.json&lt;/code&gt; file&lt;/h2&gt;
&lt;p&gt;If you keep your course materials in Git or some other
version-controlled repository, you'll already be familiar with the
&lt;a href="http://edx.readthedocs.io/projects/edx-open-learning-xml/en/latest/directory-structure.html#olx-and-directory-file-structures"&gt;directory structure of an OLX course tree.&lt;/a&gt;
If you're not,
&lt;a href="http://help.appsembler.com/article/157-how-to-export-and-import-a-course"&gt;just use edX Studio&lt;/a&gt;
to export your course into a compressed archive, download it, and
extract it on your local machine.&lt;/p&gt;
&lt;p&gt;Locate the &lt;code&gt;policies/_base&lt;/code&gt; directory. Find the &lt;code&gt;policy.json&lt;/code&gt; file
located therein. It might look like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="s2"&gt;"course/201702"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s2"&gt;"language"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"en"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s2"&gt;"invitation_only"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s2"&gt;"start"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"2017-02-01T00:00:00Z"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s2"&gt;"advertised_start"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"2017-02-01T00:00:00Z"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s2"&gt;"end"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"2017-02-28T23:59:59Z"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s2"&gt;"is_new"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s2"&gt;"catalog_visibility"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"both"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s2"&gt;"max_student_enrollments_allowed"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s2"&gt;"due"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s2"&gt;"giturl"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s2"&gt;"course_image"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"images_course_image.jpg"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s2"&gt;"advanced_modules"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"hastexo"&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s2"&gt;"hide_from_toc"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s2"&gt;"ispublic"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s2"&gt;"rerandomize"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"never"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s2"&gt;"show_calculator"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s2"&gt;"showanswer"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"attempted"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s2"&gt;"days_early_for_beta"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s2"&gt;"discussion_topics"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="s2"&gt;"General"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"id"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"i4x-hastexo-hx212-course-201702"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s2"&gt;"tabs"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"Courseware"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"type"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"courseware"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"Course Info"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"type"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"course_info"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"Textbooks"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"type"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"textbooks"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"Discussion"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"type"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"discussion"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"Wiki"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"type"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"wiki"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"Progress"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"type"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"progress"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note the &lt;code&gt;tabs&lt;/code&gt; list. It contains the list of course tabs
(&lt;a href="http://edx.readthedocs.io/projects/edx-partner-course-staff/en/latest/course_assets/pages.html"&gt;which edX Studio, confusingly, calls "pages"&lt;/a&gt;).&lt;/p&gt;
&lt;h2&gt;Step 2: Remove the default Discussion tab&lt;/h2&gt;
&lt;p&gt;You can now edit &lt;code&gt;policy.json&lt;/code&gt;, and drop the &lt;code&gt;Discussion&lt;/code&gt; entry from
the &lt;code&gt;tabs&lt;/code&gt; list, to make it look like so:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s2"&gt;"tabs"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"Courseware"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"type"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"courseware"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"Course Info"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"type"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"course_info"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"Textbooks"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"type"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"textbooks"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"Wiki"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"type"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"wiki"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"Progress"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"type"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"progress"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Maybe you also want to remove the course wiki. Just keep whichever
tabs you'd like to keep.&lt;/p&gt;
&lt;h2&gt;Step 3: Add a "static" tab&lt;/h2&gt;
&lt;p&gt;In place of the old &lt;code&gt;Discussion&lt;/code&gt; tab (which, you may have noticed, was
of a special type conspicuously named &lt;code&gt;discussion&lt;/code&gt;), you can now put a
tab of different, simpler type: &lt;code&gt;static_tab&lt;/code&gt;. Like so:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s2"&gt;"tabs"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"Courseware"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"type"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"courseware"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"Course Info"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"type"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"course_info"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"Textbooks"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"type"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"textbooks"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"Discussion"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"type"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"static_tab"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"url_slug"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"discussion"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"Wiki"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"type"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"wiki"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"Progress"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s2"&gt;"type"&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"progress"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that a &lt;code&gt;static_tab&lt;/code&gt; type tab also requires a value
&lt;code&gt;url_slug&lt;/code&gt;. What's that one about, you ask?&lt;/p&gt;
&lt;h2&gt;Step 4: add static content&lt;/h2&gt;
&lt;p&gt;Whatever you put into &lt;code&gt;url_slug&lt;/code&gt; tells Open edX to go look into the
&lt;code&gt;tabs&lt;/code&gt; subdirectory of your course root, and find a properly named
file there. In our case, that file needs to be named
&lt;code&gt;discussion.html&lt;/code&gt;, because we defined &lt;code&gt;"url_slug": "discussion"&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;So, head over to Disqus and grab the generated code from there, and
then stick it into &lt;code&gt;tabs/discussion.html&lt;/code&gt;. Something like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt; &lt;span class="na"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"disqus_thread"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;script&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;&lt;span class="c1"&gt;// &amp;lt;![CDATA[&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;function&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;// DON'T EDIT BELOW THIS LINE&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="kd"&gt;var&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;d&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;s&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;d&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;createElement&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'script'&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nx"&gt;s&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;src&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;'//&amp;lt;your Disqus site domain name&amp;gt;/embed.js'&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nx"&gt;s&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;setAttribute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'data-timestamp'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="ow"&gt;new&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;Date&lt;/span&gt;&lt;span class="p"&gt;());&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;d&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;head&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;||&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;d&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;body&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;appendChild&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nx"&gt;s&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;})();&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;// ]]&amp;gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;script&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;noscript&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;Please enable JavaScript to view the &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"https://disqus.com/?ref_noscript"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;comments powered by Disqus.&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;noscript&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;p&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Step 5: deploy&lt;/h2&gt;
&lt;p&gt;Re-compress your tarball,
&lt;a href="http://edx.readthedocs.io/projects/edx-partner-course-staff/en/latest/course_assets/pages.html"&gt;upload to Studio&lt;/a&gt;
or run
&lt;a href="https://openedx.atlassian.net/wiki/display/OpenOPS/Managing+OpenEdX+Tips+and+Tricks#ManagingOpenEdXTipsandTricks-manage.pycommands"&gt;&lt;code&gt;manage.py import&lt;/code&gt;,&lt;/a&gt;
and you're done!&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Open edX"></category></entry><entry><title>The Dos and Don'ts for Ceph for OpenStack</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/dos-donts-ceph-openstack/" rel="alternate"></link><published>2016-11-28T00:00:00+00:00</published><updated>2016-11-28T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2016-11-28:/resources/hints-and-kinks/dos-donts-ceph-openstack/</id><summary type="html">&lt;p&gt;Ceph and OpenStack are an extremely useful and
&lt;a href="https://www.openstack.org/assets/survey/April-2016-User-Survey-Report.pdf"&gt;highly popular&lt;/a&gt;
combination. Still, new Ceph/OpenStack deployments frequently come
with easily avoided shortcomings — we'll help you fix them!&lt;/p&gt;
&lt;!--break--&gt;
&lt;h2&gt;Do use &lt;code&gt;show_image_direct_url&lt;/code&gt; and the Glance v2 API&lt;/h2&gt;
&lt;p&gt;With Ceph RBD (RADOS Block Device), you have the ability to create
&lt;strong&gt;clones.&lt;/strong&gt; You can …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Ceph and OpenStack are an extremely useful and
&lt;a href="https://www.openstack.org/assets/survey/April-2016-User-Survey-Report.pdf"&gt;highly popular&lt;/a&gt;
combination. Still, new Ceph/OpenStack deployments frequently come
with easily avoided shortcomings — we'll help you fix them!&lt;/p&gt;
&lt;!--break--&gt;
&lt;h2&gt;Do use &lt;code&gt;show_image_direct_url&lt;/code&gt; and the Glance v2 API&lt;/h2&gt;
&lt;p&gt;With Ceph RBD (RADOS Block Device), you have the ability to create
&lt;strong&gt;clones.&lt;/strong&gt; You can think of clones as the writable siblings of
&lt;em&gt;snapshots&lt;/em&gt; (which are read-only). A clone creates RADOS objects only
for those parts of your block device which have been modified relative
to its parent snapshot, and this means two things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;You save space. That's a no-brainer, but in and of itself it's not
   a very compelling argument as storage space is one of the cheapest
   things in a distributed system.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;What's &lt;em&gt;not&lt;/em&gt; been modified in the clone can be served from the
   original volume. This is important because, of course, it means you
   are effectively hitting the same RADOS objects — and thus, the
   same OSDs — no matter which clone you're talking to. And that, in
   turn, means, those objects are likely to be served from the
   respective OSD's page caches, in other words, from RAM. RAM is way
   faster to access than any persistent storage device, so being able
   to serve lots of reads from the page cache is good. That, in turn,
   means, that serving data from a clone will be faster than serving
   the same data from a full copy of a volume.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Both Cinder (when creating a volume from an image) and Nova (when
serving ephemeral disks from Ceph) will make use of cloning RBD images
in the Ceph backend, and will do so automatically. But they will do so
only if &lt;code&gt;show_image_direct_url=true&lt;/code&gt; is set in &lt;code&gt;glance‑api.conf&lt;/code&gt;, and
they are configured to connect to Glance using the Glance v2
API. &lt;a href="http://docs.ceph.com/docs/jewel/rbd/rbd-openstack/#any-openstack-version"&gt;So do both.&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Do set &lt;code&gt;libvirt/images_type = rbd&lt;/code&gt; on Nova compute nodes&lt;/h2&gt;
&lt;p&gt;In Nova (using the libvirt compute driver with KVM), you have several
options of storing ephemeral disk images, that is, storage for any VM
that is &lt;em&gt;not&lt;/em&gt; booted from a Cinder volume. You do so by setting the
&lt;code&gt;images_type&lt;/code&gt; option in the &lt;code&gt;[libvirt]&lt;/code&gt; section in
&lt;code&gt;nova‑compute.conf&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;[libvirt]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;images_type&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;lt;type&amp;gt;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The default type is &lt;code&gt;disk&lt;/code&gt;, which means that when you fire up a new
VM, the following events occur:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;nova‑compute&lt;/code&gt; on your hypervisor node connects to the Glance API,
  looks up the desired image, and downloads the image to your compute
  node (into the &lt;code&gt;/var/lib/nova/instances/_base&lt;/code&gt; directory by
  default).&lt;/li&gt;
&lt;li&gt;It then creates a new qcow2 file which uses the downloaded image as
  its backing file.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This process uses up a fair amount of space on your compute nodes,
and can quite seriously delay spawning a new VM if it has been
scheduled to a host that hasn't downloaded the desired image
before. It also makes it impossible for such a VM to be live-migrated
to another host without downtime.&lt;/p&gt;
&lt;p&gt;Flipping &lt;code&gt;images_type&lt;/code&gt; to &lt;code&gt;rbd&lt;/code&gt; means the disk lives in the RBD
backend, as an RBD clone of the original image, and can be created
instantaneously. No delay on boot, no wasting space, all the benefits
of
clones. &lt;a href="http://docs.ceph.com/docs/jewel/rbd/rbd-openstack/#id2"&gt;Use it.&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Do enable RBD caching on Nova compute nodes&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;librbd&lt;/code&gt;, the library that underpins the Qemu/KVM RBD storage driver,
can enable a disk cache that uses the hypervisor host's RAM for
caching purposes. You should use this.&lt;/p&gt;
&lt;p&gt;Yes, it's a cache that is safe to use. On the one hand, the
combination of &lt;code&gt;virtio-blk&lt;/code&gt; with the Qemu RBD storage driver &lt;strong&gt;will&lt;/strong&gt;
properly honor disk flushes. That is to say, when an application
inside your VM says "I want this data on disk now," then &lt;code&gt;virtio‑blk&lt;/code&gt;,
Qemu, and Ceph will all work together to only report the write as
complete when it has been&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;written to the primary OSD,&lt;/li&gt;
&lt;li&gt;replicated to the available replica OSDs,&lt;/li&gt;
&lt;li&gt;acknowledged to have hit at least the persistent journal on all OSDs.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition, Ceph RBD has an intelligent safeguard in place: even if
it is configured to cache in write-back mode, &lt;em&gt;it will refuse to do
so&lt;/em&gt; (meaning, it will operate in write-through mode) until it has
received the first flush request from its user. Thus, if you run a VM
that just never does that — because it has been misconfigured or its
guest OS is just ages old — then RBD will stubbornly refuse to cache
any writes. The corresponding RBD option is called
&lt;a href="http://docs.ceph.com/docs/jewel/rbd/rbd-config-ref/#cache-settings"&gt;&lt;code&gt;rbd cache writethrough until flush&lt;/code&gt;&lt;/a&gt;,
it defaults to &lt;code&gt;true&lt;/code&gt; and you should never disable it.&lt;/p&gt;
&lt;p&gt;You can enable writeback caching for Ceph by setting the following
&lt;code&gt;nova-compute&lt;/code&gt; configuration option:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;[libvirt]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;images_type&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;rbd&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;...&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;disk_cachemodes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"network=writeback"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And you just should.&lt;/p&gt;
&lt;h2&gt;Do use separate pools for images, volumes, and ephemeral disks&lt;/h2&gt;
&lt;p&gt;Now that you have enabled &lt;code&gt;show_image_direct_url=true&lt;/code&gt; in Glance,
configured Cinder and &lt;code&gt;nova-compute&lt;/code&gt; to talk to Glance using the v2
API, and configured &lt;code&gt;nova-compute&lt;/code&gt; with &lt;code&gt;libvirt/images_type=rbd&lt;/code&gt;, all
your VMs and volumes will be using RBD clones. Clones can span
multiple RADOS pools, meaning you can have an RBD image (and its
snapshots) in one pool, and its clones in another.&lt;/p&gt;
&lt;p&gt;You should do exactly that, for several reasons:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Separate pools means you can lock down access to those pools
   separately. This is just a standard threat mitigation approach: if
   your &lt;code&gt;nova-compute&lt;/code&gt; node gets compromised and the attacker can
   corrupt or delete ephemeral disks, then that's bad — but it would
   be &lt;em&gt;worse&lt;/em&gt; if they could also corrupt your Glance images.&lt;/li&gt;
&lt;li&gt;Separate pools also means that you can have different pool
   settings, such as the settings for &lt;code&gt;size&lt;/code&gt; or &lt;code&gt;pg_num&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Most importantly, separate pools can use separate &lt;code&gt;crush_ruleset&lt;/code&gt;
   settings. We'll get back to this in a second, it'll come in handy
   shortly.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;It's common to have three different pools: one for your Glance images
(usually named &lt;code&gt;glance&lt;/code&gt; or &lt;code&gt;images&lt;/code&gt;), one for your Cinder volumes
(&lt;code&gt;cinder&lt;/code&gt; or &lt;code&gt;volumes&lt;/code&gt;), and one for your VMs (&lt;code&gt;nova-compute&lt;/code&gt; or
&lt;code&gt;vms&lt;/code&gt;).&lt;/p&gt;
&lt;h2&gt;Don't necessarily use SSDs for your Ceph OSD journals&lt;/h2&gt;
&lt;p&gt;Of the recommendations in this article, this one will probably be the
one that surprises the most people. Of course, conventional wisdom
holds that you should &lt;em&gt;always&lt;/em&gt; put your OSD journals on fast OSDs, and
that you should deploy SSDs and spinners in a 1:4 to 1:6 ratio, right?&lt;/p&gt;
&lt;p&gt;Let's take a look. Suppose you're following the 1:6 approach, and your
SATA spinners are capable of writing at 100 MB/s. 6 spinners make 6
OSDs, and each OSD uses a journal device that's on a partition on an
enterprise SSD. Suppose further that the SSD is capable of writing at
500 MB/s.&lt;/p&gt;
&lt;p&gt;Congratulations, in that scenario you've just made your SSD your
bottleneck. While you would be able to hit your OSDs at 600 MB/s on
aggregate, your SSD limits you to about 83% of that.&lt;/p&gt;
&lt;p&gt;In that scenario you &lt;em&gt;would&lt;/em&gt; actually be fine with a 1:4 ratio, but
make your spindles just a little faster and the SSD advantage goes out
the window again.&lt;/p&gt;
&lt;p&gt;Now, of course, do consider the alternative: if you're putting your
journals on the same drive as your OSD filestores, then you
effectively get only half the nominal bandwidth of your drive, on
average, because you write everything twice, to the same device. So
that means that &lt;em&gt;without&lt;/em&gt; SSDs, your effective spinner bandwidth is
only about 50 MB/s, so the &lt;em&gt;total&lt;/em&gt; bandwidth you get out of 6 drives
that way is more like 300 MB/s, against which 500 MB/s is still a
substantial improvement.&lt;/p&gt;
&lt;p&gt;So you will need to plug your own numbers into this, and make your own
evaluation for price &lt;em&gt;and&lt;/em&gt; performance. Just don't assume that journal
SSD will be a panacea, or that it's always a good idea to use them.&lt;/p&gt;
&lt;h2&gt;Do create all-flash OSDs&lt;/h2&gt;
&lt;p&gt;One thing your journal SSDs don't help with are reads. So, what can you
do to take advantage of SSDs on reads, too?&lt;/p&gt;
&lt;p&gt;Make them OSDs. That is, not OSD &lt;em&gt;journals,&lt;/em&gt; but actual OSDs with a
filestore &lt;em&gt;and&lt;/em&gt; journal. What this will create are OSDs that don't
just write fast, but read fast, too.&lt;/p&gt;
&lt;h2&gt;Do put your all-flash OSDs into a separate CRUSH root&lt;/h2&gt;
&lt;p&gt;Assuming you don't run on all-flash hardware, but operate a
cost-effective mixed cluster where some OSDs are spinners and others
are SSDs (or NVMe devices or whatever), you obviously want to treat
those OSDs separately. The simplest and easiest way to do that is to
create a separate CRUSH &lt;code&gt;root&lt;/code&gt; in addition to the normally configured
&lt;code&gt;default&lt;/code&gt; root.&lt;/p&gt;
&lt;p&gt;For example, you could set up your CRUSH hierarchy as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ID WEIGHT  TYPE NAME         UP/DOWN REWEIGHT PRIMARY-AFFINITY
- 
-1 4.85994 root default
-2 1.61998     host elk
 0 0.53999         osd.0          up  1.00000          1.00000 
 1 0.53999         osd.1          up  1.00000          1.00000 
 2 0.53999         osd.2          up  1.00000          1.00000 
-3 1.61998     host moose
 3 0.53999         osd.3          up  1.00000          1.00000 
 4 0.53999         osd.4          up  1.00000          1.00000 
 5 0.53999         osd.5          up  1.00000          1.00000 
-4 1.61998     host reindeer
 6 0.53999         osd.6          up  1.00000          1.00000 
 7 0.53999         osd.7          up  1.00000          1.00000 
 8 0.53999         osd.8          up  1.00000          1.00000
-5 4.85994 root highperf
-6 1.61998     host elk-ssd
 9 0.53999         osd.9          up  1.00000          1.00000 
10 0.53999         osd.10         up  1.00000          1.00000 
11 0.53999         osd.11         up  1.00000          1.00000 
-7 1.61998     host moose-ssd
12 0.53999         osd.12         up  1.00000          1.00000 
13 0.53999         osd.13         up  1.00000          1.00000 
14 0.53999         osd.14         up  1.00000          1.00000 
-8 1.61998     host reindeer-ssd
15 0.53999         osd.15         up  1.00000          1.00000 
16 0.53999         osd.16         up  1.00000          1.00000 
17 0.53999         osd.17         up  1.00000          1.00000
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In the example above, OSDs 0-8 are assigned to the &lt;code&gt;default&lt;/code&gt; root,
whereas OSDs 9-17 (our SSDs) belong to the root &lt;code&gt;highperf&lt;/code&gt;. We can now
create two separate CRUSH rulesets:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;rule replicated_ruleset {
    ruleset 0
    type replicated
    min_size 1
    max_size 10
    step take default
    step chooseleaf firstn 0 type host
    step emit
}

rule highperf_ruleset {
    ruleset 1
    type replicated
    min_size 1
    max_size 10
    step take highperf
    step chooseleaf firstn 0 type host
    step emit
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The default ruleset, &lt;code&gt;replicated_ruleset&lt;/code&gt;, picks OSDs from the
&lt;code&gt;default&lt;/code&gt; root, whereas &lt;code&gt;step take highperf&lt;/code&gt; in &lt;code&gt;highperf_ruleset&lt;/code&gt;
means it covers only OSDs in the &lt;code&gt;highperf&lt;/code&gt; root.&lt;/p&gt;
&lt;h2&gt;Do assign individual pools to your all-flash ruleset&lt;/h2&gt;
&lt;p&gt;Assigning individual pools to a new CRUSH ruleset (and hence, to a
whole different set of OSDs) is a matter of issuing a single command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ceph osd pool set &amp;lt;name&amp;gt; crush_ruleset &amp;lt;number&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;... where &lt;code&gt;&amp;lt;name&amp;gt;&lt;/code&gt; name of your pool and &lt;code&gt;&amp;lt;number&amp;gt;&lt;/code&gt; is the numerical
ID of your ruleset as per your CRUSH map. You can do this while the
pool is online, and while clients are accessing its data — although
of course, there will be a lot of remapping and backfilling so your
overall performance may be affected somewhat.&lt;/p&gt;
&lt;p&gt;Now, the assumption is that you will have more spinner storage than
SSD storage. Thus, you will want to select individual pools for your
all-flash OSDs. Here are a handful of pools that might come in handy
as first candidates to migrate to all-flash. You can interpret the
list below as a priority list: as you add more SSD capacity to your
cluster, you can move pools over to all-flash storage one by one.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Nova ephemeral RBD pools (&lt;code&gt;vms&lt;/code&gt;, &lt;code&gt;nova-compute&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;radosgw bucket indexes (&lt;code&gt;.rgw.buckets.index&lt;/code&gt; and friends)
   — if you're using radosgw as your drop-in OpenStack Swift
   replacement&lt;/li&gt;
&lt;li&gt;Cinder volume pools (&lt;code&gt;cinder&lt;/code&gt;, &lt;code&gt;volumes&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;radosgw data pools (&lt;code&gt;.rgw.buckets&lt;/code&gt; and friends) — if you need
   low-latency reads and writes on Swift storage&lt;/li&gt;
&lt;li&gt;Glance image pools (&lt;code&gt;glance&lt;/code&gt;, &lt;code&gt;images&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Cinder backup pools (&lt;code&gt;cinder-backup&lt;/code&gt;) — usually the last pool to
   convert to all-flash OSDs.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Do designate some non-Ceph compute hosts with low-latency local storage&lt;/h2&gt;
&lt;p&gt;Now, there will undoubtedly be some applications where Ceph does not
produce the latency you desire. Or, for that matter, &lt;em&gt;any&lt;/em&gt;
network-based storage. That's just a direct consequence of recent
developments in storage and network technology.&lt;/p&gt;
&lt;p&gt;Just a few years ago, the average latency of a single-sector uncached
write to a block device was on the order of a millisecond, or 1,000
microseconds (µs). In contrast, the latency incurred on a TCP packet
carrying a 512-byte (1-sector) payload was about 50 µs, which makes
for a 100-µs round trip. All in all, the &lt;em&gt;additional&lt;/em&gt; latency incurred
from writing to a device over the network, as opposed to locally, was
approximately 10%.&lt;/p&gt;
&lt;p&gt;In the interim, a single-sector write for a device of the same price
is itself about 100 µs, tops, with some reasonably-priced devices down
to about 40 µs. Network latency, in contrast, hasn't changed all that
much — going down about 20% from Gigabit Ethernet to 10 GbE.&lt;/p&gt;
&lt;p&gt;So even going to a single, un-replicated SSD device over the network
will now be 40 + 80 = 120 µs latency, vs. just 40 µs locally. That's
not a 10% overhead anymore, that's a whopping &lt;em&gt;factor&lt;/em&gt; of 3.&lt;/p&gt;
&lt;p&gt;With Ceph, that gets worse. Ceph writes data multiple times, first to
the primary OSD, then (in parallel) to all replicas. So in contrast to
a single-sector write at 40 µs, we now incur a latency of at least two
writes, &lt;em&gt;plus&lt;/em&gt; two network round-trips, to that's 40 x 2 + 80 x 2 =
240 µs, &lt;em&gt;six times&lt;/em&gt; the local write latency.&lt;/p&gt;
&lt;p&gt;The good news is, &lt;em&gt;most&lt;/em&gt; applications don't care about this sort of
latency overhead, because they're not latency-critical at all. The bad
news is, &lt;em&gt;some&lt;/em&gt; will.&lt;/p&gt;
&lt;p&gt;So, should you ditch Ceph because of that? Nope. But do consider
adding a handful of compute nodes that are &lt;em&gt;not&lt;/em&gt; configured with
&lt;code&gt;libvirt/images_type=rbd&lt;/code&gt;, but that use local disk images instead. Roll
those hosts into a
&lt;a href="http://docs.openstack.org/admin-guide/dashboard-manage-host-aggregates.html"&gt;host aggregate,&lt;/a&gt;
and map them to a specific flavor. Recommend to your users that they
use that flavor for low-latency applications.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="OpenStack"></category><category term="Ceph"></category></entry><entry><title>High Availability and Disaster Recovery in OpenStack</title><link href="https://xahteiwi.eu/resources/presentations/high-availability-and-disaster-recovery-in-openstack/" rel="alternate"></link><published>2016-11-07T00:00:00+00:00</published><updated>2016-11-07T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2016-11-07:/resources/presentations/high-availability-and-disaster-recovery-in-openstack/</id><summary type="html">&lt;p&gt;From the 2016 International Industry-Academia Workshop on Cloud
Reliability and Resilience in Berlin. An OpenStack primer followed by
a closer focus on OpenStack's HA &amp;amp; DR feature set.&lt;/p&gt;
&lt;p&gt;About 35 minutes.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/cloud-reliability-workshop/"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Use the arrow keys to navigate through the presentation, hit &lt;code&gt;Esc&lt;/code&gt; to
zoom out for an overview, or …&lt;/p&gt;</summary><content type="html">&lt;p&gt;From the 2016 International Industry-Academia Workshop on Cloud
Reliability and Resilience in Berlin. An OpenStack primer followed by
a closer focus on OpenStack's HA &amp;amp; DR feature set.&lt;/p&gt;
&lt;p&gt;About 35 minutes.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/cloud-reliability-workshop/"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Use the arrow keys to navigate through the presentation, hit &lt;code&gt;Esc&lt;/code&gt; to
zoom out for an overview, or just advance by hitting the spacebar.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="OpenStack"></category><category term="High Availability"></category></entry><entry><title>Heat and its Alternatives: Application Deployment in OpenStack</title><link href="https://xahteiwi.eu/resources/presentations/heat-and-its-alternatives-application-deployment-in-openstack/" rel="alternate"></link><published>2016-10-27T00:00:00+00:00</published><updated>2016-10-27T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2016-10-27:/resources/presentations/heat-and-its-alternatives-application-deployment-in-openstack/</id><summary type="html">&lt;p&gt;From the 2016 OpenStack Summit in Barcelona. A comparison of tools for
virtual systems orchestration in OpenStack.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;Heat&lt;/li&gt;
&lt;li&gt;Juju&lt;/li&gt;
&lt;li&gt;Ansible&lt;/li&gt;
&lt;li&gt;Cloudify&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;About 45 minutes.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Video: &lt;a href="https://youtu.be/wtXVd09qHoo"&gt;YouTube&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Slides: &lt;a href="https://fghaas.github.io/openstacksummit2016-barcelona/"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Use the arrow keys to navigate through the presentation, hit &lt;code&gt;Esc&lt;/code&gt; to
zoom out for an overview, or just advance by hitting …&lt;/p&gt;</summary><content type="html">&lt;p&gt;From the 2016 OpenStack Summit in Barcelona. A comparison of tools for
virtual systems orchestration in OpenStack.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;Heat&lt;/li&gt;
&lt;li&gt;Juju&lt;/li&gt;
&lt;li&gt;Ansible&lt;/li&gt;
&lt;li&gt;Cloudify&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;About 45 minutes.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Video: &lt;a href="https://youtu.be/wtXVd09qHoo"&gt;YouTube&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Slides: &lt;a href="https://fghaas.github.io/openstacksummit2016-barcelona/"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Use the arrow keys to navigate through the presentation, hit &lt;code&gt;Esc&lt;/code&gt; to
zoom out for an overview, or just advance by hitting the spacebar.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="OpenStack"></category><category term="Heat"></category><category term="Ansible"></category><category term="Juju"></category><category term="Cloudify"></category></entry><entry><title>CephFS and LXC: Container High Availability and Scalability, Redefined</title><link href="https://xahteiwi.eu/resources/presentations/cephfs-and-lxc-container-high-availability-and-scalability-redefined/" rel="alternate"></link><published>2016-10-06T00:00:00+00:00</published><updated>2016-10-06T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2016-10-06:/resources/presentations/cephfs-and-lxc-container-high-availability-and-scalability-redefined/</id><content type="html">&lt;p&gt;An overview of applying CephFS to LXC containers.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/lceu2016-cephlxc/"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Use the arrow keys to navigate through the presentation, hit &lt;code&gt;Esc&lt;/code&gt; to
zoom out for an overview, or just advance by hitting the spacebar.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="Ceph"></category><category term="LXC"></category></entry><entry><title>Fragile development: Why Scrum sucks, and what you should be doing instead (full talk)</title><link href="https://xahteiwi.eu/resources/presentations/fragile-development-why-scrum-sucks-and-what-you-should-be-doing-instead-full-talk/" rel="alternate"></link><published>2016-08-20T00:00:00+00:00</published><updated>2016-08-20T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2016-08-20:/resources/presentations/fragile-development-why-scrum-sucks-and-what-you-should-be-doing-instead-full-talk/</id><summary type="html">&lt;p&gt;My presentation from FrOSCon 2016. The lengthier version of the
&lt;a href="https://xahteiwi.eu/resources/presentations/why-scrum-sucks-and-what-you-ought-to-be-doing-instead/"&gt;Ignite talk&lt;/a&gt; I did a few
months before, at OpenStack Israel.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;Video: &lt;a href="https://youtu.be/f-ULT_Ic4qk"&gt;YouTube&lt;/a&gt;,
  &lt;a href="https://media.ccc.de/v/froscon2016-1722-fragile_development"&gt;CCC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/froscon2016/"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Use the arrow keys to navigate through the presentation, hit &lt;code&gt;Esc&lt;/code&gt; to
zoom out for an overview, or just advance by hitting the spacebar …&lt;/p&gt;</summary><content type="html">&lt;p&gt;My presentation from FrOSCon 2016. The lengthier version of the
&lt;a href="https://xahteiwi.eu/resources/presentations/why-scrum-sucks-and-what-you-ought-to-be-doing-instead/"&gt;Ignite talk&lt;/a&gt; I did a few
months before, at OpenStack Israel.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;Video: &lt;a href="https://youtu.be/f-ULT_Ic4qk"&gt;YouTube&lt;/a&gt;,
  &lt;a href="https://media.ccc.de/v/froscon2016-1722-fragile_development"&gt;CCC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/froscon2016/"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Use the arrow keys to navigate through the presentation, hit &lt;code&gt;Esc&lt;/code&gt; to
zoom out for an overview, or just advance by hitting the spacebar.&lt;/p&gt;</content><category term="presentations"></category><category term="Conference"></category></entry><entry><title>Fragile Development: Scrum is terrible, and you should ditch it</title><link href="https://xahteiwi.eu/blog/2016/07/05/fragile-development/" rel="alternate"></link><published>2016-07-05T00:00:00+00:00</published><updated>2016-07-05T00:00:00+00:00</updated><author><name>florian</name></author><id>tag:xahteiwi.eu,2016-07-05:/blog/2016/07/05/fragile-development/</id><summary type="html">&lt;p&gt;Scrum is irrational, impractical, and outright dangerous for software development. It is time to stop considering it a viable method for building software.&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a writeup of an
&lt;a href="https://en.wikipedia.org/wiki/Ignite_(event)"&gt;Ignite&lt;/a&gt; talk I gave at
&lt;a href="http://www.openstack-israel.org"&gt;OpenStack Israel 2016&lt;/a&gt;. The
paragraph headings below approximately correspond to the content of my
talk slides; the paragraphs themselves are an approximation of what I
said. If you're interested in the exact slide content, you can find
that &lt;a href="//fghaas.github.io/openstackisrael2016-ignite"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2&gt;Zero flexibility&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;_____&lt;/code&gt;'s roles, artifacts, events, and rules are &lt;em&gt;immutable&lt;/em&gt; and
although implementing only parts of &lt;code&gt;_____&lt;/code&gt; is possible, &lt;em&gt;the result
is not&lt;/em&gt; &lt;code&gt;_____&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;When you see a statement like this and wonder what should be filled in
for the blanks, it's rather quite likely that you would guess either a
radical political ideology, a very strict religious sect or cult, or
something to that effect. You couldn't be further from the truth.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;Scrum&lt;/code&gt;'s roles, artifacts, events, and rules are &lt;em&gt;immutable&lt;/em&gt; and
although implementing only parts of &lt;code&gt;Scrum&lt;/code&gt; is possible, &lt;em&gt;the result
is not&lt;/em&gt; &lt;code&gt;Scrum&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Yes, that's a
&lt;a href="http://www.scrumguides.org/scrum-guide.html#end-note"&gt;direct quote from the Scrum guide.&lt;/a&gt;
Scrum, by its own definition, can either be implemented completely —
that is, with all its roles, artifacts, events, and rules &lt;em&gt;unchanged&lt;/em&gt;
— or not at all. This sounds ludicrous enough as it is, and any sane,
thinking person should reject or at least resent &lt;em&gt;any&lt;/em&gt; such statement
outright. But let's give Scrum the benefit of doubt, and let's
actually start examining some of its postulates.&lt;/p&gt;
&lt;h2&gt;Teams are self-organizing&lt;/h2&gt;
&lt;p&gt;Scrum hinges on the idea that teams are comprised of capable
individuals forming teams, which then self-organize. Now I'm sure
nobody would argue that self-organizing teams cannot exist, so this
postulate does not invalidate itself outright.&lt;/p&gt;
&lt;p&gt;However, it is missing an important prerequisite: teams can
self-organize &lt;strong&gt;if they are stable.&lt;/strong&gt; And team stability is a
precondition that almost never exists in the software industry: our
industry is &lt;em&gt;growth-oriented,&lt;/em&gt; and driven by quickly-growing startups,
so in a successful organization having a new colleague every other
month is not unheard of. It is also highly &lt;em&gt;competitive&lt;/em&gt; for talent,
so having a colleague leave every few months isn't unusual either. The
moment a new person joins or leaves, you have a new team. Team
stability goes out the window, and with it any reasonable expectation
of self-organization.&lt;/p&gt;
&lt;h2&gt;Sprint after sprint after sprint&lt;/h2&gt;
&lt;p&gt;The Scrum Guide explicitly states that every &lt;em&gt;sprint&lt;/em&gt; (a time frame of
one month or less, in which the team completes objectives agreed to
for the sprint backlog) is &lt;em&gt;immediately followed by the next sprint.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This is mind-bogglingly ludicrous and outright dangerous to your
team's mental health. Software development is a marathon, and running
a marathon as an unbroken series of sprints leads to collapse or
death. In software development, it's likely to cause burnout.&lt;/p&gt;
&lt;h2&gt;The Daily Scrum&lt;/h2&gt;
&lt;p&gt;One of Scrum's immutable events is the Daily Scrum. The Scrum Guide
defines this event as a specific, daily occurrence, time-boxed to 15
minutes and involving the entirety of the development team.&lt;/p&gt;
&lt;p&gt;This is staggeringly out of place in the modern development team,
which may well be spread out over multiple offices and timezones, and
may not even physically be in one place more than a handful of times a
year. Even in the unlikely event that everyone &lt;em&gt;can&lt;/em&gt; get together in
one room for precisely fifteen minutes each day, have you ever been in
a meeting involving more than 3 people that got anything accomplished
in 15 minutes?&lt;/p&gt;
&lt;p&gt;And remember, 15 minutes. Time-boxed, immutable. If you think &lt;em&gt;your&lt;/em&gt;
Daily Scrum can be 30 or 45 minutes, or you can do it just every other
day or maybe thrice a week, recall: if you do that, you're no longer
doing Scrum.&lt;/p&gt;
&lt;h2&gt;No planning beyond the current sprint&lt;/h2&gt;
&lt;p&gt;Scrum is quite emphatic that the only thing developers should be
really concerned about in terms of planning is the next 24 hours (the
plan for which is ostensibly being laid out in the Daily Scrum), and
beyond that, the current sprint at a maximum. Now, while the idea of
freeing people's minds and allowing them to focus on a single task at
hand is certainly laudable, the practical implications of having no
medium to long-term planning is insane.&lt;/p&gt;
&lt;p&gt;I'd venture a guess that an approach where no planning is for more
than a month out is viable, under one condition: having exactly zero
users and/or customers for the product you are developing. I leave it
to you to decide how valuable it is, then, to develop the product in
the first place.&lt;/p&gt;
&lt;h2&gt;Permanent emergency mode&lt;/h2&gt;
&lt;p&gt;Arguably, some of the methods proposed in Scrum are quite suitable for
emergency situations. In a situation where you need to come up with a
solution that requires creativity, hustle, and speed, you may well sit
down, put down a requirements list, elect a coordinator and
spokesperson for your team, and just start hacking. I'd fully agree
that such situations can be extremely challenging, and quite
satisfying to come out of with flying colors.&lt;/p&gt;
&lt;p&gt;But if your organization is permanently operating in this mode,
&lt;strong&gt;quit.&lt;/strong&gt; It doesn't matter which role you're in: as a developer,
you're headed for burnout. As a manager, you're herding your team into
burnout. Either way, you shouldn't be doing this job, either in your
own interest or in that of others.&lt;/p&gt;
&lt;h2&gt;Novelty?&lt;/h2&gt;
&lt;p&gt;Scrum proponents frequently argue in its favor as the antithesis of
the obsolete waterfall model, where all deliverables are defined from
the outset and there is no room for deviation, leading to products
that are either broken, or outdated, or both the moment they are
completed. If you think we only found out recently that waterfall is
bad, you've been asleep at the switch for over 30 years. In his
seminal
&lt;a href="https://en.wikipedia.org/wiki/The_Mythical_Man-Month"&gt;Mythical Man-Month&lt;/a&gt;
essay collection from 1975, Fred Brooks pointed out some weaknesses of
this model, and in his 1986 follow-up
&lt;a href="https://en.wikipedia.org/wiki/No_Silver_Bullet"&gt;No Silver Bullet,&lt;/a&gt; he
proposes organic, incremental software development as an alternative.&lt;/p&gt;
&lt;h2&gt;Your team can't work with Scrum?&lt;/h2&gt;
&lt;p&gt;Scrum advocates frequently argue that if Scrum doesn't work with your
team, chances are that your team is the problem. This means that you
should either replace them, or at least educate them in the ways and
means of Scrum, so they can become a better-performing team.&lt;/p&gt;
&lt;p&gt;At this point, it should be fairly obvious that if Scrum doesn't work
for your team, the problem is not your team. The problem is Scrum.&lt;/p&gt;
&lt;h2&gt;What if Scrum doesn't deliver?&lt;/h2&gt;
&lt;p&gt;And finally, Scrum proponents usually argue that if Scrum fails to
deliver adequate results in your organization, it's likely because you
aren't applying its central tenets correctly. In other words, you must
come to your senses, and implement Scrum as designed, and which point
results with magically appear, and your team will be in a constant
state of flow.&lt;/p&gt;
&lt;p&gt;This is nonsense. &lt;strong&gt;If&lt;/strong&gt; you were able to actually do Scrum (meaning
in its pure, immutable, One True Way), it would surely lead to
disaster. But, it's impossible to do so anyway, so go ahead and ditch
it — stop being a scrumbag.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on my blog on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="blog"></category><category term="Philosophy"></category><category term="Development"></category></entry><entry><title>Wiping and resetting your SUSE OpenStack Cloud Crowbar configuration</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/wipe-suse-openstack-cloud-config/" rel="alternate"></link><published>2016-07-05T00:00:00+00:00</published><updated>2016-07-05T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2016-07-05:/resources/hints-and-kinks/wipe-suse-openstack-cloud-config/</id><summary type="html">&lt;p&gt;&lt;strong&gt;Note: This article was originally written for SUSE OpenStack Cloud
6, and updated for SUSE OpenStack Cloud 7. It may not apply to later
SUSE OpenStack Cloud releases.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If you're using &lt;a href="https://www.suse.com/products/suse-openstack-cloud"&gt;SUSE OpenStack
Cloud&lt;/a&gt;, you may
want to erase and reinstall your cloud deployment a few times during
the testing …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;Note: This article was originally written for SUSE OpenStack Cloud
6, and updated for SUSE OpenStack Cloud 7. It may not apply to later
SUSE OpenStack Cloud releases.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If you're using &lt;a href="https://www.suse.com/products/suse-openstack-cloud"&gt;SUSE OpenStack
Cloud&lt;/a&gt;, you may
want to erase and reinstall your cloud deployment a few times during
the testing or proof-of-concept phase. You may also want to experiment
with a few permutations of Crowbar network configurations. SUSE's
(otherwise excellent) &lt;a href="https://www.suse.com/documentation/suse-openstack-cloud-7/book_cloud_deploy/data/book_cloud_deploy.html"&gt;Deployment
Guide&lt;/a&gt;
suggests that the only way to change your Crowbar settings, after
&lt;code&gt;install-suse-cloud&lt;/code&gt; has been run, &lt;a href="https://www.suse.com/documentation/suse-openstack-cloud-7/book_cloud_deploy/data/sec_depl_adm_inst_crowbar_network.html"&gt;is to reinstall your entire admin
node&lt;/a&gt;.
That isn't really true if you know what you're doing.&lt;/p&gt;
&lt;p&gt;You may be thinking that you could just use
&lt;a href="http://snapper.io/"&gt;&lt;code&gt;snapper&lt;/code&gt;&lt;/a&gt; to
&lt;a href="https://www.suse.com/documentation/sles-12/book_sle_admin/data/sec_snapper_auto.html"&gt;revert to your last Btrfs snapshot&lt;/a&gt;
created before you ran &lt;code&gt;install-suse-cloud&lt;/code&gt;. After all, running &lt;code&gt;yast2
crowbar&lt;/code&gt;, like any other YaST module, automatically creates a
before-and-after Btrfs snapshot of your root filesystem and all its
subvolumes. So, reboot machine, select pre-&lt;code&gt;install-suse-cloud&lt;/code&gt;
snapshot, complete boot, run &lt;code&gt;snapper rollback&lt;/code&gt;, done. Right?&lt;/p&gt;
&lt;p&gt;Well, not quite. If you
&lt;a href="https://www.suse.com/documentation/suse-openstack-cloud-7/book_cloud_deploy/data/sec_depl_adm_inst_partition.html"&gt;followed the Deployment Guide closely,&lt;/a&gt;
you will have removed your Btrfs subvolume for the &lt;code&gt;/srv&lt;/code&gt; directory,
and replaced it with a separate, XFS-formatted partition. That means
it is excluded from all &lt;code&gt;snapper&lt;/code&gt; Btrfs snapshots, and thus, no
rollback for you for that directory. Which, of course, Crowbar uses
rather extensively.&lt;/p&gt;
&lt;p&gt;So, here is your checklist for resetting your admin node to a
pre-&lt;code&gt;install-suse-cloud&lt;/code&gt; state:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Reboot your admin node.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In the SLES boot menu, select an appropriate snapshot taken
  immediately prior to running &lt;code&gt;install-suse-cloud&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Boot into your snapshot.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run &lt;code&gt;snapper rollback&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reboot again.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;After rebooting, delete the following and directories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/srv/tftpboot/authorized_keys&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/srv/tftpboot/validation.pem&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;all subdirectories under &lt;code&gt;/srv/tftpboot/nodes/&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then, you can reconfigure Crowbar (&lt;code&gt;yast2 crowbar&lt;/code&gt;), run
&lt;code&gt;install-suse-cloud&lt;/code&gt;, and reboot your OpenStack nodes. They should be
discovered anew, and you're then able to redeploy your OpenStack
barclamps to them.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="OpenStack"></category><category term="SUSE"></category></entry><entry><title>Why Scrum sucks, and what you ought to be doing instead</title><link href="https://xahteiwi.eu/resources/presentations/why-scrum-sucks-and-what-you-ought-to-be-doing-instead/" rel="alternate"></link><published>2016-06-29T00:00:00+00:00</published><updated>2016-06-29T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2016-06-29:/resources/presentations/why-scrum-sucks-and-what-you-ought-to-be-doing-instead/</id><content type="html">&lt;p&gt;An &lt;a href="https://en.wikipedia.org/wiki/Ignite_(event)"&gt;Ignite&lt;/a&gt; talk I
presented at OpenStack Israel 2016.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;Video: &lt;a href="https://youtu.be/FTM_-H1cPNE"&gt;YouTube&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/openstackisrael2016-ignite/"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="presentations"></category><category term="Conference"></category><category term="Ignite"></category></entry><entry><title>Containers: Just Because Everyone Else is Doing Them Wrong, Doesn't Mean You Have To</title><link href="https://xahteiwi.eu/blog/2016/02/21/containers-just-because-everyone-else/" rel="alternate"></link><published>2016-02-21T00:00:00+00:00</published><updated>2016-02-21T00:00:00+00:00</updated><author><name>florian</name></author><id>tag:xahteiwi.eu,2016-02-21:/blog/2016/02/21/containers-just-because-everyone-else/</id><summary type="html">&lt;p&gt;The recent CVE-2015-7547 vulnerability in glibc exposed a common antipattern in container management. Here's what you can do to avoid it, and instead adopt a container management pattern that will preserve your sanity and enable you to react to critical issues in minutes.&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a writeup of &lt;a href="http://sched.co/3xVu"&gt;a presentation&lt;/a&gt; I did at
LinuxCon Europe in Dublin last year. Since Linux Foundation Events
&lt;em&gt;still&lt;/em&gt; don't come with video recording for all talks (all they do
record and publish are keynotes), I can't point you to a YouTube link,
though you're certainly welcome to
&lt;a href="https://xahteiwi.eu/resources/presentations/manageable-application-containers/"&gt;peruse my slides&lt;/a&gt;
from that talk.&lt;/p&gt;
&lt;h2&gt;The problem&lt;/h2&gt;
&lt;p&gt;Suppose you're an operator who, in a massively scaled-out and highly
automated deployment, is responsible for keeping a few hundred or a
few thousand containers up and running. Your developers put those
together and then basically throw them over the wall for you to
manage. It's your job just to keep them alive, available, and secure;
what's &lt;em&gt;in&lt;/em&gt; them is your developers' domain. Sure, you have Git repos
you build your containers from, and a Docker registry, so you can
always check what's in which container. You don't get to call the
shots, though.&lt;/p&gt;
&lt;p&gt;Suppose further that all most of your containers run some form of web
service. And let's assume, just for the sake of this discussion, that
they're all running Apache, because that's your reference
platform. Your developers may be writing applications in Python or
Ruby or (shudder) PHP, but what all your apps have in common is that
you've settled on Apache as your reference platform. Your developers
can assume that with Apache, you, the ops person, know the boldface
cold, and you can give them an extremely stable, well-tuned platform
to build on.&lt;/p&gt;
&lt;p&gt;And then Apache is affected by some disturbing security vulnerability
that you must now fix in record time. Say, something affecting your
core SSL library or maybe even your C library. Sound familiar? Thought
so.&lt;/p&gt;
&lt;h3&gt;The fix in a non-containerized world&lt;/h3&gt;
&lt;p&gt;OK, so you must now fix OpenSSL or libc on all your systems in record
time before the anticipated exploit barrage rolls in. In a world
without containers, you'd rely on your trusted software source
(normally, your distro vendor) to provide you with a fixed package or
packages for the affected libraries. You would then roll those out via
your preferred software management utility, or system automation
facility, or unattended upgrade scheme.&lt;/p&gt;
&lt;p&gt;In short, you'd have a tense time until updated packages are
available, but once they are, things get fixed in a matter of minutes.&lt;/p&gt;
&lt;h3&gt;But what now?&lt;/h3&gt;
&lt;p&gt;With the deployment of containers comes, frequently, the notion that
packaging, package management, or dependency tracking is somehow a
terrible idea. Instead, you put everything you need into one container
image, deploy one container per service, and not worry about what a
&lt;em&gt;different&lt;/em&gt; service running on the same physical hardware might need.&lt;/p&gt;
&lt;p&gt;At first glance, that simplifies things. Your developer needs MySQL
configured a certain way, and some other app needs it differently?
Fine, they can put everything in their own separate containers,
binaries, libraries and all, problem solved. Storage is dirt cheap,
containers are efficient and produce little overhead. If they ever
need to change anything, say go from one MySQL point release to
another, then they just rebuild the container, you replace the old
build with the new one, fine.&lt;/p&gt;
&lt;p&gt;But now it's not your developer who wants to change things, it's &lt;em&gt;you&lt;/em&gt;
who needs to deploy a critical fix.&lt;sup id="fnref:twitter"&gt;&lt;a class="footnote-ref" href="#fn:twitter"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;so.. using GlibC?&lt;/p&gt;
&lt;p&gt;How’s re-imaging all of your
&lt;a href="https://twitter.com/docker"&gt;@Docker&lt;/a&gt; images going?&lt;/p&gt;
&lt;p&gt;— Josh Long (龙之春)
(&lt;a href="https://twitter.com/starbuxman"&gt;@starbuxman&lt;/a&gt;) &lt;a href="https://twitter.com/starbuxman/status/700591322177019904"&gt;February 19,
2016&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So you set out to rebuild a few hundred containers, or maybe a couple
of thousand, to get the issue fixed. In a perfect environment, you
have access to every build chain, know about every version of every
container in your area of responsibility, can pinpoint exactly which
are affected by the vulnerability, have an automated toolchain to
build and deploy them, have perfect documentation so you don't need to
check back with any of your developers, so it doesn't matter whether
any one is out sick, on vacation, or has left the company since they
deployed one of their, now potentially affected, services.&lt;/p&gt;
&lt;p&gt;And of course, everyone works in such a perfect environment. Right?&lt;/p&gt;
&lt;p&gt;So now, even &lt;em&gt;after&lt;/em&gt; a fix to your issue is already available, you
&lt;em&gt;still&lt;/em&gt; need to scramble to get it deployed, and deploying is &lt;em&gt;a lot&lt;/em&gt;
more complicated than in a world without containers.&lt;/p&gt;
&lt;h2&gt;Is this an inherent problem with containers?&lt;/h2&gt;
&lt;p&gt;Of course not. The problem isn't with the fact that you're using
containers, or with the specific container technology. &lt;strong&gt;The problem
is that everyone is telling you to use containers a certain way, and
from an operational perspective that way is wrong.&lt;/strong&gt; And it's not even
"wrong but still better than all other options", it's just wrong. I
guess you could call it the Docker Fallacy.&lt;/p&gt;
&lt;p&gt;That's the bad news. The good news is that there is a way that is
better, saner, and cleaner, and will make your life as an operator
&lt;em&gt;much&lt;/em&gt; easier, while not being too hard on your developer friends.&lt;/p&gt;
&lt;h2&gt;So what's a better way?&lt;/h2&gt;
&lt;p&gt;You can use containers in a simpler, less flashy, less exciting
— in short, &lt;em&gt;better&lt;/em&gt; way.&lt;/p&gt;
&lt;h3&gt;Define a core platform, or platforms&lt;/h3&gt;
&lt;p&gt;Any organization worth its salt will select a handful of distributions
to build products and services on. Maybe it's even just one, but let's
assume you have several, say the latest Ubuntu LTS,&lt;sup id="fnref:ubuntu"&gt;&lt;a class="footnote-ref" href="#fn:ubuntu"&gt;2&lt;/a&gt;&lt;/sup&gt; the
latest CentOS, and the latest Debian. For each of these, you can
define an absolute bare-minimal list of packages. I can almost
guarantee you that none of your developers will care about a single
item on that list. A C library, a shell, an init system, coreutils,
NTP... chances are that you'll run up a list of well over 100 core
system components that &lt;em&gt;you&lt;/em&gt; will be expected to keep secure; your
developers will take them all for granted.&lt;/p&gt;
&lt;p&gt;What &lt;em&gt;you&lt;/em&gt; can take for granted, thanks to the tireless work of
packagers and distro vendors over years and years, is that you will
get timely security updates for all of those.&lt;/p&gt;
&lt;h3&gt;Deploy your core platforms as often as you need&lt;/h3&gt;
&lt;p&gt;Deploy these reference systems across your physical hardware. Deploy
as many as you need for all the containers you're expected to run on
each platform. Do so in an automated fashion, so that you never have
to log into any of these systems by hand.&lt;/p&gt;
&lt;h3&gt;Use OverlayFS for your containers&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/OverlayFS"&gt;OverlayFS&lt;/a&gt; is a union mount
filesystem that ships as part of the mainline kernel. With OverlayFS
you can do a few clever things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use a read-only base filesystem with a writable overlay to create a
  read/write union mount.&lt;/li&gt;
&lt;li&gt;Write to the union mount and only touch the overlay, leaving the
  base filesystem pristine.&lt;/li&gt;
&lt;li&gt;Hide selected content in the base filesystem from the union mount,
  through the use of
  &lt;a href="https://www.kernel.org/doc/Documentation/filesystems/overlayfs.txt"&gt;opaque directories&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Use one base filesystem with multiple overlays to create any number
  of separate read/write union mounts.&lt;/li&gt;
&lt;li&gt;Immediately make updates to the base filesystem known to &lt;em&gt;all&lt;/em&gt; union
  mounts, by simply remounting them.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This makes OverlayFS extremely powerful when used together with
LXC. You define a bunch of overlay directories — one for each of
your containers —, and they can all share one base filesystem:
your host root filesystem.&lt;sup id="fnref:automount"&gt;&lt;a class="footnote-ref" href="#fn:automount"&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Then, the union mount becomes your LXC container's root. It
automatically has read access to everything that is available on the
host, unless specifically hidden, and whatever it writes goes to the
overlay. When you discard a container, you delete the overlay.&lt;/p&gt;
&lt;p&gt;Here is a minimal example configuration for a container like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# For additional config options, please look at lxc.container.conf(5)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;# Common configuration&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;lxc.include&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/usr/share/lxc/config/ubuntu.common.conf&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;# Container specific configuration&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;lxc.arch&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;amd64&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;# Network configuration&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;lxc.network.type&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;veth&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;lxc.network.link&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;lxcbr0&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;lxc.network.flags&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;up&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;lxc.network.hwaddr&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;00:16:3e:76:59:10&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;# Automatic mounts&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;lxc.mount.auto&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;proc sys cgroup&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="na"&gt;lxc.rootfs&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;overlayfs:/var/lib/lxc/host/rootfs:/var/lib/lxc/mytestcontainer/delta0&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;lxc.utsname&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;mytestcontainer&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that the LXC userland presently enforces an OverlayFS base
directory to be in a subtree of &lt;code&gt;/var/lib/lxc&lt;/code&gt;. You can satisfy this
requirement by bind-mounting &lt;code&gt;/&lt;/code&gt; to &lt;code&gt;/var/lib/lxc/host/rootfs&lt;/code&gt;, as
shown in the example above.&lt;/p&gt;
&lt;p&gt;What this creates, among other things, is crystal-clear separation of
concerns: whatever is in the overlay is for your developers to
decide. They can pull in packages from PyPI, Ruby Gems, NPMs,
whatever. What's in the host root is your responsibility.&lt;/p&gt;
&lt;h3&gt;Automate, automate, automate&lt;/h3&gt;
&lt;p&gt;It's obvious and self-evident, but it doesn't hurt to reiterate: you
want to automate &lt;em&gt;all&lt;/em&gt; of this. You're certainly free to select your
own tools to do it, but Ansible specifically has very good LXC
container support so it makes this a breeze.&lt;/p&gt;
&lt;p&gt;Here's a simple Ansible playbook example that creates 100 containers,
all based off your host root.&lt;sup id="fnref:ansible"&gt;&lt;a class="footnote-ref" href="#fn:ansible"&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;hosts&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;localhost&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;tasks&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;Create a local bind mount for the host root filesystem&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;mount&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;/var/lib/lxc/host/rootfs&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;src&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;/&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;opts&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;bind&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;fstype&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;none&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;state&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;mounted&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;Create a template container using the host root&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;lxc_container&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;host&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;state&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;stopped&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;directory&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;/var/lib/lxc/host/rootfs&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;config&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;/var/lib/lxc/host/config&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;container_config&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;          &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"lxc.mount.auto&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;=&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;proc&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;sys&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;cgroup"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;          &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"lxc.include&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;=&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;/usr/share/lxc/config/ubuntu.common.conf"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;Create 100 OverlayFS based containers&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;lxc_container&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;host&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;backing_store&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;overlayfs&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;clone_snapshot&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;true&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;clone_name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"mytestcontainer{{&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;item&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;}}"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;state&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;started&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;with_sequence&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;count=100&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now of course, this will also mean that you'll need to get your
developers to define their container config in Ansible. However, that
is fundamentally a &lt;em&gt;good&lt;/em&gt; thing, because it means that developers and
operations people will be reading and writing the same language. Also,
if your developers can write a Dockerfile, they won't have a hard time
with Ansible YAML either.&lt;/p&gt;
&lt;h2&gt;How does this help?&lt;/h2&gt;
&lt;p&gt;With this approach, think of what you now have to do to make hundreds
of containers running on the same box get a new libc.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Update your host libc.&lt;/li&gt;
&lt;li&gt;Restart your containers.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;That's it. That is literally all you have to do to update hundreds of
containers in one fell swoop. LXC will remount your OverlayFS on
container restart, and thus all changes to the host will be
immediately visible in the container's overlay filesystem.&lt;/p&gt;
&lt;p&gt;On an Ubuntu platform, you could even go so far as automating this in
conjunction with unattended upgrades:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# /etc/apt/apt.conf.d/50unattended-upgrades&lt;/span&gt;
&lt;span class="sr"&gt;//&lt;/span&gt; &lt;span class="n"&gt;Automatically&lt;/span&gt; &lt;span class="n"&gt;upgrade&lt;/span&gt; &lt;span class="n"&gt;packages&lt;/span&gt; &lt;span class="n"&gt;from&lt;/span&gt; &lt;span class="n"&gt;these&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;origin:archive&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;pairs&lt;/span&gt;
&lt;span class="n"&gt;Unattended&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nn"&gt;Upgrade::&lt;/span&gt;&lt;span class="n"&gt;Allowed&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Origins&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s"&gt;"${distro_id}:${distro_codename}-security"&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;};&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# /etc/apt/apt.conf.d/05lxc&lt;/span&gt;
&lt;span class="nn"&gt;DPkg::&lt;/span&gt;&lt;span class="n"&gt;Post&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Invoke&lt;/span&gt;      &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="s"&gt;"/sbin/service lxc restart"&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="p"&gt;};&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So there you have it. Upgrade loads of containers in minutes. No
rebuild, no redeploy, nothing. Packaging actually does work and has
merit, regardless of what the hipster crowd is trying to sell you.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on my blog on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:twitter"&gt;
&lt;p&gt;Edit, 2016-02-22: Added Twitter quote from Josh Long. &lt;a class="footnote-backref" href="#fnref:twitter" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:ubuntu"&gt;
&lt;p&gt;At the time of writing, the latest Ubuntu LTS is 14.04 "Trusty
Tahr", which is based on a Linux 3.13 kernel. This Ubuntu stock
kernel ships with a pre-release version of OverlayFS which
predates the 3.14 mainline merge. I would not recommend using that
kernel; instead you'll want to run your hosts with a more recent
kernel from the
&lt;a href="https://wiki.ubuntu.com/Kernel/LTSEnablementStack"&gt;LTS Enablement Stack&lt;/a&gt;. Again
at the time of writing, this is a Linux 4.2 kernel that ships with
the &lt;code&gt;linux-generic-lts-wily&lt;/code&gt; package. &lt;a class="footnote-backref" href="#fnref:ubuntu" title="Jump back to footnote 2 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:automount"&gt;
&lt;p&gt;LXC containers do present per-container specific content for some
directories by default, notably &lt;code&gt;/proc&lt;/code&gt;, &lt;code&gt;/dev&lt;/code&gt;, and &lt;code&gt;/sys&lt;/code&gt;. Other
host-filesystem content can be hidden by creating opaque
directories in the container overlay; this is what you would
commonly do for directories like &lt;code&gt;/root&lt;/code&gt;, &lt;code&gt;/home&lt;/code&gt;, &lt;code&gt;/tmp&lt;/code&gt; and
others. &lt;a class="footnote-backref" href="#fnref:automount" title="Jump back to footnote 3 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:ansible"&gt;
&lt;p&gt;Please note that it's not &lt;em&gt;quite&lt;/em&gt; as simple as shown in the
Ansible example. You will want to provide some additional tweaks,
such as added mounts or opaque directories. I've tried to keep the
example brief to illustrate the concept. &lt;a class="footnote-backref" href="#fnref:ansible" title="Jump back to footnote 4 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="blog"></category><category term="LXC"></category><category term="Containers"></category><category term="Ubuntu"></category><category term="Ansible"></category></entry><entry><title>Dogfooding Dogwood</title><link href="https://xahteiwi.eu/blog/2016/02/12/dogfooding-dogwood/" rel="alternate"></link><published>2016-02-12T00:00:00+00:00</published><updated>2016-02-12T00:00:00+00:00</updated><author><name>florian</name></author><id>tag:xahteiwi.eu,2016-02-12:/blog/2016/02/12/dogfooding-dogwood/</id><summary type="html">&lt;p&gt;The Open edX "Dogwood" release is out. We've been running its code base in production for several weeks, and can share some first-hand experience.&lt;/p&gt;</summary><content type="html">&lt;p&gt;This week, the &lt;a href="https://open.edx.org"&gt;Open edX&lt;/a&gt; community
&lt;a href="https://open.edx.org/blog/newest-open-edx-release-dogwood-now-available"&gt;announced&lt;/a&gt;
its latest release,
&lt;a href="http://edx.readthedocs.org/projects/open-edx-release-notes/en/latest/dogwood.html"&gt;Open edX Dogwood&lt;/a&gt;. (In
case you don't follow the Open edX community closely, its releases are
alphabetically named after trees, so on the heels of the Birch and
Cypress releases, we now have
&lt;a href="https://en.wikipedia.org/wiki/Cornus_(genus)"&gt;Dogwood&lt;/a&gt;, and
Eucalyptus will be next.)&lt;/p&gt;
&lt;p&gt;Our team got involved in Open edX around the Cypress release
timeframe, and we shifted our OpenStack integration work to track the
master branch in December, to ensure we would be ready in time for
Dogwood. &lt;a href="//academy.hastexo.com"&gt;hastexo Academy&lt;/a&gt; also tracks master,
so if you take one of our self-paced online courses, you'll be running
the latest and greatest from Open edX.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2&gt;Checking out the new features&lt;/h2&gt;
&lt;p&gt;There are several new features in Open edX Dogwood, some of which we
tested and ran, with somewhat mixed (but generally positive) results.&lt;/p&gt;
&lt;h3&gt;Platform upgrades&lt;/h3&gt;
&lt;p&gt;Open edX now builds upon Django 1.8 and Python 2.7.10. It's great to
see some technical debt pay-down by moving beyond the now-unsupported
Django 1.4. We hope to see this continue by Eucalyptus
&lt;a href="https://openedx.slack.com/archives/general/p1455215550000885"&gt;hopefully moving to the next Ubuntu LTS, 16.04 "Xenial Xerus".&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It would also be great to see a move to Python 3, but we're not
holding our breath on that, for various reasons — including the fact
that Ansible, which Open edX uses for deployment, &lt;a href="https://lwn.net/Articles/661590/"&gt;also still requires
Python 2.&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Comprehensive theming&lt;/h3&gt;
&lt;p&gt;Comprehensive theming is a new and improved way to apply theming and
branding to Open edX platforms, which will eventually replace the
current "Stanford" theming engine (named after an Open edX theme
developed at Stanford University, which became a popular basis for
rebranding the Open edX LMS). In mid-January, we shifted
&lt;a href="https://github.com/hastexo/edx-theme"&gt;our own Stanford-style Open edX theme&lt;/a&gt;
to Comprehensive Theming and test-deployed on hastexo Academy, then
still in pre-launch. We ran into a critical bug
&lt;a href="https://github.com/edx/edx-platform/pull/11319"&gt;that has been fixed for the release,&lt;/a&gt;
and will come back to redeploying our new Comprehensive theme at a
later date.&lt;/p&gt;
&lt;p&gt;We're also waiting for a
&lt;a href="https://github.com/edx/configuration/pull/2676"&gt;patch to the &lt;code&gt;edx-configuration&lt;/code&gt; Ansible repository&lt;/a&gt;
to land, so we can properly deploy our Comprehensive theme to our Open
edX instance.&lt;/p&gt;
&lt;h3&gt;Otto&lt;/h3&gt;
&lt;p&gt;We also looked extensively at the new Open edX ecommerce framework,
"Otto", for buying and sellling course seats. Sadly, we found multiple
issues that prevented us from using it in our infrastructure for the
time being, and we pushed Otto off for our Eucalyptus respin.&lt;/p&gt;
&lt;p&gt;Otto has no support for tax assessment on course seats; this is a show
stopper for anyone who wants to sell courses to people in Europe, as
course seats are Digital Goods under EU VAT regulations and require
VAT assessment. We were admittedly a little dismayed to find that Otto
had made some design decisions that made this impossible to fix in the
way you would normally do this in the
&lt;a href="http://django-oscar.readthedocs.org/en/latest/"&gt;Oscar&lt;/a&gt; framework that
Otto builds on. Fixing Otto in-place would likely have delayed our
Academy launch by several months, so that was a delay we were
unwilling to accept. There are other issues with Otto, notably the
fact that it comes with its own PayPal integration (as if
&lt;a href="http://django-oscar-paypal.readthedocs.org/en/latest/"&gt;django-oscar-paypal&lt;/a&gt;
didn't exist), which made us rather uncomfortable.&lt;/p&gt;
&lt;p&gt;So we instead integrated hastexo Academy with our own, pure-Oscar web
store that makes use of upstream community supported features much
more extensively than Otto, and that also enables us to sell other
products and services besides hastexo Academy course seats.&lt;/p&gt;
&lt;h3&gt;LTI XBlock&lt;/h3&gt;
&lt;p&gt;With the Dogwood release, the LTI XModule has been refactored into the
&lt;a href="https://github.com/edx/xblock-lti-consumer"&gt;LTI Consumer XBlock&lt;/a&gt;. While
we do not currently use this XBlock in production, it comes in very
handy as a good reference for
&lt;a href="https://github.com/edx/xblock-lti-consumer/tree/master/lti_consumer/tests/unit"&gt;XBlock unit tests&lt;/a&gt;,
which we'll be using to improve the test coverage in our own XBlock.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2&gt;Open edX integration with OpenStack&lt;/h2&gt;
&lt;p&gt;Our OpenStack integration work for Open edX is continuing at its
regular, steady pace.&lt;/p&gt;
&lt;h3&gt;Running Open edX Dogwood on OpenStack&lt;/h3&gt;
&lt;p&gt;You're of course still able to deploy Open edX on OpenStack, using the
Heat templates we've maintained since Cypress.&lt;/p&gt;
&lt;h3&gt;Running the hastexo XBlock on Open edX Dogwood&lt;/h3&gt;
&lt;p&gt;The hastexo XBlock, enabling course authors to define arbitrarily
complex lab environments for courses with OpenStack Heat, is of course
fully supported for Open edX Dogwood. That's exactly what you're using
when speeding through interactive labs on hastexo Academy.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2&gt;Congrats, and thanks!&lt;/h2&gt;
&lt;p&gt;Congratulations are in order for the entire development community! Our
team at hastexo would like to extend a big thank-you to everyone who
made a contribution to this release.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on my blog on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="blog"></category><category term="Open edX"></category><category term="OpenStack"></category></entry><entry><title>Pacemaker's best-kept secret: crm_report</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/pacemakers-best-kept-secret/" rel="alternate"></link><published>2016-01-30T00:00:00+00:00</published><updated>2016-02-03T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2016-01-30:/resources/hints-and-kinks/pacemakers-best-kept-secret/</id><summary type="html">&lt;p&gt;Pacemaker has an excellent, but little-known, error reporting facility: crm_report.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Whenever things in Pacemaker go wrong (say, for example, resource
failover doesn't work as expected, or your cluster didn't properly
recover after a node shutdown), you'll want to find out just exactly
&lt;em&gt;why&lt;/em&gt; that happened. Of course, the actual reason for the malfunction
may be buried somewhere deep in your cluster configuration or setup,
and so you might need to look at quite a few different sources to pin
it down.&lt;/p&gt;
&lt;p&gt;Sometimes, too, you want to enlist the help of a colleague, &lt;a href="/contact"&gt;or maybe
&lt;strong&gt;our&lt;/strong&gt; help even&lt;/a&gt;, to get to the bottom of the issue. And
sometimes it's not practical to let someone access to system to just
trigger the problem and watch what breaks.&lt;/p&gt;
&lt;p&gt;Thankfully, Pacemaker ships with a utility that helps you collect
everything you or someone else might need to look at, in a simple,
compact format. Unfortunately few people, including even long-time
Pacemaker users, know that it exists: it's called &lt;code&gt;crm_report&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;Running &lt;code&gt;crm_report&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;crm_report&lt;/code&gt;'s command syntax is rather quite simple. You just tell it
how far in the past you want the report to start, and which directory
you want to collect data in:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;crm_report -f &lt;span class="s2"&gt;"2016-01-25 00:00:00"&lt;/span&gt; /tmp/crm_report
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The directory you specify must not exist. If it does, &lt;code&gt;crm_report&lt;/code&gt;
will refuse to run, rather than clobber or mess up your existing
report data.&lt;/p&gt;
&lt;p&gt;By analyzing your logs all the way back to a start date you specify,
&lt;strong&gt;&lt;code&gt;crm_report&lt;/code&gt; makes it unnecessary for you to actually try to
reproduce the problem.&lt;/strong&gt; All you need is a rough idea when the issue
occurred, and then you give &lt;code&gt;crm_report&lt;/code&gt; a timestamp a little earlier
than that as its start date.&lt;/p&gt;
&lt;p&gt;You can also specify the &lt;em&gt;end&lt;/em&gt; of the period you're interested
in. Suppose you're exactly aware of a 10-minute time window in which
the problem occurred. In that case, you could run:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;crm_report -f &lt;span class="s2"&gt;"2016-01-25 01:15:00"&lt;/span&gt; -t &lt;span class="s2"&gt;"2016-01-25 01:25:00"&lt;/span&gt; /tmp/crm_report
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Either way, &lt;code&gt;crm_report&lt;/code&gt; will collect relevant log data for the
specified time window on the host it is run on, and then connect to
the other cluster nodes (via &lt;code&gt;ssh&lt;/code&gt;) and do the same there. The latter
behavior can be disabled by adding the &lt;code&gt;-S&lt;/code&gt; or &lt;code&gt;--single-node&lt;/code&gt; option,
but there usually isn't a good reason to do that. In the end,
everything will be rolled into one tarball at
&lt;code&gt;/tmp/crm_report.tar.bz2&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;You can then pull the report tarball off the node (with &lt;code&gt;scp&lt;/code&gt;,
&lt;code&gt;rsync&lt;/code&gt;, whatever you prefer), and then share it with whom you need
to. &lt;strong&gt;Note that the tarball can contain sensitive information such as
passwords, so be careful whom you share it with.&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;What's in a &lt;code&gt;crm_report&lt;/code&gt; tarball?&lt;/h2&gt;
&lt;p&gt;There's a bunch of truly helpful information in a &lt;code&gt;crm_report&lt;/code&gt;
generated tarball. Depending on how your cluster is configured and
what problems were detected, it will contain, among other things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Your current Pacemaker Cluster Information Base (CIB),&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Your Corosync configuration,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Corosync Blackbox output (if &lt;code&gt;qb-blackbox&lt;/code&gt; is installed on your
  cluster nodes; you can read more about blackbox support
  &lt;a href="http://blog.clusterlabs.org/blog/2013/pacemaker-logging/"&gt;here&lt;/a&gt;),&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;drbd.conf&lt;/code&gt; and all your DRBD resource configuration files (if your
  cluster runs DRBD),&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;sysinfo.txt&lt;/code&gt;, a text file including your kernel, distro, Pacemaker
  version, and version information for all your installed packages,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;your Syslog, filtered for the time period you specified in your
  &lt;code&gt;crm_report&lt;/code&gt; command invocation,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;diffs for critical system information, if &lt;code&gt;crm_report&lt;/code&gt; detected
  discrepancies between nodes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In other words, it contains pretty much everything that needs to be
shared in a critical troubleshooting situation.&lt;/p&gt;
&lt;h2&gt;Why isn't this more widely known?&lt;/h2&gt;
&lt;p&gt;To be perfectly honest, we have no idea. &lt;code&gt;crm_report&lt;/code&gt; has been in
Pacemaker for years, and even prior to its existence, there was a
predecessor named &lt;code&gt;hb_report&lt;/code&gt;. It's an extraordinarily useful utility,
yet when we ask customers to send a &lt;code&gt;crm_report&lt;/code&gt; tarball during a
Pacemaker troubleshooting engagement, the usual response is, “a
what?”&lt;/p&gt;
&lt;p&gt;We hope this post makes &lt;code&gt;crm_report&lt;/code&gt; known to a wider audience, so it
gets the love it deserves. &lt;i class="fa fa-smile-o"&gt;&lt;/i&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Pacemaker"></category></entry><entry><title>Hosting a web site in radosgw</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/hosting-website-radosgw/" rel="alternate"></link><published>2016-01-26T00:00:00+00:00</published><updated>2016-01-26T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2016-01-26:/resources/hints-and-kinks/hosting-website-radosgw/</id><summary type="html">&lt;p&gt;If you're familiar with &lt;a href="//docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html"&gt;web site hosting on Amazon
S3&lt;/a&gt;,
which is a simple and cheap way to host a static web site, you might
be wondering whether or not you can do the same in Ceph radosgw.&lt;/p&gt;
&lt;p&gt;The short answer is you can't. Bucket Website is listed as &lt;em&gt;Not …&lt;/em&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;If you're familiar with &lt;a href="//docs.aws.amazon.com/AmazonS3/latest/dev/WebsiteHosting.html"&gt;web site hosting on Amazon
S3&lt;/a&gt;,
which is a simple and cheap way to host a static web site, you might
be wondering whether or not you can do the same in Ceph radosgw.&lt;/p&gt;
&lt;p&gt;The short answer is you can't. Bucket Website is listed as &lt;em&gt;Not
Supported&lt;/em&gt; in the radosgw S3 API
&lt;a href="http://docs.ceph.com/docs/master/radosgw/s3/"&gt;support matrix&lt;/a&gt;, and
radosgw doesn't have
&lt;a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/IndexDocumentSupport.html"&gt;index document support&lt;/a&gt;
either.&lt;/p&gt;
&lt;p&gt;But the longer answer is that you can, provided you use radosgw in
combination with a front-end load-balancer — which, as it happens,
can add a few more bells and whistles, as well. You could probably do
the same thing with nginx, Varnish, or Apache in a
&lt;code&gt;mod_proxy_balancer&lt;/code&gt; balancer setup, but in this example
configuration, we'll use HAProxy.&lt;/p&gt;
&lt;h2&gt;Getting started: the radosgw basics&lt;/h2&gt;
&lt;p&gt;Let's take look at a simple radosgw configuration with virtual host
support, such that you can access your buckets as either
&lt;code&gt;http://ceph.example.com/bucketname&lt;/code&gt; or
&lt;code&gt;http://bucketname.ceph.example.com&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;[client.rgw.radosgw01]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;rgw_frontends&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;civetweb port=7480&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;rgw_dns_name&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph.example.com&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;rgw_resolve_cname&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;True&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Suppose we use &lt;code&gt;s3cmd&lt;/code&gt; to upload an HTML file to this bucket, setting
a public ACL:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;s3cmd mb s3://testwebsite
s3cmd put --acl-public index.html s3://testwebsite/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then if you exposed your radosgw to the web, any client (without
authentication) would be able to retrieve
&lt;code&gt;http://testwebsite.ceph.example.com:7480/index.html&lt;/code&gt; with a web
browser, or any other HTTP client application (such as &lt;code&gt;curl&lt;/code&gt; or
&lt;code&gt;wget&lt;/code&gt;):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;curl -I http://testwebsite.ceph.example.com:7480/index.html
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Which would then return something like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kr"&gt;HTTP&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="m"&gt;1.1&lt;/span&gt; &lt;span class="m"&gt;200&lt;/span&gt; &lt;span class="ne"&gt;OK&lt;/span&gt;
&lt;span class="na"&gt;Content-Length&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;18050&lt;/span&gt;
&lt;span class="na"&gt;Accept-Ranges&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;bytes&lt;/span&gt;
&lt;span class="na"&gt;Last-Modified&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;Mon, 25 Jan 2016 21:28:47 GMT&lt;/span&gt;
&lt;span class="na"&gt;ETag&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;"b03130a4a1fc24df0f9f336f2b6d1d90"&lt;/span&gt;
&lt;span class="na"&gt;x-amz-request-id&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;tx000000000000000005a88-0056a7b7eb-312df-default&lt;/span&gt;
&lt;span class="na"&gt;Content-type&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;text/html&lt;/span&gt;
&lt;span class="na"&gt;Date&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;Tue, 26 Jan 2016 18:16:11 GMT&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Introducing HAProxy&lt;/h2&gt;
&lt;p&gt;Now let's start out with putting HAproxy in between. Nothing special
there: radosgw listens on the conventional 7480 port, and we simply
hand HAproxy traffic through there, and bind HAProxy itself to
port 80.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;global&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;log&lt;/span&gt;&lt;span class="w"&gt;         &lt;/span&gt;&lt;span class="s"&gt;/dev/log&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;local0&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;pidfile&lt;/span&gt;&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="s"&gt;/var/run/haproxy.pid&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;maxconn&lt;/span&gt;&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="mi"&gt;4000&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;user&lt;/span&gt;&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="s"&gt;haproxy&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;group&lt;/span&gt;&lt;span class="w"&gt;       &lt;/span&gt;&lt;span class="s"&gt;haproxy&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;daemon&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;# turn on stats unix socket&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;stats&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;socket&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/var/lib/haproxy/stats&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;level&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;admin&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;# Default SSL material locations&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;ca-base&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/etc/ssl/certs&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;crt-base&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/etc/haproxy/ssl&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;# Default ciphers to use on SSL-enabled listening sockets.&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;# For more information, see ciphers(1SSL).&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;ssl-default-bind-ciphers&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;HIGH&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;tune.ssl.default-dh-param&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2048&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="s"&gt;defaults&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;log&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;global&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;mode&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;http&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;option&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;httplog&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;option&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;dontlognull&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;retries&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;timeout&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;queue&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;timeout&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;connect&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;timeout&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;client&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;30000&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;timeout&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;server&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;30000&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;option&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;forwardfor&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;


&lt;span class="s"&gt;frontend&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph_front&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;bind&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;0.0.0.0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;default_backend&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph_back&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="s"&gt;backend&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph_back&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;balance&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;source&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;server&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;radosgw01&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;127.0.0.1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;7480&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;check&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Index documents&lt;/h2&gt;
&lt;p&gt;So, the first thing we'll need to add is support for index
documents. We'd like to make sure that when we retrieve
&lt;code&gt;https://testwebsite.ceph.example.com/&lt;/code&gt;, what's actually fetched from
the backend is &lt;code&gt;/index.html&lt;/code&gt;. We can do that by adding an HAproxy ACL
that matches for the trailing slash in the path, and an &lt;code&gt;http-request
set-path&lt;/code&gt; directive that appends the index document name:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;frontend&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph_front&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;bind&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;0.0.0.0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;acl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_ends_in_slash&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_end&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;-i&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;# Append index document (index.html) to any path&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;# ending in "/".&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;http-request&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;set-path&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;%[path]index.html&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_ends_in_slash&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;default_backend&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph_back&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, that's fine in terms of &lt;strong&gt;getting&lt;/strong&gt; the index document correctly:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;curl -I http://testwebsite.ceph.example.com/index.html
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kr"&gt;HTTP&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="m"&gt;1.1&lt;/span&gt; &lt;span class="m"&gt;200&lt;/span&gt; &lt;span class="ne"&gt;OK&lt;/span&gt;
&lt;span class="na"&gt;Content-Length&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;18050&lt;/span&gt;
&lt;span class="na"&gt;Accept-Ranges&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;bytes&lt;/span&gt;
&lt;span class="na"&gt;Last-Modified&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;Mon, 25 Jan 2016 21:28:47 GMT&lt;/span&gt;
&lt;span class="na"&gt;ETag&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;"b03130a4a1fc24df0f9f336f2b6d1d90"&lt;/span&gt;
&lt;span class="na"&gt;x-amz-request-id&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;tx000000000000000005a94-0056a7b9e3-312df-default&lt;/span&gt;
&lt;span class="na"&gt;Content-type&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;text/html&lt;/span&gt;
&lt;span class="na"&gt;Date&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;Tue, 26 Jan 2016 18:24:35 GMT&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;However, it of course breaks uploads and even bucket listings, or in
other words, anything that uses the S3 API. Now you could test for
some S3-specific headers in the request, but really, you should just
check whether the request is authorized, and only apply the index
document logic if it isn't, like so:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;frontend&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph_front&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;bind&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;0.0.0.0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;acl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_ends_in_slash&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_end&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;-i&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;acl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;auth_header&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;hdr(Authorization)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;-m&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;found&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;# Append index document (index.html) to any path&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;# ending in "/", unless the request has an auth header&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;http-request&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;set-path&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;%[path]index.html&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_ends_in_slash&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;!auth_header&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;default_backend&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph_back&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Great. Now we can upload using full paths without mangling, and on any
un-authenticated requests, we substitute &lt;code&gt;/index.html&lt;/code&gt; for any trailing
&lt;code&gt;/&lt;/code&gt;. In case you're wondering: yes, this works for any path, not just
the root path.&lt;/p&gt;
&lt;h2&gt;Directory paths&lt;/h2&gt;
&lt;p&gt;However, you may also want something else, which is the ability to
correctly handle a request like
&lt;code&gt;http://testwebsite.ceph.example.com/my/sub/directory&lt;/code&gt;, where of
course you want the path &lt;code&gt;/my/sub/directory&lt;/code&gt; translated into
&lt;code&gt;/my/sub/directory/index.html&lt;/code&gt;, which means we want to append a slash
&lt;em&gt;and&lt;/em&gt; an index document name to the request path.&lt;/p&gt;
&lt;p&gt;So let's do that:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;frontend&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph_front&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;bind&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;0.0.0.0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;acl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_has_dot&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_sub&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;-i&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;acl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_ends_in_slash&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_end&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;-i&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;acl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;auth_header&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;hdr(Authorization)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;-m&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;found&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;http-request&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;set-path&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;%[path]index.html&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_ends_in_slash&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;!auth_header&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;# Append trailing slash if necessary.&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;http-request&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;set-path&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;%[path]/index.html&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;!path_has_dot&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;!path_ends_in_slash&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;!auth_header&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;default_backend&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph_back&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that what we're doing here is somewhat crude. We're assuming that
any actual file that we want to retrieve looks like &lt;code&gt;name.ext&lt;/code&gt;,
meaning it has a dot (period, full stop) character in it. The
&lt;code&gt;path_sub -i .&lt;/code&gt; expression in the &lt;code&gt;path_has_dot&lt;/code&gt; ACL simply matches
any path with &lt;code&gt;.&lt;/code&gt; in it, and we're assuming that if a path has a dot
then it points to a file, if it doesn't then it points to a directory.&lt;/p&gt;
&lt;p&gt;You could be a little more clever here and use &lt;code&gt;path_regex&lt;/code&gt; instead of
&lt;code&gt;path_sub&lt;/code&gt; for a full regular expression match. But regex lookups are
slower than simple substring matches, so if the substring match works
for you, go for it.&lt;/p&gt;
&lt;p&gt;So now, we can do this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;s3cmd put --acl-public index.html s3://testwebsite/my/sub/directory/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And then:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# Note omitted trailing slash&lt;/span&gt;
curl -I http://testwebsite.ceph.example.com/my/sub/directory
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kr"&gt;HTTP&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="m"&gt;1.1&lt;/span&gt; &lt;span class="m"&gt;200&lt;/span&gt; &lt;span class="ne"&gt;OK&lt;/span&gt;
&lt;span class="na"&gt;Content-Length&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;24235&lt;/span&gt;
&lt;span class="na"&gt;Accept-Ranges&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;bytes&lt;/span&gt;
&lt;span class="na"&gt;Last-Modified&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;Mon, 25 Jan 2016 23:57:04 GMT&lt;/span&gt;
&lt;span class="na"&gt;ETag&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;"fecd005b33c0f6bfdee61b787cf54cb0"&lt;/span&gt;
&lt;span class="na"&gt;x-amz-request-id&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;tx00000000000000000bc83-0056a7bd25-312cd-default&lt;/span&gt;
&lt;span class="na"&gt;Content-type&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;text/html&lt;/span&gt;
&lt;span class="na"&gt;Date&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;Tue, 26 Jan 2016 18:38:29 GMT&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;HTTPS support&lt;/h2&gt;
&lt;p&gt;So, what else might you want to do? One obvious thing that you can use
HAproxy for is SSL termination. The radosgw embedded &lt;code&gt;civetweb&lt;/code&gt;
webserver can do that for you, but that feature is &lt;a href="http://tracker.ceph.com/issues/11239"&gt;currently mildly
broken in a rather curious
way&lt;/a&gt;. So in order to allow HTTPS
access to all your content via HAproxy instead, you would add:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;frontend&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph_front_ssl&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;bind&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;0.0.0.0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;443&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ssl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;crt&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph.pem&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;no-sslv3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;no-tls-tickets&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;reqadd&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;X-Forwarded-Proto:\&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;https&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;acl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_has_dot&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_sub&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;-i&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;acl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_ends_in_slash&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_end&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;-i&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;acl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;auth_header&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;hdr(Authorization)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;-m&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;found&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;http-request&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;set-path&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;%[path]index.html&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_ends_in_slash&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;!auth_header&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;http-request&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;set-path&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;%[path]/index.html&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;!path_has_dot&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;!path_ends_in_slash&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;!auth_header&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;default_backend&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph_back&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;But maybe you'd like to &lt;strong&gt;force,&lt;/strong&gt; not merely allow, HTTPS
access. &lt;code&gt;redirect&lt;/code&gt; to the rescue:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;frontend&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph_front&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;bind&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;0.0.0.0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;reqadd&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;X-Forwarded-Proto:\&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;http&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;redirect&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;scheme&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;https&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;code&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;301&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;!&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kn"&gt;ssl_fc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="s"&gt;frontend&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph_front_ssl&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;bind&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;0.0.0.0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;443&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ssl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;crt&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph.pem&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;no-sslv3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;no-tls-tickets&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;reqadd&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;X-Forwarded-Proto:\&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;https&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;acl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_has_dot&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_sub&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;-i&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;acl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_ends_in_slash&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_end&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;-i&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;acl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;auth_header&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;hdr(Authorization)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;-m&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;found&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;http-request&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;set-path&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;%[path]index.html&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_ends_in_slash&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;!auth_header&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;http-request&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;set-path&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;%[path]/index.html&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;!path_has_dot&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;!path_ends_in_slash&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;!auth_header&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;default_backend&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph_back&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And here we go:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# Note HTTP&lt;/span&gt;
curl -IL http://testwebsite.ceph.example.com/my/sub/directory
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kr"&gt;HTTP&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="m"&gt;1.1&lt;/span&gt; &lt;span class="m"&gt;301&lt;/span&gt; &lt;span class="ne"&gt;Moved Permanently&lt;/span&gt;
&lt;span class="na"&gt;Content-length&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;0&lt;/span&gt;
&lt;span class="na"&gt;Location&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;https://testwebsite.ceph.example.com/my/sub/directory&lt;/span&gt;
&lt;span class="na"&gt;Connection&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="l"&gt;close&lt;/span&gt;

HTTP/1.1 200 OK
Content-Length: 24235
Accept-Ranges: bytes
Last-Modified: Mon, 25 Jan 2016 23:57:04 GMT
ETag: "fecd005b33c0f6bfdee61b787cf54cb0"
x-amz-request-id: tx00000000000000000bdeb-0056a7bf9b-312cd-default
Content-type: text/html
Date: Tue, 26 Jan 2016 18:48:59 GMT
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Compression&lt;/h2&gt;
&lt;p&gt;And finally, maybe you'd like to speed up access to the stuff on your
site. Why not add gzip on-the-fly-compression? It's supported by every
browser worth its salt, and will make your users happier. You'll want
to restrict compression to specific MIME types though. In the
configuration below, we enable compression for plain text, HTML, XML,
CSS, JavaScript, and SVG images.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;frontend&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph_front&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;bind&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;0.0.0.0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;reqadd&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;X-Forwarded-Proto:\&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;http&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;redirect&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;scheme&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;https&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;code&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;301&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;!&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kn"&gt;ssl_fc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="s"&gt;frontend&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph_front_ssl&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;bind&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;0.0.0.0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;443&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ssl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;crt&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph.pem&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;no-sslv3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;no-tls-tickets&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;reqadd&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;X-Forwarded-Proto:\&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;https&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;acl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_has_dot&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_sub&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;-i&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;acl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_ends_in_slash&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_end&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;-i&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;/&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;acl&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;auth_header&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;hdr(Authorization)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;-m&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;found&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;http-request&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;set-path&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;%[path]index.html&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;path_ends_in_slash&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;!auth_header&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;http-request&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;set-path&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;%[path]/index.html&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;!path_has_dot&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;!path_ends_in_slash&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;!auth_header&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;compression&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;algo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;gzip&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;compression&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;type&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;text/html&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;text/xml&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;text/plain&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;text/css&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;application/javascript&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;image/svg+xml&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="s"&gt;default_backend&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;ceph_back&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Let's see how that helps us. Do a request without gzip encoding
support, and observe that its total download size matches the
document's &lt;code&gt;Content-Length&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;curl https://testwebsite.ceph.example.com/my/sub/directory &amp;gt; /dev/null
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;  &lt;span class="c1"&gt;% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current&lt;/span&gt;
                                 &lt;span class="nv"&gt;Dload&lt;/span&gt;  &lt;span class="nv"&gt;Upload&lt;/span&gt;   &lt;span class="nv"&gt;Total&lt;/span&gt;   &lt;span class="nv"&gt;Spent&lt;/span&gt;    &lt;span class="nv"&gt;Left&lt;/span&gt;  &lt;span class="nv"&gt;Speed&lt;/span&gt;
&lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="mi"&gt;24235&lt;/span&gt;  &lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="mi"&gt;24235&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;  &lt;span class="mi"&gt;94565&lt;/span&gt;      &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="s s-Atom"&gt;--:--:--&lt;/span&gt; &lt;span class="s s-Atom"&gt;--:--:--&lt;/span&gt; &lt;span class="s s-Atom"&gt;--:--:--&lt;/span&gt; &lt;span class="mi"&gt;94299&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, add an &lt;code&gt;Accept-Encoding&lt;/code&gt; header:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;curl -H &lt;span class="s1"&gt;'Accept-Encoding: gzip'&lt;/span&gt; https://testwebsite.ceph.example.com/my/sub/directory &amp;gt; /dev/null
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;  &lt;span class="c1"&gt;% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current&lt;/span&gt;
                                 &lt;span class="nv"&gt;Dload&lt;/span&gt;  &lt;span class="nv"&gt;Upload&lt;/span&gt;   &lt;span class="nv"&gt;Total&lt;/span&gt;   &lt;span class="nv"&gt;Spent&lt;/span&gt;    &lt;span class="nv"&gt;Left&lt;/span&gt;  &lt;span class="nv"&gt;Speed&lt;/span&gt;
&lt;span class="mi"&gt;100&lt;/span&gt;  &lt;span class="mi"&gt;5237&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;  &lt;span class="mi"&gt;5237&lt;/span&gt;    &lt;span class="mi"&gt;0&lt;/span&gt;     &lt;span class="mi"&gt;0&lt;/span&gt;  &lt;span class="mi"&gt;19243&lt;/span&gt;      &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="s s-Atom"&gt;--:--:--&lt;/span&gt; &lt;span class="s s-Atom"&gt;--:--:--&lt;/span&gt; &lt;span class="s s-Atom"&gt;--:--:--&lt;/span&gt; &lt;span class="mi"&gt;19324&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;There. Actual download size goes from 24KB down to just 5KB. &lt;/p&gt;
&lt;h2&gt;Where to go from here&lt;/h2&gt;
&lt;p&gt;There's a few additional features to be added here. You
could enable CORS or HSTS, for example, and of course you could add
more backends. But if you read this far, you surely get the idea.&lt;/p&gt;
&lt;p&gt;And you're welcome to examine the headers you can pull from this page
you're reading, wink wink. :)&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Ceph"></category></entry><entry><title>My first Open edX contribution</title><link href="https://xahteiwi.eu/blog/2016/01/05/my-first-open-edx-contribution/" rel="alternate"></link><published>2016-01-05T00:00:00+00:00</published><updated>2016-01-05T00:00:00+00:00</updated><author><name>florian</name></author><id>tag:xahteiwi.eu,2016-01-05:/blog/2016/01/05/my-first-open-edx-contribution/</id><summary type="html">&lt;p&gt;In which I talk about landing my first patch in Open edX.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've finally submitted my first code contribution to &lt;a href="https://open.edx.org/"&gt;Open
edX&lt;/a&gt;, a trivial patch for an annoying issue in
the LMS start page. The PR is
&lt;a href="https://github.com/edx/edx-platform/pull/11138"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The LMS component in Open edX is the stuff that actually provides a
learning platform to students, including the courseware itself, a
discussion forum, a wiki, and everything else you need for an
immersive learning experience. In our own &lt;a href="//academy.hastexo.com"&gt;hastexo
Academy&lt;/a&gt; environment, it of course also loads
the &lt;a href="//github.com/hastexo/hastexo-xblock"&gt;hastexo XBlock&lt;/a&gt; to interface
with arbitrarily complex, on-demand lab environments.&lt;/p&gt;
&lt;p&gt;If you want to know how the LMS fits into Open edX overall, there's
&lt;a href="//open.edx.org/sites/default/files/wysiwyg/open-edx-pages/edX_architecture_CMS_LMS_0.png" title="Open edX architecture diagram"&gt;an overview
graphic&lt;/a&gt; over at
&lt;a href="//open.edx.org"&gt;open.edx.org&lt;/a&gt; for your perusal.&lt;/p&gt;
&lt;p&gt;Being a new contributor to Open edX, this obviously involves jumping
through &lt;a href="https://github.com/edx/edx-platform/blob/master/CONTRIBUTING.rst"&gt;yet another Contributor Agreement
process&lt;/a&gt;. Here's
to hoping this gets resolved quickly.&lt;/p&gt;
&lt;h3&gt;Update, 2016-02-03&lt;/h3&gt;
&lt;p&gt;The contributor agreement was &lt;a href="//github.com/edx/edx-platform/pull/11138#issuecomment-168964638"&gt;squared away really
fast&lt;/a&gt;;
the patch review did, however, take some time. &lt;a href="//github.com/edx/edx-platform/commit/71a6779dfa44baa27d9c2b509587385edb4380af"&gt;But it's in
now&lt;/a&gt;.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on my blog on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="blog"></category><category term="Open edX"></category></entry><entry><title>Removing buckets in radosgw (and their contents)</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/removing-buckets-in-radosgw-and-their-contents/" rel="alternate"></link><published>2015-12-23T11:34:34+01:00</published><updated>2015-12-23T11:34:34+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2015-12-23:/resources/hints-and-kinks/removing-buckets-in-radosgw-and-their-contents/</id><summary type="html">&lt;p&gt;Every once in a while you'll want to remove a bucket in radosgw,
including all the objects contained in that bucket.&lt;/p&gt;
&lt;p&gt;Now you might use a utility like &lt;a href="http://s3tools.org/s3cmd"&gt;&lt;code&gt;s3cmd&lt;/code&gt;&lt;/a&gt;
for that purpose:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;s3cmd rb --recursive s3://mybucket
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The advantage to this approach is that your users can do it, using …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Every once in a while you'll want to remove a bucket in radosgw,
including all the objects contained in that bucket.&lt;/p&gt;
&lt;p&gt;Now you might use a utility like &lt;a href="http://s3tools.org/s3cmd"&gt;&lt;code&gt;s3cmd&lt;/code&gt;&lt;/a&gt;
for that purpose:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;s3cmd rb --recursive s3://mybucket
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The advantage to this approach is that your users can do it, using
just the regular S3 API. But this approach may be slow, particularly
if you have previously created your objects with &lt;code&gt;rest-bench&lt;/code&gt;,
&lt;code&gt;cosbench&lt;/code&gt;, or another benchmarking tool.&lt;/p&gt;
&lt;p&gt;So in the event that you want to remove buckets, and their objects,
directly from &lt;code&gt;radosgw&lt;/code&gt;, you can do so with&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;radosgw-admin bucket rm --bucket=mybucket --purge-objects
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This is usually the faster approach.&lt;/p&gt;
&lt;p&gt;If, at any time, you want to nuke all buckets owned by a particular
user, there is a command for that, as well. Use this one with care:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;radosgw&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="k"&gt;admin&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;user&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;rm&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;--uid=[username] --purge-data&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Ceph"></category></entry><entry><title>A minimal Ubuntu OpenStack Juju configuration in just four nodes</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/ubuntu-openstack-juju-4-nodes/" rel="alternate"></link><published>2015-12-23T00:00:00+00:00</published><updated>2015-12-23T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2015-12-23:/resources/hints-and-kinks/ubuntu-openstack-juju-4-nodes/</id><summary type="html">&lt;p&gt;Juju is Ubuntu's supported and preferred means of deployment
automation for an OpenStack cloud. While in Juju, a deployment unit (a
&lt;em&gt;Juju charm&lt;/em&gt;) generally expects to fully own the filesystem it is
being deployed on, Juju allows you to co-deploy charms on the same
physical machines, by way of using …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Juju is Ubuntu's supported and preferred means of deployment
automation for an OpenStack cloud. While in Juju, a deployment unit (a
&lt;em&gt;Juju charm&lt;/em&gt;) generally expects to fully own the filesystem it is
being deployed on, Juju allows you to co-deploy charms on the same
physical machines, by way of using LXC containers.&lt;/p&gt;
&lt;p&gt;Now in general, Juju should allow you to deploy complex service
&lt;em&gt;bundles&lt;/em&gt; in one swoop, however this works best when deploying to the
bare metal (i.e. without containers). Still, it is perfectly possible
to automate Juju deployment of an entire OpenStack cloud in just 4
physical nodes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A controller node (running your OpenStack APIs and your dashboard);&lt;/li&gt;
&lt;li&gt;a compute node (running VMs under libvirt/KVM management);&lt;/li&gt;
&lt;li&gt;a network gateway node (providing L3 network connectivity);&lt;/li&gt;
&lt;li&gt;a storage node (providing Cinder volumes via iSCSI and LVM).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The assumption for the setup below is that you already have a Juju
infrastructure in place. You may have set this up with MAAS, or you
may have just bootstrapped a deployment node and then created a Juju
&lt;code&gt;manual&lt;/code&gt; environment and added your 4 nodes via SSH.&lt;/p&gt;
&lt;p&gt;Note that the environment described here should not be used for
production purposes. However, the same approach is also applicable to
a 3-node controller HA cluster, 2-node Neutron gateway cluster with
support for HA routers, and as many converged Ceph/&lt;code&gt;nova-compute&lt;/code&gt;
nodes as you want.&lt;/p&gt;
&lt;h2&gt;Juju configuration&lt;/h2&gt;
&lt;p&gt;Consider the following Juju configuration YAML example, which you
might put into your home directory as &lt;code&gt;juju-config.yaml&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nt"&gt;keystone&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;openstack-origin&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;'cloud:trusty-liberty'&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;admin-password&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;'my&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;very&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;secret&lt;/span&gt;&lt;span class="nv"&gt; &lt;/span&gt;&lt;span class="s"&gt;password'&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nt"&gt;nova-cloud-controller&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;openstack-origin&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;'cloud:trusty-liberty'&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;network-manager&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;Neutron&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nt"&gt;neutron-gateway&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;openstack-origin&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;'cloud:trusty-liberty'&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;ext-port&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;eth2&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;bridge-mappings&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;'external:br-ex'&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;os-data-network&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;192.168.133.0/24&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;instance-mtu&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;1400&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nt"&gt;neutron-api&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;openstack-origin&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;'cloud:trusty-liberty'&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;network-device-mtu&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;1400&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;# Always make sure you enable security groups&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;neutron-security-groups&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;true&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;overlay-network-type&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;vxlan&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nt"&gt;rabbitmq-server&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;# Cinder is deployed in two parts: one for the API and scheduler&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;# (which can live in a container), one for the volume service (which&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;# cannot, at least not for the LVM/iSCSI backend)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nt"&gt;cinder-api&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;openstack-origin&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;'cloud:trusty-liberty'&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;enabled-services&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;api,scheduler&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nt"&gt;cinder-volume&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;openstack-origin&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;'cloud:trusty-liberty'&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;enabled-services&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;volume&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;# Adjust this to match the block device on your volume host&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;block-device&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;vdb&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nt"&gt;glance&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;openstack-origin&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;'cloud:trusty-liberty'&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nt"&gt;heat&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;openstack-origin&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;'cloud:trusty-liberty'&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nt"&gt;mysql&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nt"&gt;openstack-dashboard&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;openstack-origin&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;'cloud:trusty-liberty'&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;webroot&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;/&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nt"&gt;nova-compute&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;openstack-origin&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;'cloud:trusty-liberty'&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;manage-neutron-plugin-legacy-mode&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;false&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;# Change to qemu if in a nested cloud environment&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;virt-type&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;kvm&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nt"&gt;neutron-openvswitch&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;os-data-network&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;192.168.133.0/24&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Deployment&lt;/h2&gt;
&lt;p&gt;Then, you can run the following shell script to deploy your control
services to LXC containers on machine 1, &lt;code&gt;nova-compute&lt;/code&gt; (and its
subordinate charm, &lt;code&gt;neutron-openvswitch&lt;/code&gt;) to machine 2,
&lt;code&gt;neutron-gateway&lt;/code&gt; to machine 3, and &lt;code&gt;cinder-volume&lt;/code&gt; to machine 4.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="ch"&gt;#!/bin/bash -ex&lt;/span&gt;

&lt;span class="nv"&gt;CONFIG&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;~/juju-config.yaml

juju deploy --config&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$CONFIG&lt;/span&gt; mysql --to lxc:1
juju deploy --config&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$CONFIG&lt;/span&gt; rabbitmq-server --to lxc:1

sleep 120s

juju deploy --config&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$CONFIG&lt;/span&gt; keystone --to lxc:1
juju add-relation keystone:shared-db mysql:shared-db

juju deploy --config&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$CONFIG&lt;/span&gt; glance --to lxc:1
juju add-relation glance:identity-service keystone:identity-service
juju add-relation glance:shared-db mysql:shared-db

juju deploy --config&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$CONFIG&lt;/span&gt; neutron-api --to lxc:1
juju add-relation neutron-api:amqp rabbitmq-server:amqp
juju add-relation neutron-api:identity-service keystone:identity-service
juju add-relation neutron-api:shared-db mysql:shared-db

juju deploy --config&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$CONFIG&lt;/span&gt; neutron-gateway --to &lt;span class="m"&gt;3&lt;/span&gt;
juju add-relation neutron-gateway:amqp rabbitmq-server:amqp
juju add-relation neutron-gateway:neutron-plugin-api neutron-api:neutron-plugin-api
juju add-relation neutron-gateway:shared-db mysql:shared-db

juju deploy --config&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$CONFIG&lt;/span&gt; nova-cloud-controller --to lxc:1
juju add-relation nova-cloud-controller:amqp rabbitmq-server:amqp
juju add-relation nova-cloud-controller:identity-service keystone:identity-service
juju add-relation nova-cloud-controller:image-service glance:image-service
juju add-relation nova-cloud-controller:neutron-api neutron-api:neutron-api
juju add-relation nova-cloud-controller:shared-db mysql:shared-db

juju deploy --config&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$CONFIG&lt;/span&gt; nova-compute --to &lt;span class="m"&gt;2&lt;/span&gt;
juju add-relation nova-compute:amqp rabbitmq-server:amqp
juju add-relation nova-compute:cloud-compute nova-cloud-controller:cloud-compute
juju add-relation nova-compute:image-service glance:image-service
juju add-relation nova-compute:shared-db mysql:shared-db

juju deploy --config&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$CONFIG&lt;/span&gt; neutron-openvswitch
juju add-relation neutron-openvswitch:amqp rabbitmq-server:amqp
juju add-relation neutron-openvswitch:neutron-plugin-api neutron-api:neutron-plugin-api
juju add-relation neutron-openvswitch:neutron-plugin nova-compute:neutron-plugin 
juju deploy --config&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$CONFIG&lt;/span&gt; cinder cinder-api --to lxc:1
juju add-relation cinder-api:amqp rabbitmq-server:amqp
juju add-relation cinder-api:cinder-volume-service nova-cloud-controller:cinder-volume-service
juju add-relation cinder-api:identity-service keystone:identity-service
juju add-relation cinder-api:image-service glance:image-service
juju add-relation cinder-api:shared-db mysql:shared-db

juju deploy --config&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$CONFIG&lt;/span&gt; cinder cinder-volume --to &lt;span class="m"&gt;4&lt;/span&gt;
juju add-relation cinder-volume:amqp rabbitmq-server:amqp
juju add-relation cinder-volume:shared-db mysql:shared-db
juju add-relation cinder-volume:image-service glance:image-service

juju deploy --config&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$CONFIG&lt;/span&gt; openstack-dashboard --to &lt;span class="m"&gt;1&lt;/span&gt;
juju add-relation openstack-dashboard:identity-service keystone:identity-service

juju deploy --config&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$CONFIG&lt;/span&gt; heat --to lxc:1
juju add-relation heat:amqp rabbitmq-server:amqp
juju add-relation heat:identity-service keystone:identity-service
juju add-relation heat:shared-db mysql:shared-db
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And you're done! The whole process should give you an OpenStack cloud
in about 20-30 minutes.&lt;/p&gt;
&lt;p&gt;By the way, an exceedingly useful command to watch the installation progress of your Juju environment is:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;watch "juju stat --format=tabular"
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="OpenStack"></category><category term="Juju"></category></entry><entry><title>A Python one-liner for pretty-printing radosgw utilization</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/radosgw-utilization-one-liner/" rel="alternate"></link><published>2015-12-17T00:00:00+00:00</published><updated>2015-12-17T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2015-12-17:/resources/hints-and-kinks/radosgw-utilization-one-liner/</id><summary type="html">&lt;p&gt;In case you need a quick overview of how many radosgw objects live in your Ceph cluster, here‘s how you do that in one (slightly involved) line of Python.&lt;/p&gt;</summary><content type="html">&lt;p&gt;In case you need a quick overview of how many radosgw objects live in
your Ceph cluster, your first step is normally this command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;radosgw-admin bucket stats
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When used &lt;em&gt;without&lt;/em&gt; the &lt;code&gt;--bucket=&amp;lt;name&amp;gt;&lt;/code&gt; argument, this command lists
a bunch of statistics for &lt;em&gt;all&lt;/em&gt; your radosgw buckets, in a somewhat
convoluted JSON format. If you only want a simple list of all your
buckets and the number of objects they contain, you can use the
following bit of Python list comprehension magic:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;radosgw-admin bucket stats &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
  python -c &lt;span class="s1"&gt;'import json; import sys; print "\n".join(["%s: %s" % (str(x["bucket"]), ", ".join(["%s: %s" % (k, v["num_objects"]) for k,v in x["usage"].iteritems()])) for x in json.load(sys.stdin) if isinstance(x,dict)])'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And while the above is all on one line so you can easily copy and
paste, here are the Python bits in a slightly more legible format:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;

&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdin&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"bucket"&lt;/span&gt;&lt;span class="p"&gt;]),&lt;/span&gt;
                             &lt;span class="s2"&gt;", "&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                    &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"num_objects"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
                                        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"usage"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iteritems&lt;/span&gt;&lt;span class="p"&gt;()]))&lt;/span&gt;
                 &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;
                 &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;isinstance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Of course, you'll need to substitute &lt;code&gt;print()&lt;/code&gt; for &lt;code&gt;print&lt;/code&gt; if your
system runs only Python 3.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Ceph"></category><category term="Python"></category></entry><entry><title>Understanding radosgw benchmarks</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/understanding-radosgw-benchmarks/" rel="alternate"></link><published>2015-11-18T14:01:42+01:00</published><updated>2015-11-18T14:01:42+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2015-11-18:/resources/hints-and-kinks/understanding-radosgw-benchmarks/</id><summary type="html">&lt;p&gt;We've noticed that there are a few common misconceptions around
radosgw performance, and we're hoping that this post can clear up some
of those.&lt;/p&gt;
&lt;p&gt;radosgw is of course Ceph's RESTful object gateway. That means that
you can use any client that speaks the Amazon S3 or OpenStack Swift
protocol to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;We've noticed that there are a few common misconceptions around
radosgw performance, and we're hoping that this post can clear up some
of those.&lt;/p&gt;
&lt;p&gt;radosgw is of course Ceph's RESTful object gateway. That means that
you can use any client that speaks the Amazon S3 or OpenStack Swift
protocol to interact with your Ceph cluster. Since RESTful object
access is HTTP based, this also means you can combine radosgw with
HTTP load balancers, reverse proxies and the like, which often comes
in handy.&lt;/p&gt;
&lt;p&gt;In general, as any RESTful object storage, you would generally store
data in radosgw that you read and write in one chunk, and where bulk
storage is more important than online availability (if you need data
at your fingertips, you'd use RBD or CephFS or even straight-up RADOS
instead, but those are for different use cases).&lt;/p&gt;
&lt;p&gt;The performance implications of using radosgw (or any RESTful object
storage, for that matter) usually apply to one of two different use
cases:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Either you want to store lots of data in bulk, and come back to it
  later. This, for example, is why in OpenStack backups of volumes and
  databases typically go to OpenStack Swift or radosgw speaking the
  Swift protocol.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Or you want to store lots of relatively small data chunks really
  fast. Suppose you have a monitoring system storing data points in
  S3.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So either you want to write big chunks of data, in which case you're
interested in throughput (typically measured in amount of data per
unit time, such as MB/s). Or you want to write small chunks, then
what's important is completed operations per unit time (typically
measured in number of writes per second, which in the RESTful case
would be HTTP PUTs per second).&lt;/p&gt;
&lt;p&gt;Now with radosgw, you can measure this with a handy tool called
rest-bench. Sadly rest-bench no longer builds with Ceph for Infernalis
and later, because the Ceph developers now favor Intel's COSbench
utility. But rest-bench from older Ceph releases will be around for a
while and it's handy because unlike COSbench, it doesn't require Java.&lt;/p&gt;
&lt;p&gt;So let's take a look. The general invocation for rest-bench is like
this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;rest-bench -t &lt;span class="nv"&gt;$CONCURRENCY&lt;/span&gt; -b &lt;span class="nv"&gt;$SIZE&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
  --seconds&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$SECS&lt;/span&gt; --api-host&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$RGW&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
  --bucket&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$BUCKET&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
  --access-key&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$KEY&lt;/span&gt; --secret&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$SECRET&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
  --no-cleanup write
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;What does that mean?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;$CONCURRENCY&lt;/code&gt; is the number of concurrently running PUT
  operations. Basically, this is how many clients you want to
  simulate. The default is 16.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;$SIZE&lt;/code&gt; is the size of an individual object being written. The default
  here is 4MB.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;$RGW&lt;/code&gt; is of course your radosgw host including a port number.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;$SECS&lt;/code&gt; is the number of seconds to run the benchmark. The default is
  60, but in order to get a quick idea of your radosgw performance, as
  little as 10 is often sufficient.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;$BUCKET&lt;/code&gt; is the scratch bucket where you're creating objects during
  the benchmark run.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;$ACCESS_KEY&lt;/code&gt; and &lt;code&gt;$SECRET&lt;/code&gt; are the access and secret keys you created
  with &lt;code&gt;radosgw-admin user create&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;write&lt;/code&gt; specifies a random write benchmark.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;--no-cleanup&lt;/code&gt; specifies that you don't want the bucket to be
    cleaned out after the benchmark run. It's normally fine to run
    several benchmarks in a row and only empty the benchmark bucket
    when done with all.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Object size&lt;/h2&gt;
&lt;p&gt;First, we'll examine how object size affects radosgw throughput and
latency.&lt;/p&gt;
&lt;p&gt;So let's start out with a benchmark run that uses the default settings
for concurrency and object sizes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;RGW&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;localhost:7480
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;SECS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;10&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;SIZE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$((&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&amp;lt;&amp;lt;&lt;span class="m"&gt;22&lt;/span&gt;&lt;span class="k"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# 4MB object size&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;BUCKET&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;bench
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;CONCURRENCY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;16&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;KEY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;your_radosgw_key
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;SECRET&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;your_radosgw_secret

rest-bench -t &lt;span class="nv"&gt;$CONCURRENCY&lt;/span&gt; -b &lt;span class="nv"&gt;$SIZE&lt;/span&gt; --seconds&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$SECS&lt;/span&gt; --api-host&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$RGW&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
--bucket&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$BUCKET&lt;/span&gt; --access-key&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$KEY&lt;/span&gt; --secret&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$SECRET&lt;/span&gt; --no-cleanup write
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;host&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;localhost&lt;/span&gt;:&lt;span class="mi"&gt;7480&lt;/span&gt;
&lt;span class="nv"&gt;Maintaining&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="nv"&gt;concurrent&lt;/span&gt; &lt;span class="nv"&gt;writes&lt;/span&gt; &lt;span class="nv"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;4194304&lt;/span&gt; &lt;span class="nv"&gt;bytes&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;up&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="nv"&gt;seconds&lt;/span&gt; &lt;span class="nv"&gt;or&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;objects&lt;/span&gt;
[...]
&lt;span class="nv"&gt;Total&lt;/span&gt; &lt;span class="nv"&gt;time&lt;/span&gt; &lt;span class="nv"&gt;run&lt;/span&gt;:         &lt;span class="mi"&gt;10&lt;/span&gt;.&lt;span class="mi"&gt;312134&lt;/span&gt;
&lt;span class="nv"&gt;Total&lt;/span&gt; &lt;span class="nv"&gt;writes&lt;/span&gt; &lt;span class="nv"&gt;made&lt;/span&gt;:      &lt;span class="mi"&gt;399&lt;/span&gt;
&lt;span class="nv"&gt;Write&lt;/span&gt; &lt;span class="nv"&gt;size&lt;/span&gt;:             &lt;span class="mi"&gt;4194304&lt;/span&gt;
&lt;span class="nv"&gt;Bandwidth&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;MB&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;sec&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:     &lt;span class="mi"&gt;154&lt;/span&gt;.&lt;span class="mi"&gt;769&lt;/span&gt; 
[...]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So that means we achieved a bandwidth of just under 155 MB/s (which is
near the max RADOS bandwidth this particular cluster is capable of;
it's by no means a high-end system) and we managed 399 writes, or
approx. 40 PUTs/s.&lt;/p&gt;
&lt;p&gt;Let's see how going even bigger changes things:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ &lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;SIZE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$((&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&amp;lt;&amp;lt;&lt;span class="m"&gt;26&lt;/span&gt;&lt;span class="k"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# 64MB object size&lt;/span&gt;

$ rest-bench -t &lt;span class="nv"&gt;$CONCURRENCY&lt;/span&gt; -b &lt;span class="nv"&gt;$SIZE&lt;/span&gt; --seconds&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$SECS&lt;/span&gt; --api-host&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$RGW&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
--bucket&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$BUCKET&lt;/span&gt; --access-key&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$KEY&lt;/span&gt; --secret&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$SECRET&lt;/span&gt; --no-cleanup write
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;host&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;localhost&lt;/span&gt;:&lt;span class="mi"&gt;7480&lt;/span&gt;
 &lt;span class="nv"&gt;Maintaining&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="nv"&gt;concurrent&lt;/span&gt; &lt;span class="nv"&gt;writes&lt;/span&gt; &lt;span class="nv"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;67108864&lt;/span&gt; &lt;span class="nv"&gt;bytes&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;up&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="nv"&gt;seconds&lt;/span&gt; &lt;span class="nv"&gt;or&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;objects&lt;/span&gt;
[...]
 &lt;span class="nv"&gt;Total&lt;/span&gt; &lt;span class="nv"&gt;time&lt;/span&gt; &lt;span class="nv"&gt;run&lt;/span&gt;:         &lt;span class="mi"&gt;13&lt;/span&gt;.&lt;span class="mi"&gt;959088&lt;/span&gt;
&lt;span class="nv"&gt;Total&lt;/span&gt; &lt;span class="nv"&gt;writes&lt;/span&gt; &lt;span class="nv"&gt;made&lt;/span&gt;:      &lt;span class="mi"&gt;35&lt;/span&gt;
&lt;span class="nv"&gt;Write&lt;/span&gt; &lt;span class="nv"&gt;size&lt;/span&gt;:             &lt;span class="mi"&gt;67108864&lt;/span&gt;
&lt;span class="nv"&gt;Bandwidth&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;MB&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;sec&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:     &lt;span class="mi"&gt;160&lt;/span&gt;.&lt;span class="mi"&gt;469&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Perfectly logical. Our bandwidth doesn't change much, but of course
the number of PUTs we get done per second decreases significantly, to
a puny 3 PUTs/s. (Note: radosgw does break down objects into smaller
chunks when it talks to RADOS. However, this doesn't change the fact
that a client needs to haul a 64MB object across the network and
through the radosgw HTTP server.)&lt;/p&gt;
&lt;p&gt;Let's do the opposite now, and go for smaller objects. Suppose your
application is using a typical object size of 32K.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;SIZE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$((&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&amp;lt;&amp;lt;&lt;span class="m"&gt;15&lt;/span&gt;&lt;span class="k"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# 32KB object size&lt;/span&gt;
rest-bench -t &lt;span class="nv"&gt;$CONCURRENCY&lt;/span&gt; -b &lt;span class="nv"&gt;$SIZE&lt;/span&gt; --seconds&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$SECS&lt;/span&gt; --api-host&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$RGW&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
--bucket&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$BUCKET&lt;/span&gt; --access-key&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$KEY&lt;/span&gt; --secret&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$SECRET&lt;/span&gt; --no-cleanup write
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;host&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;localhost&lt;/span&gt;:&lt;span class="mi"&gt;7480&lt;/span&gt;
 &lt;span class="nv"&gt;Maintaining&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="nv"&gt;concurrent&lt;/span&gt; &lt;span class="nv"&gt;writes&lt;/span&gt; &lt;span class="nv"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;32768&lt;/span&gt; &lt;span class="nv"&gt;bytes&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;up&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="nv"&gt;seconds&lt;/span&gt; &lt;span class="nv"&gt;or&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;objects&lt;/span&gt;
[...]
 &lt;span class="nv"&gt;Total&lt;/span&gt; &lt;span class="nv"&gt;time&lt;/span&gt; &lt;span class="nv"&gt;run&lt;/span&gt;:         &lt;span class="mi"&gt;10&lt;/span&gt;.&lt;span class="mi"&gt;042325&lt;/span&gt;
&lt;span class="nv"&gt;Total&lt;/span&gt; &lt;span class="nv"&gt;writes&lt;/span&gt; &lt;span class="nv"&gt;made&lt;/span&gt;:      &lt;span class="mi"&gt;2965&lt;/span&gt;
&lt;span class="nv"&gt;Write&lt;/span&gt; &lt;span class="nv"&gt;size&lt;/span&gt;:             &lt;span class="mi"&gt;32768&lt;/span&gt;
&lt;span class="nv"&gt;Bandwidth&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;MB&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;sec&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:     &lt;span class="mi"&gt;9&lt;/span&gt;.&lt;span class="mi"&gt;227&lt;/span&gt;
[...]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Of course if we looked at our bandwidth alone, this would be an
abysmal result. But your application is trying to write 32K chunks,
and lots of them. And it's succeeding just fine; we're now near 300
PUTs/s.&lt;/p&gt;
&lt;p&gt;Going even smaller, we'd expect PUTs/s to trend further up and nominal
MB/s to go down. Let's try with 4K objects:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;SIZE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$((&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&amp;lt;&amp;lt;&lt;span class="m"&gt;12&lt;/span&gt;&lt;span class="k"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# 4KB object size&lt;/span&gt;
rest-bench -t &lt;span class="nv"&gt;$CONCURRENCY&lt;/span&gt; -b &lt;span class="nv"&gt;$SIZE&lt;/span&gt; --seconds&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$SECS&lt;/span&gt; --api-host&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$RGW&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
--bucket&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$BUCKET&lt;/span&gt; --access-key&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$KEY&lt;/span&gt; --secret&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$SECRET&lt;/span&gt; --no-cleanup write
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;host&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;localhost&lt;/span&gt;:&lt;span class="mi"&gt;7480&lt;/span&gt;
 &lt;span class="nv"&gt;Maintaining&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="nv"&gt;concurrent&lt;/span&gt; &lt;span class="nv"&gt;writes&lt;/span&gt; &lt;span class="nv"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;4096&lt;/span&gt; &lt;span class="nv"&gt;bytes&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;up&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="nv"&gt;seconds&lt;/span&gt; &lt;span class="nv"&gt;or&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;objects&lt;/span&gt;
[...]
&lt;span class="nv"&gt;Total&lt;/span&gt; &lt;span class="nv"&gt;time&lt;/span&gt; &lt;span class="nv"&gt;run&lt;/span&gt;:         &lt;span class="mi"&gt;10&lt;/span&gt;.&lt;span class="mi"&gt;052134&lt;/span&gt;
&lt;span class="nv"&gt;Total&lt;/span&gt; &lt;span class="nv"&gt;writes&lt;/span&gt; &lt;span class="nv"&gt;made&lt;/span&gt;:      &lt;span class="mi"&gt;3249&lt;/span&gt;
&lt;span class="nv"&gt;Write&lt;/span&gt; &lt;span class="nv"&gt;size&lt;/span&gt;:             &lt;span class="mi"&gt;4096&lt;/span&gt;
&lt;span class="nv"&gt;Bandwidth&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;MB&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;sec&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:     &lt;span class="mi"&gt;1&lt;/span&gt;.&lt;span class="mi"&gt;263&lt;/span&gt; 
[...]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And sure enough, 325 PUTs/s.&lt;/p&gt;
&lt;p&gt;So in summary, larger object sizes increase your write bandwidth to
your radosgw cluster, while smaller objects enable a higher
writes-per-second load.&lt;/p&gt;
&lt;h2&gt;Concurrency&lt;/h2&gt;
&lt;p&gt;Another aspect that influences your radosgw performance is
concurrency. Generally, the principle is simple: if you have multiple
parallel applications that write to radosgw and that don't have to
wait for each other, your aggregate throughput will be higher, and
your writes-per-second will be higher as well. If you have a small
number (in the worst case, a single one that is single-threaded) and
you can only ever issue one PUT at a time, both throughput and
writes-per-second will be lower in aggregate.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;RGW&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;localhost:7480
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;SECS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;10&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;SIZE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$((&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&amp;lt;&amp;lt;&lt;span class="m"&gt;22&lt;/span&gt;&lt;span class="k"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# back to 4MB object size&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;BUCKET&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;bench
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;CONCURRENCY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;16&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;KEY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&amp;lt;key&amp;gt;
&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;SECRET&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&amp;lt;secret&amp;gt;

$ rest-bench -t &lt;span class="nv"&gt;$CONCURRENCY&lt;/span&gt; -b &lt;span class="nv"&gt;$SIZE&lt;/span&gt; --seconds&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$SECS&lt;/span&gt; --api-host&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$RGW&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
--bucket&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$BUCKET&lt;/span&gt; --access-key&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$KEY&lt;/span&gt; --secret&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$SECRET&lt;/span&gt; --no-cleanup write
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;host&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;localhost&lt;/span&gt;:&lt;span class="mi"&gt;7480&lt;/span&gt;
 &lt;span class="nv"&gt;Maintaining&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="nv"&gt;concurrent&lt;/span&gt; &lt;span class="nv"&gt;writes&lt;/span&gt; &lt;span class="nv"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;4194304&lt;/span&gt; &lt;span class="nv"&gt;bytes&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;up&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="nv"&gt;seconds&lt;/span&gt; &lt;span class="nv"&gt;or&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;objects&lt;/span&gt;
[...]
&lt;span class="nv"&gt;Total&lt;/span&gt; &lt;span class="nv"&gt;time&lt;/span&gt; &lt;span class="nv"&gt;run&lt;/span&gt;:         &lt;span class="mi"&gt;10&lt;/span&gt;.&lt;span class="mi"&gt;294444&lt;/span&gt;
&lt;span class="nv"&gt;Total&lt;/span&gt; &lt;span class="nv"&gt;writes&lt;/span&gt; &lt;span class="nv"&gt;made&lt;/span&gt;:      &lt;span class="mi"&gt;394&lt;/span&gt;
&lt;span class="nv"&gt;Write&lt;/span&gt; &lt;span class="nv"&gt;size&lt;/span&gt;:             &lt;span class="mi"&gt;4194304&lt;/span&gt;
&lt;span class="nv"&gt;Bandwidth&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;MB&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;sec&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:     &lt;span class="mi"&gt;153&lt;/span&gt;.&lt;span class="mi"&gt;092&lt;/span&gt; 
[...]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;CONCURRENCY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;
rest-bench -t &lt;span class="nv"&gt;$CONCURRENCY&lt;/span&gt; -b &lt;span class="nv"&gt;$SIZE&lt;/span&gt; --seconds&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$SECS&lt;/span&gt; --api-host&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$RGW&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
--bucket&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$BUCKET&lt;/span&gt; --access-key&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$KEY&lt;/span&gt; --secret&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$SECRET&lt;/span&gt; --no-cleanup write
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;host&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;localhost&lt;/span&gt;:&lt;span class="mi"&gt;7480&lt;/span&gt;
 &lt;span class="nv"&gt;Maintaining&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;concurrent&lt;/span&gt; &lt;span class="nv"&gt;writes&lt;/span&gt; &lt;span class="nv"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;4194304&lt;/span&gt; &lt;span class="nv"&gt;bytes&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;up&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="nv"&gt;seconds&lt;/span&gt; &lt;span class="nv"&gt;or&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;objects&lt;/span&gt;
[...]
 &lt;span class="nv"&gt;Total&lt;/span&gt; &lt;span class="nv"&gt;time&lt;/span&gt; &lt;span class="nv"&gt;run&lt;/span&gt;:         &lt;span class="mi"&gt;10&lt;/span&gt;.&lt;span class="mi"&gt;090768&lt;/span&gt;
&lt;span class="nv"&gt;Total&lt;/span&gt; &lt;span class="nv"&gt;writes&lt;/span&gt; &lt;span class="nv"&gt;made&lt;/span&gt;:      &lt;span class="mi"&gt;147&lt;/span&gt;
&lt;span class="nv"&gt;Write&lt;/span&gt; &lt;span class="nv"&gt;size&lt;/span&gt;:             &lt;span class="mi"&gt;4194304&lt;/span&gt;
&lt;span class="nv"&gt;Bandwidth&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;MB&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;sec&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:     &lt;span class="mi"&gt;58&lt;/span&gt;.&lt;span class="mi"&gt;271&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Logical, right? Rather than allowing 16 threads to interact with the
cluster in parallel, we now have to wait for every single PUT to
complete before we can issue the next. Pretty obvious to see both our
writes-per-second and our aggregate bandwidth to drop by more than
half.&lt;/p&gt;
&lt;p&gt;The effect is even slightly less pronounced with smaller
objects. Compare the two for 4KB objects:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;SIZE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$((&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="s"&gt;&amp;lt;&amp;lt;12)) # 4KB object size&lt;/span&gt;
&lt;span class="s"&gt;export CONCURRENCY=1&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;
rest-bench &lt;span class="o"&gt;-&lt;/span&gt;t &lt;span class="nv"&gt;$CONCURRENCY&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;b &lt;span class="nv"&gt;$SIZE&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="nv"&gt;seconds&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$SECS&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;api-host&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$RGW&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
&lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="nv"&gt;bucket&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$BUCKET&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;access-key&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$KEY&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="nv"&gt;secret&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$SECRET&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;no-cleanup write
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;host&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;localhost&lt;/span&gt;:&lt;span class="mi"&gt;7480&lt;/span&gt;
 &lt;span class="nv"&gt;Maintaining&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="nv"&gt;concurrent&lt;/span&gt; &lt;span class="nv"&gt;writes&lt;/span&gt; &lt;span class="nv"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;4096&lt;/span&gt; &lt;span class="nv"&gt;bytes&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;up&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="nv"&gt;seconds&lt;/span&gt; &lt;span class="nv"&gt;or&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;objects&lt;/span&gt;
[...]
 &lt;span class="nv"&gt;Total&lt;/span&gt; &lt;span class="nv"&gt;time&lt;/span&gt; &lt;span class="nv"&gt;run&lt;/span&gt;:         &lt;span class="mi"&gt;10&lt;/span&gt;.&lt;span class="mi"&gt;053976&lt;/span&gt;
&lt;span class="nv"&gt;Total&lt;/span&gt; &lt;span class="nv"&gt;writes&lt;/span&gt; &lt;span class="nv"&gt;made&lt;/span&gt;:      &lt;span class="mi"&gt;3211&lt;/span&gt;
&lt;span class="nv"&gt;Write&lt;/span&gt; &lt;span class="nv"&gt;size&lt;/span&gt;:             &lt;span class="mi"&gt;4096&lt;/span&gt;
&lt;span class="nv"&gt;Bandwidth&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;MB&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;sec&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:     &lt;span class="mi"&gt;1&lt;/span&gt;.&lt;span class="mi"&gt;248&lt;/span&gt; 
[...]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;export&lt;/span&gt; &lt;span class="nv"&gt;CONCURRENCY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; 
rest-bench -t &lt;span class="nv"&gt;$CONCURRENCY&lt;/span&gt; -b &lt;span class="nv"&gt;$SIZE&lt;/span&gt; --seconds&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$SECS&lt;/span&gt; --api-host&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$RGW&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
--bucket&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$BUCKET&lt;/span&gt; --access-key&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$KEY&lt;/span&gt; --secret&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$SECRET&lt;/span&gt; --no-cleanup write
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;host&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;localhost&lt;/span&gt;:&lt;span class="mi"&gt;7480&lt;/span&gt;
 &lt;span class="nv"&gt;Maintaining&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;concurrent&lt;/span&gt; &lt;span class="nv"&gt;writes&lt;/span&gt; &lt;span class="nv"&gt;of&lt;/span&gt; &lt;span class="mi"&gt;4096&lt;/span&gt; &lt;span class="nv"&gt;bytes&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;up&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt; &lt;span class="nv"&gt;seconds&lt;/span&gt; &lt;span class="nv"&gt;or&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="nv"&gt;objects&lt;/span&gt;
[...]
 &lt;span class="nv"&gt;Total&lt;/span&gt; &lt;span class="nv"&gt;time&lt;/span&gt; &lt;span class="nv"&gt;run&lt;/span&gt;:         &lt;span class="mi"&gt;10&lt;/span&gt;.&lt;span class="mi"&gt;007962&lt;/span&gt;
&lt;span class="nv"&gt;Total&lt;/span&gt; &lt;span class="nv"&gt;writes&lt;/span&gt; &lt;span class="nv"&gt;made&lt;/span&gt;:      &lt;span class="mi"&gt;1632&lt;/span&gt;
&lt;span class="nv"&gt;Write&lt;/span&gt; &lt;span class="nv"&gt;size&lt;/span&gt;:             &lt;span class="mi"&gt;4096&lt;/span&gt;
&lt;span class="nv"&gt;Bandwidth&lt;/span&gt; &lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;MB&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;sec&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:     &lt;span class="mi"&gt;0&lt;/span&gt;.&lt;span class="mi"&gt;637&lt;/span&gt;
[...]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Both writes-per-second and throughput drop by half.&lt;/p&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;Note: If you've dealt with storage performance considerations before,
some of these will be blindingly obvious. Apologies for that; it just
shows that Ceph is generally a well-behaved system that does what you
would normally expect.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Larger objects have less overhead, and as such increase your
  throughput,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Smaller objects increase writes-per-second at the expense of
  aggregate throughput, because they have more overhead,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Serialization and contention (both of which mean reduced
  concurrency) reduce your data throughput and your writes-per-second.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What does this mean for your radosgw application?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Concurrency is good. If your application can fire a bunch of RESTful
  objects at radosgw, which don't have to wait for each other, great.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you need to optimize for lots of PUTs per second, make sure that
  your application sends data in reasonably sized chunks. And again,
  make sure it is capable of doing so in parallel.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you need to optimize for throughput instead, make sure that your application coalesces data into large objects. There is a big difference between sending one object of 10MB, and 10 objects of 1 MB.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Ceph"></category></entry><entry><title>OpenStack for Open edX: Inside and Out (SWITCH ICT-Focus 2015)</title><link href="https://xahteiwi.eu/resources/presentations/ictfocus2015/" rel="alternate"></link><published>2015-11-10T00:00:00+00:00</published><updated>2015-11-10T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2015-11-10:/resources/presentations/ictfocus2015/</id><content type="html">&lt;p&gt;My presentation at &lt;a href="https://switch.ch"&gt;SWITCH&lt;/a&gt; ICT-Focus 2015.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/ictfocus2015/"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="Conference"></category><category term="OpenStack"></category><category term="Open edX"></category></entry><entry><title>Clusters, Routers, Agents and Networks: High Availability in Neutron</title><link href="https://xahteiwi.eu/resources/presentations/openstacksummit2015-tokyo-neutron-ha/" rel="alternate"></link><published>2015-10-28T00:00:00+00:00</published><updated>2015-10-28T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2015-10-28:/resources/presentations/openstacksummit2015-tokyo-neutron-ha/</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;Of everything that we can build and deploy in a highly-available
fashion in OpenStack, deploying highly available networking has been
one of the trickiest, most complex aspects to get right.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I team up with Adam Spiers (SUSE) and Assaf Muller (Red Hat) to
discuss high availability in OpenStack Neutron.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;Video …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;blockquote&gt;
&lt;p&gt;Of everything that we can build and deploy in a highly-available
fashion in OpenStack, deploying highly available networking has been
one of the trickiest, most complex aspects to get right.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I team up with Adam Spiers (SUSE) and Assaf Muller (Red Hat) to
discuss high availability in OpenStack Neutron.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;Video: &lt;a href="https://youtu.be/vBZgtHgSdOY"&gt;YouTube&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/openstacksummit2015-tokyo-neutron-ha/"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="OpenStack"></category><category term="Conference"></category></entry><entry><title>Automated OpenStack deployment: A comparison</title><link href="https://xahteiwi.eu/resources/presentations/automated-openstack-deployment-a-comparison/" rel="alternate"></link><published>2015-10-27T00:00:00+00:00</published><updated>2015-10-27T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2015-10-27:/resources/presentations/automated-openstack-deployment-a-comparison/</id><summary type="html">&lt;p&gt;From the 2015 OpenStack Summit in Tokyo. A comparison of automated
deployment tools for OpenStack.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;OSP Director on RHEL OSP 7&lt;/li&gt;
&lt;li&gt;Juju on Ubuntu Trusty&lt;/li&gt;
&lt;li&gt;Chef/Crowbar on SUSE OpenStack Cloud 5&lt;/li&gt;
&lt;li&gt;Ansible on Rackspace Private Cloud&lt;/li&gt;
&lt;li&gt;Fuel on Mirantis OpenStack&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;About 45 minutes.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Video: &lt;a href="https://youtu.be/LM1ANSge01g"&gt;YouTube&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Slides: &lt;a href="https://fghaas.github.io/openstacksummit2015-tokyo-deployment/"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Use the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;From the 2015 OpenStack Summit in Tokyo. A comparison of automated
deployment tools for OpenStack.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;OSP Director on RHEL OSP 7&lt;/li&gt;
&lt;li&gt;Juju on Ubuntu Trusty&lt;/li&gt;
&lt;li&gt;Chef/Crowbar on SUSE OpenStack Cloud 5&lt;/li&gt;
&lt;li&gt;Ansible on Rackspace Private Cloud&lt;/li&gt;
&lt;li&gt;Fuel on Mirantis OpenStack&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;About 45 minutes.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Video: &lt;a href="https://youtu.be/LM1ANSge01g"&gt;YouTube&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Slides: &lt;a href="https://fghaas.github.io/openstacksummit2015-tokyo-deployment/"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Use the arrow keys to navigate through the presentation, hit &lt;code&gt;Esc&lt;/code&gt; to
zoom out for an overview, or just advance by hitting the spacebar.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="OpenStack"></category></entry><entry><title>Open edX</title><link href="https://xahteiwi.eu/resources/presentations/open-edx/" rel="alternate"></link><published>2015-10-12T05:45:00+00:00</published><updated>2015-10-12T05:45:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2015-10-12:/resources/presentations/open-edx/</id><summary type="html">&lt;p&gt;&lt;a href="http://open.edx.org"&gt;Open edX&lt;/a&gt; is an extensible, highly scalable,
open-source learning management platform. Originally conceived at
&lt;a href="http://www.mit.edu"&gt;MIT&lt;/a&gt; and &lt;a href="http://www.harvard.edu"&gt;Harvard
University&lt;/a&gt;, the edx.org platform it is
currently backed by more than 70 organizations world-wide and serves
more than 4 million students. Since 2013, the software running edx.org
is available under an …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="http://open.edx.org"&gt;Open edX&lt;/a&gt; is an extensible, highly scalable,
open-source learning management platform. Originally conceived at
&lt;a href="http://www.mit.edu"&gt;MIT&lt;/a&gt; and &lt;a href="http://www.harvard.edu"&gt;Harvard
University&lt;/a&gt;, the edx.org platform it is
currently backed by more than 70 organizations world-wide and serves
more than 4 million students. Since 2013, the software running edx.org
is available under an open source software license, enabling private and
public organizations to run and operate the same learning platform under
the Open edX initiative.&lt;/p&gt;
&lt;p&gt;hastexo's contribution to Open edX is twofold: first, we enabled Open
edX to run in an automated, distributed fashion on the OpenStack
platform. Then, we taught Open edX the ability to automate the
orchestration of on-demand OpenStack training environments. Both are now
an integral part of our hastexo Academy service offering.&lt;/p&gt;
&lt;p&gt;Want to find out how you can use Open edX and OpenStack to your
advantage? Check out the short animation below (with audio) to find out.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/academy-openedx/"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="Open edX"></category></entry><entry><title>Manageable Application Containers: Lightning Quick Updates, Scaleable Security, Easy High Availability</title><link href="https://xahteiwi.eu/resources/presentations/manageable-application-containers/" rel="alternate"></link><published>2015-10-07T00:00:00+00:00</published><updated>2015-10-07T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2015-10-07:/resources/presentations/manageable-application-containers/</id><summary type="html">&lt;p&gt;From LinuxCon Europe 2015 in Dublin. An alternative approach to
managing application containers.&lt;/p&gt;
&lt;!--break--&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/lceu2015/"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Use the arrow keys to navigate through the presentation, hit &lt;code&gt;Esc&lt;/code&gt; to
zoom out for an overview, or just advance by hitting the spacebar.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct …&lt;/p&gt;</summary><content type="html">&lt;p&gt;From LinuxCon Europe 2015 in Dublin. An alternative approach to
managing application containers.&lt;/p&gt;
&lt;!--break--&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/lceu2015/"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Use the arrow keys to navigate through the presentation, hit &lt;code&gt;Esc&lt;/code&gt; to
zoom out for an overview, or just advance by hitting the spacebar.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="LXC"></category><category term="Containers"></category><category term="Conference"></category></entry><entry><title>OpenStack Orchestration and Automation</title><link href="https://xahteiwi.eu/resources/presentations/osil2015-orchestration/" rel="alternate"></link><published>2015-06-15T00:00:00+00:00</published><updated>2015-06-15T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2015-06-15:/resources/presentations/osil2015-orchestration/</id><content type="html">&lt;p&gt;My presentation from OpenStack Israel 2015. A fast-paced
introduction to &lt;code&gt;cloud-init&lt;/code&gt; and OpenStack Heat.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;Video: &lt;a href="https://youtu.be/oXYXqwnr5io"&gt;YouTube&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/osil2015-orchestration/"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="OpenStack"></category><category term="Conference"></category></entry><entry><title>Ceph Tech Talk: Placement Groups</title><link href="https://xahteiwi.eu/resources/presentations/ceph-tech-talk-pg/" rel="alternate"></link><published>2015-05-27T00:00:00+00:00</published><updated>2015-05-27T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2015-05-27:/resources/presentations/ceph-tech-talk-pg/</id><summary type="html">&lt;p&gt;A Ceph Tech Talk on the ins and outs of Ceph Placement Groups (PGs).&lt;/p&gt;
&lt;!--break--&gt;
&lt;p&gt;Special thanks to Patrick McGarry for inviting me to speak on a Ceph
Tech Talk.&lt;/p&gt;
&lt;p&gt;For the slide deck, use the PgUp/PgDown keys to navigate, or just
advance by hitting the spacebar.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Video: &lt;a href="https://youtu.be/BPuaKErc0uA"&gt;YouTube&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Slides …&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;A Ceph Tech Talk on the ins and outs of Ceph Placement Groups (PGs).&lt;/p&gt;
&lt;!--break--&gt;
&lt;p&gt;Special thanks to Patrick McGarry for inviting me to speak on a Ceph
Tech Talk.&lt;/p&gt;
&lt;p&gt;For the slide deck, use the PgUp/PgDown keys to navigate, or just
advance by hitting the spacebar.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Video: &lt;a href="https://youtu.be/BPuaKErc0uA"&gt;YouTube&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Slides: &lt;a href="https://fghaas.github.io/ceph-tech-talk-pg/"&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="Ceph"></category></entry><entry><title>Have Data, Want Scale, Indefinitely: Exploring Ceph</title><link href="https://xahteiwi.eu/resources/presentations/ceph-intro/" rel="alternate"></link><published>2014-11-15T00:00:00+00:00</published><updated>2014-11-15T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2014-11-15:/resources/presentations/ceph-intro/</id><summary type="html">&lt;p&gt;An introduction to Ceph (with audio).&lt;/p&gt;
&lt;!--break--&gt;
&lt;p&gt;For the slide deck, use the PgUp/PgDown keys to navigate, or just
advance by hitting the spacebar. For audio narration, just click the
icon in the bottom-left corner and the presentation will auto-advance
in step with the narration.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/ceph-intro/"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally …&lt;/p&gt;</summary><content type="html">&lt;p&gt;An introduction to Ceph (with audio).&lt;/p&gt;
&lt;!--break--&gt;
&lt;p&gt;For the slide deck, use the PgUp/PgDown keys to navigate, or just
advance by hitting the spacebar. For audio narration, just click the
icon in the bottom-left corner and the presentation will auto-advance
in step with the narration.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/ceph-intro/"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="Ceph"></category></entry><entry><title>Ceph Performance Demystified: Benchmarks, Tools, and the Metrics that Matter</title><link href="https://xahteiwi.eu/resources/presentations/ceph-day-london/" rel="alternate"></link><published>2014-10-22T00:00:00+00:00</published><updated>2014-10-22T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2014-10-22:/resources/presentations/ceph-day-london/</id><content type="html">&lt;p&gt;Mystified about Ceph performance tuning and benchmarking? Don't
despair!&lt;/p&gt;
&lt;p&gt;This presentation was given at Ceph Day London in 2014. &lt;!--break--&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Slides: &lt;a href="//fghaas.github.io/ceph-day-london/"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Video (courtesy of the Ceph team at Red Hat): &lt;a href="//youtu.be/0B_A9VkRb1E"&gt;YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="Ceph"></category></entry><entry><title>OpenStack High Availability: Are We There Yet?</title><link href="https://xahteiwi.eu/resources/presentations/lceu2014-openstack-ha/" rel="alternate"></link><published>2014-10-14T00:00:00+00:00</published><updated>2014-10-14T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2014-10-14:/resources/presentations/lceu2014-openstack-ha/</id><content type="html">&lt;p&gt;My presentation from LinuxCon Europe 2014, outlining the state
of high availability in OpenStack.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/lceu2014-openstack-ha/"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="OpenStack"></category><category term="Conference"></category></entry><entry><title>Speak! How to talk in public and not wreck your voice</title><link href="https://xahteiwi.eu/resources/presentations/speak-how-to-talk-in-public-and-not-wreck-your-voice/" rel="alternate"></link><published>2014-07-24T00:00:00+00:00</published><updated>2014-07-24T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2014-07-24:/resources/presentations/speak-how-to-talk-in-public-and-not-wreck-your-voice/</id><content type="html">&lt;p&gt;An &lt;a href="https://en.wikipedia.org/wiki/Ignite_(event)"&gt;Ignite&lt;/a&gt; talk I
presented at OSCON 2014. Decidedly non-technical, this covers vocal
hygiene and how to take care of your voice.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;Video: &lt;a href="https://youtu.be/2LZXGesneMo"&gt;YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="presentations"></category><category term="Conference"></category><category term="OSCON"></category><category term="Ignite"></category></entry><entry><title>Hands On Trove: Database as a Service in OpenStack</title><link href="https://xahteiwi.eu/resources/presentations/hands-trove-database-service-openstack/" rel="alternate"></link><published>2014-03-27T11:17:00+00:00</published><updated>2014-03-27T11:17:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2014-03-27:/resources/presentations/hands-trove-database-service-openstack/</id><summary type="html">&lt;p&gt;&lt;a href="http://www.percona.com/live/mysql-conference-2014/sessions/hands-trove-database-service-openstack-mysql"&gt;This
tutorial&lt;/a&gt;
covered OpenStack Trove at Percona Live 2014. If you want to recreate
the experience, read on!&lt;/p&gt;
&lt;!--break--&gt;
&lt;p&gt;In order to make the most of this tutorial, you can recreate the
interactive steps presented. Please note: the process, while simple, is
extremely bandwidth intensive and you don't want to be …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="http://www.percona.com/live/mysql-conference-2014/sessions/hands-trove-database-service-openstack-mysql"&gt;This
tutorial&lt;/a&gt;
covered OpenStack Trove at Percona Live 2014. If you want to recreate
the experience, read on!&lt;/p&gt;
&lt;!--break--&gt;
&lt;p&gt;In order to make the most of this tutorial, you can recreate the
interactive steps presented. Please note: the process, while simple, is
extremely bandwidth intensive and you don't want to be the bandwidth hog
that everyone hates in your hotel, or on a conference wifi. Do so in
your office (or home) instead.&lt;/p&gt;
&lt;p&gt;The set-up process is decribed in &lt;a href="https://github.com/fghaas/perconalive2014/blob/master/README.md"&gt;a brief
README&lt;/a&gt;.
Effectively, it boils down to cloning a Git repo and then running
vagrant up, and you'll be good to go. But do pay attention to the system
requirements.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Slides: &lt;a href="https://www.slideshare.net/slideshow/embed_code/33588994"&gt;SlideShare&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="Conference"></category><category term="MySQL"></category><category term="OpenStack"></category></entry><entry><title>Fun with extended attributes in Ceph Dumpling</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/fun-extended-attributes-ceph-dumpling/" rel="alternate"></link><published>2014-02-24T16:50:17+01:00</published><updated>2014-02-24T16:50:17+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2014-02-24:/resources/hints-and-kinks/fun-extended-attributes-ceph-dumpling/</id><summary type="html">&lt;p&gt;This is a rather nasty bug in Ceph OSD, affecting 0.67 "Dumpling" and
earlier releases. It is fixed in versions later than 0.70, and a
simple workaround is available, but when it hits, this issue can be
pretty painful.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Please read this post to the end.&lt;/strong&gt; This is …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a rather nasty bug in Ceph OSD, affecting 0.67 "Dumpling" and
earlier releases. It is fixed in versions later than 0.70, and a
simple workaround is available, but when it hits, this issue can be
pretty painful.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Please read this post to the end.&lt;/strong&gt; This is by no means a punch
being thrown at Ceph, in fact it rather clearly illustrates a very
sane choice that the Ceph developers have made. If you run Ceph
Emperor or later, you are not affected by this issue, but it will be
an interesting read in data integrity in distributed systems anyway.&lt;/p&gt;
&lt;h2&gt;Too much of a good thing: large extended attributes&lt;/h2&gt;
&lt;p&gt;Here is how to reproduce the problem in a very simple bit of Python
code, against Ceph Dumpling.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Do not run this on a production system. Don't. Ever.&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="ch"&gt;#!/usr/bin/python&lt;/span&gt;

&lt;span class="c1"&gt;# import rados&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;rados&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Rados&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conffile&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'/etc/ceph/ceph.conf'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;cluster&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;cluster&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open_ioctx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'test'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;ioctx&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;o&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;rados&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Object&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ioctx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'onebyte'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# Write one byte as the object content&lt;/span&gt;
        &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'a'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Wrote object'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# Write an attribute of 8M&lt;/span&gt;
        &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set_xattr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'val'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'a'&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Set large attribute'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# Retrieving an attribute by name should succeed&lt;/span&gt;
        &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_xattr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'val'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Retrieved large attribute'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="c1"&gt;# Walking the attribute list should fail&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;alist&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;o&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_xattrs&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Retrieved whole attribute list'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;rados&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Error&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Failed to retrieve attribute list. '&lt;/span&gt;
                  &lt;span class="s1"&gt;'Congratulations, you probably just '&lt;/span&gt;
                  &lt;span class="s1"&gt;'corrupted one of your PGs.'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;raise&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Removing the disabling comment character is left as an exercise for
the daring reader, just in case your cut &amp;amp; paste trigger finger is
itchy. &lt;strong&gt;Do not run this against a production system.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;So what are we doing here? We're creating a single RADOS object named
&lt;code&gt;onebyte&lt;/code&gt; in a pool called &lt;code&gt;test&lt;/code&gt;. It is, as the name implies, only
one byte long (it contains just the letter a), but it has a very long
attribute named &lt;code&gt;val&lt;/code&gt;, which is 8 Megabytes' worth of &lt;code&gt;a&lt;/code&gt;'s.&lt;/p&gt;
&lt;p&gt;(In case you're wondering: yes, there are applications that set very
large attributes on RADOS objects. radosgw is one of them.)&lt;/p&gt;
&lt;p&gt;Since you've been able to set the attribute, you can also retrieve it,
which is why the call to &lt;code&gt;get_xattr('val')&lt;/code&gt; succeeds just fine. But if
you fetch the entire attribute &lt;em&gt;list&lt;/em&gt; (with &lt;code&gt;get_xattrs&lt;/code&gt;), then you
run into an &lt;code&gt;E2BIG&lt;/code&gt; error.&lt;/p&gt;
&lt;p&gt;You can confirm that on the Linux command line, using the &lt;code&gt;rados&lt;/code&gt;
utility, just the same. First, getting the object and getting an xattr
by name:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ sudo rados -p &lt;span class="nb"&gt;test&lt;/span&gt; get onebyte -
a

$ sudo rados -p &lt;span class="nb"&gt;test&lt;/span&gt; getxattr onebyte val - &lt;span class="m"&gt;2&lt;/span&gt;&amp;gt;&lt;span class="p"&gt;&amp;amp;&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;  &lt;span class="p"&gt;|&lt;/span&gt; head -c &lt;span class="m"&gt;50&lt;/span&gt;
aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Obviously, you're welcome to omit the head redirection if you prefer
to flood your screen. But for proving we can still retrieve the
attribute value, 50 characters is quite sufficient.&lt;/p&gt;
&lt;p&gt;Let's try &lt;em&gt;listing&lt;/em&gt; the attributes, though:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ sudo rados -p &lt;span class="nb"&gt;test&lt;/span&gt; listxattr onebyte 
error getting xattr &lt;span class="nb"&gt;set&lt;/span&gt; test/onebyte: Argument list too long
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Oops. &lt;code&gt;Argument list too long&lt;/code&gt; is bash's way of translating the
&lt;code&gt;E2BIG&lt;/code&gt; error for you, because that's what it usually means. In this
case, though, it's actually what we get from the rados utility, and
that gets it from the OSD it's talking to, and that gets it from the
filesystem.&lt;/p&gt;
&lt;h2&gt;Digging deeper&lt;/h2&gt;
&lt;p&gt;Now let's take a look where this object is stored.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ sudo ceph osd map &lt;span class="nb"&gt;test&lt;/span&gt; onebyte
$ osdmap e191 pool &lt;span class="s1"&gt;'test'&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; object &lt;span class="s1"&gt;'onebyte'&lt;/span&gt; -&amp;gt; pg &lt;span class="m"&gt;3&lt;/span&gt;.ed47d009 &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;.1&lt;span class="o"&gt;)&lt;/span&gt; -&amp;gt; up &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;,2&lt;span class="o"&gt;]&lt;/span&gt; acting &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;,2&lt;span class="o"&gt;]&lt;/span&gt;
So it&lt;span class="s1"&gt;'s PG 3.1, currently mapped to OSDs 0 (primary) and 2 (replica). We happen to be on the very host where OSD 0 is running, so let'&lt;/span&gt;s take a closer look:

$ sudo getfattr -d /var/lib/ceph/osd/ceph-0/current/3.1_head/onebyte__head_ED47D009__3 
/var/lib/ceph/osd/ceph-0/current/3.1_head/onebyte__head_ED47D009__3: Argument list too long
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Same thing, E2BIG. Sure, if we can't enumerate the attributes
ourselves, the OSD can't either. But it's still fairly benign, because
we can still retrieve the object, right?&lt;/p&gt;
&lt;h2&gt;Adding daemon failure&lt;/h2&gt;
&lt;p&gt;Well, not so much. Let's see what happens if one of our OSDs gets
restarted. This is a perfectly benign operation that Ceph is expected
to (and does) handle very gracefully.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ sudo restart ceph-osd &lt;span class="nv"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;
ceph-osd &lt;span class="o"&gt;(&lt;/span&gt;ceph/0&lt;span class="o"&gt;)&lt;/span&gt; start/running, process &lt;span class="m"&gt;7922&lt;/span&gt;
$ sudo rados -p &lt;span class="nb"&gt;test&lt;/span&gt; get onebyte -
a
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The object is still there. What if, incidentally, the other OSD also
happens to go down some time later, and stays down?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ sudo stop ceph-osd &lt;span class="nv"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;
ceph-osd &lt;span class="o"&gt;(&lt;/span&gt;ceph/2&lt;span class="o"&gt;)&lt;/span&gt; stop/waiting
$ sudo ceph osd out &lt;span class="m"&gt;2&lt;/span&gt;
marked out osd.2.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Remember, &lt;em&gt;"at scale, something always fails"&lt;/em&gt;. Ceph is built for
exactly that, and its algorithms deal with this type of failure in
stride. So at this point, we would expect Ceph to remap the PGs that
were previously on OSD 2 to OSD 1, and synchronize with OSD 0. And a
few minutes later, all hell breaks loose:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nt"&gt;sudo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;ceph&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;-s&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;cluster&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;bd70ea39-58fc-4117-ade1-03a4d429cb49&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;   &lt;/span&gt;&lt;span class="nt"&gt;health&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;HEALTH_WARN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;200&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;pgs&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;degraded&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;pgs&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;recovering&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;200&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;pgs&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;stuck&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;unclean&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;recovery&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;2&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;degraded&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;100&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;000&lt;/span&gt;&lt;span class="o"&gt;%);&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;unfound&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;100&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;000&lt;/span&gt;&lt;span class="o"&gt;%)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;   &lt;/span&gt;&lt;span class="nt"&gt;monmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;e4&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;mons&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;at&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="err"&gt;ubuntu-ceph1=192.168.122.201:6789/0,ubuntu-ceph2=192.168.122.202:6789/0,ubuntu-ceph3=192.168.122.203:6789/0&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;election&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;epoch&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;180&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;quorum&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;0&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;ubuntu-ceph1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;ubuntu-ceph2&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="nt"&gt;ubuntu-ceph3&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;   &lt;/span&gt;&lt;span class="nt"&gt;osdmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;e237&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;osds&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;up&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;in&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;pgmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;v1335&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;200&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;pgs&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;active&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nt"&gt;recovering&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nt"&gt;degraded&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;199&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;active&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nt"&gt;degraded&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;bytes&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;data&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;38684&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;KB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;used&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;5071&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;MB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;5108&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;MB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;avail&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;2&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;degraded&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;100&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;000&lt;/span&gt;&lt;span class="o"&gt;%);&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;unfound&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;100&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nc"&gt;000&lt;/span&gt;&lt;span class="o"&gt;%)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;   &lt;/span&gt;&lt;span class="nt"&gt;mdsmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;e1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;0&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;0&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nt"&gt;up&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Fighting a fire&lt;/h2&gt;
&lt;p&gt;Wow. We shut down only one OSD (OSD 2), the other one (OSD 0) was
merely restarted, but it has crashed in the interim. Its mon osd down
out interval has also expired, so it has been marked out as well. All
of our PGs are stuck degraded, one has an unfound object (that's the
one whose xattrs can no longer be enumerated). Yikes.&lt;/p&gt;
&lt;p&gt;We scramble to bring our just-shutdown OSD back in.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ sudo start ceph-osd &lt;span class="nv"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;
ceph-osd &lt;span class="o"&gt;(&lt;/span&gt;ceph/2&lt;span class="o"&gt;)&lt;/span&gt; start/running, process &lt;span class="m"&gt;7426&lt;/span&gt;
$ sudo ceph osd &lt;span class="k"&gt;in&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;
marked &lt;span class="k"&gt;in&lt;/span&gt; osd.2.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Does this make things better?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sudo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;cluster&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bd70ea39&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;58&lt;/span&gt;&lt;span class="n"&gt;fc&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;4117&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ade1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;03&lt;/span&gt;&lt;span class="n"&gt;a4d429cb49&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;health&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;HEALTH_WARN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pgs&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;degraded&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pgs&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;recovering&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pgs&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;stuck&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;unclean&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;recovery&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;degraded&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;100.000&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;monmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;e4&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mons&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;at&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;{&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ceph1&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;192.168.122.201&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;6789&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ceph2&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;192.168.122.202&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;6789&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ceph3&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;192.168.122.203&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;6789&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="err"&gt;}&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;election&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;epoch&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;180&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;quorum&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ceph1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ceph2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ceph3&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;osdmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;e243&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;osds&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;up&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;in&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;pgmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;v1343&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;pgs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;active&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;recovering&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;degraded&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;199&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;active&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;degraded&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bytes&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;38812&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;KB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;used&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5071&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;MB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5108&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;MB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;avail&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;degraded&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;100.000&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mdsmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;e1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;up&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="mi"&gt;2014&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;56.868771&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mon&lt;/span&gt;&lt;span class="mf"&gt;.0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;INF&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;osdmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;e242&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;osds&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;up&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;in&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;2014&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;56.895559&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mon&lt;/span&gt;&lt;span class="mf"&gt;.0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;INF&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pgmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;v1342&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;pgs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;active&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;recovering&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;degraded&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;199&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;active&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;degraded&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bytes&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;38812&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;KB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;used&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5071&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;MB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5108&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;MB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;avail&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;degraded&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;100.000&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;2014&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;57.901188&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mon&lt;/span&gt;&lt;span class="mf"&gt;.0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;INF&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;osdmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;e243&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;osds&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;up&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;in&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;2014&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;57.918612&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mon&lt;/span&gt;&lt;span class="mf"&gt;.0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;INF&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pgmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;v1343&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;pgs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;active&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;recovering&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;degraded&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;199&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;active&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;degraded&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bytes&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;38812&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;KB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;used&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5071&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;MB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5108&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;MB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;avail&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;degraded&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;100.000&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;2014&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;59.920149&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mon&lt;/span&gt;&lt;span class="mf"&gt;.0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;INF&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;osdmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;e244&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;osds&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;up&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;in&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;2014&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;59.931825&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mon&lt;/span&gt;&lt;span class="mf"&gt;.0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;INF&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pgmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;v1344&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;pgs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;active&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;recovering&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;degraded&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;199&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;active&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;degraded&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bytes&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;38812&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;KB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;used&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5071&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;MB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5108&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;MB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;avail&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;degraded&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;100.000&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;2014&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;00.940319&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mon&lt;/span&gt;&lt;span class="mf"&gt;.0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;INF&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;osd&lt;/span&gt;&lt;span class="mf"&gt;.2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;192.168.122.203&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;6800&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;8362&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;boot&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;2014&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;00.940987&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mon&lt;/span&gt;&lt;span class="mf"&gt;.0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;INF&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;osdmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;e245&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;osds&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;up&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;in&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;2014&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;00.954275&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mon&lt;/span&gt;&lt;span class="mf"&gt;.0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;INF&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pgmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;v1345&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;pgs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;active&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;recovering&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;degraded&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;199&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;active&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;degraded&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bytes&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;38812&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;KB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;used&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5071&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;MB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5108&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;MB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;avail&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;degraded&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;100.000&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;2014&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;01.960942&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mon&lt;/span&gt;&lt;span class="mf"&gt;.0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;INF&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;osdmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;e246&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;osds&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;up&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;in&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;2014&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;01.975509&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mon&lt;/span&gt;&lt;span class="mf"&gt;.0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;INF&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pgmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;v1346&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;pgs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;active&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;recovering&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;degraded&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;199&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;active&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;degraded&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bytes&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;38812&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;KB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;used&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5071&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;MB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5108&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;MB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;avail&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;degraded&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;100.000&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;2014&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;03.982202&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mon&lt;/span&gt;&lt;span class="mf"&gt;.0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;INF&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;osdmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;e247&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;osds&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;up&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;in&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;2014&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;03.994963&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mon&lt;/span&gt;&lt;span class="mf"&gt;.0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;INF&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pgmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;v1347&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;pgs&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;active&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;recovering&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;degraded&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;199&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;active&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;degraded&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bytes&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;data&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;38812&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;KB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;used&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5071&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;MB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5108&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;MB&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;avail&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;degraded&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;100.000&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;2014&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;05.005162&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mon&lt;/span&gt;&lt;span class="mf"&gt;.0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;INF&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;osd&lt;/span&gt;&lt;span class="mf"&gt;.2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;192.168.122.203&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;6800&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;8483&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;boot&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;2014&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;02&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;05.005386&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mon&lt;/span&gt;&lt;span class="mf"&gt;.0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;INF&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;osdmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;e248&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;osds&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;up&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;in&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Hardly. OSDs flapping right and left. Ouch ouch ouch.&lt;/p&gt;
&lt;h2&gt;Desperation: not your friend&lt;/h2&gt;
&lt;p&gt;OK, let's try to do something really terrible and get rid of that file manually.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ sudo ceph osd map &lt;span class="nb"&gt;test&lt;/span&gt; onebyte
osdmap e254 pool &lt;span class="s1"&gt;'test'&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; object &lt;span class="s1"&gt;'onebyte'&lt;/span&gt; -&amp;gt; pg &lt;span class="m"&gt;3&lt;/span&gt;.ed47d009 &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;.1&lt;span class="o"&gt;)&lt;/span&gt; -&amp;gt; up &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt; acting &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So it's mapped to OSD 1 now, which is expected. Let's take a look and see if we can find and remove it.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="err"&gt;@&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ceph2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;~$&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ls&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;var&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;osd&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;current&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mf"&gt;3.1&lt;/span&gt;&lt;span class="n"&gt;_head&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="err"&gt;@&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ceph2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;~$&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;An empty directory. Well of course, they could never actually peer, so
the data never got synchronized. So there's pretty much one thing
left.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="err"&gt;@&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ceph3&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;~$&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sudo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;stop&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;osd&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;stop&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Unknown&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;instance&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="err"&gt;@&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ceph3&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;~$&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sudo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;rm&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;var&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;osd&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;current&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mf"&gt;3.1&lt;/span&gt;&lt;span class="n"&gt;_head&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;onebyte__head_ED47D009__3&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="err"&gt;@&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ceph3&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;~$&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sudo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;osd&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;osd&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;running&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;process&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;9069&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="err"&gt;@&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ceph1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;~$&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sudo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;stop&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;osd&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;stop&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Unknown&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;instance&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="err"&gt;@&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ceph1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;~$&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sudo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;rm&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="k"&gt;var&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;osd&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;current&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mf"&gt;3.1&lt;/span&gt;&lt;span class="n"&gt;_head&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;onebyte__head_ED47D009__3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="err"&gt;@&lt;/span&gt;&lt;span class="n"&gt;ubuntu&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ceph1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;~$&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sudo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;osd&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;osd&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ceph&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;running&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;process&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;9485&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;There. Shut down the OSDs, nuked the files, brought the OSDs back up.&lt;/p&gt;
&lt;h2&gt;A Fire Contained&lt;/h2&gt;
&lt;p&gt;And after a few more seconds, finally:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ sudo ceph -s
  cluster bd70ea39-58fc-4117-ade1-03a4d429cb49
   health HEALTH_OK
   monmap e4: &lt;span class="m"&gt;3&lt;/span&gt; mons at &lt;span class="o"&gt;{&lt;/span&gt;ubuntu-ceph1&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;192&lt;/span&gt;.168.122.201:6789/0,ubuntu-ceph2&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;192&lt;/span&gt;.168.122.202:6789/0,ubuntu-ceph3&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;192&lt;/span&gt;.168.122.203:6789/0&lt;span class="o"&gt;}&lt;/span&gt;, election epoch &lt;span class="m"&gt;180&lt;/span&gt;, quorum &lt;span class="m"&gt;0&lt;/span&gt;,1,2 ubuntu-ceph1,ubuntu-ceph2,ubuntu-ceph3
   osdmap e259: &lt;span class="m"&gt;3&lt;/span&gt; osds: &lt;span class="m"&gt;3&lt;/span&gt; up, &lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="k"&gt;in&lt;/span&gt;
    pgmap v1367: &lt;span class="m"&gt;200&lt;/span&gt; pgs: &lt;span class="m"&gt;200&lt;/span&gt; active+clean&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt; bytes data, &lt;span class="m"&gt;122&lt;/span&gt; MB used, &lt;span class="m"&gt;15204&lt;/span&gt; MB / &lt;span class="m"&gt;15326&lt;/span&gt; MB avail
   mdsmap e1: &lt;span class="m"&gt;0&lt;/span&gt;/0/1 up
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Whew.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$ sudo rados -p &lt;span class="nb"&gt;test&lt;/span&gt; get onebyte -
error getting test/onebyte: No such file or directory
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now obviously the offending object is gone, which is ugly and we could
have manually recreated that file and set some magic user.ceph
attributes enabling us to keep the object, but in this case we just
didn't care and wanted our cluster back up and running as soon as
possible.&lt;/p&gt;
&lt;h2&gt;Prevention&lt;/h2&gt;
&lt;p&gt;So we have a brutal cure for this problem that is roughly akin to
performing brain surgery with a fork and spoon. What could we have
done better?&lt;/p&gt;
&lt;p&gt;LevelDB to the rescue. Ceph optionally (and in later versions, by
default) stores attributes that would overflow the filesystem xattr
store in a separate database called an omap, using Google's embedded
LevelDB database. And in Dumpling, this feature is disabled by default
-- with an exception for ext3/4, which have interesting attribute
limitations themselves.&lt;/p&gt;
&lt;p&gt;This is the all-important option that needs to go in your ceph.conf:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="na"&gt;filestore xattr use omap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can enable this on a running cluster and this will retain and
preserve any xattrs previously set on RADOS objects. Attributes mapped
to file xattrs will simply be moved to the omap database (note however
that the opposite is not true, but you'll never want to disable this
option anymore, anyway).&lt;/p&gt;
&lt;p&gt;As of
&lt;a href="https://github.com/ceph/ceph/commit/dc0dfb9e01d593afdd430ca776cf4da2c2240a20"&gt;this Ceph commit&lt;/a&gt;
(which went into Ceph 0.70), the option is no longer available and is
always treated as if set to true, so those versions are not affected
by the issue described in this post.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Ceph"></category></entry><entry><title>Unrecoverable unfound objects in Ceph 0.67 and earlier</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/unrecoverable-unfound-objects-ceph-067-and-earlier/" rel="alternate"></link><published>2014-01-28T18:52:02+01:00</published><updated>2014-01-28T18:52:02+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2014-01-28:/resources/hints-and-kinks/unrecoverable-unfound-objects-ceph-067-and-earlier/</id><summary type="html">&lt;p&gt;As &lt;a href="http://ceph.com/"&gt;Ceph&lt;/a&gt; author &lt;a href="https://twitter.com/Liewegas"&gt;Sage
Weil&lt;/a&gt; points out frequently, distributed
storage solutions for all their goodness &lt;a href="http://youtu.be/JfRqpdgoiRQ?t=36m20s"&gt;have a "dirty little
secret"&lt;/a&gt;: No matter just how
redundant and reliable they are by design, a bug in the storage
software itself can be a real issue.&lt;/p&gt;
&lt;p&gt;And occasionally, the bug doesn't have to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;As &lt;a href="http://ceph.com/"&gt;Ceph&lt;/a&gt; author &lt;a href="https://twitter.com/Liewegas"&gt;Sage
Weil&lt;/a&gt; points out frequently, distributed
storage solutions for all their goodness &lt;a href="http://youtu.be/JfRqpdgoiRQ?t=36m20s"&gt;have a "dirty little
secret"&lt;/a&gt;: No matter just how
redundant and reliable they are by design, a bug in the storage
software itself can be a real issue.&lt;/p&gt;
&lt;p&gt;And occasionally, the bug doesn't have to be in the storage software
itself.&lt;/p&gt;
&lt;p&gt;Every self-respecting Linux file system supports &lt;a href="http://en.wikipedia.org/wiki/Extended_file_attributes"&gt;extended file
attributes
("xattrs")&lt;/a&gt;,
and XFS (commonly used with Ceph OSDs) is no exception. When OSDs
store RADOS objects in the OSD filestore, they make heavy use of
key-value pairs. To do so, they can employ two approaches:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;storing key-value pairs in filesystem xattrs directly (inline
  xattrs);&lt;/li&gt;
&lt;li&gt;storing them in a separate key-value store known as an object map or
  omap (based on &lt;a href="https://github.com/google/leveldb"&gt;Google LevelDB&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;RADOS generally expects that the maximum xattr size on a file is
practically unlimited, so if your filestore is on a filesystem where
that is &lt;em&gt;not&lt;/em&gt; the case (such as ext4), you would generally use omaps.&lt;/p&gt;
&lt;p&gt;Enabling the use of omaps is easy enough. This goes in your ceph.conf:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;[osd]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;filestore xattr use omap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;true&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Ceph releases since 0.66 will
&lt;a href="https://github.com/ceph/ceph/commit/6d90dad45e089447562e9a01fd9ca0f7a2aaf2b1"&gt;enable this automatically&lt;/a&gt;
if the filestore is determined to be running on ext4. But for the XFS
and BTRFS filesystem, the general recommendation (and default
behavior) remained to just use inline xattrs. This is also true for
the stable Ceph "Dumpling" release (0.67).&lt;/p&gt;
&lt;p&gt;Since Ceph 0.70, the configuration option
&lt;a href="https://github.com/ceph/ceph/commit/dc0dfb9e01d593afdd430ca776cf4da2c2240a20"&gt;has been dropped&lt;/a&gt;
and Ceph since always behaves as if &lt;code&gt;filestore xattr use omap&lt;/code&gt; was set
to &lt;code&gt;true&lt;/code&gt;. Now there is a reason for that, and it is a bit trickier
than you might expect.&lt;/p&gt;
&lt;p&gt;When manipulating extended attributes, applications (including
ceph-osd) make use of the
&lt;a href="http://man7.org/linux/man-pages/man2/fgetxattr.2.html"&gt;&lt;code&gt;getxattr()&lt;/code&gt;, &lt;code&gt;setxattr()&lt;/code&gt;, and &lt;code&gt;listxattr()&lt;/code&gt; syscalls&lt;/a&gt;. Expectedly,
these syscalls retrieve, set, and enumerate extended attributes set on
a file.&lt;/p&gt;
&lt;p&gt;Now it is actually possible to set so many keys, or so large values,
that while &lt;code&gt;getxattr()&lt;/code&gt; and &lt;code&gt;setxattr()&lt;/code&gt; executed on a specific file
continue to work just fine, &lt;code&gt;listxattr()&lt;/code&gt; returns with &lt;code&gt;-E2BIG&lt;/code&gt;. Now
it turns out that&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;radosgw can actually set attribute lists that large, and&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ceph-osd will fail if it cannot determine the file attributes for a
  file under its control.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When this happens, the object shows as &lt;code&gt;unfound&lt;/code&gt; in &lt;code&gt;ceph health
detail&lt;/code&gt;, and sadly, the documented operation to recover unfound
objects fails. The affected Placement Group (PG) also remains stuck,
again being reported as such in ceph health detail.&lt;/p&gt;
&lt;p&gt;If you actually have run into this problem, you should really call
Inktank for support. (You can also give us a call, of course, and
we'll be happy to help you confirm the problem. But we will refer you
to Inktank for the actual fix -- we don't fiddle and mess around with
RADOS object internals, and neither should you.)&lt;/p&gt;
&lt;h2&gt;How to avoid this in the first place?&lt;/h2&gt;
&lt;p&gt;If you're on Ceph 0.70 or later, congratulations. You should be safe,
as omaps are enabled and anything that would overflow your xattrs
instead gets stored in an omap.&lt;/p&gt;
&lt;p&gt;If you're on any earlier version, including the currently
stable 0.67.x "Dumpling" series, enable filestore xattr use omap. Do
it now, regardless of what filesystem your OSDs run on. Then restart
your OSDs one by one; your existing xattrs won't get lost.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Ceph"></category></entry><entry><title>linux.conf.au 2014, or My Annual Journey To Awesome</title><link href="https://xahteiwi.eu/blog/2014/01/20/linuxconfau-2014-or-my-annual-journey-to-awesome/" rel="alternate"></link><published>2014-01-20T11:36:00+00:00</published><updated>2014-01-20T11:36:00+00:00</updated><author><name>florian</name></author><id>tag:xahteiwi.eu,2014-01-20:/blog/2014/01/20/linuxconfau-2014-or-my-annual-journey-to-awesome/</id><summary type="html">&lt;p&gt;Earlier this month, I got on a flight to Perth, WA to make my annual
trek to &lt;strong&gt;linux.conf.au&lt;/strong&gt;, the largest open-source conference in the
Southern Hemisphere and one of my favorite conferences on the circuit.
LCA is an excellent, volunteer-run, hugely insightful conference and
well worth the 26-hour …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Earlier this month, I got on a flight to Perth, WA to make my annual
trek to &lt;strong&gt;linux.conf.au&lt;/strong&gt;, the largest open-source conference in the
Southern Hemisphere and one of my favorite conferences on the circuit.
LCA is an excellent, volunteer-run, hugely insightful conference and
well worth the 26-hour trip.&lt;/p&gt;
&lt;p&gt;I arrived in Perth in time to catch part of the Systems Administration
mini-conference on day 1. In particular, I caught a &lt;a href="https://www.youtube.com/watch?v=jwBdrvEXMk0"&gt;&lt;strong&gt;systemd&lt;/strong&gt;
talk&lt;/a&gt; by &lt;strong&gt;Rodger
Donaldson&lt;/strong&gt; which was both informative and entertaining, so I encourage
you to watch that when you get the chance.&lt;/p&gt;
&lt;p&gt;Day 2 had the OpenStack miniconf, which was good but a bit too focused
on OpenStack governance and organizational issues in its first half. In
the afternoon, talks got more technical, which was a clear improvement.&lt;/p&gt;
&lt;p&gt;Wednesday talks included a highly entertaining &lt;a href="https://www.youtube.com/watch?v=_mQKyIAx6Mc"&gt;look at MySQL's
history&lt;/a&gt; from &lt;strong&gt;Stewart
Smith&lt;/strong&gt;, &lt;strong&gt;Dave Chinner&lt;/strong&gt;'s musings on where &lt;a href="https://www.youtube.com/watch?v=DxZzSifuV4Q"&gt;Linux
filesystems&lt;/a&gt; came from, and
an insightful &lt;a href="https://www.youtube.com/watch?v=XyDcYV9doL8"&gt;RADOS deep
dive&lt;/a&gt; from &lt;strong&gt;Sage Weil.&lt;/strong&gt;
There was also a DRBD talk that I was not so fond of, but I've already
shared my thoughts about that one on Google+, and you're certainly
welcome to &lt;a href="https://plus.google.com/u/0/+FlorianHaas/posts/KTtvUzmATJM"&gt;take a
look&lt;/a&gt; over
there.&lt;/p&gt;
&lt;p&gt;My own &lt;a href="http://youtu.be/YWVz1CSxayU"&gt;Rapid OpenStack Deployment for Novices and Experts
Alike&lt;/a&gt; tutorial was on Thursday, had a nice
turnout, and my hands-on stuff all worked! What more could I possibly
ask for?&lt;/p&gt;
&lt;p&gt;Besides my own talk, you should also totally watch &lt;strong&gt;Matthew Garrett&lt;/strong&gt;'s
&lt;a href="https://www.youtube.com/watch?v=ixMStnFzgRM"&gt;Thursday keynote&lt;/a&gt; and
&lt;strong&gt;Lana Brindley&lt;/strong&gt;'s &lt;a href="https://www.youtube.com/watch?v=HKmaCpOv0Ww"&gt;agile documentation tutorial with Lego
goodness&lt;/a&gt;. And of course,
my clear favorite among all LCA talks this year, Bdale Garbee's
&lt;a href="https://www.youtube.com/watch?v=j7Et_eWJExU"&gt;reflections on losing his
house&lt;/a&gt; in a wildfire last
year.&lt;/p&gt;
&lt;p&gt;As for Friday, again a stellar keynote from &lt;strong&gt;Jonathan Oxer&lt;/strong&gt; (&lt;a href="https://www.youtube.com/watch?v=0GHMTXiDqoA"&gt;Arduino
satellites in space&lt;/a&gt;, geek
overload), Lennart's &lt;a href="https://www.youtube.com/watch?v=sJyVaKZ8tbc"&gt;kdbus
talk&lt;/a&gt; which you've probably
already &lt;a href="https://lwn.net/Articles/580194/"&gt;read on LWN&lt;/a&gt; about, and a
brilliant &lt;a href="http://mirror.linux.org.au/pub/linux.conf.au/2014/Friday/122-LCA_2014_-_Lightning_Talks_pt2_and_Thanks.mp4"&gt;lightning
talk&lt;/a&gt;
from Tim Serong about building a DIY bookscanner.&lt;/p&gt;
&lt;p&gt;All in all, linux.conf.au in Perth was terrific, as usual, and I am
absolutely planning to be there again next year. The trip will be even
more atrociuous as next year's venue is
&lt;a href="http://lca2015.linux.org.au"&gt;Auckland&lt;/a&gt;, but it will be totally worth
it. No doubt in my mind at all.&lt;/p&gt;
&lt;p&gt;I'd like to extend a huge thank-you to all LCA attendees, fellow
speakers, organizers and volunteers who make this conference a fantastic
event year after year. See you in 2015!&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on my blog on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="blog"></category><category term="linux.conf.au"></category><category term="OpenStack"></category></entry><entry><title>Greetings from Havana: A fresh perspective on globally distributed OpenStack</title><link href="https://xahteiwi.eu/resources/presentations/greetings-from-havana/" rel="alternate"></link><published>2013-12-10T00:00:00+00:00</published><updated>2013-12-10T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2013-12-10:/resources/presentations/greetings-from-havana/</id><summary type="html">&lt;p&gt;My second appearance at OpenStack Israel, this time with news on
distributed OpenStack environments in the Havana release.&lt;/p&gt;
&lt;!--break--&gt;
&lt;p&gt;The video (courtesy of OpenStack Israel) and slides are below. For the
introduction given in Hebrew, the slides contain a transcript in
English.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Video: &lt;a href="https://youtu.be/28p6Ls6hQJM"&gt;YouTube&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/openstackisraeldec2013/#/personal-intro"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on …&lt;/p&gt;</summary><content type="html">&lt;p&gt;My second appearance at OpenStack Israel, this time with news on
distributed OpenStack environments in the Havana release.&lt;/p&gt;
&lt;!--break--&gt;
&lt;p&gt;The video (courtesy of OpenStack Israel) and slides are below. For the
introduction given in Hebrew, the slides contain a transcript in
English.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Video: &lt;a href="https://youtu.be/28p6Ls6hQJM"&gt;YouTube&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/openstackisraeldec2013/#/personal-intro"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="Conference"></category><category term="OpenStack"></category></entry><entry><title>Ceph: object storage, block storage, file system, replication, massive scalability and then some!</title><link href="https://xahteiwi.eu/resources/presentations/ceph-object-storage-block-storage-file-system-replication-massive-scalabilit/" rel="alternate"></link><published>2013-05-31T08:02:00+00:00</published><updated>2013-05-31T08:02:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2013-05-31:/resources/presentations/ceph-object-storage-block-storage-file-system-replication-massive-scalabilit/</id><content type="html">&lt;p&gt;This is one of my most popular talks, co-presented with intrepid
cartoonist-turned-engineer &lt;a href="http://ourobengr.com/"&gt;Tim Serong&lt;/a&gt; from
&lt;a href="https://www.suse.com/"&gt;SUSE&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Video: &lt;a href="https://youtu.be/dDA1sBg4H98"&gt;YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="Ceph"></category><category term="Conference"></category></entry><entry><title>Ceph: The Storage Stack for OpenStack</title><link href="https://xahteiwi.eu/resources/presentations/ceph-storage-stack-openstack/" rel="alternate"></link><published>2013-05-28T11:49:00+00:00</published><updated>2013-05-28T11:49:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2013-05-28:/resources/presentations/ceph-storage-stack-openstack/</id><summary type="html">&lt;p&gt;My presentation from &lt;a href="http://www.openstack-israel.org"&gt;OpenStack
Israel&lt;/a&gt;, May 27, 2013. After a brief
introduction into Ceph, I dive into OpenStack specific Ceph features
and outlines RBD integration with Glance and Cinder, and explains
RadosGW Swift compatibility.&lt;/p&gt;
&lt;!--break--&gt;
&lt;p&gt;Use the PgUp/PgDown keys to navigate through the presentation, or just
advance by hitting the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;My presentation from &lt;a href="http://www.openstack-israel.org"&gt;OpenStack
Israel&lt;/a&gt;, May 27, 2013. After a brief
introduction into Ceph, I dive into OpenStack specific Ceph features
and outlines RBD integration with Glance and Cinder, and explains
RadosGW Swift compatibility.&lt;/p&gt;
&lt;!--break--&gt;
&lt;p&gt;Use the PgUp/PgDown keys to navigate through the presentation, or just
advance by hitting the spacebar.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/openstackisrael2013/"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="Ceph"></category><category term="Conference"></category></entry><entry><title>Enter the cuttlefish!</title><link href="https://xahteiwi.eu/blog/2013/05/07/enter-the-cuttlefish/" rel="alternate"></link><published>2013-05-07T07:43:00+00:00</published><updated>2013-05-07T07:43:00+00:00</updated><author><name>florian</name></author><id>tag:xahteiwi.eu,2013-05-07:/blog/2013/05/07/enter-the-cuttlefish/</id><summary type="html">&lt;p&gt;Today, the developers released Ceph 0.61, codenamed cuttlefish. There
are some interesting features in this new release, take a look.&lt;/p&gt;
&lt;p&gt;One thing that will undoubtedly make Ceph a lot more palatable to
RHEL/CentOS users is the &lt;strong&gt;availability of Ceph in EPEL&lt;/strong&gt;. This was
&lt;a href="http://www.inktank.com/ceph/ceph-is-in-epel-and-why-red-hat-users-should-care/"&gt;originally announced in late
March …&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Today, the developers released Ceph 0.61, codenamed cuttlefish. There
are some interesting features in this new release, take a look.&lt;/p&gt;
&lt;p&gt;One thing that will undoubtedly make Ceph a lot more palatable to
RHEL/CentOS users is the &lt;strong&gt;availability of Ceph in EPEL&lt;/strong&gt;. This was
&lt;a href="http://www.inktank.com/ceph/ceph-is-in-epel-and-why-red-hat-users-should-care/"&gt;originally announced in late
March&lt;/a&gt;,
but 0.61 is the first supported release that comes with Red Hat
compatible RPMs. Note that at the time of writing, EPEL is obviously
&lt;a href="http://dl.fedoraproject.org/pub/epel/testing/6/x86_64/"&gt;still stuck on the 0.56 bobtail
release&lt;/a&gt;, but it
is expected that cuttlefish support will follow shortly. In the interim,
cuttlefish packages are available outside EPEL, &lt;a href="http://ceph.com/docs/master/install/rpm/"&gt;on the ceph.com yum
repo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This allows you to run a Ceph cluster on RHEL/CentOS. It does, however
come with a few limitations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You can't use RBD from a kvm/libvirt box that is running RHEL. RHEL
    does not ship with librados support enabled in the qemu-kvm builds,
    and removing this limitation would mean for third parties to provide
    their own libvirt/kvm build. As of today, tough, no RBD-support
    libvirt/kvm lives in &lt;a href="http://wiki.centos.org/AdditionalResources/Repositories/CentOSPlus"&gt;CentOS
    Plus&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;You can't use the kernel rbd or ceph modules from a client that is
    running RHEL. RBD and Ceph filesystem support is absent from RHEL
    kernels.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I'm curious to see if and when that will change, given Red Hat's &lt;a href="http://www.gluster.org/2013/05/glusterfs-is-ready-for-openstack/"&gt;focus
on
GlusterFS&lt;/a&gt;
as their preferred distributed storage solution. It will be interesting
to see what happens there.&lt;/p&gt;
&lt;p&gt;Another neat little new feature is the ability to &lt;strong&gt;set quotas on
pools,&lt;/strong&gt; which is something that we've frequently had customers ask for
in our consulting practice.&lt;/p&gt;
&lt;p&gt;Then there are &lt;strong&gt;incremental snapshots for RBD,&lt;/strong&gt; another really handy
feature for RBD management in cloud solutions like
&lt;a href="https://www.hastexo.com/knowledge/openstack"&gt;OpenStack&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;There's more, and you may head over to the press release and the Inktank
blog for more details. And then you might want to mark your calendars
for one of the following events:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;At the &lt;a href="https://www.hastexo.com/resources/news-releases/der-openstack-dach-tag-2013-das-erste-ganzt%C3%A4gige-event-der-openstack-communi"&gt;OpenStack DACH
    Day&lt;/a&gt;
    at &lt;a href="http://www.linuxtag.org/2013/de/program/program/freitag-24-mai-2013/open-stack.html"&gt;LinuxTag in Berlin on May
    24&lt;/a&gt;,
    Wolfgang Schulze from Inktank gives an overview about Ceph (in
    German, &lt;a href="http://www.eventbrite.com/e/openstack-dach-day-2013-tickets-3206509757"&gt;register
    here&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;At &lt;a href="http://www.openstack-israel.org/"&gt;OpenStack Israel&lt;/a&gt; on May 27,
    I'll be speaking about Ceph integration with OpenStack (in English,
    &lt;a href="http://www.meetup.com/IGTCloud/events/99146542/"&gt;register here&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;And at &lt;a href="http://openstackceeday.com/"&gt;OpenStack CEE&lt;/a&gt; on May 29 in
    Budapest, Martin speaks about &lt;em&gt;Scale-out Made Easy: Petabyte Storage
    with Ceph&lt;/em&gt; (in English, &lt;a href="http://www.eventbrite.com/e/openstack-cee-day-2013-budapest-registration-5634033546"&gt;register
    here&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All these events are expected to sell out beforehand, and they are only
a couple of weeks away. So make sure you grab your seat, and we'll see
you there!&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on my blog on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="blog"></category><category term="Ceph"></category></entry><entry><title>More Reliable, More Resilient, More Redundant</title><link href="https://xahteiwi.eu/resources/presentations/more-reliable-more-resilient-more-redundant/" rel="alternate"></link><published>2013-04-17T16:33:00+00:00</published><updated>2013-04-17T16:33:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2013-04-17:/resources/presentations/more-reliable-more-resilient-more-redundant/</id><summary type="html">&lt;p&gt;Another update on OpenStack's progress in high availability, for the
Grizzly and Havana releases. Presented at the OpenStack Summit in
Portland, on April 17, 2013.&lt;/p&gt;
&lt;!--break--&gt;
&lt;p&gt;I give an overview of infrastructure, compute and networking high
availability development in the April 2013 OpenStack Grizzly release,
and an outlook for OpenStack Havana …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Another update on OpenStack's progress in high availability, for the
Grizzly and Havana releases. Presented at the OpenStack Summit in
Portland, on April 17, 2013.&lt;/p&gt;
&lt;!--break--&gt;
&lt;p&gt;I give an overview of infrastructure, compute and networking high
availability development in the April 2013 OpenStack Grizzly release,
and an outlook for OpenStack Havana.&lt;/p&gt;
&lt;p&gt;Use the PgUp/PgDown keys to navigate through the presentation, or just
advance by hitting the spacebar.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/openstacksummitapril2013/"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="OpenStack"></category></entry><entry><title>High Availability Update: You can now vote our talk into the OpenStack summit!</title><link href="https://xahteiwi.eu/blog/2013/02/21/high-availability-update-you-can-now-vote-our-talk-into-the-openstack-summit/" rel="alternate"></link><published>2013-02-21T06:59:00+00:00</published><updated>2013-02-21T06:59:00+00:00</updated><author><name>florian</name></author><id>tag:xahteiwi.eu,2013-02-21:/blog/2013/02/21/high-availability-update-you-can-now-vote-our-talk-into-the-openstack-summit/</id><summary type="html">&lt;p&gt;For the upcoming OpenStack Summit in Portland, Syed Armani and I have
&lt;a href="https://www.openstack.org/summit/portland-2013/vote-for-speakers/presentation/531"&gt;submitted a
talk&lt;/a&gt;
on OpenStack high availability. Here's how you can make sure it makes it
into the program.&lt;/p&gt;
&lt;p&gt;Our talk, &lt;strong&gt;&lt;em&gt;More reliable, more resilient, more redundant: High
Availability Update for Grizzly and beyond,&lt;/em&gt;&lt;/strong&gt; is an extended overview …&lt;/p&gt;</summary><content type="html">&lt;p&gt;For the upcoming OpenStack Summit in Portland, Syed Armani and I have
&lt;a href="https://www.openstack.org/summit/portland-2013/vote-for-speakers/presentation/531"&gt;submitted a
talk&lt;/a&gt;
on OpenStack high availability. Here's how you can make sure it makes it
into the program.&lt;/p&gt;
&lt;p&gt;Our talk, &lt;strong&gt;&lt;em&gt;More reliable, more resilient, more redundant: High
Availability Update for Grizzly and beyond,&lt;/em&gt;&lt;/strong&gt; is an extended overview
about current and future high availability features in OpenStack. It
covers infrastructure high availability, HA features in Nova, Quantum,
and several other topics.&lt;/p&gt;
&lt;p&gt;I've given a shorter version of this talk &lt;a href="https://www.hastexo.com/resources/presentations/high-availability-update-grizzly-and-havana"&gt;just this week, at the 2nd
Swiss OpenStack User Group
meetup,&lt;/a&gt;
where apparently &lt;a href="http://www.meetup.com/zhgeeks/events/97648722/"&gt;around 55 people liked it a
lot.&lt;/a&gt; You can take a
look at the slides
&lt;a href="https://www.hastexo.com/resources/presentations/high-availability-update-grizzly-and-havana"&gt;here,&lt;/a&gt;
and there will also be a video that should be available later this week.&lt;/p&gt;
&lt;p&gt;So, to make sure that this talk makes it into the Summit, we need your
help! Voting for Summit sessions is up, and you can vote for our talk
&lt;a href="https://www.openstack.org/summit/portland-2013/vote-for-speakers/presentation/531"&gt;here.&lt;/a&gt;
Please note, you must be an OpenStack Foundation member to vote. If
you're not, and you're into OpenStack, you can &lt;a href="https://www.openstack.org/join/register/"&gt;join (for free!) as an
Individual Member.&lt;/a&gt; Then, you
can immediately &lt;a href="https://www.openstack.org/summit/portland-2013/vote-for-speakers/presentation/531"&gt;proceed to the voting
page&lt;/a&gt;
to cast your vote.&lt;/p&gt;
&lt;p&gt;Thanks for your support, and we hope to see you in Portland!&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on my blog on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="blog"></category><category term="Conference"></category><category term="OpenStack"></category></entry><entry><title>High Availability Update (Grizzly and Havana)</title><link href="https://xahteiwi.eu/resources/presentations/high-availability-update-grizzly-and-havana/" rel="alternate"></link><published>2013-02-20T12:58:00+00:00</published><updated>2013-02-20T12:58:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2013-02-20:/resources/presentations/high-availability-update-grizzly-and-havana/</id><summary type="html">&lt;p&gt;Another update on
&lt;a href="https://www.hastexo.com/knowledge/openstack"&gt;OpenStack's&lt;/a&gt; progress in
high availability, for the Grizzly and Havana releases. Presented at the
Swiss OpenStack User Group meetup in Zurich, on February 19, 2013.&lt;/p&gt;
&lt;!--break--&gt;
&lt;p&gt;I give an overview of infrastructure, compute and networking high
availability development in the run-up to the Grizzly feature freeze.&lt;/p&gt;
&lt;p&gt;Use the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Another update on
&lt;a href="https://www.hastexo.com/knowledge/openstack"&gt;OpenStack's&lt;/a&gt; progress in
high availability, for the Grizzly and Havana releases. Presented at the
Swiss OpenStack User Group meetup in Zurich, on February 19, 2013.&lt;/p&gt;
&lt;!--break--&gt;
&lt;p&gt;I give an overview of infrastructure, compute and networking high
availability development in the run-up to the Grizzly feature freeze.&lt;/p&gt;
&lt;p&gt;Use the PgUp/PgDown keys to navigate through the presentation, or just
advance by hitting the spacebar.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/chosugmeetup201302/"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="OpenStack"></category></entry><entry><title>My week at linux.conf.au 2013</title><link href="https://xahteiwi.eu/blog/2013/01/28/my-week-at-linuxconfau-2013/" rel="alternate"></link><published>2013-01-28T01:27:00+00:00</published><updated>2013-01-28T01:27:00+00:00</updated><author><name>florian</name></author><id>tag:xahteiwi.eu,2013-01-28:/blog/2013/01/28/my-week-at-linuxconfau-2013/</id><summary type="html">&lt;p&gt;linux.conf.au 2013 has kicked off this morning, and here is a brief
preview of my talks and related activities this week.&lt;/p&gt;
&lt;p&gt;This afternoon, as part of the &lt;a href="https://lca2013.linux.org.au/wiki/Miniconfs/CloudDistributedStorageandHighAvailability"&gt;Cloud, Distributed Storage and High
Availability
miniconf,&lt;/a&gt;
I am moderating the &lt;a href="https://lca2013.linux.org.au/wiki/Miniconfs/CloudDistributedStorageandHighAvailability"&gt;Grand Distributed Storage
Debate&lt;/a&gt;.
In this debate, we'll have Sage …&lt;/p&gt;</summary><content type="html">&lt;p&gt;linux.conf.au 2013 has kicked off this morning, and here is a brief
preview of my talks and related activities this week.&lt;/p&gt;
&lt;p&gt;This afternoon, as part of the &lt;a href="https://lca2013.linux.org.au/wiki/Miniconfs/CloudDistributedStorageandHighAvailability"&gt;Cloud, Distributed Storage and High
Availability
miniconf,&lt;/a&gt;
I am moderating the &lt;a href="https://lca2013.linux.org.au/wiki/Miniconfs/CloudDistributedStorageandHighAvailability"&gt;Grand Distributed Storage
Debate&lt;/a&gt;.
In this debate, we'll have Sage Weil (for Ceph) and John Mark Walker
(for GlusterFS) go head-to-head about the merits of their respective
projects.&lt;/p&gt;
&lt;p&gt;On Tuesday, during the &lt;a href="http://linux.conf.au/schedule/30100/view_talk?day=tuesday"&gt;OpenStack
miniconf,&lt;/a&gt;
I'm doing a talk on integrating Ceph with OpenStack.&lt;/p&gt;
&lt;p&gt;Finally, on Friday afternoon, Tim Serong and I are scheduled to do &lt;a href="http://linux.conf.au/schedule/30091/view_talk?day=friday"&gt;a
full hands-on Ceph
tutorial.&lt;/a&gt;
Watch this space, we'll announce where to download your VM images no
later than Wednesday (as soon as we've figured out just where in the
conference network we can upload it).&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on my blog on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>Solid-state drives and Ceph OSD journals</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/solid-state-drives-and-ceph-osd-journals/" rel="alternate"></link><published>2013-01-13T20:33:58+01:00</published><updated>2013-01-13T20:33:58+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2013-01-13:/resources/hints-and-kinks/solid-state-drives-and-ceph-osd-journals/</id><summary type="html">&lt;p&gt;Considerations for running Ceph OSD journals on SSDs.&lt;/p&gt;</summary><content type="html">&lt;p&gt;Object Storage Daemons
(&lt;a href="http://ceph.com/docs/master/man/8/ceph-osd/"&gt;OSDs&lt;/a&gt;) are the Ceph
stack's workhorses for data storage. They're significantly smarter
than many of their counterparts in distributed block-storage solutions
(open source or not), and their design is instrumental in securing the
stack's reliability and scalability.&lt;/p&gt;
&lt;p&gt;Among other things, OSDs are responsible for the decentralized
replication — which is highly configurable — of objects in the
store. They do so in a primary-copy fashion: every Ceph object (more
precisely, the Placement Group it is a part of) is written to the
primary OSD first, and from there replicates to one or several replica
OSDs to ensure redundancy. This replication is synchronous, such that
a new or updated object guarantees its availability (in the way
configured by the cluster administrator) before an application is
notified that the write has completed.&lt;/p&gt;
&lt;p&gt;More specifically, in order for an OSD to acknowledge a write as
completed, the new object must have been written to the OSD's
journal. OSDs use a write-ahead mode for local operations: a write
hits the journal first, and from there is then being copied into the
backing filestore. (Note: if your filestore is using btrfs, the
journal is applied in parallel with the filestore write instead. Btrfs
still being experimental, however, this is not a configuration often
used in production.) Thus, for best cluster performance it is crucial
that the journal is fast, whereas the filestore can be comparatively
slow.&lt;/p&gt;
&lt;p&gt;This, in turn, leads to a common design principle for Ceph clusters
that are both fast and cost-effective:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Put your filestores on slow, cheap drives (such as SATA spinners),&lt;/li&gt;
&lt;li&gt;put your journals on fast drives (SSDs, Fusion-IO cards, whatever
  you can afford).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Another common design principle is that you create one OSD per
spinning disk that you have in the system. Many contemporary systems
come with only two SSD slots, and then as many spinners as you
want. That is not a problem for journal capacity — a single OSD's
journal is usually no larger than about 6 GB, so even for a 16-spinner
system (approx. 96GB journal space) appropriate SSDs are available at
reasonable expense.&lt;/p&gt;
&lt;p&gt;Many operators are scared of an SSD suddenly dying a horrible death,
so they put their SSDs in a RAID-1. Many are also tempted to put their
OSD journal partitions onto the same RAID. Another option is to use,
say, one partition on each of your SSD in a RAID for the operating
system installation, and then chop up the rest of your SSDs as
non-RAIDed Ceph OSD journals.&lt;/p&gt;
&lt;p&gt;This creates an interesting situation when you get to more than about
10-or-so OSDs (the exact number is hard to give). Now you have your OS
and several OSD journals on the same physical SSD. SSDs are much
faster than spinners, but they have neither infinite throughput nor
zero latency. Eventually, you might hit your SSD's physical limits for
random I/O all over the place. For example, if one of your hosts dies
and the rest now reshuffles data to restore the desired level of
redundancy, you may see relatively intensive I/O all over the other
OSDs — this is exacerbated in a system where you have few OSD hosts
which host many OSD disks.&lt;/p&gt;
&lt;p&gt;Putting your journal SSDs in a RAID set looks like a good idea at
first. Specifically, Ceph OSDs currently cannot recover from a broken
SSD journal without reinitializing and recovering the entire
filestore. This means that as soon as SSD acting as journal backing
storage burns up, you've effectively lost those OSDs completely and
need to recover them from scratch.&lt;sup id="fnref:mkjournal"&gt;&lt;a class="footnote-ref" href="#fn:mkjournal"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Put them in a RAID-1, problem solved?  Well, not quite, because you've
now duplicated all of your journal writes and you're hitting two SSDs
all over the place. Thus it's generally a much better idea to put half
of your journals on one SSD, and half on the other. If one of your
SSDs burns up you'll still lose the OSDs whose journals it hosts — but
it'll only be half of the OSDs hosted on that node altogether.&lt;/p&gt;
&lt;p&gt;Any such performance issues get worse if some of your OSDs are also
MONs: your OSD journals now compete with your operating system and
your MONs for I/O on the same SSDs. Once your SSDs get hit so hard
that your MONs can't do I/O, those MONs eventually die. This might not
harm your operations if you have sufficient backup MONs available, and
everything will be fine again once your recovery is complete, but it's
still a nuisance. This is remarkably common specifically in POCs, by
the way, where people often try to repurpose three of their old,
two-SSDs-plus-dozens-of-disks storage servers for a 3-node Ceph
cluster.&lt;/p&gt;
&lt;p&gt;So, as you are considering your OSD journal and filestore layout, take
note of the following general guidelines:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;By and large, try to go for a relatively small number of OSDs per
  node, ideally not more than 8. This combined with SSD journals is
  likely to give you the best overall performance.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you do go with OSD nodes with a very high number of disks,
  consider dropping the idea of an SSD-based journal. Yes, in this
  kind of setup you might actually do better with journals on the
  spinners.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Alternatively in the same scenario, consider putting your operating
  system install on one or a couple of the spinners (presumably
  smaller ones than the others), and use the (un-RAIDed) SSDs for OSD
  journals exclusively.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Consider having a few dedicated MONs (MONs that are not also OSDs).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Note on &lt;code&gt;ceph-osd --mkjournal&lt;/code&gt;&lt;/h2&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:mkjournal"&gt;
&lt;p&gt;Since this article was originally published, a &lt;code&gt;--mkjournal&lt;/code&gt;
option was added to the &lt;code&gt;ceph-osd&lt;/code&gt; command, allowing you to
recreate a journal for an existing OSD. This mitigates the issue
in that you don't need to recreate OSDs from scratch when a
journal device breaks — but the OSDs will still be &lt;strong&gt;temporarily&lt;/strong&gt;
unavailable. &lt;a class="footnote-backref" href="#fnref:mkjournal" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="hints-and-kinks"></category><category term="Ceph"></category><category term="Performance"></category></entry><entry><title>Thoughts on "ecosystems"</title><link href="https://xahteiwi.eu/blog/2012/12/16/thoughts-on-ecosystems/" rel="alternate"></link><published>2012-12-16T14:47:00+00:00</published><updated>2012-12-16T14:47:00+00:00</updated><author><name>florian</name></author><id>tag:xahteiwi.eu,2012-12-16:/blog/2012/12/16/thoughts-on-ecosystems/</id><summary type="html">&lt;p&gt;Over the past couple of years, it seems that the term &lt;em&gt;ecosystem&lt;/em&gt; is
being broadly applied to what we previously called a &lt;em&gt;community.&lt;/em&gt; I
don't like that, and here's why.&lt;/p&gt;
&lt;p&gt;The origin of the term &lt;em&gt;ecosystem,&lt;/em&gt; when applied to the environment in
which a software project is being developed, used …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Over the past couple of years, it seems that the term &lt;em&gt;ecosystem&lt;/em&gt; is
being broadly applied to what we previously called a &lt;em&gt;community.&lt;/em&gt; I
don't like that, and here's why.&lt;/p&gt;
&lt;p&gt;The origin of the term &lt;em&gt;ecosystem,&lt;/em&gt; when applied to the environment in
which a software project is being developed, used and promoted, is
unknown, at least to the best of my knowledge. Some say that it was
&lt;a href="http://krow.net/" title="Brian Aker"&gt;Brian Aker&lt;/a&gt; who first spoke of “the
MySQL ecosystem”, and it seemed rather fitting at the time. Presently
though, it seems there's ecosystems everywhere: the Linux ecosystem, the
OpenStack ecosystem, the Python ecosystem, you name it.&lt;/p&gt;
&lt;p&gt;And it annoys me.&lt;/p&gt;
&lt;p&gt;It annoys me not in the way marketing drone babbling annoys me, like
when someone waxes lyrical about synergies or paradigm shifts — that's
the kind of fluff you automatically filter out and disregard, a bit like
page numbers in the slide decks of presenters stuck in the 20th century.
But the ecosystem thing is frequently used also by developers and users,
the actual movers and shakers, in the way we would previously use
&lt;em&gt;community.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Now let's look for a moment at how a community works. A community is
governed by rules and morals. Those can be explicit, as written-down
laws, covenants or contracts. Much more commonly though, they are
implicit: everybody understands them, everybody is expected to abide by
them, and if you break them, you're being shunned — but there's no
requirement to write these rules down.&lt;/p&gt;
&lt;p&gt;When we think about communities, most will naturally associate this with
a large group of people, like a clan or tribe, maybe a few hundred or
even a few thousand individuals. Puny, right? We need something grander,
something that alludes to hundreds or thousands of species with maybe
millions of individuals playing a part. Let's pick a term: &lt;em&gt;ecosystem.&lt;/em&gt;
Yay! Problem solved. Waaaay bigger than a community. So much more
awe-inspiring.&lt;/p&gt;
&lt;p&gt;But guess what: &lt;strong&gt;an ecosystem is fundamentally amoral.&lt;/strong&gt; In an
ecosystem, there is no right or wrong — other than survival being right,
and if it happens to be at everyone else's expense, that doesn't make it
wrong. From the inside perspective of an ecosystem, if an invasive
species intrudes and steamrolls the entire habitat, so be it: it just
changed the ecosystem. Nature shrugs. Nature also shrugs at parasites,
disease, deception, camouflage, poison, and gangs of predators
collaborating with swift and deadly force to mercilessly kill a
defenseless herbivore.&lt;/p&gt;
&lt;p&gt;Now you're welcome to call me out on my naïveté, and point out that it
is precisely those things that happen in business every day. I am
acutely aware of that. I believe, however, we ought to consider them
evils, and some may consider them &lt;em&gt;necessary&lt;/em&gt; evils at times. They
shouldn't the foundations on which we build our &lt;em&gt;communities.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/Speech_acts"&gt;Words matter.&lt;/a&gt; I think we
should use them wisely.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on my blog on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="blog"></category><category term="Philosophy"></category></entry><entry><title>On the merits of working from home, in a distributed virtual team</title><link href="https://xahteiwi.eu/blog/2012/12/06/on-the-merits-of-working-from-home-in-a-distributed-virtual-team/" rel="alternate"></link><published>2012-12-06T17:38:00+00:00</published><updated>2012-12-06T17:38:00+00:00</updated><author><name>florian</name></author><id>tag:xahteiwi.eu,2012-12-06:/blog/2012/12/06/on-the-merits-of-working-from-home-in-a-distributed-virtual-team/</id><summary type="html">&lt;p&gt;During lunch at the EMEA OpenStack day in London this week, I had a
brief but excellent conversation with fellow OpenStacker &lt;a href="https://twitter.com/adamspiers"&gt;Adam
Spiers&lt;/a&gt; from SUSE. Our chat turned to
the merits of working from home, and he encouraged me to write up a blog
post about some of the ideas …&lt;/p&gt;</summary><content type="html">&lt;p&gt;During lunch at the EMEA OpenStack day in London this week, I had a
brief but excellent conversation with fellow OpenStacker &lt;a href="https://twitter.com/adamspiers"&gt;Adam
Spiers&lt;/a&gt; from SUSE. Our chat turned to
the merits of working from home, and he encouraged me to write up a blog
post about some of the ideas of mine and of my co-founders' which we
have since made hastexo policy, however informal or unwritten.&lt;/p&gt;
&lt;p&gt;Note that much of what follows aren't necessarily original ideas of
ours. Many of my thoughts I owe to some very insightful chats I've had
over the past few months with the delightful &lt;a href="http://sarahnovotny.com/"&gt;Sarah
Novotny&lt;/a&gt;, original co-founder of &lt;a href="http://bluegecko.com/"&gt;Blue
Gecko&lt;/a&gt;, seasoned
&lt;a href="http://www.oscon.com/oscon2012"&gt;OSCON&lt;/a&gt; conference chair and now CIO at
&lt;a href="http://meteor-ent.com/"&gt;Meteor Entertainment&lt;/a&gt;. If you get a chance to
talk to Sarah at a conference and poll her views on this, I can highly
recommend you seize that chance.&lt;/p&gt;
&lt;p&gt;It all starts with the observation that the separation of the place you
live in, and the place you work at, is a fairly recent concept in human
history. Prior to the &lt;a href="http://en.wikipedia.org/wiki/Industrial_Revolution"&gt;Industrial
Revolution&lt;/a&gt;, which
originated in late 18th century England and steamrolled first Europe and
then the rest of the world, no such separation was common: the
blacksmith would live upstairs in his shop, so would the bakerman or the
butcher. The teacher would dwell, with his family, in the local school.
The farmer, and the farmhands, would live on that farm. In such a
setting it follows naturally that the work day spans essentially your
entire waking time: you would start your day's work as soon as you got
up, and finished it when you retired for the night. It would be equally
natural to close the shop and interrupt your work for perhaps an hour at
a time, in order to consume a meal with your family or run an errand, or
to hold the &lt;em&gt;&lt;a href="http://en.wikipedia.org/wiki/Siesta"&gt;siesta&lt;/a&gt;&lt;/em&gt; common in
the Mediterranean to pass the hottest hours of the day.&lt;/p&gt;
&lt;p&gt;Then with the Industrial Revolution, everything changed. In the name of
efficiency and progress, we decided that we had to pool workers in one
place — called a factory, or perhaps a shipyard — because now we needed
collaboration: one person could no longer fulfill the task alone, so we
had to get many people to one place to fulfill it together. And as a
natural continuation of our pre-industrial routine, people would work
ten to twelve hours a day, six days a week — until we realized that it
started messing up our lives, inflicting misery on our families and
social ties. And we invented a new concept called spare time: time we
could spend by ourselves, or with our families and friends, something we
didn't have to ask for in the pre-industrial age when our work and life
would naturally have been integrated. And we gradually got to “advances”
like first the
&lt;a href="http://en.wikipedia.org/wiki/Buffalo_switchmen%27s_strike"&gt;10-hour&lt;/a&gt;
workday, then the 8-hour workday, then the 40-hour &lt;a href="http://en.wikipedia.org/wiki/Workweek"&gt;work
week&lt;/a&gt; when we decided it would be
better to have a rest of two days a week rather than one.&lt;/p&gt;
&lt;p&gt;Then we invented white-collar, office jobs, and we gradually moved from
an industry-dominated to a service-dominated economy. And because by
this time we were all well trained in the rules of industrial life, and
because it had brought us progress and prosperity, we applied the same
concepts to offices that we previously had applied to factories and
shipyards: we would gather everyone in the same place, removed from home
and families, and we would get everyone to accept fixed “office hours”
when all hands would have to be present. Of course, we still needed to
collaborate, it's just that the tasks differed from the ones we faced in
factories and shipyards.&lt;/p&gt;
&lt;p&gt;Fast forward to the early 21st century, where we are suddenly endowed
with an abundance of readily available, cheap technology that allows us
to communicate and collaborate instantly, from almost anywhere. And it
is at this point that the unnatural split between work and non-work
life, which we inflicted upon ourselves during the Industrial Revolution
and which we have managed to rationalize with the brainwash that a
“clean separation” of “work and private life” is “essential” to
well-being — that has become a complete anachronism. It is no longer
vital for the people making up a company to physically be in the same
place to collaborate, to serve customers, and to be productive and make
a difference to communities. In fact, I consider it counterproductive.
We've finally arrived in a position where we can restore the very
natural way for humans to live and work, namely integrated with our
families, from home, connected through technology that enables us to
communicate just as effectively as sitting at the same desk. It also
enables us to live healthier, better lives.&lt;/p&gt;
&lt;p&gt;I'm fully aware that this style of work is probably not for everyone.
But if you're thinking it's not for you (and I was one of those, until a
little over a year ago) it's worth asking yourself &lt;em&gt;why&lt;/em&gt; you're thinking
that. Is it really because you &lt;em&gt;want&lt;/em&gt; to work in an office, or because
everyone has &lt;em&gt;told you&lt;/em&gt; for most of your career that you want to work in
an office?&lt;/p&gt;
&lt;p&gt;Here at hastexo, it took us some time — several months — to figure out
all-electronic collaboration, but the machinery is working extremely
well now. The &lt;a href="https://www.google.com/work/apps/business/"&gt;Google Apps&lt;/a&gt;
stack has been enormously useful for us in that regard. We practically
live in &lt;a href="http://www.google.com/+/learnmore/hangouts/"&gt;Google Hangouts&lt;/a&gt;
and documents shared on &lt;a href="http://drive.google.com"&gt;Google Drive&lt;/a&gt;. We jot
down ideas in Google Docs and sketch architectures in Google Drawings.
We do our weekly standups that way, and increasingly customer meetings,
too. We collaboratively draft and edit slide decks for training. And we
rehearse conference talks via video call. It just works, and it's huge
fun that way. And it enables us to close our laptops and go read bedtime
stories to our kids when we're done.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on my blog on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="blog"></category><category term="Philosophy"></category></entry><entry><title>Adding MySQL/Galera resources to Pacemaker</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/mysqlgalera-pacemaker-adding-mysqlgalera-resources-pacemaker/" rel="alternate"></link><published>2012-12-04T10:53:27+01:00</published><updated>2012-12-04T10:53:27+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-12-04:/resources/hints-and-kinks/mysqlgalera-pacemaker-adding-mysqlgalera-resources-pacemaker/</id><summary type="html">&lt;p&gt;Once you have one instance of Galera running, and it is running on the
same node that holds the temporarily-configured cluster IP
(192.168.122.99 in our example), you can add your resources to the
Pacemaker cluster configuration.&lt;/p&gt;
&lt;p&gt;Create a temporary file, such as &lt;code&gt;/tmp/galera.crm&lt;/code&gt;, with the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Once you have one instance of Galera running, and it is running on the
same node that holds the temporarily-configured cluster IP
(192.168.122.99 in our example), you can add your resources to the
Pacemaker cluster configuration.&lt;/p&gt;
&lt;p&gt;Create a temporary file, such as &lt;code&gt;/tmp/galera.crm&lt;/code&gt;, with the following
contents:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;primitive&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p_ip_mysql_galera&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ocf&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;heartbeat&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;IPaddr2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;\&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;nic&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"eth1"&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;iflabel&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"galera"&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;\&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;ip&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"192.168.122.99"&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;cidr_netmask&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"24"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;primitive&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p_mysql&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ocf&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;heartbeat&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;mysql&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;\&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;params&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"/etc/mysql/my.cnf"&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;\&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;pid&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"/var/run/mysqld/mysqld.pid"&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;\&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;socket&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"/var/run/mysqld/mysqld.sock"&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;\&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;binary&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"/usr/sbin/mysqld"&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;\&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;op&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;monitor&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;interval&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"30s"&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;\&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;op&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;interval&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"0"&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;timeout&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"60s"&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;\&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;op&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;stop&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;interval&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"0"&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;timeout&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"60s"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;clone&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;cl_mysql&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p_mysql&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;\&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;meta&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;interleave&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"true"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;colocation&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;c_ip_galera_on_mysql&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;\&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;inf&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p_ip_mysql_galera&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;cl_mysql&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;property&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;stonith&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;enabled&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"false"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, import this into your Pacemaker configuration:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;crm configure load update /tmp/galera.crm
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;What this creates are a couple of Pacemaker resources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The cluster IP address, 192.168.122.99
  (&lt;code&gt;p_ip_mysql_galera&lt;/code&gt;). Throughout the lifetime of the cluster, this
  will always be available on one of the nodes where any MySQL/Galera
  instance is running. This is the IP address new Galera nodes use
  when joining the cluster.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The MySQL server itself (&lt;code&gt;cl_mysql&lt;/code&gt;), which will be automatically
  recovered in-place if it ever fails.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Galera"></category><category term="MySQL"></category><category term="Pacemaker"></category></entry><entry><title>Bootstrapping the Galera cluster</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/mysqlgalera-pacemaker-bootstrapping-galera-cluster/" rel="alternate"></link><published>2012-12-04T10:53:27+01:00</published><updated>2012-12-04T10:53:27+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-12-04:/resources/hints-and-kinks/mysqlgalera-pacemaker-bootstrapping-galera-cluster/</id><summary type="html">&lt;p&gt;In order to bootstrap your Galera cluster, manually bring up the
cluster IP address on the desired interface. In this example, we'll
use 192.168.122.99 and eth1:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ip address add &lt;span class="m"&gt;192&lt;/span&gt;.168.122.99/24 dev eth1 label eth1:galera
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And initialize the Galera cluster:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;mysqld --wsrep_cluster_address&lt;span class="o"&gt;=&lt;/span&gt;gcomm …&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;In order to bootstrap your Galera cluster, manually bring up the
cluster IP address on the desired interface. In this example, we'll
use 192.168.122.99 and eth1:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ip address add &lt;span class="m"&gt;192&lt;/span&gt;.168.122.99/24 dev eth1 label eth1:galera
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And initialize the Galera cluster:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;mysqld --wsrep_cluster_address&lt;span class="o"&gt;=&lt;/span&gt;gcomm:// &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note the empty &lt;code&gt;gcomm://&lt;/code&gt; address.&lt;/p&gt;
&lt;p&gt;An avalanche of output is likely to follow. Near the end, you should
see entries similar to these:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Note&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;WSREP&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Synchronized&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;with&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;group&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ready&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;connections&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;Note&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;mysqld&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ready&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;connections&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;At this point, your MySQL/Galera cluster is properly initialized. It
only has one node, and it is not under cluster management yet, but
it's already a working Galera installation.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Galera"></category><category term="MySQL"></category><category term="Pacemaker"></category></entry><entry><title>Configuring Corosync</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/mysqlgalera-pacemaker-configuring-corosync/" rel="alternate"></link><published>2012-12-04T10:53:27+01:00</published><updated>2012-12-04T10:53:27+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-12-04:/resources/hints-and-kinks/mysqlgalera-pacemaker-configuring-corosync/</id><summary type="html">&lt;p&gt;You now need configure Corosync. The following example configuration
file assumes that your cluster nodes have two network interfaces,
using the 192.168.122.0/24 and 192.168.133.0/24 networks. You will
need to adjust this to your own network configuration.&lt;/p&gt;
&lt;p&gt;Set the contents of &lt;code&gt;/etc/corosync …&lt;/code&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;You now need configure Corosync. The following example configuration
file assumes that your cluster nodes have two network interfaces,
using the 192.168.122.0/24 and 192.168.133.0/24 networks. You will
need to adjust this to your own network configuration.&lt;/p&gt;
&lt;p&gt;Set the contents of &lt;code&gt;/etc/corosync/corosync.conf&lt;/code&gt; as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;compatibility&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;whitetank&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="n"&gt;totem&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;version&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;secauth&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;on&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;threads&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;rrp_mode&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;active&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;token&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;10000&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="kd"&gt;interface&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;                &lt;/span&gt;&lt;span class="n"&gt;ringnumber&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;                &lt;/span&gt;&lt;span class="n"&gt;bindnetaddr&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;192.168&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mf"&gt;122.0&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;                &lt;/span&gt;&lt;span class="n"&gt;mcastaddr&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;239.255&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mf"&gt;42.0&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;                &lt;/span&gt;&lt;span class="n"&gt;mcastport&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5405&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;                &lt;/span&gt;&lt;span class="n"&gt;ttl&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="kd"&gt;interface&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;                &lt;/span&gt;&lt;span class="n"&gt;ringnumber&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;                &lt;/span&gt;&lt;span class="n"&gt;bindnetaddr&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;192.168&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mf"&gt;133.0&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;                &lt;/span&gt;&lt;span class="n"&gt;mcastaddr&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;239.255&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mf"&gt;42.1&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;                &lt;/span&gt;&lt;span class="n"&gt;mcastport&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;5405&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;                &lt;/span&gt;&lt;span class="n"&gt;ttl&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="n"&gt;logging&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;fileline&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;off&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;to_stderr&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;no&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;to_logfile&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;no&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;to_syslog&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;yes&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;off&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;timestamp&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;on&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="n"&gt;logger_subsys&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;                &lt;/span&gt;&lt;span class="n"&gt;subsys&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;AMF&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;                &lt;/span&gt;&lt;span class="n"&gt;debug&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;off&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Also, create an authkey file for node authentication:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;dd &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/dev/urandom &lt;span class="nv"&gt;of&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/etc/corosync/authkey &lt;span class="nv"&gt;bs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;128&lt;/span&gt; &lt;span class="nv"&gt;count&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;
chmod &lt;span class="m"&gt;0400&lt;/span&gt; /etc/corosync/authkey
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And create &lt;code&gt;/etc/corosync/service.d/pacemaker&lt;/code&gt; with the following content:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nt"&gt;service&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;pacemaker&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;ver&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;1&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, distribute the configuration across your cluster:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;for&lt;/span&gt; n &lt;span class="k"&gt;in&lt;/span&gt; bob charlie&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
  rsync -av /etc/corosync/* &lt;span class="nv"&gt;$n&lt;/span&gt;:/etc/corosync
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And start Corosync on all cluster nodes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;service corosync start
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once Corosync has started on all nodes, you should be able to check its status with the &lt;code&gt;corosync-cfgtool&lt;/code&gt; and &lt;code&gt;corosync-objctl&lt;/code&gt; commands:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# corosync-cfgtool -s&lt;/span&gt;
Printing ring status.
Local node ID &lt;span class="m"&gt;1870309568&lt;/span&gt;
RING ID &lt;span class="m"&gt;0&lt;/span&gt;
    &lt;span class="nv"&gt;id&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;192&lt;/span&gt;.168.122.111
    &lt;span class="nv"&gt;status&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; ring &lt;span class="m"&gt;0&lt;/span&gt; active with no faults
RING ID &lt;span class="m"&gt;1&lt;/span&gt;
    &lt;span class="nv"&gt;id&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;192&lt;/span&gt;.168.133.111
    &lt;span class="nv"&gt;status&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; ring &lt;span class="m"&gt;1&lt;/span&gt; active with no faults
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Both rings should be in the &lt;code&gt;active with no faults&lt;/code&gt; state.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# corosync-objctl runtime.totem.pg.mrp.srp.members&lt;/span&gt;
runtime.totem.pg.mrp.srp.1870309568.ip&lt;span class="o"&gt;=&lt;/span&gt;r&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; ip&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;192&lt;/span&gt;.168.122.111&lt;span class="o"&gt;)&lt;/span&gt; r&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; ip&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;192&lt;/span&gt;.168.133.111&lt;span class="o"&gt;)&lt;/span&gt; 
runtime.totem.pg.mrp.srp.1870309568.join_count&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;
runtime.totem.pg.mrp.srp.1870309568.status&lt;span class="o"&gt;=&lt;/span&gt;joined
runtime.totem.pg.mrp.srp.1887086784.ip&lt;span class="o"&gt;=&lt;/span&gt;r&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; ip&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;192&lt;/span&gt;.168.122.112&lt;span class="o"&gt;)&lt;/span&gt; r&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; ip&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;192&lt;/span&gt;.168.133.112&lt;span class="o"&gt;)&lt;/span&gt; 
runtime.totem.pg.mrp.srp.1887086784.join_count&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;
runtime.totem.pg.mrp.srp.1887086784.status&lt;span class="o"&gt;=&lt;/span&gt;joined
runtime.totem.pg.mrp.srp.1903864000.ip&lt;span class="o"&gt;=&lt;/span&gt;r&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; ip&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;192&lt;/span&gt;.168.122.113&lt;span class="o"&gt;)&lt;/span&gt; r&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; ip&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;192&lt;/span&gt;.168.133.113&lt;span class="o"&gt;)&lt;/span&gt; 
runtime.totem.pg.mrp.srp.1903864000.join_count&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;
runtime.totem.pg.mrp.srp.1903864000.status&lt;span class="o"&gt;=&lt;/span&gt;joined
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;All three nodes members should be in the membership with both of their
interfaces, and their status should be &lt;code&gt;joined&lt;/code&gt;.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Galera"></category><category term="MySQL"></category><category term="Pacemaker"></category></entry><entry><title>Dealing with node failure</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/mysqlgalera-pacemaker-dealing-node-failure/" rel="alternate"></link><published>2012-12-04T10:53:27+01:00</published><updated>2012-12-04T10:53:27+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-12-04:/resources/hints-and-kinks/mysqlgalera-pacemaker-dealing-node-failure/</id><summary type="html">&lt;p&gt;If an entire node happens to get killed, and that node currently does
not hold the Galera IP (192.168.122.99 in our example), then the other
nodes simply continue to function normally, and you can connect to and
use them without interruption. In the example below, &lt;code&gt;alice&lt;/code&gt; has …&lt;/p&gt;</summary><content type="html">&lt;p&gt;If an entire node happens to get killed, and that node currently does
not hold the Galera IP (192.168.122.99 in our example), then the other
nodes simply continue to function normally, and you can connect to and
use them without interruption. In the example below, &lt;code&gt;alice&lt;/code&gt; has left
the cluster:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="o"&gt;============&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;Last&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;updated&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Mon&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Dec&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;55&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2012&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;Last&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;change&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Mon&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Dec&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2012&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;via&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;crmd&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;on&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;charlie&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nl"&gt;Stack&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;openais&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;Current&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;DC&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;charlie&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;partition&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;with&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;quorum&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nl"&gt;Version&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.1.7&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ee0730e13d124c3d58f00016c3376a1de5323cff&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Nodes&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;configured&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;expected&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;votes&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Resources&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;configured&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;============&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nl"&gt;Online&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bob&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;charlie&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nl"&gt;OFFLINE&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;alice&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="n"&gt;Full&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;list&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;of&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;resources&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="n"&gt;p_ip_mysql_galera&lt;/span&gt;&lt;span class="w"&gt;       &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ocf&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;heartbeat&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;IPaddr2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt;       &lt;/span&gt;&lt;span class="n"&gt;Started&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bob&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Clone&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Set&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;cl_mysql&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;p_mysql&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="nl"&gt;Started&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bob&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;charlie&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="nl"&gt;Stopped&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p_mysql&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If the node dies that does currently hold the Galera IP
(192.168.122.99 in our example), then the cluster IP shifts to a
different node, and when the failed node returns, it can re-fetch the
cluster state from the node that took over the IP address. In the
example below, in a healthy cluster the IP happens to be running on
&lt;code&gt;bob&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="o"&gt;============&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;Last&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;updated&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Mon&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;Dec&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;32&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;35&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2012&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;Last&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;change&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Mon&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;Dec&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2012&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;via&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;crmd&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;on&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;charlie&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nl"&gt;Stack&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;openais&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;Current&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;DC&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;charlie&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;partition&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;with&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;quorum&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nl"&gt;Version&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.1.7&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ee0730e13d124c3d58f00016c3376a1de5323cff&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Nodes&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;configured&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;expected&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;votes&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Resources&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;configured&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;============&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nl"&gt;Online&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt; bob alice charlie &lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;Full&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;list&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;of&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;resources&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="n"&gt;p_ip_mysql_galera&lt;/span&gt;&lt;span class="w"&gt;       &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nl"&gt;ocf&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="nl"&gt;heartbeat&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;IPaddr2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt;       &lt;/span&gt;&lt;span class="n"&gt;Started&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bob&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Clone&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;Set&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;cl_mysql&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;p_mysql&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="nl"&gt;Started&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt; alice bob charlie &lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Subsequently, &lt;code&gt;bob&lt;/code&gt; is affected by a failure, and the IP address
shifts to &lt;code&gt;alice&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="o"&gt;============&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;Last&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;updated&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Mon&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Dec&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;33&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;33&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2012&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;Last&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;change&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Mon&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Dec&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2012&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;via&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;crmd&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;on&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;charlie&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nl"&gt;Stack&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;openais&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;Current&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;DC&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;charlie&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;partition&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;with&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;quorum&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nl"&gt;Version&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.1.7&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ee0730e13d124c3d58f00016c3376a1de5323cff&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Nodes&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;configured&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;expected&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;votes&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Resources&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;configured&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;============&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nl"&gt;Online&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;alice&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;charlie&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nl"&gt;OFFLINE&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bob&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="n"&gt;Full&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;list&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;of&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;resources&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="n"&gt;p_ip_mysql_galera&lt;/span&gt;&lt;span class="w"&gt;       &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ocf&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;heartbeat&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;IPaddr2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt;       &lt;/span&gt;&lt;span class="n"&gt;Started&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;alice&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Clone&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Set&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;cl_mysql&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;p_mysql&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="nl"&gt;Started&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;alice&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;charlie&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="nl"&gt;Stopped&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p_mysql&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When &lt;code&gt;bob&lt;/code&gt; returns, it simply connects to &lt;code&gt;alice&lt;/code&gt; (which now hosts the
cluster IP), fetches the database state from there, and continues to
run:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="o"&gt;============&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;Last&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;updated&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Mon&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;Dec&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;35&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;46&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2012&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;Last&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;change&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Mon&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;Dec&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;23&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2012&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;via&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;crmd&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;on&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;charlie&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nl"&gt;Stack&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;openais&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;Current&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;DC&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;charlie&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;partition&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;with&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;quorum&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nl"&gt;Version&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.1.7&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ee0730e13d124c3d58f00016c3376a1de5323cff&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Nodes&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;configured&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;expected&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;votes&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Resources&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;configured&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;============&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nl"&gt;Online&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt; bob alice charlie &lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;Full&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;list&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;of&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;resources&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="n"&gt;p_ip_mysql_galera&lt;/span&gt;&lt;span class="w"&gt;       &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nl"&gt;ocf&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="nl"&gt;heartbeat&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;IPaddr2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt;       &lt;/span&gt;&lt;span class="n"&gt;Started&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;alice&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Clone&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;Set&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;cl_mysql&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;p_mysql&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="nl"&gt;Started&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt; alice bob charlie &lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Galera"></category><category term="MySQL"></category><category term="Pacemaker"></category></entry><entry><title>MySQL/Galera in Pacemaker High Availability Clusters</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/mysqlgalera-pacemaker-high-availability-clusters/" rel="alternate"></link><published>2012-12-04T10:53:27+01:00</published><updated>2012-12-04T10:53:27+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-12-04:/resources/hints-and-kinks/mysqlgalera-pacemaker-high-availability-clusters/</id><summary type="html">&lt;p&gt;In this walkthrough, you will create a Pacemaker managed MySQL/Galera
cluster. It assumes that you are running on a Debian 6.0 (squeeze)
box, but the concepts should be equally applicable to other platforms
with minimal modifications.&lt;/p&gt;
&lt;p&gt;It also assumes that your Galera cluster will consist of three nodes …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In this walkthrough, you will create a Pacemaker managed MySQL/Galera
cluster. It assumes that you are running on a Debian 6.0 (squeeze)
box, but the concepts should be equally applicable to other platforms
with minimal modifications.&lt;/p&gt;
&lt;p&gt;It also assumes that your Galera cluster will consist of three nodes,
named alice, bob and charlie. Furthermore, all cluster nodes can
resolve each other's hostnames.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Please note: All commands in this walkthrough require that you are
logged into your system as root.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;First, make sure you have the required packages installed. One of the
easiest ways to get your hands on MySQL/Galera binaries is to install
Percona XtraDB Cluster, which our friends at Percona make available in
their public software repository.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;/etc/apt/sources.list.d/percona.list&lt;/code&gt; with the following
content:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;deb&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;http://repo.percona.com/apt&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kp"&gt;squeeze&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kp"&gt;main&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Fetch the Percona repository signing key:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;apt-key adv --keyserver hkp://keys.gnupg.net --recv-keys 1C4CBDCDCD2EFD2A
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You also require Pacemaker packages from the Debian backports
repository. Do do so, create &lt;code&gt;/etc/apt/sources.list.d/backports.list&lt;/code&gt;
with the following content:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;deb&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;http://backports.debian.org/debian-backports&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kp"&gt;squeeze-backports&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kp"&gt;main&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, update your package lists:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;apt-get update
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once that is completed, you are able to install the
&lt;code&gt;percona-xtradb-cluster-server-5.5&lt;/code&gt; package:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;apt-get -y install percona-xtradb-cluster-server-5.5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that &lt;code&gt;percona-xtradb-cluster-server-5.5&lt;/code&gt; conflicts with the
standard Debian &lt;code&gt;mysql-server&lt;/code&gt; packages, so if you have any of those
installed, they will be removed in the process of installing XtraDB
Cluster.&lt;/p&gt;
&lt;p&gt;Stop the MySQL server services for the time being:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;service mysql stop
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Also required is the pacemaker package (and its dependencies) from
squeeze-backports:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;apt-get -t squeeze-backports install pacemaker
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And finally rsync is required for one of the supported Snapshot State
Transfer (SST) methods for Galera:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;apt-get install rsync
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, all required packages are installed and you're ready to configure
XtraDB Cluster.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Galera"></category><category term="MySQL"></category><category term="Pacemaker"></category></entry><entry><title>Recovering from full cluster shutdown</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/mysqlgalera-pacemaker-recovering-full-cluster-shutdown/" rel="alternate"></link><published>2012-12-04T10:53:27+01:00</published><updated>2012-12-04T10:53:27+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-12-04:/resources/hints-and-kinks/mysqlgalera-pacemaker-recovering-full-cluster-shutdown/</id><summary type="html">&lt;p&gt;If at any time &lt;em&gt;all&lt;/em&gt; of the nodes in your cluster have been taken
down, it is necessary to re-initialize the Galera replication
state. In effect, this is identical to bootstrapping the cluster.&lt;/p&gt;
&lt;p&gt;Start by manually bringing up the cluster IP on one of your nodes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ip address add &lt;span class="m"&gt;192 …&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;If at any time &lt;em&gt;all&lt;/em&gt; of the nodes in your cluster have been taken
down, it is necessary to re-initialize the Galera replication
state. In effect, this is identical to bootstrapping the cluster.&lt;/p&gt;
&lt;p&gt;Start by manually bringing up the cluster IP on one of your nodes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ip address add &lt;span class="m"&gt;192&lt;/span&gt;.168.122.99/24 dev eth1 label eth1:galera
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Re-initialize the Galera cluster:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;mysqld --wsrep_cluster_address&lt;span class="o"&gt;=&lt;/span&gt;gcomm:// &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note the empty &lt;code&gt;gcomm://&lt;/code&gt; address.&lt;/p&gt;
&lt;p&gt;Finally, clear your resource state with &lt;code&gt;crm resource cleanup
cl_mysql&lt;/code&gt;. Pacemaker will leave the running IP address and MySQL
instance untouched, and bring up the additional MySQL instances.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Galera"></category><category term="MySQL"></category><category term="Pacemaker"></category></entry><entry><title>Setting Galera-specific MySQL options</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/mysqlgalera-pacemaker-setting-galera-specific-mysql-options/" rel="alternate"></link><published>2012-12-04T10:53:27+01:00</published><updated>2012-12-04T10:53:27+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-12-04:/resources/hints-and-kinks/mysqlgalera-pacemaker-setting-galera-specific-mysql-options/</id><summary type="html">&lt;p&gt;Now you can proceed with setting Galera specifics in your MySQL
configurations.&lt;/p&gt;
&lt;p&gt;Create a configuration file, &lt;strong&gt;identical on all cluster nodes,&lt;/strong&gt; named
&lt;code&gt;/etc/mysql/conf.d/galera.cnf&lt;/code&gt; with the following content:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;[mysqld]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;bind_address&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;0.0.0.0&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;binlog_format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;ROW&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;default_storage_engine&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;InnoDB&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;innodb_autoinc_lock_mode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;2&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;innodb_locks_unsafe_for_binlog&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;1&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Create another configuration file …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Now you can proceed with setting Galera specifics in your MySQL
configurations.&lt;/p&gt;
&lt;p&gt;Create a configuration file, &lt;strong&gt;identical on all cluster nodes,&lt;/strong&gt; named
&lt;code&gt;/etc/mysql/conf.d/galera.cnf&lt;/code&gt; with the following content:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;[mysqld]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;bind_address&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;0.0.0.0&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;binlog_format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;ROW&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;default_storage_engine&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;InnoDB&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;innodb_autoinc_lock_mode&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;2&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;innodb_locks_unsafe_for_binlog&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;1&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Create another configuration file, &lt;strong&gt;specific to each cluster node,&lt;/strong&gt;
named &lt;code&gt;/etc/mysql/conf.d/wsrep.cnf&lt;/code&gt; with the following content:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;[mysqld]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;# node alice has address 192.168.122.111&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;wsrep_node_address&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;192.168.122.111&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;wsrep_provider&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/usr/lib/libgalera_smm.so&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;wsrep_slave_threads&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;8&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;wsrep_sst_method&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;rsync&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;wsrep_cluster_address&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;gcomm://192.168.122.99&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;[mysqld]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;# node bob has address 192.168.122.112&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;wsrep_node_address&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;192.168.122.112&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;wsrep_provider&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/usr/lib/libgalera_smm.so&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;wsrep_slave_threads&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;8&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;wsrep_sst_method&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;rsync&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;wsrep_cluster_address&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;gcomm://192.168.122.99&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;[mysqld]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;# node charlie has address 192.168.122.111&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;wsrep_node_address&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;192.168.122.113&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;wsrep_provider&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/usr/lib/libgalera_smm.so&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;wsrep_slave_threads&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;8&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;wsrep_sst_method&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;rsync&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;wsrep_cluster_address&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;gcomm://192.168.122.99&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can now proceed with bootstrapping your cluster.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Galera"></category><category term="MySQL"></category><category term="Pacemaker"></category></entry><entry><title>Starting Pacemaker</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/mysqlgalera-pacemaker-starting-pacemaker/" rel="alternate"></link><published>2012-12-04T10:53:27+01:00</published><updated>2012-12-04T10:53:27+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-12-04:/resources/hints-and-kinks/mysqlgalera-pacemaker-starting-pacemaker/</id><summary type="html">&lt;p&gt;Once Corosync is running, you are able to start the Pacemaker cluster
resource manager on all cluster nodes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;service pacemaker start
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once cluster startup is completed, you should see output similar to
the following when invoking the &lt;code&gt;crm_mon&lt;/code&gt; utility:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;============
Last updated: Mon Dec  3 15:37:59 2012
Last change …&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;Once Corosync is running, you are able to start the Pacemaker cluster
resource manager on all cluster nodes:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;service pacemaker start
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once cluster startup is completed, you should see output similar to
the following when invoking the &lt;code&gt;crm_mon&lt;/code&gt; utility:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;============
Last updated: Mon Dec  3 15:37:59 2012
Last change: Mon Dec  3 15:37:58 2012 via crmd on alice
Stack: openais
Current DC: alice - partition with quorum
Version: 1.1.7-ee0730e13d124c3d58f00016c3376a1de5323cff
3 Nodes configured, 3 expected votes
0 Resources configured.
============

Online: [ bob alice charlie ]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Galera"></category><category term="MySQL"></category><category term="Pacemaker"></category></entry><entry><title>Testing resource recovery</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/mysqlgalera-pacemaker-testing-resource-recovery/" rel="alternate"></link><published>2012-12-04T10:53:27+01:00</published><updated>2012-12-04T10:53:27+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-12-04:/resources/hints-and-kinks/mysqlgalera-pacemaker-testing-resource-recovery/</id><summary type="html">&lt;p&gt;If MySQL happens to die in your cluster, Pacemaker will automatically
recover the service in place. To test this, select any node on your
cluster and send the &lt;code&gt;mysqld&lt;/code&gt; process a &lt;code&gt;KILL&lt;/code&gt; signal:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;killall -KILL mysqld
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, monitor your cluster status with &lt;code&gt;crm_mon -rf&lt;/code&gt;. After a few
seconds, you should …&lt;/p&gt;</summary><content type="html">&lt;p&gt;If MySQL happens to die in your cluster, Pacemaker will automatically
recover the service in place. To test this, select any node on your
cluster and send the &lt;code&gt;mysqld&lt;/code&gt; process a &lt;code&gt;KILL&lt;/code&gt; signal:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;killall -KILL mysqld
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, monitor your cluster status with &lt;code&gt;crm_mon -rf&lt;/code&gt;. After a few
seconds, you should see one of your &lt;code&gt;p_mysql&lt;/code&gt; clones entering the
&lt;code&gt;FAILED&lt;/code&gt; state:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="o"&gt;============&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;Last&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;updated&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Mon&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Dec&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;03&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;25&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2012&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;Last&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;change&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Mon&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Dec&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;54&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;44&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2012&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;via&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;crmd&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;on&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bob&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nl"&gt;Stack&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;openais&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;Current&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;DC&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;charlie&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;partition&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;with&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;quorum&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nl"&gt;Version&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.1.7&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ee0730e13d124c3d58f00016c3376a1de5323cff&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Nodes&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;configured&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;expected&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;votes&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Resources&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;configured&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;============&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nl"&gt;Online&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bob&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;alice&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;charlie&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="n"&gt;Full&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;list&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;of&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;resources&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p_ip_mysql_galera&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ocf&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;heartbeat&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;IPaddr2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt;   &lt;/span&gt;&lt;span class="n"&gt;Started&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;alice&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Clone&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Set&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;cl_mysql&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;p_mysql&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="nl"&gt;p_mysql&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ocf&lt;/span&gt;&lt;span class="o"&gt;::&lt;/span&gt;&lt;span class="n"&gt;heartbeat&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;mysql&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Started&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bob&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;FAILED&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="nl"&gt;Started&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;alice&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;charlie&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="n"&gt;Migration&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;summary&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Node&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;alice&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Node&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bob&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Node&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;charlie&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;

&lt;span class="n"&gt;Failed&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;actions&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nl"&gt;p_mysql&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="n"&gt;_monitor_30000&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;bob&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;call&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;rc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;complete&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;not&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;running&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, after a few seconds, the resource will automatically recover:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="o"&gt;============&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;Last&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;updated&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Mon&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;Dec&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;03&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;35&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2012&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;Last&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;change&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Mon&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;Dec&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;54&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;44&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2012&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;via&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;crmd&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;on&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;bob&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nl"&gt;Stack&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;openais&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="k"&gt;Current&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;DC&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;charlie&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;partition&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;with&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;quorum&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nl"&gt;Version&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.1.7&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ee0730e13d124c3d58f00016c3376a1de5323cff&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Nodes&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;configured&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;expected&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;votes&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Resources&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;configured&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;============&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nl"&gt;Online&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt; bob alice charlie &lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="k"&gt;Full&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;list&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;of&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;resources&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;p_ip_mysql_galera&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nl"&gt;ocf&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="nl"&gt;heartbeat&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;IPaddr2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt;   &lt;/span&gt;&lt;span class="n"&gt;Started&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;alice&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Clone&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;Set&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;cl_mysql&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;p_mysql&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;     &lt;/span&gt;&lt;span class="nl"&gt;Started&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt; alice bob charlie &lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="n"&gt;Migration&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;summary&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Node&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;alice&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Node&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;bob&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;
&lt;span class="w"&gt;   &lt;/span&gt;&lt;span class="nl"&gt;p_mysql&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;migration&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;threshold&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1000000&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;fail&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nf"&gt;count&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Node&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;charlie&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;

&lt;span class="n"&gt;Failed&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;actions&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nl"&gt;p_mysql&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="n"&gt;_monitor_30000&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;bob&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;call&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;rc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;complete&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;not&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;running&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To subsequently get rid of the entry in the &lt;code&gt;Failed actions&lt;/code&gt; list, use
&lt;code&gt;crm resource cleanup cl_mysql&lt;/code&gt;.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Galera"></category><category term="MySQL"></category><category term="Pacemaker"></category></entry><entry><title>MySQL High Availability Deep Dive</title><link href="https://xahteiwi.eu/resources/presentations/mysql-high-availability-deep-dive/" rel="alternate"></link><published>2012-12-03T13:50:00+00:00</published><updated>2012-12-03T13:50:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-12-03:/resources/presentations/mysql-high-availability-deep-dive/</id><content type="html">&lt;p&gt;This is a tutorial that Yves Trudeau and I presented at the
Percona Live UK 2012 conference in London. It covers Pacemaker
integration with DRBD, MySQL Replication, and Galera.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;Slides: &lt;a href="https://docs.google.com/presentation/d/12CzmvBOUpbIOrS2CGbG4PU6v74g99C0gGlh0Zf0Qh7g/embed"&gt;Google Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="Conference"></category><category term="MySQL"></category><category term="Pacemaker"></category><category term="Galera"></category></entry><entry><title>GlusterFS in High Availability Clusters</title><link href="https://xahteiwi.eu/resources/presentations/glusterfs-high-availability-clusters/" rel="alternate"></link><published>2012-11-08T08:15:00+00:00</published><updated>2012-11-08T08:15:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-11-08:/resources/presentations/glusterfs-high-availability-clusters/</id><summary type="html">&lt;p&gt;My Pacemaker presentation from the GlusterFS Workshop at LinuxCon
Europe 2012. Presented in Barcelona in November of 2012, this is a
overview of integrating GlusterFS with the Pacemaker cluster stack.&lt;/p&gt;
&lt;p&gt;This tutorial gives an overview of&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Pacemaker stack,&lt;/li&gt;
&lt;li&gt;Using GlusterFS for Pacemaker storage,&lt;/li&gt;
&lt;li&gt;Managing GlusterFS volumes from Pacemaker.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My …&lt;/p&gt;</summary><content type="html">&lt;p&gt;My Pacemaker presentation from the GlusterFS Workshop at LinuxCon
Europe 2012. Presented in Barcelona in November of 2012, this is a
overview of integrating GlusterFS with the Pacemaker cluster stack.&lt;/p&gt;
&lt;p&gt;This tutorial gives an overview of&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Pacemaker stack,&lt;/li&gt;
&lt;li&gt;Using GlusterFS for Pacemaker storage,&lt;/li&gt;
&lt;li&gt;Managing GlusterFS volumes from Pacemaker.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My original presentation included several live demos. In this version,
they have been replaced by placeholders.&lt;/p&gt;
&lt;p&gt;Use the PgUp/PgDown keys to navigate through the presentation, or just
advance by hitting the spacebar.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/lceu2012/glusterfs.html"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="Conference"></category><category term="GlusterFS"></category></entry><entry><title>Hands-On With Ceph</title><link href="https://xahteiwi.eu/resources/presentations/hands-ceph/" rel="alternate"></link><published>2012-11-08T08:15:00+00:00</published><updated>2012-11-08T08:15:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-11-08:/resources/presentations/hands-ceph/</id><summary type="html">&lt;p&gt;My Ceph tutorial from LinuxCon Europe 2012. Presented in
Barcelona in November of 2012, this is a dense summary of the features
of the &lt;a href="https://www.hastexo.com/knowledge/storage-io/ceph"&gt;Ceph&lt;/a&gt;
distributed storage stack.&lt;/p&gt;
&lt;p&gt;This tutorial gives an overview of&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Native RADOS object storage,&lt;/li&gt;
&lt;li&gt;The RBD block device,&lt;/li&gt;
&lt;li&gt;ReSTful object storage with radosgw,&lt;/li&gt;
&lt;li&gt;the Ceph distributed …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;My Ceph tutorial from LinuxCon Europe 2012. Presented in
Barcelona in November of 2012, this is a dense summary of the features
of the &lt;a href="https://www.hastexo.com/knowledge/storage-io/ceph"&gt;Ceph&lt;/a&gt;
distributed storage stack.&lt;/p&gt;
&lt;p&gt;This tutorial gives an overview of&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Native RADOS object storage,&lt;/li&gt;
&lt;li&gt;The RBD block device,&lt;/li&gt;
&lt;li&gt;ReSTful object storage with radosgw,&lt;/li&gt;
&lt;li&gt;the Ceph distributed filesystem.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My original presentation included several live demos. In this
version, they have been replaced by placeholders.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Slides: &lt;a href="https://fghaas.github.io/lceu2012/ceph.html"&gt;GitHub&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="Ceph"></category><category term="Conference"></category></entry><entry><title>Talking Ceph and GlusterFS at LinuxCon Europe</title><link href="https://xahteiwi.eu/blog/2012/10/24/talking-ceph-and-glusterfs-at-linuxcon-europe/" rel="alternate"></link><published>2012-10-24T12:55:00+00:00</published><updated>2012-10-24T12:55:00+00:00</updated><author><name>florian</name></author><id>tag:xahteiwi.eu,2012-10-24:/blog/2012/10/24/talking-ceph-and-glusterfs-at-linuxcon-europe/</id><summary type="html">&lt;p&gt;Early next month, I'll be off to Barcelona for speaking at LinuxCon
Europe. Here's an overview of my talks.&lt;/p&gt;
&lt;p&gt;November 5-7, the &lt;a href="http://www.linuxfoundation.org/"&gt;Linux Foundation&lt;/a&gt; is
holding the annual &lt;a href="http://events.linuxfoundation.org/events/linuxcon-europe"&gt;LinuxCon
Europe&lt;/a&gt; in one
of Europe's most beautiful cities — some say &lt;em&gt;the&lt;/em&gt; most beautiful —
Barcelona. I will be attending the full conference …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Early next month, I'll be off to Barcelona for speaking at LinuxCon
Europe. Here's an overview of my talks.&lt;/p&gt;
&lt;p&gt;November 5-7, the &lt;a href="http://www.linuxfoundation.org/"&gt;Linux Foundation&lt;/a&gt; is
holding the annual &lt;a href="http://events.linuxfoundation.org/events/linuxcon-europe"&gt;LinuxCon
Europe&lt;/a&gt; in one
of Europe's most beautiful cities — some say &lt;em&gt;the&lt;/em&gt; most beautiful —
Barcelona. I will be attending the full conference, and presenting two
talks.&lt;/p&gt;
&lt;p&gt;Wednesday, November 7, is a day full of tutorials at LinuxCon Europe. I
am presenting &lt;a href="http://linuxconeurope2012.sched.org/event/83ef77ad003a026246f37e639cd562db"&gt;Hands-On with Ceph: Object Storage, Block Storage,
Filesystem &amp;amp;
More&lt;/a&gt;,
a deep dive into the Ceph stack. This is a double-slot tutorial,
scheduled for 2:45 - 4:25pm in the Verdi room.&lt;/p&gt;
&lt;p&gt;Then on Thursday, the GlusterFS community team has invited me to speak
at the &lt;a href="http://linuxconeurope2012.sched.org/overview/type/gluster+workshop"&gt;Gluster
Workshop.&lt;/a&gt; This
workshop is complimentary to &lt;a href="http://events.linuxfoundation.org/events/linuxcon-europe/attend/register"&gt;registered LinuxCon Europe
attendees&lt;/a&gt;,
but you can also &lt;a href="https://www.regonline.com/Register/Checkin.aspx?EventID=1109147"&gt;register
separately&lt;/a&gt;
just for the workshop. In that talk, I'll speak about &lt;a href="http://linuxconeurope2012.sched.org/event/2b898583721726bd6a8d8e15af2084d8"&gt;GlusterFS in High
Availability Clusters: Integration with the Pacemaker HA
Stack&lt;/a&gt;.
It's also a 1-hour slot, from 10 - 11am in Vivaldi.&lt;/p&gt;
&lt;p&gt;I'm pretty excited about this trip: it's close to home, it's a great
conference, and I've never been to Barcelona before. So, if you're
headed there, please &lt;a href="https://www.hastexo.com/users/florian/contact"&gt;drop me a
note&lt;/a&gt; and let me know so
we can catch up. Thanks — see you there!&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on my blog on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="blog"></category><category term="Ceph"></category><category term="Conference"></category><category term="GlusterFS"></category></entry><entry><title>Migrating virtual machines from block-based storage to RADOS/Ceph</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/migrating-virtual-machines-block-based-storage-radosceph/" rel="alternate"></link><published>2012-10-22T15:31:23+01:00</published><updated>2012-10-22T15:31:23+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-10-22:/resources/hints-and-kinks/migrating-virtual-machines-block-based-storage-radosceph/</id><summary type="html">&lt;p&gt;Ceph allows you to replace existing SAN storage (or SAN drop-in
substitutes) with a flexible storage solution with real scale-out
capabilities. Here is how you migrate existing virtual machines
managed by libvirt from block-based storage to a Ceph based storage
solution.&lt;/p&gt;
&lt;h2&gt;Prerequisites&lt;/h2&gt;
&lt;p&gt;What you'll need in order to successfully manage …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Ceph allows you to replace existing SAN storage (or SAN drop-in
substitutes) with a flexible storage solution with real scale-out
capabilities. Here is how you migrate existing virtual machines
managed by libvirt from block-based storage to a Ceph based storage
solution.&lt;/p&gt;
&lt;h2&gt;Prerequisites&lt;/h2&gt;
&lt;p&gt;What you'll need in order to successfully manage the migration from
block-based storage to a working Ceph cluster is this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A working Ceph cluster. You probably guessed this one. More
  specifically, you should have&lt;/li&gt;
&lt;li&gt;access to the client.admin key of your RADOS
    installation. Usually, the key will be stored in /etc/ceph/keyring
    on nodes running RADOS.&lt;/li&gt;
&lt;li&gt;a RADOS pool in which you can create RBD images. You can either
    use the standard rbd pool or create your own pool. We'll use the
    libvirt pool throughout the following example.&lt;/li&gt;
&lt;li&gt;a set of credentials for a client to connect to the cluster and
    create and use RBD devices. If you use a libvirt version &amp;lt; 0.9.7,
    you will have to use the default client.admin credentials for this
    purpose. If you run libvirt 0.9.7 or later, you should use a
    separate set of credentials (i.e. create a user called
    e.g. client.rbd and use that one). That user should have at least
    the allow r permission on your mons, and allow rw on your osds
    (the latter you can restrict to the rbd pool used if you wish).&lt;/li&gt;
&lt;li&gt;qemu in version 0.14 or higher&lt;/li&gt;
&lt;li&gt;libvirt in version 0.8.7 or higher (0.9.7 or higher if you want to
  use a separate user for this)&lt;/li&gt;
&lt;li&gt;Ceph 0.48 ("argonaut") or higher&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Getting Started&lt;/h2&gt;
&lt;p&gt;When migrating a VM from block-based storage to a Ceph cluster, you
unfortunately can't avoid a period of downtime (after all, you won't
be able to reliably copy a filesystem from place A to B while it's
still changing on the go). So the first thing to do is shut down a
currently running virtual machine, like we will do with the
ubuntu-amd64-alice VM in this example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;virsh shutdown ubuntu-amd64-alice
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then you need to create an RBD image within that pool. Suppose you
would like to create one that is 100GB in size (recall, all RBD images
are thin-provisioned, so it won't actually use 100GB in the Ceph
cluster right from the start).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;qemu-img create -f rbd rbd:libvirt/ubuntu-amd64-alice 100G
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This means you are connecting to the Ceph mon servers (defined in the
default configuration file, /etc/ceph/ceph.conf) using the
client.admin identity, whose authentication key should be stored in
/etc/ceph/keyring. The nominal image size is 102400MB, it's part of
the libvirt pool and its name is a hardly creative ubuntu-amd64-alice.&lt;/p&gt;
&lt;p&gt;You can run this command from any node inside or outside your Ceph
cluster, as long as the configuration file and authentication
credentials are stored in the appropriate location. The next step,
however, is one that you must complete on the node where you can
currently access your block-based storage. This could either be the
machine that you have your VM's device currently connected to via
iSCSI or - if you are using a SAN drop-in replacement based on DRBD -
the machine that currently has the VM's DRBD resource in Primary mode.&lt;/p&gt;
&lt;p&gt;If you are unsure what your VM's block device is, take a look at the
VM's configuration with&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;virsh dumpxml ubuntu-amd64-alice
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;to find out the actual device name (look out for paragraphs including
a &lt;disk&gt; statement). In our case, the actual device is
/dev/drbd/by-res/vm-ubuntu-amd64-alice. Now let's go ahead and do the
actual conversion. Please note: For the following command to work, you
need a properly populated /etc/ceph directory because that is where
qemu-img gets its information from. This is the command that initiates
the conversion:&lt;/disk&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;qemu-img convert -f raw -O rbd \
  /dev/drbd/by-res/vm-ubuntu-amd64-alice \
  rbd:libvirt/ubuntu-amd64-alice
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once the qemu-img command has completed, the actual conversion of your
data is already done. That was easy, wasn't it? The final step is to
change your libvirt VM configuration file to reflect the changes.&lt;/p&gt;
&lt;h2&gt;Adapting the VM's libvirt configuration (libvirt &amp;lt; 0.9.7)&lt;/h2&gt;
&lt;p&gt;If we want our VM to run on top of a Ceph object store, we need to
tell libvirt how to start the VM appropriately. Luckily, current
versions of libvirt support Ceph-based RBD backing devices out of the
box. Please note: All following steps assume that you have your
/etc/ceph set up properly. This means that a working ceph.conf and a
keyring file containing the authentication key for client.admin is
present.&lt;/p&gt;
&lt;p&gt;Open up your VM's configuration for editing with&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;virsh edit ubuntu-amd64-alice
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and scroll down to the VM's disk definition. In our example, that part of the configuration looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nt"&gt;&amp;lt;disk&lt;/span&gt; &lt;span class="na"&gt;type=&lt;/span&gt;&lt;span class="s"&gt;'block'&lt;/span&gt; &lt;span class="na"&gt;device=&lt;/span&gt;&lt;span class="s"&gt;'disk'&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;driver&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;'qemu'&lt;/span&gt; &lt;span class="na"&gt;type=&lt;/span&gt;&lt;span class="s"&gt;'raw'&lt;/span&gt; &lt;span class="na"&gt;cache=&lt;/span&gt;&lt;span class="s"&gt;'none'&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;source&lt;/span&gt; &lt;span class="na"&gt;dev=&lt;/span&gt;&lt;span class="s"&gt;'/dev/drbd/by-res/vm-ubuntu-amd64-alice'&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;target&lt;/span&gt; &lt;span class="na"&gt;dev=&lt;/span&gt;&lt;span class="s"&gt;'vda'&lt;/span&gt; &lt;span class="na"&gt;bus=&lt;/span&gt;&lt;span class="s"&gt;'virtio'&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;address&lt;/span&gt; &lt;span class="na"&gt;type=&lt;/span&gt;&lt;span class="s"&gt;'pci'&lt;/span&gt; &lt;span class="na"&gt;domain=&lt;/span&gt;&lt;span class="s"&gt;'0x0000'&lt;/span&gt; &lt;span class="na"&gt;bus=&lt;/span&gt;&lt;span class="s"&gt;'0x00'&lt;/span&gt; &lt;span class="na"&gt;slot=&lt;/span&gt;&lt;span class="s"&gt;'0x05'&lt;/span&gt; &lt;span class="na"&gt;function=&lt;/span&gt;&lt;span class="s"&gt;'0x0'&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/disk&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Replace it with an entry using our RBD image:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nt"&gt;&amp;lt;disk&lt;/span&gt; &lt;span class="na"&gt;type=&lt;/span&gt;&lt;span class="s"&gt;'network'&lt;/span&gt; &lt;span class="na"&gt;device=&lt;/span&gt;&lt;span class="s"&gt;'disk'&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;driver&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;'qemu'&lt;/span&gt; &lt;span class="na"&gt;type=&lt;/span&gt;&lt;span class="s"&gt;'raw'&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;source&lt;/span&gt; &lt;span class="na"&gt;protocol=&lt;/span&gt;&lt;span class="s"&gt;'rbd'&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;'libvirt/ubuntu-amd64-alice'&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;host&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;'192.168.133.111'&lt;/span&gt; &lt;span class="na"&gt;port=&lt;/span&gt;&lt;span class="s"&gt;'6789'&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;host&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;'192.168.133.112'&lt;/span&gt; &lt;span class="na"&gt;port=&lt;/span&gt;&lt;span class="s"&gt;'6789'&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;host&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;'192.168.133.113'&lt;/span&gt; &lt;span class="na"&gt;port=&lt;/span&gt;&lt;span class="s"&gt;'6789'&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;/source&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;target&lt;/span&gt; &lt;span class="na"&gt;dev=&lt;/span&gt;&lt;span class="s"&gt;'vda'&lt;/span&gt; &lt;span class="na"&gt;bus=&lt;/span&gt;&lt;span class="s"&gt;'virtio'&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;address&lt;/span&gt; &lt;span class="na"&gt;type=&lt;/span&gt;&lt;span class="s"&gt;'pci'&lt;/span&gt; &lt;span class="na"&gt;domain=&lt;/span&gt;&lt;span class="s"&gt;'0x0000'&lt;/span&gt; &lt;span class="na"&gt;bus=&lt;/span&gt;&lt;span class="s"&gt;'0x00'&lt;/span&gt; &lt;span class="na"&gt;slot=&lt;/span&gt;&lt;span class="s"&gt;'0x05'&lt;/span&gt; &lt;span class="na"&gt;function=&lt;/span&gt;&lt;span class="s"&gt;'0x0'&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/disk&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Be sure to replace the three IPs in the above example with the actual
IPs of your MON servers.&lt;/p&gt;
&lt;p&gt;Finally, start your virtual machine:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;virsh start ubuntu-amd64-alice
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Adapting the VM's libvirt configuration (libvirt &amp;gt;= 0.9.7)&lt;/h2&gt;
&lt;p&gt;Starting with libvirt 0.9.7, you can use a user other than
client.admin to access RBD images via libvirt. We recommend to do
this. Creating such a setup works very similar to the one without a
separate user; the main difference is that it requires you to define a
secret in libvirt for the VM. First of all, figure out what user you
will be using from within libvirt and where that user's authentication
key is stored. For this example, we will assume that the user is
called client.rbd and that this user's key is stored in
/etc/ceph/keyring.client.rbd. Now, create a new UUID by calling&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;uuidgen
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;on the command line. The UUID for our example will be
5cddc503-9c29-4aa8-943a-c097f87677cf.  Then, open
/etc/libvirt/secrets/ubuntu-amd64-alice.xml and define a secret block
in there:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nt"&gt;&amp;lt;secret&lt;/span&gt; &lt;span class="na"&gt;ephemeral=&lt;/span&gt;&lt;span class="s"&gt;"no"&lt;/span&gt; &lt;span class="na"&gt;private=&lt;/span&gt;&lt;span class="s"&gt;"no"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;uuid&amp;gt;&lt;/span&gt;5cddc503-9c29-4aa8-943a-c097f87677cf&lt;span class="nt"&gt;&amp;lt;/uuid&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;usage&lt;/span&gt; &lt;span class="na"&gt;type=&lt;/span&gt;&lt;span class="s"&gt;"ceph"&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;name&amp;gt;&lt;/span&gt;client.rbd secret&lt;span class="nt"&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/usage&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/secret&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Be sure to replace the example's UUID with your own, self-generated
value. Make libvirt add this secret to its internal keyring:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;virsh secret-define \
  /etc/libvirt/secrets/ubuntu-amd64-alice.xml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now find out your user's secret key. Do&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ceph auth get-or-create client.rbd
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and take note of the key. In our example,
AQB0Q4ZQYDB2MBAAYzWmHvpg7t1MzV1E0jkBww== is the key that will allow us
access as client.rbd. Then define the actual password for our secret
definition:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;virsh secret-set-value \
  5cddc503-9c29-4aa8-943a-c097f87677cf \
  AQB0Q4ZQYDB2MBAAYzWmHvpg7t1MzV1E0jkBww==
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Again, be sure to use your self-generated UUID instead of the one in
this example. Also replace the example key with your real
key. Finally, go ahead and adapt your VM settings. Open your VM
configuration with&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;virsh edit ubuntu-amd64-alice
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and scroll down to the VM's disk definition. In our example, that part of the configuration looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nt"&gt;&amp;lt;disk&lt;/span&gt; &lt;span class="na"&gt;type=&lt;/span&gt;&lt;span class="s"&gt;'block'&lt;/span&gt; &lt;span class="na"&gt;device=&lt;/span&gt;&lt;span class="s"&gt;'disk'&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;driver&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;'qemu'&lt;/span&gt; &lt;span class="na"&gt;type=&lt;/span&gt;&lt;span class="s"&gt;'raw'&lt;/span&gt; &lt;span class="na"&gt;cache=&lt;/span&gt;&lt;span class="s"&gt;'none'&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;source&lt;/span&gt; &lt;span class="na"&gt;dev=&lt;/span&gt;&lt;span class="s"&gt;'/dev/drbd/by-res/vm-ubuntu-amd64-alice'&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;target&lt;/span&gt; &lt;span class="na"&gt;dev=&lt;/span&gt;&lt;span class="s"&gt;'vda'&lt;/span&gt; &lt;span class="na"&gt;bus=&lt;/span&gt;&lt;span class="s"&gt;'virtio'&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;address&lt;/span&gt; &lt;span class="na"&gt;type=&lt;/span&gt;&lt;span class="s"&gt;'pci'&lt;/span&gt; &lt;span class="na"&gt;domain=&lt;/span&gt;&lt;span class="s"&gt;'0x0000'&lt;/span&gt; &lt;span class="na"&gt;bus=&lt;/span&gt;&lt;span class="s"&gt;'0x00'&lt;/span&gt; &lt;span class="na"&gt;slot=&lt;/span&gt;&lt;span class="s"&gt;'0x05'&lt;/span&gt; &lt;span class="na"&gt;function=&lt;/span&gt;&lt;span class="s"&gt;'0x0'&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/disk&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Replace it with an entry using our RBD image:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nt"&gt;&amp;lt;disk&lt;/span&gt; &lt;span class="na"&gt;type=&lt;/span&gt;&lt;span class="s"&gt;'network'&lt;/span&gt; &lt;span class="na"&gt;device=&lt;/span&gt;&lt;span class="s"&gt;'disk'&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;driver&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;'qemu'&lt;/span&gt; &lt;span class="na"&gt;type=&lt;/span&gt;&lt;span class="s"&gt;'raw'&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;auth&lt;/span&gt; &lt;span class="na"&gt;username=&lt;/span&gt;&lt;span class="s"&gt;'rbd'&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;secret&lt;/span&gt; &lt;span class="na"&gt;type=&lt;/span&gt;&lt;span class="s"&gt;'ceph'&lt;/span&gt; &lt;span class="na"&gt;usage=&lt;/span&gt;&lt;span class="s"&gt;'client.rbd secret'&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;/auth&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;source&lt;/span&gt; &lt;span class="na"&gt;protocol=&lt;/span&gt;&lt;span class="s"&gt;'rbd'&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;'libvirt/ubuntu-amd64-alice'&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;host&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;'192.168.133.111'&lt;/span&gt; &lt;span class="na"&gt;port=&lt;/span&gt;&lt;span class="s"&gt;'6789'&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;host&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;'192.168.133.112'&lt;/span&gt; &lt;span class="na"&gt;port=&lt;/span&gt;&lt;span class="s"&gt;'6789'&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
    &lt;span class="nt"&gt;&amp;lt;host&lt;/span&gt; &lt;span class="na"&gt;name=&lt;/span&gt;&lt;span class="s"&gt;'192.168.133.113'&lt;/span&gt; &lt;span class="na"&gt;port=&lt;/span&gt;&lt;span class="s"&gt;'6789'&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;/source&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;target&lt;/span&gt; &lt;span class="na"&gt;dev=&lt;/span&gt;&lt;span class="s"&gt;'vda'&lt;/span&gt; &lt;span class="na"&gt;bus=&lt;/span&gt;&lt;span class="s"&gt;'virtio'&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
  &lt;span class="nt"&gt;&amp;lt;address&lt;/span&gt; &lt;span class="na"&gt;type=&lt;/span&gt;&lt;span class="s"&gt;'pci'&lt;/span&gt; &lt;span class="na"&gt;domain=&lt;/span&gt;&lt;span class="s"&gt;'0x0000'&lt;/span&gt; &lt;span class="na"&gt;bus=&lt;/span&gt;&lt;span class="s"&gt;'0x00'&lt;/span&gt; &lt;span class="na"&gt;slot=&lt;/span&gt;&lt;span class="s"&gt;'0x05'&lt;/span&gt; &lt;span class="na"&gt;function=&lt;/span&gt;&lt;span class="s"&gt;'0x0'&lt;/span&gt;&lt;span class="nt"&gt;/&amp;gt;&lt;/span&gt;
&lt;span class="nt"&gt;&amp;lt;/disk&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Be sure to replace the three IPs in the above example with the actual
IPs of your MON servers.&lt;/p&gt;
&lt;p&gt;Finally, start your virtual machine:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;virsh start ubuntu-amd64-alice
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That's it. Your VM should now boot up and use its RBD image from Ceph
instead of its original block-based storage backing device.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Ceph"></category><category term="libvirt"></category></entry><entry><title>Pacemaker and the recent GitHub service interruption</title><link href="https://xahteiwi.eu/blog/2012/09/26/pacemaker-and-the-recent-github-service-interruption/" rel="alternate"></link><published>2012-09-26T11:32:00+00:00</published><updated>2012-09-26T11:32:00+00:00</updated><author><name>florian</name></author><id>tag:xahteiwi.eu,2012-09-26:/blog/2012/09/26/pacemaker-and-the-recent-github-service-interruption/</id><summary type="html">&lt;p&gt;It never fails. Someone manages to break their Pacemaker cluster, and
&lt;a href="http://openlife.cc/author"&gt;Henrik&lt;/a&gt; starts preaching &lt;a href="http://openlife.cc/blogs/2012/september/failover-evil"&gt;his usual sermon
of why Pacemaker is
terrible&lt;/a&gt; and why
you should never-ever use it. And when that someone is
&lt;a href="https://github.com/"&gt;GitHub&lt;/a&gt;, which we all know, use and love, then
that sermon gets a bit of excess …&lt;/p&gt;</summary><content type="html">&lt;p&gt;It never fails. Someone manages to break their Pacemaker cluster, and
&lt;a href="http://openlife.cc/author"&gt;Henrik&lt;/a&gt; starts preaching &lt;a href="http://openlife.cc/blogs/2012/september/failover-evil"&gt;his usual sermon
of why Pacemaker is
terrible&lt;/a&gt; and why
you should never-ever use it. And when that someone is
&lt;a href="https://github.com/"&gt;GitHub&lt;/a&gt;, which we all know, use and love, then
that sermon gets a bit of excess attention. Let's take a quick look at
the facts.&lt;/p&gt;
&lt;!--break--&gt;
&lt;p&gt;The week of September 10, GitHub suffered a couple of outages which
caused a total downtime of 1 hour and 46 minutes, as
&lt;a href="https://github.com/jnewland"&gt;Jesse&lt;/a&gt; precisely pointed out &lt;a href="https://github.com/blog/1261-github-availability-this-week"&gt;in a blog
post&lt;/a&gt;.
Exhibiting the excellent transparency that GitHub always offers at any
time its infrastructure is affected by issues (remember &lt;a href="https://github.com/blog/1068-public-key-security-vulnerability-and-mitigation"&gt;their
role-model behavior in an SSH security
incident&lt;/a&gt;
a few months back), Jesse explains, in a very detailed way, what
happened on one of their Pacemaker clusters.&lt;/p&gt;
&lt;p&gt;Now, all of what follows is based exclusively on the information in that
blog post of Jesse's. I have no inside knowledge of the incident, so my
picture may be incomplete or skewed. But here's my take on it anyway. I
do encourage you to read Jesse's post full-length, as the rest of this
post otherwise won't make much sense. I'll just quote certain pieces of
it and comment on them here.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Please note:&lt;/strong&gt; nothing in this post should be construed as a put-down
of GitHub's excellent staff. They run a fantastic service and do an
awesome job. It's just that their post-mortem seems to have created some
misconceptions in the MySQL community about the Pacemaker stack as a
whole, and those I'd like to help rectify. Also, I'm posting this in the
hope that it provides useful insight to both the GitHub folks, and to
anyone else facing similar issues.&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Enable Maintenance Mode when you should&lt;/h2&gt;
&lt;p&gt;From the original post:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Monday's migration caused higher load on the database than our
operations team has previously seen during these sorts of migrations.
So high, in fact, that they caused Percona Replication Manager's
health checks to fail on the master. In response to the failed master
health check, Percona Replication manager moved the 'active' role and
the master database to another server in the cluster and stopped MySQL
on the node it perceived as failed.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
At the time of this failover, the new database selected for the
'active' role had a cold InnoDB buffer pool and performed rather
poorly. The system load generated by the site's query load on a cold
cache soon caused Percona Replication Manager's health checks to fail
again, and the 'active' role failed back to the server it was on
originally.
&lt;p&gt;&lt;/p&gt;
At this point, I decided to disable all health checks by enabling
Pacemaker's &lt;code&gt;maintenance-mode&lt;/code&gt;; an operating mode in which no health
checks or automatic failover actions are performed. Performance on the
site slowly recovered as the buffer pool slowly reached normal levels.
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now there's actually several issues in there even in this early stage.
Maintenance mode is generally the right thing to do here, but you enable
it &lt;em&gt;before&lt;/em&gt; making large changes to the configuration, and you disable
it when done. If you're uncomfortable with the cluster manager taking
its hands off the entire cluster, and you know what you're doing, you
could also just disable cluster management and monitoring on a specific
resource. Both approaches are explained
&lt;a href="https://www.hastexo.com/resources/hints-and-kinks/maintenance-active-pacemaker-clusters"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Also, as far as "health checks failing" on the master is concerned,
pretty much the only thing that is likely to cause such a failure in
this instance is a timeout, and you can adjust those even on a
per-operation basis in Pacemaker. But even that is unnecessary if you
enable maintenance mode at the right time.&lt;/p&gt;
&lt;h2&gt;"Maintenance mode" really means maintenance mode&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;The following morning, our operations team was notified by a developer
of incorrect query results returning from the node providing the
'standby' role. I investigated the situation and determined that when
the cluster was placed into maintenance-mode the day before, actions
that should have caused the node elected to serve the 'standby' role
to change its replication master and start replicating were prevented
from occurring.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Well, of course. In maintenance mode, Pacemaker takes its hands off your
resources. If you're enabling maintenance mode right in the middle of a
failover, then that's not exactly a stellar idea. If you do, then it's
your job to complete those actions manually.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I determined that the best course of action was to
disable &lt;code&gt;maintenance-mode&lt;/code&gt; to allow Pacemaker and the Percona
Replication Manager to rectify the situation.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;"Best" might be an exaggeration, if I may say so.&lt;/p&gt;
&lt;h2&gt;A segfault and rejected cluster messages&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Upon attempting to disable &lt;code&gt;maintenance-mode&lt;/code&gt;, a Pacemaker segfault
occurred that resulted in a cluster state partition.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;OK, that's bad, but what exactly segfaulted? crmd? attrd? pengine? Or
the master Heartbeat process? But the next piece of information would
have me believe that the segfault really isn't the root cause of the
cluster partition:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;After this update, two nodes (I'll call them 'a' and 'b') rejected
most messages from the third node ('c'), while the third node rejected
most messages from the other two.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now it's a pity that we don't have any version information and logs, but
this looks very much like the "not in our membership" issue present up
to Pacemaker 1.1.6. This is a known issue, the fix is to update to a
more recent version (&lt;a href="https://github.com/ClusterLabs/pacemaker/commit/03f6105592281901cc10550b8ad19af4beb5f72f"&gt;here's the
commit,&lt;/a&gt; on
GitHub of course), and the workaround is to just restart the Pacemaker
services on the affected node(s) while in maintenance mode.&lt;/p&gt;
&lt;h2&gt;A non-quorate partition running MySQL?&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Despite having configured the cluster to require a majority of
machines to agree on the state of the cluster before taking action,
two simultaneous master election decisions were attempted without
proper coordination. In the first cluster, master election was
interrupted by messages from the second cluster and MySQL was stopped.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now this is an example of me being tempted to say, "logs or it didn't
happen." If you've got the default no-quorum-policy of "block", and
you're getting a non-quorate partition, and you don't have any resources
with operations &lt;em&gt;explicitly&lt;/em&gt; configured to ignore quorum, then "two
simultaneous master election decisions" can only refer to the Designated
Coordinator (DC) election, which has no bearing whatsoever on MySQL
master status. Luckily, Pacemaker allows us to take a meaningful
snapshot of all cluster logs and status after the fact with crm_report.
It would be quite interesting to see a tarball from that.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In the second, single-node cluster, node 'c' was elected at 8:19 AM,
and any subsequent messages from the other two-node cluster were
discarded. As luck would have it, the 'c' node was the node that our
operations team previously determined to be out of date. We detected
this fact and powered off this out-of-date node at 8:26 AM to end the
partition and prevent further data drift, taking down all production
database access and thus all access to github.com.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That's obviously a bummer, but really, if that partition is non-quorate,
and Pacemaker hasn't explicitly been configured to ignore that, no
cluster resources would start there. Needless to say a working fencing
configuration would have helped oodles, too.&lt;/p&gt;
&lt;h2&gt;Your cluster has no crystal ball, but it does have a command line&lt;/h2&gt;
&lt;p&gt;I'll skip over most of the rest of the GitHub post, because it's an
explanation of how these backend issues affected GitHub users. I'll just
hop on down to this piece:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The automated failover of our main production database could be
described as the root cause of both of these downtime events. In each
situation in which that occurred, if any member of our operations team
had been asked if the failover should have been performed, the answer
would have been a resounding no.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Well, you could have told your Pacemaker of that fact beforehand. Enable
maintenance mode and you're good to go.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;There are many situations in which automated failover is an excellent
strategy for ensuring the availability of a service. After careful
consideration, we've determined that ensuring the availability of our
primary production database is not one of these situations. To this
end, we've made changes to our Pacemaker configuration to ensure
failover of the 'active' database role will only occur when initiated
by a member of our operations team.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That splash you just heard was the bath water. The scream was the baby
being tossed out with it.&lt;/p&gt;
&lt;p&gt;Automated failover is a pretty poor strategy &lt;em&gt;in the middle of a large
configuration change.&lt;/em&gt; And Pacemaker gives you a simple and easy
interface to disable it, by changing a single cluster property. Failure
to do so may result in problems, and in this case it did.&lt;/p&gt;
&lt;p&gt;When you put a baby seat on the passenger side of your car, you disable
the air bag to prevent major injury. But if you take that baby seat out
and an adult passenger rides with you, are you seriously saying you're
going to manually initiate the air bag in case of a crash? I hope you're
not.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Finally, our operations team is performing a full audit of our
Pacemaker and Heartbeat stack focusing on the code path that triggered
the segfault on Tuesday.&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That's probably a really good idea. For anyone planning to do the same,
&lt;a href="https://www.hastexo.com/services/checkup"&gt;we can help.&lt;/a&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on my blog on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;
&lt;!--break--&gt;</content><category term="blog"></category><category term="MySQL"></category><category term="Pacemaker"></category></entry><entry><title>Maintenance in active Pacemaker clusters</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/maintenance-active-pacemaker-clusters/" rel="alternate"></link><published>2012-09-24T19:49:31+01:00</published><updated>2012-09-24T19:49:31+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-09-24:/resources/hints-and-kinks/maintenance-active-pacemaker-clusters/</id><summary type="html">&lt;p&gt;In a Pacemaker cluster, as in a standalone system, operators must
complete maintenance tasks such as software upgrades and configuration
changes. Here's what you need to keep Pacemaker's built-in monitoring
features from creating unwanted side effects.&lt;/p&gt;
&lt;h2&gt;Maintenance mode&lt;/h2&gt;
&lt;p&gt;This is quite possibly Pacemaker's single most useful feature for
cluster maintenance …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In a Pacemaker cluster, as in a standalone system, operators must
complete maintenance tasks such as software upgrades and configuration
changes. Here's what you need to keep Pacemaker's built-in monitoring
features from creating unwanted side effects.&lt;/p&gt;
&lt;h2&gt;Maintenance mode&lt;/h2&gt;
&lt;p&gt;This is quite possibly Pacemaker's single most useful feature for
cluster maintenance. In maintenance mode, Pacemaker essentially takes
a "hands-off" approach to your cluster. Enabling Pacemaker maintenance
mode is very easy using the Pacemaker &lt;code&gt;crm&lt;/code&gt; shell:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;crm configure property maintenance-mode&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;true&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In maintenance mode, you can stop or restart cluster resources at
will. Pacemaker will not attempt to restart them. All resources
automatically become unmanaged, that is, Pacemaker will cease
monitoring them and hence be oblivious about their status. You can
even stop all Pacemaker services on a node, and all the daemons and
processes originally started as Pacemaker managed cluster resources
will continue to run.&lt;/p&gt;
&lt;p&gt;You should know that when you start Pacemaker services on a node while
the cluster in maintenance mode, Pacemaker will initiate a single
one-shot monitor operation (a "probe") for every resource just so it
has an understanding of what resources are currently running on that
node. It will, however, take no further action other than determining
the resources' status.&lt;/p&gt;
&lt;p&gt;You disable maintenance mode with the crm shell, as well:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;crm configure property maintenance-mode&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;false&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Maintenance mode is something you enable before running other
maintenance actions, not when you're already half-way through
them. And unless you're very well versed in the interdependencies of
resources running on the cluster you're working on, it's usually the
very safest option.&lt;/p&gt;
&lt;p&gt;In short: when doing maintenance on your Pacemaker cluster, by
default, enable maintenance mode before you start, and disable it
after you're done.&lt;/p&gt;
&lt;h2&gt;Disabling monitoring and error recovery on specific resources&lt;/h2&gt;
&lt;p&gt;For any configuration changes that take no more than a few minutes,
involving an admin that is potentially watching a console window the
whole time, maintenance mode is highly recommended. However, enabling
maintenance mode can be a bit hard to argue for large configuration
changes lasting, say, several hours. Think of a massive database
rebuild, for example. In such a case, you may want to put only your
database resource in something like maintenance mode, and have
Pacemaker continue to monitor other resources like normal.&lt;/p&gt;
&lt;p&gt;You can do so by switching the resource to unmanaged mode and disable
its monitor operation:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;crm configure edit p_database
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then change the &lt;code&gt;is-managed&lt;/code&gt; meta  attribute and disable the &lt;code&gt;monitor&lt;/code&gt;
operation:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;meta is-managed=false
op monitor interval=&amp;lt;interval&amp;gt; enabled=false
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once you've done that, you'll effectively have enabled something akin
to maintenance mode for a single resource. You can reverse this as you
would expect:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;crm configure edit p_database
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then change the &lt;code&gt;is-managed&lt;/code&gt; meta attribute and re-enable the
&lt;code&gt;monitor&lt;/code&gt; operation:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;meta is-managed=true
op monitor interval=&amp;lt;interval&amp;gt; enabled=true
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When using this approach, all other resources will be monitored and
automatically recovered as they normally would. Thus, you'll have to
be acutely aware of any side effects your maintenance activities have
on other resources. If you're unsure, you should use the global
maintenance mode instead.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Pacemaker"></category></entry><entry><title>High Availability in OpenStack</title><link href="https://xahteiwi.eu/resources/presentations/high-availability-openstack/" rel="alternate"></link><published>2012-08-30T15:48:00+00:00</published><updated>2012-08-30T15:48:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-08-30:/resources/presentations/high-availability-openstack/</id><summary type="html">&lt;p&gt;An update on high-availability development during the
&lt;a href="http://www.openstack.org"&gt;OpenStack&lt;/a&gt; Folsom development cycle. This
presentation was delivered August 30, 2012 in San Diego, California. It
was part of the inaugural
&lt;a href="http://events.linuxfoundation.org/events/cloudopen-north-america"&gt;CloudOpen&lt;/a&gt;
conference hosted by the &lt;a href="http://www.linuxfoundation.org"&gt;Linux
Foundation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Following up on my earlier talks at OpenStack Summit and OSCON, I
summarized the high-availability …&lt;/p&gt;</summary><content type="html">&lt;p&gt;An update on high-availability development during the
&lt;a href="http://www.openstack.org"&gt;OpenStack&lt;/a&gt; Folsom development cycle. This
presentation was delivered August 30, 2012 in San Diego, California. It
was part of the inaugural
&lt;a href="http://events.linuxfoundation.org/events/cloudopen-north-america"&gt;CloudOpen&lt;/a&gt;
conference hosted by the &lt;a href="http://www.linuxfoundation.org"&gt;Linux
Foundation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Following up on my earlier talks at OpenStack Summit and OSCON, I
summarized the high-availability features OpenStack gained during the
Folsom development cycle.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Slides: &lt;a href='https://prezi.com/embed/xaclzhzpjmau/"&amp;gt;&amp;lt;/'&gt;Prezi&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="Conference"></category><category term="OpenStack"></category></entry><entry><title>Speaking and BoFing at CloudOpen in San Diego!</title><link href="https://xahteiwi.eu/blog/2012/08/20/speaking-and-bofing-at-cloudopen-in-san-diego/" rel="alternate"></link><published>2012-08-20T07:26:00+00:00</published><updated>2012-08-20T07:26:00+00:00</updated><author><name>florian</name></author><id>tag:xahteiwi.eu,2012-08-20:/blog/2012/08/20/speaking-and-bofing-at-cloudopen-in-san-diego/</id><summary type="html">&lt;p&gt;Next week, I will be speaking at the inaugural CloudOpen conference in
San Diego. This is your chance to learn about
&lt;a href="https://www.hastexo.com/knowledge/openstack"&gt;OpenStack&lt;/a&gt; high
availability and
&lt;a href="https://www.hastexo.com/knowledge/storage-io/ceph"&gt;Ceph!&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;August 29-31, San Diego hosts the
first &lt;a href="http://events.linuxfoundation.org/events/cloudopen-north-america"&gt;CloudOpen&lt;/a&gt;
conference, colocated with &lt;a href="http://events.linuxfoundation.org/events/linuxcon-north-america"&gt;LinuxCon North
America&lt;/a&gt;.
CloudOpen is the &lt;a href="http://www.linuxfoundation.org/"&gt;Linux Foundation&lt;/a&gt;'s
brand new, stack-agnostic cloud …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Next week, I will be speaking at the inaugural CloudOpen conference in
San Diego. This is your chance to learn about
&lt;a href="https://www.hastexo.com/knowledge/openstack"&gt;OpenStack&lt;/a&gt; high
availability and
&lt;a href="https://www.hastexo.com/knowledge/storage-io/ceph"&gt;Ceph!&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;August 29-31, San Diego hosts the
first &lt;a href="http://events.linuxfoundation.org/events/cloudopen-north-america"&gt;CloudOpen&lt;/a&gt;
conference, colocated with &lt;a href="http://events.linuxfoundation.org/events/linuxcon-north-america"&gt;LinuxCon North
America&lt;/a&gt;.
CloudOpen is the &lt;a href="http://www.linuxfoundation.org/"&gt;Linux Foundation&lt;/a&gt;'s
brand new, stack-agnostic cloud conference where OpenStackers can mingle
with CloudStackers and Eucalyptus folks to discuss open-source cloud
solutions.&lt;/p&gt;
&lt;p&gt;It's also the conference where I will be giving my fourth (and likely
last, at least for the time being) incarnation of the High Availability
for OpenStack talk I first delivered at the Folsom design summit back in
April. Since then, we've had a lot of community involvement for HA in
OpenStack, and have made some excellent progress, and I will be more
than happy to report on that. This presentation is on &lt;a href="http://cloudopen2012.sched.org/event/06939ee7fd5fe48bf202525bbd7e506d#.UDIX9hXwh2M"&gt;Thursday,
2:25-3:10pm in Executsoemive Center Room
2&lt;/a&gt;,
in the &lt;em&gt;Operations&lt;/em&gt; track.&lt;/p&gt;
&lt;p&gt;Also, &lt;a href="http://ceph.com/community/people-profile/sage-weil/"&gt;Sage Weil&lt;/a&gt;
of Ceph fame is joining me for an birds-of-a-feather (BoF) session on
Ceph. &lt;a href="http://rtrk.us/"&gt;Ross Turk&lt;/a&gt; and I had such an excellent turnout
(and a great time) in the Ceph BoF at OSCON that we just had to do
another. And Sage agreed to take part, which is excellent. He has &lt;a href="http://cloudopen2012.sched.org/event/f3e84388068b1855c5a705a97c917f44#.UDIZeBXwh2M"&gt;a
talk on Ceph in the main conference
track&lt;/a&gt;
as well.&lt;/p&gt;
&lt;p&gt;The conference organizers do not announce BoF sessions ahead of time on
the CloudOpen web site, so I've simply &lt;a href="https://plus.google.com/events/cq28o7cvj9dg1ki1om3clfo8700/110443614427234590648"&gt;set up a Google+
event&lt;/a&gt;
for you to check in on. The exact location is still TBD (we will be
assigned a room based on availability), but we will definitely be in the
conference area at the Sheraton in San Diego. If you're attending
CloudOpen and you want to learn more about Ceph, you're more than
welcome to join us!&lt;/p&gt;
&lt;p&gt;My personal CloudOpen schedule is available
&lt;a href="http://cloudopen2012.sched.org/fghaas"&gt;here&lt;/a&gt;, by the way. Feel free to
grab me at a talk, or in the hallway. See you in San Diego!&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on my blog on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="blog"></category><category term="Ceph"></category><category term="Conference"></category><category term="high availability"></category><category term="OpenStack"></category></entry><entry><title>Highly Available Cloud: Pacemaker integration with OpenStack</title><link href="https://xahteiwi.eu/resources/presentations/highly-available-cloud-pacemaker-integration-openstack/" rel="alternate"></link><published>2012-07-17T21:12:00+00:00</published><updated>2012-07-17T21:12:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-07-17:/resources/presentations/highly-available-cloud-pacemaker-integration-openstack/</id><summary type="html">&lt;p&gt;This presentation was delivered July 17, 2012 at OSCON in
Portland, Oregon.&lt;/p&gt;
&lt;p&gt;I summarize high availability in OpenStack Folsom, particularly
OpenStack integration with the Pacemaker high availability cluster
stack.&lt;/p&gt;
&lt;p&gt;I talk about high availability shortcomings in OpenStack Essex,
comparing OpenStack to some of its important competitors. I then
explain how …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This presentation was delivered July 17, 2012 at OSCON in
Portland, Oregon.&lt;/p&gt;
&lt;p&gt;I summarize high availability in OpenStack Folsom, particularly
OpenStack integration with the Pacemaker high availability cluster
stack.&lt;/p&gt;
&lt;p&gt;I talk about high availability shortcomings in OpenStack Essex,
comparing OpenStack to some of its important competitors. I then
explain how these shortcomings are being addressed in Folsom, and give
an overview of the current progress in view of current OpenStack Folsom
development.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Slides: &lt;a href='https://prezi.com/embed/p4jstawrfqwh/"&amp;gt;&amp;lt;/'&gt;Prezi&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="Conference"></category><category term="OpenStack"></category><category term="Pacemaker"></category></entry><entry><title>Configuring radosgw to behave like Amazon S3</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/configuring-radosgw-behave-amazon-s3/" rel="alternate"></link><published>2012-07-09T08:15:57+01:00</published><updated>2012-07-09T08:15:57+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-07-09:/resources/hints-and-kinks/configuring-radosgw-behave-amazon-s3/</id><summary type="html">&lt;p&gt;If you've heard of Ceph, you've surely heard of radosgw, a RESTful
gateway interface to the RADOS object store. You've probably also
heard that it provides a front-end interface that is compatible with
Amazon's S3 API.&lt;/p&gt;
&lt;p&gt;The question remains, if you have an S3 client that always assumes it
can …&lt;/p&gt;</summary><content type="html">&lt;p&gt;If you've heard of Ceph, you've surely heard of radosgw, a RESTful
gateway interface to the RADOS object store. You've probably also
heard that it provides a front-end interface that is compatible with
Amazon's S3 API.&lt;/p&gt;
&lt;p&gt;The question remains, if you have an S3 client that always assumes it
can find objects at http://bucket.s3.amazonaws.com, how can you use
such a client to interact, unmodified, with your radosgw host (or
hosts)?&lt;/p&gt;
&lt;p&gt;Pulling this off is actually remarkably simple, if you can control
what nameserver your clients use to resolve DNS names. Which should be
a given in the private cloud space.&lt;/p&gt;
&lt;p&gt;First, of course, you'll need an installed and configured Ceph cluster
with one or several radosgw nodes. The Ceph documentation is an
excellent reference for setting up radosgw.&lt;/p&gt;
&lt;h2&gt;Configuring radosgw to support virtual hosts&lt;/h2&gt;
&lt;p&gt;Then, you make sure you have the following entry in your Ceph configuration (normally in /etc/ceph/ceph.conf):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;[client.radosgw.charlie]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="na"&gt;rgw dns name&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;s3.amazonaws.com&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Substitute charlie with whatever name you want to use for your radosgw
client when you interact with Ceph. What the rgw dns name option
specifies is that radosgw will answer queries also for URLs like
http://bucket.hostname/object, as opposed to just
http://hostname/bucket/object.&lt;/p&gt;
&lt;h2&gt;Configuring Apache to respond to S3 host names&lt;/h2&gt;
&lt;p&gt;Also, add a wildcard record to the ServerAlias directive in the web server configuration for your radosgw host. For example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nt"&gt;&amp;lt;VirtualHost&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;*:80&lt;/span&gt;&lt;span class="nt"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;ServerName&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;radosgw.example.com&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;ServerAlias&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;s3.amazonaws.com&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;ServerAlias&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;*.amazonaws.com&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Configuring your DNS server&lt;/h2&gt;
&lt;p&gt;Then, set up your DNS server with a wildcard record in the
s3.amazonaws.com zone, and have nameserver respond to requests in that
zone. The zone file (for BIND9, in this case) could look like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$TTL    604800
@   IN  SOA alice.example.com. root.alice.example.com. (
                  2     ; Serial
             604800     ; Refresh
              86400     ; Retry
            2419200     ; Expire
             604800 )   ; Negative Cache TTL
;
@   IN  NS  alice.example.com.
@   IN  A   192.168.122.113
*   IN  CNAME   @
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this zone, the A record s3.amazonaws.com resolves
to 192.168.122.113, and any sub-domain (like
mybucket.s3.amazonaws.com) also resolves to that same address via a
CNAME record.&lt;/p&gt;
&lt;h2&gt;Using your RADOS store with S3 clients&lt;/h2&gt;
&lt;p&gt;And then you just configure your client hosts to resolve DNS names via
that nameserver, and use your preferred client application to interact
with it.&lt;/p&gt;
&lt;p&gt;For example, for a user that you've created with radosgw-admin, which
uses the access key 12345 with a secret of 67890, and Mark Atwood's
popular &lt;code&gt;Net::Amazon::S3::Tools&lt;/code&gt; toolkit, here's how you can interact
with your RADOS objects:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# export AWS_ACCESS_KEY_ID=12345&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;# export AWS_ACCESS_KEY_SECRET=67890&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;# s3mkbucket mymostawesomebucket&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;# s3ls&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;mymostawesomebucket&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;# s3put mymostawesomebucket/foobar &amp;lt;&amp;lt;&amp;lt; "hello world"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;# s3ls mymostawesomebucket&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;foobar&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="c1"&gt;# s3get mymostawesomebucket/foobar&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;hello&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;world&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Simple enough. You can add one more nifty feature.&lt;/p&gt;
&lt;h2&gt;Adding load balancing&lt;/h2&gt;
&lt;p&gt;radosgw can scale horizontally, and all you need to do to make this
work is to duplicate your radosgw and Apache configuration onto a
different host, and then add a second record to your DNS zone:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;$TTL    604800
@   IN  SOA alice.example.com. root.alice.example.com. (
                  3     ; Serial
             604800     ; Refresh
              86400     ; Retry
            2419200     ; Expire
             604800 )   ; Negative Cache TTL
;
@   IN  NS  alice.example.com.
@   IN  A   192.168.122.112
@   IN  A   192.168.122.113
*   IN  CNAME   @
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, as you access more buckets, you'll hit the A records in a
round-robin fashion, meaning your requests will be balanced across the
servers. Add as many as you like.&lt;/p&gt;
&lt;h2&gt;HTTPS support&lt;/h2&gt;
&lt;p&gt;Obviously, the above steps will not work for HTTPS connections to the
REST API. And really, making that work would amount to some pretty
terrible SSL certificate authority and client trust hackery, so just
don't do it.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Ceph"></category></entry><entry><title>Fencing in VMware virtualized Pacemaker nodes</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/fencing-vmware-virtualized-pacemaker-nodes/" rel="alternate"></link><published>2012-05-18T09:43:28+01:00</published><updated>2012-05-18T09:43:28+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-05-18:/resources/hints-and-kinks/fencing-vmware-virtualized-pacemaker-nodes/</id><summary type="html">&lt;p&gt;For users of VMware virtualization, it's becoming increasingly common
to deploy Pacemaker clusters within the virtual infrastructure. Doing
this requires that you set up fencing via ESX Server or, more
commonly, vCenter. Here's how to do that.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;cluster-glue&lt;/code&gt; package contains node Pacemaker's fencing (STONITH)
plugins, one of which is …&lt;/p&gt;</summary><content type="html">&lt;p&gt;For users of VMware virtualization, it's becoming increasingly common
to deploy Pacemaker clusters within the virtual infrastructure. Doing
this requires that you set up fencing via ESX Server or, more
commonly, vCenter. Here's how to do that.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;cluster-glue&lt;/code&gt; package contains node Pacemaker's fencing (STONITH)
plugins, one of which is the &lt;code&gt;external/vcenter&lt;/code&gt; plugin. It enables
Pacemaker to interface with an ESX Server host or vCenter server. When
a Pacemaker node needs to be fenced, the fencing node contacts the
vCenter host and instructs it to knock out the offending node.&lt;/p&gt;
&lt;p&gt;For this to work, your configuration needs to satisfy a couple of prerequisites:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Your setup needs a reasonably recent cluster-glue package (the one
  that ships in Debian squeeze-backports and Ubuntu precise is fine).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;You need to install the &lt;a href="http://www.vmware.com/support/developer/vc-sdk/"&gt;vSphere Web Services
  SDK&lt;/a&gt; on your
  nodes. This itself has a number of Perl prerequisites. On
  Debian/Ubuntu systems, you should be able to install them with:&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;aptitude install libarchive-zip-perl libcrypt-ssleay-perl \
  libclass-methodmaker-perl libuuid-perl \
  libsoap-lite-perl libxml-libxml-perl
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, create a set of vCenter credentials with the &lt;code&gt;credstore_admin.pl&lt;/code&gt;
utility that comes bundled with the SDK:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;/usr/lib/vmware-vcli/apps/general/credstore_admin.pl \
  -s &amp;lt;vCenter server IP or hostname&amp;gt; \
  -u &amp;lt;vCenter username&amp;gt; \
  -p &amp;lt;vCenter password&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This creates a credentials file in
&lt;code&gt;.vmware/credstore/vicredentials.xml&lt;/code&gt; relative to your home
directory. Copy this file into a location where Pacemaker can find it,
say &lt;code&gt;/etc/vicredentials.xml&lt;/code&gt;, and make sure it gets 0600
permissions. Also, remember to copy it to all your cluster nodes. Once
your credentials are properly set up, you can test the STONITH agent's
functionality by invoking it directly, like so:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;  &lt;span class="nv"&gt;VI_SERVER&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&amp;lt;vCenter server IP or hostname&amp;gt; &lt;span class="se"&gt;\&lt;/span&gt;
  &lt;span class="nv"&gt;VI_CREDSTORE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/etc/vicredentials.xml &lt;span class="se"&gt;\&lt;/span&gt;
  &lt;span class="nv"&gt;HOSTLIST&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"&amp;lt;pacemaker hostname&amp;gt;=&amp;lt;vCenter virtual machine name&amp;gt;"&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
  &lt;span class="nv"&gt;RESETPOWERON&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
  /usr/lib/stonith/plugins/external/vcenter gethosts
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;pacemaker hostname=""&gt; is the name of one of your cluster nodes as per
uname -n, and &lt;vcenter machine="" name="" virtual=""&gt; is the corresponding
machine name in your vCenter inventory. If everything is working fine,
the gethosts command should return the Pacemaker hostname again.&lt;/vcenter&gt;&lt;/pacemaker&gt;&lt;/p&gt;
&lt;p&gt;Now, on to adding this to the Pacemaker configuration. The example
below is for two hosts named alice and bob, which in the inventory
happen to be listed by their FQDN in the example.com domain:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;primitive p_fence_alice stonith:external/vcenter \
  params VI_SERVER="vcenter.example.com" \
    VI_CREDSTORE="/etc/vicredentials.xml" \
    HOSTLIST="alice=alice.example.com" \
    RESETPOWERON="0" \
    pcmk_host_check="static-list" \
    pcmk_host_list="alice" \
  op monitor interval="60"
primitive p_fence_bob stonith:external/vcenter \
  params VI_SERVER="vcenter.example.com" \
    VI_CREDSTORE="/etc/vicredentials.xml" \
    HOSTLIST="bob=bob.example.com" \
    RESETPOWERON="0" \
    pcmk_host_check="static-list" \
    pcmk_host_list="bob" \
  op monitor interval="60"
location l_fence_alice p_fence_alice -inf: alice
location l_fence_bob p_fence_bob -inf: bob
property stonith-enabled="true"
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;At this point you should be able to test fencing with &lt;code&gt;stonith_admin
-F&lt;/code&gt; or &lt;code&gt;crm node fence&lt;/code&gt;. Or simulate a node problem with &lt;code&gt;killall -9
corosync&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Special thanks for this goes to Nhan Ngo Dinh both for writing the
plugin in the first place, and for providing an excellent and
straightforward README file for it.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Pacemaker"></category></entry><entry><title>An exciting day for the Ceph community</title><link href="https://xahteiwi.eu/blog/2012/05/03/an-exciting-day-for-the-ceph-community/" rel="alternate"></link><published>2012-05-03T11:10:00+00:00</published><updated>2012-05-03T11:10:00+00:00</updated><author><name>florian</name></author><id>tag:xahteiwi.eu,2012-05-03:/blog/2012/05/03/an-exciting-day-for-the-ceph-community/</id><summary type="html">&lt;p&gt;Today, as you've probably noticed if you're following the development of
the &lt;a href="https://www.hastexo.com/knowledge/storage-io/ceph"&gt;Ceph&lt;/a&gt; stack,
something mighty cool has been happening. The
&lt;a href="http://ceph.com/"&gt;ceph.com&lt;/a&gt; web site received a major makeover with a
slick new design, and the people behind Ceph have &lt;a href="http://www.marketwired.com/press-release/new-startup-inktank-delivers-the-future-of-storage-with-ceph-1652261.htm"&gt;announced the launch
of a brand new
company&lt;/a&gt;
to drive …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Today, as you've probably noticed if you're following the development of
the &lt;a href="https://www.hastexo.com/knowledge/storage-io/ceph"&gt;Ceph&lt;/a&gt; stack,
something mighty cool has been happening. The
&lt;a href="http://ceph.com/"&gt;ceph.com&lt;/a&gt; web site received a major makeover with a
slick new design, and the people behind Ceph have &lt;a href="http://www.marketwired.com/press-release/new-startup-inktank-delivers-the-future-of-storage-with-ceph-1652261.htm"&gt;announced the launch
of a brand new
company&lt;/a&gt;
to drive the Ceph stack, &lt;a href="http://www.inktank.com"&gt;Inktank&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As I've previously blogged here, Ceph is &lt;a href="https://www.hastexo.com/blogs/florian/2012/03/08/ceph-tickling-my-geek-genes"&gt;one of the most interesting
storage
technologies&lt;/a&gt;
out on the market today – and this includes both open-source and
commercial offerings. It's exceptionally well designed, extremely
scalable, and useful for a frighteningly diverse set of usage scenarios.
Up to this point, Ceph development has been driven and funded by &lt;a href="http://newdream.net/"&gt;New
Dream Network&lt;/a&gt;, a long-standing hosting provider
operating out of Southern California since 1997 under the
&lt;a href="http://www.dreamhost.com/"&gt;DreamHost&lt;/a&gt; brand. Now, it's being launched
into its own company.&lt;/p&gt;
&lt;p&gt;Inktank is about to offer professional services and training around the
Ceph stack. I've had the pleasure to meet with Inktank President &amp;amp; COO
Bryan Bogensberger and others at the OpenStack conference in San
Francisco. Indeed, meeting with them was one of my motivations for being
there – besides &lt;a href="https://www.hastexo.com/resources/presentations/reliable-redundant-resilient-high-availability-openstack"&gt;high availability in
OpenStack&lt;/a&gt;,
of course.&lt;/p&gt;
&lt;p&gt;What Inktank enables us to do is to remain involved in the Ceph
community even more than we previously were. We're already offering Ceph
instruction as part of our &lt;a href="https://www.hastexo.com/services/training/hastexo-high-availability-expert"&gt;High Availability
Expert&lt;/a&gt;
and &lt;a href="https://www.hastexo.com/services/training/cloud-bootcamp"&gt;Cloud Bootcamp for
OpenStack&lt;/a&gt;
training classes. &lt;a href="https://www.hastexo.com/who/martin"&gt;Martin&lt;/a&gt; has
&lt;a href="https://www.hastexo.com/resources/presentations/glusterfs-und-ceph-skalierbares-storage-ohne-wenn-und-aber"&gt;presented Ceph at
CeBIT&lt;/a&gt;
in Germany this year. He has also just published a well-received
&lt;a href="http://www.admin-magazine.com/HPC/Articles/The-RADOS-Object-Store-and-Ceph-Filesystem"&gt;article on Ceph in the U.S. edition of ADMIN
magazine&lt;/a&gt;,
and I have another one coming up in next month's Issue 218 of &lt;a href="http://www.linuxjournal.com"&gt;Linux
Journal&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So, we're excited for Inktank and wish them the best – even though we
sadly can't be at their &lt;a href="https://www.eventbrite.com/e/always-bet-on-ink-tickets-3311680325"&gt;launch party in Las Vegas on May
8&lt;/a&gt;.
We appreciate the invitation, guys – have fun!&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on my blog on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="blog"></category><category term="Ceph"></category></entry><entry><title>A look back at my first OpenStack Design Summit &amp; Conference</title><link href="https://xahteiwi.eu/blog/2012/04/24/a-look-back-at-my-first-openstack-design-summit-conference/" rel="alternate"></link><published>2012-04-24T09:35:00+00:00</published><updated>2012-04-24T09:35:00+00:00</updated><author><name>florian</name></author><id>tag:xahteiwi.eu,2012-04-24:/blog/2012/04/24/a-look-back-at-my-first-openstack-design-summit-conference/</id><summary type="html">&lt;p&gt;I've just returned from the &lt;a href="http://www.openstack.org/conference/san-francisco-2012/"&gt;OpenStack Folsom Design Summit and Spring
2012
Conference&lt;/a&gt;,
and am finally getting rid of my jet lag. Here's a summary of what's
been a mind-blowing conference experience for me.&lt;/p&gt;
&lt;!--break--&gt;
&lt;p&gt;This was my first OpenStack Design Summit and Conference. And as anyone
who's in open source …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've just returned from the &lt;a href="http://www.openstack.org/conference/san-francisco-2012/"&gt;OpenStack Folsom Design Summit and Spring
2012
Conference&lt;/a&gt;,
and am finally getting rid of my jet lag. Here's a summary of what's
been a mind-blowing conference experience for me.&lt;/p&gt;
&lt;!--break--&gt;
&lt;p&gt;This was my first OpenStack Design Summit and Conference. And as anyone
who's in open source is acutely aware, some communities can be reluctant
to accept newcomers. Some may even seem outright hostile to the timid.
Not the &lt;a href="http://www.openstack.org/community"&gt;OpenStack&lt;/a&gt; community.&lt;/p&gt;
&lt;p&gt;The minute I sat down in the opening session of the Design Summit on
Monday, I felt instantly welcome and at home. Even as a relative
OpenStack newbie (who was invited to the Design Summit to provide some
insights and guidance on high availability), I immediately got the
impression that I was in the right place at the right time. I've rarely
seen a developer community on such a positive vibe. Sure, we'll blast
each other on technical disagreements, but all in a good-natured, fun
way.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://folsomdesignsummit2012.sched.org/event/fa2a5803a4b4ba857db57c84a1e1d3bc"&gt;My own Design Summit
session&lt;/a&gt;
clearly wasn't without such disagreements, and expectedly so. But I
think we came to some excellent conclusions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Infrastructure high availability will be an overarching design goal
    in the upcoming OpenStack Folsom release.&lt;/li&gt;
&lt;li&gt;We will shoot for providing HA solutions for all OpenStack
    infrastructure services. This includes MySQL, RabbitMQ, Glance,
    Keystone, Nova and Horizon (Swift already has HA built in). hastexo
    will play a very active role in this.&lt;/li&gt;
&lt;li&gt;We will not reinvent the wheel, and instead rely on &lt;a href="http://clusterlabs.org/"&gt;the Pacemaker
    stack&lt;/a&gt; wherever possible.&lt;/li&gt;
&lt;li&gt;Most of the challenge is really in the documentation and in the
    development of reference solutions that deployment solutions
    (&lt;a href="https://jujucharms.com/"&gt;Juju&lt;/a&gt;, &lt;a href="https://www.chef.io/chef/"&gt;Chef&lt;/a&gt;,
    &lt;a href="https://puppetlabs.com/"&gt;Puppet&lt;/a&gt;) can then build on. We will take a
    lot of responsibility in that effort, as well.&lt;/li&gt;
&lt;li&gt;Some services still require some work to become fully HA capable.
    Cinder (the volume service that's being factored out of Nova for
    Folsom) is one example, Quantum is another. This work will be
    tackled.&lt;/li&gt;
&lt;li&gt;We're currently planning to stop short of providing monitoring and
    HA for Nova instances (a.k.a. &lt;em&gt;guest HA&lt;/em&gt;). This is on the list for
    the next release past Folsom.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With those issues discussed, voted on and on the record, I had the honor
of &lt;a href="http://openstackconferencespring2012.sched.org/event/a6d940d2ebd11e37c6ac389f7d4d2125"&gt;presenting them to a larger audience at the main
conference&lt;/a&gt;.
It seems to have hit home pretty well, based on feedback from attendees
given in-person and on Twitter. &lt;span style="text-decoration: line-through;"&gt;I'm hoping the conference
organizers will make a video recording available shortly. Meanwhile, my
presentation is already available
&lt;a href="https://prezi.com/gxaohiwl46z2/high-availability-in-openstack/"&gt;here&lt;/a&gt;.&lt;/span&gt; &lt;a href="https://www.hastexo.com/resources/presentations/reliable-redundant-resilient-high-availability-openstack"&gt;It's
now available here in the &lt;em&gt;Presentations&lt;/em&gt;
section.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Overall, this has been a wonderful and very well organized conference,
and I'm very much looking forward to coming back next time around.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on my blog on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;
&lt;!--break--&gt;</content><category term="blog"></category><category term="Conference"></category><category term="OpenStack"></category></entry><entry><title>Reliable, Redundant, Resilient: High Availability in OpenStack</title><link href="https://xahteiwi.eu/resources/presentations/reliable-redundant-resilient-high-availability-in-openstack/" rel="alternate"></link><published>2012-04-20T15:36:00+00:00</published><updated>2012-04-20T15:36:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-04-20:/resources/presentations/reliable-redundant-resilient-high-availability-in-openstack/</id><content type="html">&lt;p&gt;I explain the high availability features in the upcoming OpenStack
Folsom release at the OpenStack Conference Spring 2012. This
presentation was delivered April 21, 2012 in San Francisco,
California.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;Slides: &lt;a href='https://prezi.com/embed/gxaohiwl46z2/"&amp;gt;&amp;lt;/'&gt;Prezi&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="OpenStack"></category></entry><entry><title>Speaking at OSCON 2012</title><link href="https://xahteiwi.eu/blog/2012/04/03/speaking-at-oscon-2012/" rel="alternate"></link><published>2012-04-03T09:24:00+00:00</published><updated>2012-04-03T09:24:00+00:00</updated><author><name>florian</name></author><id>tag:xahteiwi.eu,2012-04-03:/blog/2012/04/03/speaking-at-oscon-2012/</id><summary type="html">&lt;p&gt;I'll be speaking at &lt;a href="http://www.oscon.com/oscon2012"&gt;OSCON 2012&lt;/a&gt; in
Portland, on high availability in
&lt;a href="https://www.hastexo.com/knowledge/openstack"&gt;OpenStack&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I learned from O'Reilly yesterday that my presentation proposal for this
year's &lt;a href="http://www.oscon.com/oscon2012"&gt;OSCON&lt;/a&gt;, which takes place July
16-20, 2012 in Portland, Oregon, has been accepted. As this is my first
OSCON speaking slot (actually, it's my first …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I'll be speaking at &lt;a href="http://www.oscon.com/oscon2012"&gt;OSCON 2012&lt;/a&gt; in
Portland, on high availability in
&lt;a href="https://www.hastexo.com/knowledge/openstack"&gt;OpenStack&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I learned from O'Reilly yesterday that my presentation proposal for this
year's &lt;a href="http://www.oscon.com/oscon2012"&gt;OSCON&lt;/a&gt;, which takes place July
16-20, 2012 in Portland, Oregon, has been accepted. As this is my first
OSCON speaking slot (actually, it's my first OSCON altogether), this is
a thrilling speaking opportunity for me.&lt;/p&gt;
&lt;p&gt;My talk, &lt;em&gt;Highly Available Cloud: OpenStack integration with Pacemaker&lt;/em&gt;
is currently (tentatively, I suppose) scheduled for 11:30 on July 18.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on my blog on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="blog"></category><category term="Conference"></category><category term="OpenStack"></category><category term="OSCON"></category></entry><entry><title>Presentation accepted for OpenStack Spring 2012 Conference</title><link href="https://xahteiwi.eu/blog/2012/03/28/presentation-accepted-for-openstack-spring-2012-conference/" rel="alternate"></link><published>2012-03-28T19:52:00+00:00</published><updated>2012-03-28T19:52:00+00:00</updated><author><name>florian</name></author><id>tag:xahteiwi.eu,2012-03-28:/blog/2012/03/28/presentation-accepted-for-openstack-spring-2012-conference/</id><summary type="html">&lt;p&gt;I just learned that my presentation is going ahead at the &lt;a href="http://www.openstack.org/conference/san-francisco-2012/"&gt;OpenStack
Spring 2012
Conference&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;My presentation, &lt;em&gt;Reliable, Redundant: High Availability in
OpenStack,&lt;/em&gt; has been accepted for the main conference track. The
official schedule isn't yet up pending confirmation from all speakers,
but I've been tentatively informed that it's on …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I just learned that my presentation is going ahead at the &lt;a href="http://www.openstack.org/conference/san-francisco-2012/"&gt;OpenStack
Spring 2012
Conference&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;My presentation, &lt;em&gt;Reliable, Redundant: High Availability in
OpenStack,&lt;/em&gt; has been accepted for the main conference track. The
official schedule isn't yet up pending confirmation from all speakers,
but I've been tentatively informed that it's on at 11:30 am on Friday,
April 20.&lt;/p&gt;
&lt;p&gt;This of course means that you should totally &lt;a href="http://www.openstack.org/conference/san-francisco-2012/register/"&gt;register for the
conference&lt;/a&gt;
if you haven't already done so, and I'll be happy to chat with anyone
interested in OpenStack HA. See you in San Francisco!&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on my blog on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="blog"></category><category term="Conference"></category><category term="OpenStack"></category></entry><entry><title>Mandatory and advisory ordering in Pacemaker</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/mandatory-and-advisory-ordering-pacemaker/" rel="alternate"></link><published>2012-03-22T15:02:14+01:00</published><updated>2012-03-22T15:02:14+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-03-22:/resources/hints-and-kinks/mandatory-and-advisory-ordering-pacemaker/</id><summary type="html">&lt;p&gt;Ever wonder what's the difference between &lt;code&gt;order &amp;lt;name&amp;gt; inf:
&amp;lt;first-resource&amp;gt; &amp;lt;second-resource&amp;gt;&lt;/code&gt; and a score of something other
than &lt;code&gt;inf&lt;/code&gt;? We'll explain.&lt;/p&gt;
&lt;p&gt;If you specify an order constraint score of &lt;code&gt;INFINITY&lt;/code&gt; (&lt;code&gt;inf&lt;/code&gt; or the
keyword &lt;code&gt;mandatory&lt;/code&gt; in crm shell syntax), then the order constraint is
considered mandatory. If you specify &lt;code&gt;0 …&lt;/code&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Ever wonder what's the difference between &lt;code&gt;order &amp;lt;name&amp;gt; inf:
&amp;lt;first-resource&amp;gt; &amp;lt;second-resource&amp;gt;&lt;/code&gt; and a score of something other
than &lt;code&gt;inf&lt;/code&gt;? We'll explain.&lt;/p&gt;
&lt;p&gt;If you specify an order constraint score of &lt;code&gt;INFINITY&lt;/code&gt; (&lt;code&gt;inf&lt;/code&gt; or the
keyword &lt;code&gt;mandatory&lt;/code&gt; in crm shell syntax), then the order constraint is
considered mandatory. If you specify &lt;code&gt;0&lt;/code&gt;, or the keyword &lt;code&gt;advisory&lt;/code&gt;
then it's advisory. What does that mean?&lt;/p&gt;
&lt;p&gt;Firstly, anytime two resources are started in the same cluster
transition, order constraints do apply regardless of whether they're
mandatory or advisory. So for the two constraints shown here:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;order o_foo_before_bar inf: foo bar
order o_foo_before_bar 0: foo bar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;... if &lt;code&gt;foo&lt;/code&gt; and &lt;code&gt;bar&lt;/code&gt; are just starting, &lt;code&gt;foo&lt;/code&gt; starts first, and
&lt;code&gt;bar&lt;/code&gt; starts only when &lt;code&gt;foo&lt;/code&gt;'s start operation is completed. So what's
the difference, really?&lt;/p&gt;
&lt;h2&gt;Mandatory ordering&lt;/h2&gt;
&lt;p&gt;In a &lt;strong&gt;mandatory&lt;/strong&gt; order constraint, the order is enforced under all
circumstances. Consider the following example (primitive definitions
omitted to keep this short):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;order o_foo_before_bar inf: foo bar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Suppose &lt;code&gt;foo&lt;/code&gt; fails. Now &lt;code&gt;foo&lt;/code&gt; must be recovered, but before that,
&lt;code&gt;bar&lt;/code&gt; must also stop. So the sequence of events is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;foo&lt;/code&gt; fails&lt;/li&gt;
&lt;li&gt;Pacemaker attempts to stop &lt;code&gt;foo&lt;/code&gt; again (to make sure it's cleaned
   up).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bar&lt;/code&gt; stops.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;foo&lt;/code&gt; starts&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bar&lt;/code&gt; starts.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If &lt;code&gt;foo&lt;/code&gt; fails to start back up, then &lt;code&gt;bar&lt;/code&gt; will remain stopped. Based
on the start-failure-is-fatal and migration-threshold settings both
resources can now potentially migrate to other nodes, but if &lt;code&gt;foo&lt;/code&gt;
can't be started anywhere, &lt;code&gt;bar&lt;/code&gt; also remains stopped.&lt;/p&gt;
&lt;h2&gt;Advisory ordering&lt;/h2&gt;
&lt;p&gt;In an &lt;strong&gt;advisory&lt;/strong&gt; order constraint, the order is enforced only if
both resources start in the same transition. Otherwise, it's
ignored. Consider the following example (primitive definitions again
omitted):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;order o_foo_before_bar 0: foo bar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Again, suppose &lt;code&gt;foo&lt;/code&gt; fails. &lt;code&gt;foo&lt;/code&gt; must be recovered, but now &lt;code&gt;bar&lt;/code&gt; can
keep running as it's not being started in the same transition. Thus:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;foo&lt;/code&gt; fails&lt;/li&gt;
&lt;li&gt;Pacemaker attempts to stop &lt;code&gt;foo&lt;/code&gt; again (to make sure it's cleaned
   up).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;foo&lt;/code&gt; starts&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If &lt;code&gt;foo&lt;/code&gt; fails to start back up, then &lt;code&gt;bar&lt;/code&gt; can continue to
run. Still, based on the &lt;code&gt;start-failure-is-fatal&lt;/code&gt; and
&lt;code&gt;migration-threshold&lt;/code&gt; settings applying to &lt;code&gt;foo&lt;/code&gt;, either it or both
resources (depending on colocation constraints) can potentially
migrate to other nodes.&lt;/p&gt;
&lt;h2&gt;So when do I use which?&lt;/h2&gt;
&lt;p&gt;Advisory ordering is good for when your dependent resource can recover
from a brief interruption in the resource it depends on. For example,
you'll want to fire up your libvirt daemon before you start your
Pacemaker-managed virtual machines, but if libvirtd were ever to crash
you can restart it without needing to restart VMs.&lt;/p&gt;
&lt;p&gt;Mandatory ordering is for stricter dependencies. Filesystems mounted
from an iSCSI device will probably want to be remounted if the iSCSI
initator has reported an error. Likewise, you'll probably also want to
restart the applications working with that filesystem.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Pacemaker"></category></entry><entry><title>High Availability in OpenStack</title><link href="https://xahteiwi.eu/blog/2012/03/21/high-availability-in-openstack/" rel="alternate"></link><published>2012-03-21T13:08:00+00:00</published><updated>2012-03-21T13:08:00+00:00</updated><author><name>florian</name></author><id>tag:xahteiwi.eu,2012-03-21:/blog/2012/03/21/high-availability-in-openstack/</id><summary type="html">&lt;p&gt;A few thoughts on high availability features (or the current absence
thereof) in OpenStack.&lt;/p&gt;
&lt;p&gt;I've just proposed a session for the &lt;a href="http://wiki.openstack.org/Summit/Folsom"&gt;OpenStack Folsom design
summit&lt;/a&gt; which &lt;a href="http://www.joinfu.com/"&gt;Jay
Pipes&lt;/a&gt; was nice enough to invite me to
(thanks!), and I thought I'd write up a few thoughts of mine ahead of
time …&lt;/p&gt;</summary><content type="html">&lt;p&gt;A few thoughts on high availability features (or the current absence
thereof) in OpenStack.&lt;/p&gt;
&lt;p&gt;I've just proposed a session for the &lt;a href="http://wiki.openstack.org/Summit/Folsom"&gt;OpenStack Folsom design
summit&lt;/a&gt; which &lt;a href="http://www.joinfu.com/"&gt;Jay
Pipes&lt;/a&gt; was nice enough to invite me to
(thanks!), and I thought I'd write up a few thoughts of mine ahead of
time to get the discussion started.&lt;/p&gt;
&lt;p&gt;A little while back, Tristan van Bokkem &lt;a href="http://www.mail-archive.com/openstack@lists.launchpad.net/msg07495.html"&gt;started a discussion on high
availability for
Nova&lt;/a&gt;
on the OpenStack mailing list. So in Nova specifically, there are a few
components where high availability is readily available; you just have
to use it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MySQL. That's a no-brainer. &lt;a href="https://www.hastexo.com/resources/presentations/zen-pacemaker"&gt;MySQL HA with
    Pacemaker&lt;/a&gt;
    has been done so many times that I won't rehash it here. What's nice
    in this regard is that
    &lt;a href="http://galeracluster.com/products/mysql_galera"&gt;Galera&lt;/a&gt; (included
    in &lt;a href="http://www.percona.com/software/percona-xtradb-cluster"&gt;Percona XtraDB
    Cluster&lt;/a&gt;)
    now promises to do away with the limitations of both
    &lt;a href="https://www.hastexo.com/drbd"&gt;DRBD&lt;/a&gt; and traditional &lt;a href="http://dev.mysql.com/doc/refman/5.6/en/replication.html"&gt;MySQL
    replication&lt;/a&gt;,
    and provide multiple-node, multiple-master &lt;em&gt;synchronous&lt;/em&gt; replication
    for MySQL. As I'm sure you're aware, classic MySQL replication isn't
    synchronous, and DRBD can't do multi-node master-master, but the
    Galera based solution looks promising, &lt;a href="http://www.percona.com/blog/2012/01/09/announcement-of-percona-xtradb-cluster-alpha-release/"&gt;if not as mature as the
    other
    two&lt;/a&gt;.
    Of course, I don't understand why the Galera folks had to reinvent
    not only replication (which makes sense) but also cluster membership
    and management (which doesn't), but that's a different discussion to
    be had altogether.&lt;/li&gt;
&lt;li&gt;RabbitMQ. Has somewhat similar HA considerations as MySQL. A
    Pacemaker/DRBD-based solution &lt;a href="http://www.rabbitmq.com/pacemaker.html"&gt;exists, but is considered deprecated
    by the RabbitMQ
    maintainers&lt;/a&gt;. Enter
    &lt;a href="http://www.rabbitmq.com/ha.html"&gt;mirrored queues,&lt;/a&gt; where again the
    developers seemingly threw out the baby with the bath water and
    rather than just reimplementing replication (sensible), they came up
    with their own cluster manager (questionable). Their mirrored queues
    would probably have played very nicely with master/slave sets in
    Pacemaker.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As Tom Ellis &lt;a href="http://www.mail-archive.com/openstack@lists.launchpad.net/msg07595.html"&gt;pointed out in another
email&lt;/a&gt;
the previously mentioned thread, there are more HA considerations for
services in Nova proper.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;nova-volume still has a lot of work to do. It has an iSCSI
    &lt;a href="http://nova.openstack.org/api/nova.volume.driver.html"&gt;driver&lt;/a&gt;
    which can of course be used as an iSCSI proxy pointed at a highly
    available, potentially DRBD-backed, software iSCSI target. Or at an
    iSCSI based hardware solution that has HA built-in, such as HP
    LeftHand. Alternatively, we could just operate on RBD volumes (part
    of
    &lt;a href="https://www.hastexo.com/blogs/florian/2012/03/08/ceph-tickling-my-geek-genes"&gt;Ceph&lt;/a&gt;)
    which will also take care of redundancy for us, and add seamless
    scaleout and remirroring. That being said, there is currently no
    real HA provision for the nova-volume service itself, and that's
    something that will be required.&lt;/li&gt;
&lt;li&gt;Compute nodes can all run their own instance of nova-api.&lt;/li&gt;
&lt;li&gt;Front-end API servers can all run nova-scheduler, with a load
    balancer in front of them.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The
&lt;a href="https://www.hastexo.com/knowledge/high-availability/pacemaker"&gt;Pacemaker&lt;/a&gt;
stack has the potential of being a nice fit for most of the above. It
comes with &lt;a href="http://linux-ha.org/doc/man-pages/re-ra-iSCSITarget.html"&gt;iSCSI target
support&lt;/a&gt; (RBD
doesn't need Pacemaker on the server end, as Ceph takes care of its own
HA). Pacemaker also ties in directly with upstart, so any upstart job
can be monitored as a Pacemaker service. And Pacemaker's &lt;a href="http://clusterlabs.org/doc/en-US/Pacemaker/1.1/html/Pacemaker_Explained/s-resource-clone.html" title="Don't balk at the XML! That's Pacemaker's reference documentation; any sane person would use the crm shell to manage Pacemaker resources in real life."&gt;clone
facility&lt;/a&gt;
makes it easy to run multiple instances of inherently stateless services
with minimal configuration. What's more, Pacemaker comes with full
integration for the &lt;a href="http://horms.net/projects/ldirectord/"&gt;ldirectord&lt;/a&gt;
load-balancing service. Of course, Pacemaker adds a reliable
communications layer
(&lt;a href="https://www.hastexo.com/knowledge/high-availability/corosync"&gt;Corosync&lt;/a&gt;)
and a multi-master, self-replicating configuration facility.&lt;/p&gt;
&lt;p&gt;As for non-Nova Openstack services, Glance could use some Pacemaker
integration (not hard to do; it's just that someone has to do it).&lt;/p&gt;
&lt;p&gt;Ceph, in my opinion, has the very interesting potential of being a
redundant, scalable storage one-stop shop for OpenStack. It serves the
purposes of both volume/block storage (with RBD) and object storage
(with RADOS/radosgw). And, as already pointed out, it comes with HA,
replication, and scalability built-in.&lt;/p&gt;
&lt;p&gt;Comments and feedback on the above are much appreciated. For OpenStack
developers who visit this blog for the first time: you need to login to
post comments in our effort to combat comment spam – but you can simply
use your Launchpad OpenID to do so.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on my blog on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="blog"></category></entry><entry><title>On my (ex-)maintainership of the DRBD User's Guide</title><link href="https://xahteiwi.eu/blog/2012/03/20/on-my-ex-maintainership-of-the-drbd-users-guide/" rel="alternate"></link><published>2012-03-20T11:01:00+00:00</published><updated>2012-03-20T11:01:00+00:00</updated><author><name>florian</name></author><id>tag:xahteiwi.eu,2012-03-20:/blog/2012/03/20/on-my-ex-maintainership-of-the-drbd-users-guide/</id><summary type="html">&lt;p&gt;Here's a quick summary of my past and current relationship with the DRBD
User's Guide.&lt;/p&gt;
&lt;p&gt;As you probably know, I created the original &lt;a href="http://drbd.linbit.com/users-guide/"&gt;DRBD User's
Guide&lt;/a&gt; several years back, and I
maintained it throughout my time at Linbit. &lt;a href="https://fghaas.wordpress.com/2011/09/05/on-to-new-endeavors/"&gt;When I left last
year&lt;/a&gt;, it
was originally mutually understood (or so …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Here's a quick summary of my past and current relationship with the DRBD
User's Guide.&lt;/p&gt;
&lt;p&gt;As you probably know, I created the original &lt;a href="http://drbd.linbit.com/users-guide/"&gt;DRBD User's
Guide&lt;/a&gt; several years back, and I
maintained it throughout my time at Linbit. &lt;a href="https://fghaas.wordpress.com/2011/09/05/on-to-new-endeavors/"&gt;When I left last
year&lt;/a&gt;, it
was originally mutually understood (or so I thought) that I could
continue to maintain it – as a non-employee, in a community capacity,
without compensation, just as it's common in many other open source
projects. I tend to enjoy technical writing, and it was something I
certainly was looking forward to. And things got off to a promising
start, the first (trivial) patch to the documentation which I
&lt;a href="http://lists.linbit.com/pipermail/drbd-dev/2011-September/001684.html"&gt;submitted&lt;/a&gt;
in my new life &lt;a href="http://git.drbd.org/gitweb.cgi?p=drbd-documentation.git;a=commit;h=35d41237aea064686ee21621b9fb1b9111a4424c"&gt;was quickly merged without
issue&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;When I made my
&lt;a href="http://lists.linbit.com/pipermail/drbd-dev/2011-November/001987.html"&gt;second&lt;/a&gt;
and
&lt;a href="http://lists.linbit.com/pipermail/drbd-dev/2011-November/001999.html"&gt;third&lt;/a&gt;
submission to the documentation, the latter of which was a a bit more
elaborate, things got a bit strange. This was after hastexo went
operational, although whether that is at all related to the sequence of
events I don't know. At any rate, I was being served with a
"Documentation Contributor License Agreement". Which wasn't considered
necessary in my earlier patch. Which involved copyright assignment.
Which I balked at. I don't necessarily object to copyright assignment if
I write on a contract, as I occasionally do for technical magazines --
but what I wrote definitely hadn't been contracted out to me. I had
simply submitted it unsolicited in the mere hope it was going to be
useful, and I wasn't interested in contract work, either. In addition,
the documentation was (and is) under a &lt;a href="http://creativecommons.org/licenses/by-sa/3.0/"&gt;liberal CC-BY-SA
license&lt;/a&gt; which made any
copyright assignment unnecessary for a simple contribution. In my humble
opinion, that is.&lt;/p&gt;
&lt;p&gt;So I raised these points, and my concerns were rejected, and my patches
didn't make it in. Note, I have no quarrel with this at all – it may
well be a perfectly sane business decision. But that's none of my
business anymore, and I respect their decision just fine. They have
stuck to their decision, and that is just fine too.&lt;/p&gt;
&lt;p&gt;It only means that I don't maintain the User's Guide anymore, and I'm
evidently also unable to contribute patches, corrections or improvements
unless I consent to copyright assignment, which I disagree with in this
instance. So unless the policy changes at some point in the future, I
won't be contributing to the User's Guide any longer.&lt;/p&gt;
&lt;p&gt;My name will remain in the authors list pretty much indefinitely (unless
someone publishes a complete rewrite) as that is required by law, but
you should interpret that as my being the original author – technically
a co-author, as I always made a point of crediting Lars' and Phil's
earlier work that the User's Guide was based on. My co-authorship
doesn't imply, however, that I'm a currently active author or
maintainer.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on my blog on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="blog"></category><category term="DRBD"></category></entry><entry><title>Managing cron jobs with Pacemaker</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/managing-cron-jobs-pacemaker/" rel="alternate"></link><published>2012-03-19T16:42:40+01:00</published><updated>2012-03-19T16:42:40+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-03-19:/resources/hints-and-kinks/managing-cron-jobs-pacemaker/</id><summary type="html">&lt;p&gt;It's not uncommon in Pacemaker clusters to run specific cron jobs only
on a node that currently runs a particular resource. The
&lt;code&gt;ocf:heartbeat:symlink&lt;/code&gt; resource agent can be exceptionally helpful in
this situation. Here's how to use it.&lt;/p&gt;
&lt;p&gt;Suppose you've got a cron job for Postfix whose definition normally …&lt;/p&gt;</summary><content type="html">&lt;p&gt;It's not uncommon in Pacemaker clusters to run specific cron jobs only
on a node that currently runs a particular resource. The
&lt;code&gt;ocf:heartbeat:symlink&lt;/code&gt; resource agent can be exceptionally helpful in
this situation. Here's how to use it.&lt;/p&gt;
&lt;p&gt;Suppose you've got a cron job for Postfix whose definition normally
lives in &lt;code&gt;/etc/cron.d/postfix&lt;/code&gt;. All your Postfix related data is in a
mountpoint &lt;code&gt;/srv/postfix&lt;/code&gt; (that filesystem could live on iSCSI, or DRBD,
or it could be a GlusterFS mount – that's irrelevant for the purposes
of this discussion). And as such, you've moved your cron definition to
&lt;code&gt;/srv/postfix/cron&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now you want that cron job to execute only on the node that also is
currently the active Postfix host. That's not hard at all:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;primitive p_postfix ocf:heartbeat:postfix \
  params config_dir="/etc/postfix" \
  op monitor interval="10"
primitive p_symlink ocf:heartbeat:symlink \
  params target="/srv/postfix/cron" \
    link="/etc/cron.d/postfix" \
    backup_suffix=".disabled" \
  op monitor interval="10"
primitive p_cron lsb:cron \
  op monitor interval=10
order o_symlink_before_cron inf: p_symlink p_cron
colocation c_cron_on_symlink inf: p_cron p_symlink
colocation c_symlink_on_postfix inf: p_symlink p_postfix
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;What this will do for you is this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Check whether a file named &lt;code&gt;postfix&lt;/code&gt; already exists in &lt;code&gt;/etc/cron.d&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If it does, rename it to &lt;code&gt;postfix.disabled&lt;/code&gt; (remember, cron ignores
  job definitions with dots in the filename)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(Re-)Create the postfix job definition as a symlink to
  &lt;code&gt;/srv/postfix/cron&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Restart &lt;code&gt;cron&lt;/code&gt; when it's done.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;code&gt;c_symlink_on_postfix&lt;/code&gt; colocation ensures that all of this happens
on the node where the &lt;code&gt;p_postfix&lt;/code&gt; resource is also active.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Pacemaker"></category></entry><entry><title>Storage Replication in High-Performance High-Availability Environments</title><link href="https://xahteiwi.eu/resources/presentations/storage-replication-high-performance-high-availability-environments/" rel="alternate"></link><published>2012-03-19T10:54:00+00:00</published><updated>2012-03-19T10:54:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-03-19:/resources/presentations/storage-replication-high-performance-high-availability-environments/</id><summary type="html">&lt;p&gt;At linux.conf.au 2012, Florian I this presentation on the integration
of &lt;a href="https://www.hastexo.com/drbd"&gt;DRBD&lt;/a&gt;, Flashcache and
&lt;a href="https://www.hastexo.com/knowledge/high-availability/pacemaker"&gt;Pacemaker&lt;/a&gt;
in the High Availability and Distributed Storage miniconf.&lt;/p&gt;
&lt;p&gt;In this 30-minute presentation, I explore the benefits of
&lt;a href="https://github.com/facebook/flashcache"&gt;Flashcache&lt;/a&gt; for replicated
storage. Flashcache, &lt;a href="https://www.facebook.com/note.php?note_id=388112370932"&gt;originally developed at
Facebook,&lt;/a&gt; is a
general purpose, &lt;a href="https://github.com/facebook/flashcache/blob/master/doc/flashcache-doc.txt"&gt;block level cache …&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;At linux.conf.au 2012, Florian I this presentation on the integration
of &lt;a href="https://www.hastexo.com/drbd"&gt;DRBD&lt;/a&gt;, Flashcache and
&lt;a href="https://www.hastexo.com/knowledge/high-availability/pacemaker"&gt;Pacemaker&lt;/a&gt;
in the High Availability and Distributed Storage miniconf.&lt;/p&gt;
&lt;p&gt;In this 30-minute presentation, I explore the benefits of
&lt;a href="https://github.com/facebook/flashcache"&gt;Flashcache&lt;/a&gt; for replicated
storage. Flashcache, &lt;a href="https://www.facebook.com/note.php?note_id=388112370932"&gt;originally developed at
Facebook,&lt;/a&gt; is a
general purpose, &lt;a href="https://github.com/facebook/flashcache/blob/master/doc/flashcache-doc.txt"&gt;block level cache device implemented in the Linux
device-mapper
framework.&lt;/a&gt;
You can use flashcache in two distinct ways in Pacemaker
high-availability clusters, which I both explain in his talk.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Video: &lt;a href="https://youtu.be/l910kiEuHOM"&gt;YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="DRBD"></category><category term="Flashcache"></category><category term="Pacemaker"></category><category term="Performance"></category></entry><entry><title>Roll Your Own Cloud</title><link href="https://xahteiwi.eu/resources/presentations/roll-your-own-cloud/" rel="alternate"></link><published>2012-03-19T08:27:00+00:00</published><updated>2012-03-19T08:27:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-03-19:/resources/presentations/roll-your-own-cloud/</id><summary type="html">&lt;p&gt;Tim Serong and I explore the capabilities of KVM, iSCSI, DRBD and Pacemaker to
create a fully open-source enterprise cloud.&lt;/p&gt;
&lt;p&gt;Shot at linux.conf.au 2011 in Brisbane, this is me babbling, and Tim
live-cartooning to the delight of the audience.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Video: &lt;a href="https://youtu.be/NyHJ8Uf03qg"&gt;YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo …&lt;/code&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Tim Serong and I explore the capabilities of KVM, iSCSI, DRBD and Pacemaker to
create a fully open-source enterprise cloud.&lt;/p&gt;
&lt;p&gt;Shot at linux.conf.au 2011 in Brisbane, this is me babbling, and Tim
live-cartooning to the delight of the audience.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Video: &lt;a href="https://youtu.be/NyHJ8Uf03qg"&gt;YouTube&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="DRBD"></category><category term="KVM"></category><category term="libvirt"></category><category term="Pacemaker"></category></entry><entry><title>What's a Totem "Retransmit List" all about in Corosync?</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/whats-totem-retransmit-list-all-about-corosync/" rel="alternate"></link><published>2012-03-15T09:11:34+01:00</published><updated>2012-03-15T09:11:34+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-03-15:/resources/hints-and-kinks/whats-totem-retransmit-list-all-about-corosync/</id><summary type="html">&lt;p&gt;Occasionally, you may see errors similar to this in your system logs:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;corosync [TOTEM ] Retransmit List: e4 e5 e7 e8 ea eb ed ee
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here's what causes them, and what you can do to fix the issue.&lt;/p&gt;
&lt;p&gt;Corosync, more specifically its Totem protocol implementation, defines
a maximum number of cluster …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Occasionally, you may see errors similar to this in your system logs:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;corosync [TOTEM ] Retransmit List: e4 e5 e7 e8 ea eb ed ee
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here's what causes them, and what you can do to fix the issue.&lt;/p&gt;
&lt;p&gt;Corosync, more specifically its Totem protocol implementation, defines
a maximum number of cluster messages that can be sent during one token
rotation. By default, that number is 50, but you may modify this value
by setting the &lt;code&gt;window_size&lt;/code&gt; parameter in your &lt;code&gt;corosync.conf&lt;/code&gt;
configuration file.&lt;/p&gt;
&lt;p&gt;When among several fast cluster nodes ("processors" in Totem speak)
there are one or few slow ones, the kernel receive buffers can't cope,
messages get lost, and they then need to be retransmitted. This is
what causes the Retransmit List notifications in the syslogs. This
doesn't mean you're losing any messages or data. But it does mean that
your cluster performance degrades when this happens, and thus you
should really fix that problem.&lt;/p&gt;
&lt;p&gt;There are a few considerations that apply to tuning Corosync's
&lt;code&gt;window_size&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If you have a small cluster (say, 8 nodes or less), and they all can
  be expected to perform equally well because they have identical or
  nearly-identical hardware, then setting a large &lt;code&gt;window_size&lt;/code&gt; of up
  to 300 should be fine.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If your cluster is rather heterogeneous, then you should probably
  stick with the default of 50. Definitely don't go higher than
  256000/MTU, where MTU is that of the network interface(s) Corosync
  communicates over. For a standard Ethernet interface the default MTU
  is 1500, which would make for a maximum &lt;code&gt;window_size&lt;/code&gt; of 170.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you're running on the generally safe default of 50, and you're
  still getting Retransmit List notifications, then one of your nodes
  is most likely significantly slower than the others, and you had
  better find the cause of that and fix it. The node could be under
  constant excessive load, or have a problem with its network driver,
  or may be plugged into an incorrectly-configured switch port.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Corosync"></category></entry><entry><title>The Zen of Pacemaker</title><link href="https://xahteiwi.eu/resources/presentations/zen-pacemaker/" rel="alternate"></link><published>2012-03-13T13:37:00+00:00</published><updated>2012-03-13T13:37:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-03-13:/resources/presentations/zen-pacemaker/</id><summary type="html">&lt;p&gt;I team up with Tim Serong and Andrew Beekhof for a tutorial at
linux.conf.au 2012.&lt;/p&gt;
&lt;!--break--&gt;
&lt;p&gt;Pacemaker author Andrew Beekhof dropped in as well, to field questions
and provide additional insight into Pacemaker development.&lt;/p&gt;
&lt;p&gt;The tutorial covers the configuration of a MySQL 2-node high
availability cluster front to back …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I team up with Tim Serong and Andrew Beekhof for a tutorial at
linux.conf.au 2012.&lt;/p&gt;
&lt;!--break--&gt;
&lt;p&gt;Pacemaker author Andrew Beekhof dropped in as well, to field questions
and provide additional insight into Pacemaker development.&lt;/p&gt;
&lt;p&gt;The tutorial covers the configuration of a MySQL 2-node high
availability cluster front to back, diving into the configuration of
replicated storage, the cluster communications infrastructure, cluster
resource management, and of course the MySQL database itself.&lt;/p&gt;
&lt;p&gt;Reviews for this tutorial were rather enthusiastic, with bloggers
comparing the experience to &lt;a href="http://www.anchor.com.au/blog/2012/01/lca-day-3-high-availability/"&gt;an enlightenment session from the Jedi
grand
masters&lt;/a&gt;
of high availability.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Video: &lt;a href="https://youtu.be/3GoT36cK6os"&gt;YouTube&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Slides: &lt;a href="https://www.slideshare.net/slideshow/embed_code/key/jIo0ZxOl7znyYd"&gt;SlideShare&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="Conference"></category><category term="Pacemaker"></category></entry><entry><title>Finding out which OSDs currently store a specific RADOS object</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/which-osd-stores-specific-rados-object/" rel="alternate"></link><published>2012-03-09T22:55:06+01:00</published><updated>2012-03-09T22:55:06+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-03-09:/resources/hints-and-kinks/which-osd-stores-specific-rados-object/</id><summary type="html">&lt;p&gt;Ever wanted to know just which of your OSDs a RADOS object is
currently stored in? Here's how.&lt;/p&gt;
&lt;p&gt;Suppose you've got an RBD device, named &lt;code&gt;test&lt;/code&gt;. Then you can use the
&lt;code&gt;rbd info&lt;/code&gt; command to display which name prefix is used by the RADOS
objects that make up the RBD …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Ever wanted to know just which of your OSDs a RADOS object is
currently stored in? Here's how.&lt;/p&gt;
&lt;p&gt;Suppose you've got an RBD device, named &lt;code&gt;test&lt;/code&gt;. Then you can use the
&lt;code&gt;rbd info&lt;/code&gt; command to display which name prefix is used by the RADOS
objects that make up the RBD:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ceph04:~ # rbd info test
rbd image 'test':
    size 1024 MB in 256 objects
    order 22 (4096 KB objects)
    block_name_prefix: rb.0.0
    parent:  (pool -1)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this example, the prefix we're looking for is &lt;code&gt;rb.0.0&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;What's the RBD currently made of?&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ceph04:~ # rados -p rbd ls | grep "^rb.0.0."
rb.0.0.000000000000
rb.0.0.000000000020
rb.0.0.000000000021
rb.0.0.000000000040
rb.0.0.000000000042
rb.0.0.000000000060
rb.0.0.000000000063
rb.0.0.000000000080
rb.0.0.000000000081
rb.0.0.000000000082
rb.0.0.000000000083
rb.0.0.000000000084
rb.0.0.000000000085
rb.0.0.000000000086
rb.0.0.000000000087
rb.0.0.000000000088
rb.0.0.0000000000a0
rb.0.0.0000000000a5
rb.0.0.0000000000c0
rb.0.0.0000000000c6
rb.0.0.0000000000e0
rb.0.0.0000000000e7
rb.0.0.0000000000ff
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now suppose you're interested in where &lt;code&gt;rb.0.0.0000000000a5&lt;/code&gt; is.&lt;/p&gt;
&lt;p&gt;You first grab an OSD map:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;ceph04&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;# ceph osd getmap -o /tmp/osdmap&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;2012&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;03&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;31&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;47.055376&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mon&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;osd&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;getmap&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="mi"&gt;2012&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;03&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;09&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;21&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;31&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;47.056624&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;mon&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;'got osdmap epoch 187'&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;wrote&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2273&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;byte&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;payload&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;tmp&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;osdmap&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And now you can use &lt;code&gt;osdmaptool&lt;/code&gt; to test an object name against the
mapfile:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;ceph04&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;~&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="c1"&gt;# osdmaptool --test-map-object rb.0.0.0000000000a5 /tmp/osdmap &lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;osdmaptool&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;osdmap&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;'/tmp/osdmap'&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;object&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;'rb.0.0.0000000000a5'&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.7&lt;/span&gt;&lt;span class="n"&gt;ea1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;... meaning the object lives in Placement Group &lt;code&gt;0.7ea1&lt;/code&gt;, of which
replicas currently exist in OSDs 2 and 0.&lt;/p&gt;
&lt;p&gt;Why do you want to know this? Normally, really, you don't. All the
replication and distribution happens under the covers without your
intervention. But you can use this rather neatly if you want to watch
your data being redistributed as you take out OSDs temporarily, and
put them back in.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Ceph"></category></entry><entry><title>Ceph: tickling my geek genes</title><link href="https://xahteiwi.eu/blog/2012/03/08/ceph-tickling-my-geek-genes/" rel="alternate"></link><published>2012-03-08T20:12:00+00:00</published><updated>2012-03-08T20:12:00+00:00</updated><author><name>florian</name></author><id>tag:xahteiwi.eu,2012-03-08:/blog/2012/03/08/ceph-tickling-my-geek-genes/</id><summary type="html">&lt;p&gt;Haven't heard of &lt;a href="http://ceph.com/"&gt;Ceph&lt;/a&gt;, the open-source distributed
petascale storage stack? Well, you've really been missing out. It's not
just a filesystem. It's a filesystem, and a striped/replicated block
device provider, and a virtualization storage backend, and a cloud
object store, and then some.&lt;/p&gt;
&lt;p&gt;Most of you will, by now …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Haven't heard of &lt;a href="http://ceph.com/"&gt;Ceph&lt;/a&gt;, the open-source distributed
petascale storage stack? Well, you've really been missing out. It's not
just a filesystem. It's a filesystem, and a striped/replicated block
device provider, and a virtualization storage backend, and a cloud
object store, and then some.&lt;/p&gt;
&lt;p&gt;Most of you will, by now, probably have heard of the Ceph filesystem, a
distributed, replicated, extremely scaleable filesystem that &lt;a href="http://kernelnewbies.org/Linux_2_6_34#head-87b23f85b5bdd35c0ab58c1ebfdcbd48d1658eef"&gt;went
upstream with the 2.6.34 kernel
release.&lt;/a&gt; But
that filesystem is really just a client to something that happens server
side, which is much more than just file storage.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://ceph.com/category/rados/"&gt;RADOS&lt;/a&gt;, the reliable autonomic
distributed object store is a massively distributed, replicating,
rack-aware object store. It organizes storage in objects, where each
object has an identifier, a payload, and a number of attributes.&lt;/p&gt;
&lt;p&gt;Objects are allocated to a Placement Group (PG), and each PG maps to one
or several Object Storage Devices or OSDs. OSDs are managed by a
userspace daemon – everything server-side in Ceph is in userspace,
really – and locally map to a simple directory. For local storage,
objects simply map to flat files, so OSDs don't need to muck around with
local block storage. And they can take advantage of lots of useful
features built into advanced filesystems, like extended attributes,
clones/reflinks, copy-on-write (with btrfs). Extra points for the effort
to &lt;em&gt;not&lt;/em&gt; reinvent wheels.&lt;/p&gt;
&lt;p&gt;The entire object store uses a deterministic placement algorithm, CRUSH
(Controlled Replication Under Scaleable Hashing). There's never a
central instance to ask on every access, instead, everything can work
out where objects are. That means the store scales out seamlessly, and
can expand and contract on the admin's whim.&lt;/p&gt;
&lt;p&gt;And based on that basic architecture, there's a number of entry points
and deployment scenarios for the stack:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;radosgw&lt;/strong&gt; provides a RESTful API for dynamic cloud storage. And it
    includes an S3 and Swift frontend to act as object storage for
    AWS/Eucalyptus and OpenStack clouds, respectively.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Qemu-RBD&lt;/strong&gt; is a storage driver for the Qemu/KVM hypervisor (fully
    integrated with libvirt) that allows the hypervisor to access
    replicated block devices that are also striped across the object
    store – with a configurable number of replicas, of course.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;RBD&lt;/strong&gt; is a Linux block device that, again, is striped and
    replicated over the object store.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;librados&lt;/strong&gt; (C) and &lt;strong&gt;libradospp&lt;/strong&gt; (C++) are APIs to access the
    object store programmatically, and come with a number of scripting
    language bindings. As you've probably guessed, Qemu-RBD builds on
    librados.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ceph&lt;/strong&gt; (the filesystem) exposes POSIX filesystem semantics built
    on top of RADOS, where all POSIX-related metadata is again stored in
    the object store. This is a remarkably thin client layer at just
    17,000 LOC (compare to GFS2 at 26,000 and OCFS2 at 68,000).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In short: it's cool stuff. And it's 100% open source, it's all under the
LGPL 2.1, and the developers have made a point of not creating any
closed-source "enterprise" features – in short, they're not shipping
"open core".&lt;sup id="fnref:crippleware"&gt;&lt;a class="footnote-ref" href="#fn:crippleware"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;We've recently started contributing to the Ceph project to improve its
high-availability cluster integration: we've submitted Pacemaker
agents &lt;a href="https://github.com/ceph/ceph/commit/92cfad42030889d52911814faa717bebbd4dd22f"&gt;to monitor the Ceph daemons
proper&lt;/a&gt;
(a pretty trivial wrapper for a script that ships with Ceph, for now).
And we've also contributed &lt;a href="https://github.com/ceph/ceph/commit/c31b86963ab3c51b5c6d17f6e3222fe164ef3ee9"&gt;a resource agent to manage an RBD device
as a Pacemaker
resource&lt;/a&gt;.
The latter gives Pacemaker users the ability to use RBD devices as a
drop-in replacement for iSCSI devices, MD devices under Pacemaker
control, or DRBD. The Ceph community
has been exceptionally welcoming and has made contributing a
pleasure – there's no copyright assignment nonsense, no CLAs, just a
very positive attitude toward outside contributions.&lt;/p&gt;
&lt;p&gt;And in case you want to use a Ceph filesystem as a generally available
file system in your Pacemaker cluster (as you would with NFS, GlusterFS,
GFS2, or OCFS2), you can &lt;a href="https://github.com/ClusterLabs/resource-agents/commit/f93668b4b60682363a686a293810e34ad4088a47"&gt;do that now,
too&lt;/a&gt;.
However, please be cautioned that that should be considered an
experimental feature: the Ceph devs have made it very clear on numerous
occasions that they're currently focusing on making RADOS and RBD rock
solid, and then they'll tackle the POSIX filesystem layer to get it out
of experimental mode.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on my blog on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:crippleware"&gt;
&lt;p&gt;The original version used the term &lt;em&gt;crippleware&lt;/em&gt; here,
  which I now consider highly inappropriate. (The term &lt;em&gt;open core&lt;/em&gt;, to
  the best of my recollection, wasn't particularly current in 2012.) I
  would like to apologize for my use of the previous term. The article
  contains no other edits in comparison to the 2012 original. &lt;a class="footnote-backref" href="#fnref:crippleware" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="blog"></category><category term="Ceph"></category></entry><entry><title>Solve a DRBD split-brain in 4 steps</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/solve-drbd-split-brain-4-steps/" rel="alternate"></link><published>2012-03-06T01:29:24+01:00</published><updated>2012-03-06T01:29:24+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-03-06:/resources/hints-and-kinks/solve-drbd-split-brain-4-steps/</id><summary type="html">&lt;p&gt;Whenever a DRBD setup runs into a situation where the replication
network is disconnected and fencing policy is set to &lt;code&gt;dont-care&lt;/code&gt;
(default), there is the potential risk of a split-brain. Even with
resource level fencing or STONITH setup, there are corner cases that
will end up in a split-brain.&lt;/p&gt;
&lt;p&gt;When …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Whenever a DRBD setup runs into a situation where the replication
network is disconnected and fencing policy is set to &lt;code&gt;dont-care&lt;/code&gt;
(default), there is the potential risk of a split-brain. Even with
resource level fencing or STONITH setup, there are corner cases that
will end up in a split-brain.&lt;/p&gt;
&lt;p&gt;When your DRBD resource is in a split-brain situation, don't panic!
Split-brain means that the contents of the backing devices of your
DRBD resource on both sides of your cluster started to diverge. At
some point in time, the DRBD resource on both nodes went into the
Primary role while the cluster nodes themselves were disconnected from
each other.&lt;/p&gt;
&lt;p&gt;Different writes happened to both sides of your cluster
afterwards. After reconnecting, DRBD doesn't know which set of data is
"right" and which is "wrong".&lt;/p&gt;
&lt;h2&gt;Indications of a Split-Brain&lt;/h2&gt;
&lt;p&gt;The symptoms of a split-brain are that the peers will not reconnect on
DRBD startup but stay in connection state StandAlone or
WFConnection. The latter will be shown if the remote peer detected the
split-brain earlier and was faster at shutdown its connection. In your
kernel logs you will see messages like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="n"&gt;kernel&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;block&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;drbd0&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Split&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Brain&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;detected&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dropping&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;connection&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;4 Steps to solve the Split-Brain&lt;/h2&gt;
&lt;h3&gt;Step 1&lt;/h3&gt;
&lt;p&gt;Manually choose a node which data modifications will be discarded.&lt;/p&gt;
&lt;p&gt;We call it the split brain victim. Choose wisely, all modifications
will be lost! When in doubt run a backup of the victim's data before
you continue.&lt;/p&gt;
&lt;p&gt;When running a Pacemaker cluster, you can enable maintenance mode. If
the split brain victim is in Primary role, bring down all applications
using this resource. Now switch the victim to Secondary role:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;victim# drbdadm secondary resource
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;Step 2&lt;/h3&gt;
&lt;p&gt;Disconnect the resource if it's in connection state &lt;code&gt;WFConnection&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;victim&lt;/span&gt;# &lt;span class="nv"&gt;drbdadm&lt;/span&gt; &lt;span class="k"&gt;disconnect&lt;/span&gt; &lt;span class="nv"&gt;resource&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;Step 3&lt;/h3&gt;
&lt;p&gt;Force discard of all modifications on the split brain victim:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;victim&lt;/span&gt;# &lt;span class="nv"&gt;drbdadm&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="nv"&gt;discard&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;my&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;data&lt;/span&gt; &lt;span class="k"&gt;connect&lt;/span&gt; &lt;span class="nv"&gt;resource&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;for DRBD 8.4.x:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;victim&lt;/span&gt;# &lt;span class="nv"&gt;drbdadm&lt;/span&gt; &lt;span class="k"&gt;connect&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="nv"&gt;discard&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;my&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;data&lt;/span&gt; &lt;span class="nv"&gt;resource&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;Step 4&lt;/h3&gt;
&lt;p&gt;Resync will start automatically if the survivor was in
&lt;code&gt;WFConnection&lt;/code&gt; network state. If the split brain survivor is still in
&lt;code&gt;Standalone&lt;/code&gt; connection state, reconnect it:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;survivor&lt;/span&gt;# &lt;span class="nv"&gt;drbdadm&lt;/span&gt; &lt;span class="k"&gt;connect&lt;/span&gt; &lt;span class="nv"&gt;resource&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;At the latest now the resynchronization from the survivor
(&lt;code&gt;SyncSource&lt;/code&gt;) to the victim (&lt;code&gt;SyncTarget&lt;/code&gt;) starts immediately. There
is no full sync initiated but all modifications on the victim will be
overwritten by the survivor's data and modifications on the survivor
will be applied to the victim.&lt;/p&gt;
&lt;h2&gt;Background: What happens?&lt;/h2&gt;
&lt;p&gt;With the default after-split-brain policies of disconnect this will
happen always in dual primary setups. It can happen in single primary
setups if one peer changes at least once its role from Secondary to
Primary while disconnected from the previous (before network
interruption) Primary.&lt;/p&gt;
&lt;p&gt;There are a variety of automatic policies to solve a split brain but
some of them will overwrite (potentially valid) data without further
inquiry. Even with theses policies in place a unresolvable split-brain
can occur.&lt;/p&gt;
&lt;p&gt;The split-brain is detected once the peers reconnect and do their DRBD
protocol handshake which also includes exchanging of the Generation
Identifiers (GIs).&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="DRBD"></category></entry><entry><title>Checking Corosync cluster membership</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/checking-corosync-cluster-membership/" rel="alternate"></link><published>2012-03-04T23:42:35+01:00</published><updated>2012-03-04T23:42:35+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-03-04:/resources/hints-and-kinks/checking-corosync-cluster-membership/</id><summary type="html">&lt;p&gt;It's simple and easy to get Pacemaker's view of the status of members
in a cluster – just invoke &lt;code&gt;crm_mon&lt;/code&gt;. But what if you want to check on
the cluster membership when Pacemaker is not running, or you want to
make sure whether Corosync's view of the cluster is identical to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;It's simple and easy to get Pacemaker's view of the status of members
in a cluster – just invoke &lt;code&gt;crm_mon&lt;/code&gt;. But what if you want to check on
the cluster membership when Pacemaker is not running, or you want to
make sure whether Corosync's view of the cluster is identical to
Pacemaker's? Here's how.&lt;/p&gt;
&lt;h2&gt;Checking ring status with &lt;code&gt;corosync-cfgtool&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;corosync-cfgtool&lt;/code&gt; utility displays the cluster connectivity status
when invoked with the &lt;code&gt;-s&lt;/code&gt; flag:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# corosync-cfgtool -s&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;Printing&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ring&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;Local&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;node&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ID&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;303938909&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;RING&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ID&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;10.0&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ring&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;active&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;with&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;no&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;faults&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="n"&gt;RING&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ID&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;192.168&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mf"&gt;42.1&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ring&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;active&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;with&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;no&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;faults&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The above is the status of two healthy rings; a failed ring (one
affected by a network interruption, for example) would show a &lt;code&gt;FAULTY&lt;/code&gt;
status.&lt;/p&gt;
&lt;p&gt;There's a catch. In a two-node cluster, if both nodes were to start
while all cluster communication links are down, then Corosync would
form &lt;em&gt;two&lt;/em&gt; memberships with healthy, one-member rings. Both of the
nodes would show a ring status similar to the above, but your cluster
still wouldn't be communicating. So, you can't rely on
&lt;code&gt;corosync-cfgtool -s&lt;/code&gt; alone. You must also check Corosync's member
list.&lt;/p&gt;
&lt;h2&gt;Querying the member list with &lt;code&gt;corosync-cmapctl&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;We can examine Corosync's cluster member list with the &lt;code&gt;corosync-cmapctl&lt;/code&gt; command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;# corosync-cmapctl | grep member
runtime.totem.pg.mrp.srp.members.303938909.ip=r(0) ip(10.0.1.1) r(1) ip(192.168.42.1) 
runtime.totem.pg.mrp.srp.members.303938909.join_count=1
runtime.totem.pg.mrp.srp.members.303938909.status=joined
runtime.totem.pg.mrp.srp.members.320716125.ip=r(0) ip(10.0.1.2) r(1) ip(192.168.42.2) 
runtime.totem.pg.mrp.srp.members.320716125.join_count=1
runtime.totem.pg.mrp.srp.members.320716125.status=joined
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this example, we have two nodes (with node IDs &lt;code&gt;303938909&lt;/code&gt; and
&lt;code&gt;320716125&lt;/code&gt;). They are both configured to use two communication rings,
&lt;code&gt;r(0)&lt;/code&gt; and &lt;code&gt;r(1)&lt;/code&gt;, and both of them have successfully joined the
cluster.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; In earlier Corosync releases (pre-2.0), the
&lt;code&gt;corosync-cmapctl&lt;/code&gt; tool was called &lt;code&gt;corosync-objctl&lt;/code&gt;. Its command
syntax for querying the member list was identical.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Corosync"></category></entry><entry><title>Fencing in Libvirt/KVM virtualized cluster nodes</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/fencing-libvirtkvm-virtualized-cluster-nodes/" rel="alternate"></link><published>2012-02-29T13:56:42+01:00</published><updated>2012-02-29T13:56:42+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-02-29:/resources/hints-and-kinks/fencing-libvirtkvm-virtualized-cluster-nodes/</id><summary type="html">&lt;p&gt;Often, people deploy the Pacemaker stack in virtual environments for
purposes of testing and evaluation. In such environments, it's easy to
test Pacemaker's fencing capabilities by tying in with the hypervisor.&lt;/p&gt;
&lt;p&gt;This quick howto illustrates how to configure fencing for two virtual
cluster nodes hosted on a libvirt/KVM hypervisor …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Often, people deploy the Pacemaker stack in virtual environments for
purposes of testing and evaluation. In such environments, it's easy to
test Pacemaker's fencing capabilities by tying in with the hypervisor.&lt;/p&gt;
&lt;p&gt;This quick howto illustrates how to configure fencing for two virtual
cluster nodes hosted on a libvirt/KVM hypervisor host.&lt;/p&gt;
&lt;h2&gt;libvirt configuration (hypervisor)&lt;/h2&gt;
&lt;p&gt;In order to do libvirt fencing, your hypervisor should have its
libvirtd daemon listen on a network socket. libvirtd is capable of
doing this, both on an encrypted TLS socket, and on a regular,
unencrypted TCP port. Needless to say, for production use you should
only use TLS, but for testing and evaluation – and for that purpose
only – TCP is fine.&lt;/p&gt;
&lt;p&gt;In order for your hypervisor to listen on an unauthenticated,
insecure, unencrypted network socket (did we mention that's unsuitable
for production?), add the following lines to your libvirtd
configuration file:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="na"&gt;listen_tls&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;0&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;listen_tcp&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;1&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;tcp_port&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"16509"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="na"&gt;auth_tcp&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"none"&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can also set the &lt;code&gt;listen_addr&lt;/code&gt; parameter, for example to have
libvirtd listen only on the network that your virtual machines run
in. If you don't set listen_addr, libvirtd will simply listen on the
wildcard address.&lt;/p&gt;
&lt;p&gt;You'll also have to add the &lt;code&gt;-l&lt;/code&gt; or &lt;code&gt;--listen&lt;/code&gt; flag to your libvirtd
invocation. On Debian/Ubuntu platforms, you can do so by editing the
&lt;code&gt;/etc/default/libvirt-bin&lt;/code&gt; configuration file.&lt;/p&gt;
&lt;p&gt;Once you've done that, you can use &lt;code&gt;netstat -ltp&lt;/code&gt; to check whether
libvirtd is in fact listening on its configured port, 16509/tcp. Also,
make sure that you don't have a firewall blocking that port.&lt;/p&gt;
&lt;h2&gt;libvirt configuration (virtual machines)&lt;/h2&gt;
&lt;p&gt;Inside your virtual machines, you'll also have to install the libvirt
client binaries – the fencing mechanism uses the virsh utility under
the covers. Some platforms provide a &lt;code&gt;libvirt-client&lt;/code&gt; package for that
purpose; for other's, you'll simply have to install the full &lt;code&gt;libvirt&lt;/code&gt;
package.&lt;/p&gt;
&lt;p&gt;Once that is set up, you should be able to run this command from
inside your virtual machines:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;virsh --connect&lt;span class="o"&gt;=&lt;/span&gt;qemu+tcp://&amp;lt;IP of your hypervisor&amp;gt;/system &lt;span class="se"&gt;\&lt;/span&gt;
  list --all
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;... and that command should list all the domains running on that host,
including the one you're connecting from.&lt;/p&gt;
&lt;h2&gt;Pacemaker configuration&lt;/h2&gt;
&lt;p&gt;In one of your virtual machines, you can now set up your fencing
configuration.&lt;/p&gt;
&lt;p&gt;This example assumes that you have two nodes named alice and bob, that
their corresponding virtual machine domain names are also alice and
bob, and that they can reach their hypervisor by TCP at 192.168.0.1:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;primitive p_fence_alice stonith:external/libvirt \
  params hostlist="alice" \
   hypervisor_uri="qemu+tcp://192.168.0.1/system" \
  op monitor interval="60"
primitive p_fence_bob stonith:external/libvirt \
  params hostlist="bob" \
    hypervisor_uri="qemu+tcp://192.168.0.1/system" \
  op monitor interval="60"
location l_fence_alice p_fence_alice -inf: alice
location l_fence_bob p_fence_bob -inf: bob
property stonith-enabled=true
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now you can test fencing to the best of your abilities.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Pacemaker"></category></entry><entry><title>Network connectivity check in Pacemaker</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/network-connectivity-check-pacemaker/" rel="alternate"></link><published>2012-02-27T17:45:19+01:00</published><updated>2012-02-27T17:45:19+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-02-27:/resources/hints-and-kinks/network-connectivity-check-pacemaker/</id><summary type="html">&lt;p&gt;If you want a Pacemaker cluster to move resources on changes on the
network connectivity of an individual node, there are two major steps
involved:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Let Pacemaker monitor connectivity;&lt;/li&gt;
&lt;li&gt;Configure constraints to react on connectivity changes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Prerequisites&lt;/h2&gt;
&lt;p&gt;Be sure to run at least Pacemaker 1.0.11 or 1.1 …&lt;/p&gt;</summary><content type="html">&lt;p&gt;If you want a Pacemaker cluster to move resources on changes on the
network connectivity of an individual node, there are two major steps
involved:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Let Pacemaker monitor connectivity;&lt;/li&gt;
&lt;li&gt;Configure constraints to react on connectivity changes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Prerequisites&lt;/h2&gt;
&lt;p&gt;Be sure to run at least Pacemaker 1.0.11 or 1.1.6 to include some
important fixes affecting the &lt;code&gt;ocf:pacemaker:ping&lt;/code&gt; resource agent.&lt;/p&gt;
&lt;p&gt;Preferably, choose more than one reliable ping targets in your network
(like a highly available gateway router, a core switch, or DNS
server).&lt;/p&gt;
&lt;h2&gt;Pacemaker configuration&lt;/h2&gt;
&lt;p&gt;The following crm shell code snippet configures a cloned ping resource
including constraints to run Dummy resources on any node that has
connectivity at all. Please note, that the first constraint forbids to
run &lt;code&gt;p_dummy1&lt;/code&gt; if all nodes lose connectivity. The second constraint
places &lt;code&gt;p_dummy2&lt;/code&gt; on the node that has the best connectivity:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;primitive p_ping ocf:pacemaker:ping \
   params host_list="dns.example.com router.example.com" \
   multiplier="1000" dampen="60s"\
   op monitor interval="10s"
clone cl_ping p_ping

primitive p_dummy1 ocf:pacemaker:Dummy
primitive p_dummy2 ocf:pacemaker:Dummy

location l_dummy1_needs_connectivity p_dummy1 \
  rule -inf: not_defined pingd or pingd lte 0
location l_dummy2_likes_best_connectivity p_dummy2 \
  rule pingd: defined pingd
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Pacemaker"></category></entry><entry><title>Speaking at the 2012 Percona Live MySQL Conference</title><link href="https://xahteiwi.eu/blog/2012/02/27/speaking-2012-percona-live-mysql-conference/" rel="alternate"></link><published>2012-02-27T13:39:00+00:00</published><updated>2012-02-27T13:39:00+00:00</updated><author><name>florian</name></author><id>tag:xahteiwi.eu,2012-02-27:/blog/2012/02/27/speaking-2012-percona-live-mysql-conference/</id><summary type="html">&lt;p&gt;This year, I have the pleasure of returning to the MySQL Conference &amp;amp;
Expo as a speaker. Percona have picked up the torch that O'Reilly had
held as the conference organizers, and they're putting together a 3-day
conference this year. I am co-presenting a tutorial with Yves Trudeau
from Percona.&lt;/p&gt;
&lt;p&gt;Our …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This year, I have the pleasure of returning to the MySQL Conference &amp;amp;
Expo as a speaker. Percona have picked up the torch that O'Reilly had
held as the conference organizers, and they're putting together a 3-day
conference this year. I am co-presenting a tutorial with Yves Trudeau
from Percona.&lt;/p&gt;
&lt;p&gt;Our tutorial is called &lt;a href="http://www.percona.com/live/mysql-conference-2012/sessions/mysql-high-availability-deep-dive-pacemaker-drbd-mysql-replication-and-more"&gt;High Availability Deep Dive: Pacemaker, DRBD,
MySQL Replication, and
more!&lt;/a&gt; and
it's going to be the only full-day tutorial offered in this year's
conference. In it, Yves and I are going to cover&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;/p&gt;
    An overview of the Pacemaker cluster stack (the classic "this is
    Pacemaker" introduction)
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;
-   &lt;/p&gt;
DRBD-backed MySQL replication (another classic and widely deployed
scenario)
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;
-   &lt;/p&gt;
MySQL replication under Pacemaker management (a new option which
Yves has vastly improved through a big patch set to the MySQL RA).
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Do I expect this talk to be controversial? Definitely. The amount of
"Pacemaker is terrible" and "Pacemaker is unsuitable for managing highly
available databases" that has been around the blogosphere lately is
pretty mind-boggling.&lt;/p&gt;
&lt;p&gt;But strangely enough, most of the things brought forward against
Pacemaker by its detractors seem like a time-warp back to about 2007.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;/p&gt;
    "We must use XML to manage Pacemaker!" Nonsense. In fact, that was
    &lt;em&gt;never&lt;/em&gt; true – the release of Pacemaker as a separate project and
    the release of the crm shell coincided. Ever since, Pacemaker
    configuration has been as text-based as MySQL itself.
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;
-   &lt;/p&gt;
"All Pacemaker can do is react to node failure!" Nothing could be
further from the truth. Pacemaker has some of the most sophisticated
resource monitoring and auto-recovery capabilities under the sun.
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;
-   &lt;/p&gt;
"OK. But all it can do to react to &lt;em&gt;resource&lt;/em&gt; failure is kill a
daemon!" Bogus again. It will happily do whatever the resource agent
specifies. Or the admin, through the configuration. 
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In our tutorial, we're going to dispel a few of these myths. We
certainly make no claims as to Pacemaker being the one and only solution
for MySQL HA, but it's one that serves lots of use cases excellently.&lt;/p&gt;
&lt;p&gt;Needless to say, I'll also hang around for the conference proper, and
I'm very much looking forward to seeing lots of familiar faces. I'll
also remain in the Bay Area for some time after the MySQL conference –
more on that in a day or two.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on my blog on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="blog"></category><category term="Conference"></category><category term="MySQL"></category></entry><entry><title>GFS2 in Pacemaker (Debian/Ubuntu)</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/gfs2-pacemaker-debianubuntu/" rel="alternate"></link><published>2012-02-26T20:34:08+01:00</published><updated>2012-02-26T20:34:08+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-02-26:/resources/hints-and-kinks/gfs2-pacemaker-debianubuntu/</id><summary type="html">&lt;p&gt;Setting up GFS2 in Pacemaker requires configuring the Pacemaker DLM,
the Pacemaker GFS control daemon, and a GFS2 filesystem itself.&lt;/p&gt;
&lt;h2&gt;Prerequisites&lt;/h2&gt;
&lt;p&gt;GFS2 with Pacemaker integration is supported on Debian
(&lt;code&gt;squeeze-backports&lt;/code&gt; and up) and Ubuntu (10.04 LTS and up). You'll need
the &lt;code&gt;dlm-pcmk&lt;/code&gt;, &lt;code&gt;gfs2-tools&lt;/code&gt;, and &lt;code&gt;gfs-pcmk&lt;/code&gt; packages.&lt;/p&gt;
&lt;p&gt;Fencing is imperative …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Setting up GFS2 in Pacemaker requires configuring the Pacemaker DLM,
the Pacemaker GFS control daemon, and a GFS2 filesystem itself.&lt;/p&gt;
&lt;h2&gt;Prerequisites&lt;/h2&gt;
&lt;p&gt;GFS2 with Pacemaker integration is supported on Debian
(&lt;code&gt;squeeze-backports&lt;/code&gt; and up) and Ubuntu (10.04 LTS and up). You'll need
the &lt;code&gt;dlm-pcmk&lt;/code&gt;, &lt;code&gt;gfs2-tools&lt;/code&gt;, and &lt;code&gt;gfs-pcmk&lt;/code&gt; packages.&lt;/p&gt;
&lt;p&gt;Fencing is imperative. Get a proper fencing/STONITH configuration set
up and test it thoroughly.&lt;/p&gt;
&lt;h2&gt;Pacemaker configuration&lt;/h2&gt;
&lt;p&gt;The Pacemaker configuration, shown here in &lt;code&gt;crm&lt;/code&gt; shell syntax, normally
puts all the required resources into one cloned group. Have a look at
this configuration snippet:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;primitive p_dlm_controld ocf:pacemaker:controld \
  params daemon="dlm_controld.pcmk" \
  op start interval="0" timeout="90" \
  op stop interval="0" timeout="100" \
  op monitor interval="10"
primitive p_gfs_controld ocf:pacemaker:controld \
  params daemon="gfs_controld.pcmk"\
  op start interval="0" timeout="90" \
  op stop interval="0" timeout="100" \
  op monitor interval="10"
primitive p_fs_gfs2 ocf:heartbeat:Filesystem \
  params device="&amp;lt;your device path&amp;gt;" \
    directory="&amp;lt;your mount point&amp;gt;" \
    fstype="gfs2" \
  op monitor interval="10"
group g_gfs2 p_dlm_controld p_gfs_controld p_fs_gfs2
clone cl_gfs2 g_gfs2 \
  meta interleave="true"
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then when that's done, your filesystem should happily mount on all nodes.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Pacemaker"></category></entry><entry><title>Interleaving in Pacemaker clones</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/interleaving-pacemaker-clones/" rel="alternate"></link><published>2012-02-26T20:34:08+01:00</published><updated>2012-02-26T20:34:08+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-02-26:/resources/hints-and-kinks/interleaving-pacemaker-clones/</id><summary type="html">&lt;p&gt;Ever wonder what &lt;code&gt;meta interleave&lt;/code&gt; really means in a Pacemaker clone
definition? We'll explain.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;interleave&lt;/code&gt; meta attribute is only valid on Pacemaker clone
definitions – and their extended version of sorts, master/slave
sets. It's not available on primitives and groups. Clones are often
used in configurations involving cluster filesystems …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Ever wonder what &lt;code&gt;meta interleave&lt;/code&gt; really means in a Pacemaker clone
definition? We'll explain.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;interleave&lt;/code&gt; meta attribute is only valid on Pacemaker clone
definitions – and their extended version of sorts, master/slave
sets. It's not available on primitives and groups. Clones are often
used in configurations involving cluster filesystems, such as GFS2
(&lt;a href="https://xahteiwi.eu/resources/hints-and-kinks/gfs2-pacemaker-debianubuntu/"&gt;here's an example&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Consider the following example (primitive definitions omitted to keep
this short):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;clone cl_foo p_foo meta interleave=false
clone cl_bar p_bar meta interleave=false
order o_foo_before_bar inf: cl_foo cl_bar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;What this means is for the &lt;code&gt;order&lt;/code&gt; constraint to be fulfilled, &lt;em&gt;all&lt;/em&gt;
instances of &lt;code&gt;cl_foo&lt;/code&gt; must start before &lt;em&gt;any&lt;/em&gt; instance of &lt;code&gt;cl_bar&lt;/code&gt;
can. Often, that's not what you want.&lt;/p&gt;
&lt;p&gt;In contrast, consider this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;clone cl_foo p_foo meta interleave=true
clone cl_bar p_bar meta interleave=true
order o_foo_before_bar inf: cl_foo cl_bar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Here, for each node, as soon as the &lt;em&gt;local&lt;/em&gt; instance of &lt;code&gt;cl_foo&lt;/code&gt; has
started, the corresponding local instance of &lt;code&gt;cl_bar&lt;/code&gt; can, too. &lt;strong&gt;This
is what's usually desired – when in doubt, allow interleaving.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;One thing that often throws people is that interleaving only works
when Pacemaker is configured to run the same number of instances of
two clones on the same node. Thus,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;clone cl_foo p_foo\
  meta interleave=true \
    globally-unique=true clone-node-max=2
clone cl_bar p_bar meta interleave=false
order o_foo_before_bar inf: cl_foo cl_bar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;... won't work, as Pacemaker is allowed to run 2 instances of &lt;code&gt;cl_foo&lt;/code&gt;
on the same node, but only one of &lt;code&gt;cl_bar&lt;/code&gt; (the default for
&lt;code&gt;clone-node-max&lt;/code&gt; is 1).&lt;/p&gt;
&lt;p&gt;Also, &lt;code&gt;globally-unique=true&lt;/code&gt; is a requirement for any
&lt;code&gt;clone-node-max&lt;/code&gt;&amp;gt;1 – which means that interleaving between a
globally-unique and a not globally-unique clone is also not supported.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Pacemaker"></category></entry><entry><title>OCFS2 in Pacemaker (Debian/Ubuntu)</title><link href="https://xahteiwi.eu/resources/hints-and-kinks/ocfs2-pacemaker-debianubuntu/" rel="alternate"></link><published>2012-02-24T17:01:20+01:00</published><updated>2012-02-24T17:01:20+01:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2012-02-24:/resources/hints-and-kinks/ocfs2-pacemaker-debianubuntu/</id><summary type="html">&lt;p&gt;Setting up OCFS2 in Pacemaker requires configuring the Pacemaker DLM,
the O2CB lock manager for OCFS2, and an OCFS2 filesystem itself.&lt;/p&gt;
&lt;h2&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;OCFS2 with Pacemaker integration is supported on Debian
  (&lt;code&gt;squeeze-backports&lt;/code&gt; and up) and Ubuntu (10.04 LTS and up). You'll
  need the &lt;code&gt;dlm-pcmk&lt;/code&gt;, &lt;code&gt;ocfs2-tools&lt;/code&gt;, &lt;code&gt;ocfs2-tools-pacemaker&lt;/code&gt; and
  &lt;code&gt;openais&lt;/code&gt; packages.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fencing …&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;Setting up OCFS2 in Pacemaker requires configuring the Pacemaker DLM,
the O2CB lock manager for OCFS2, and an OCFS2 filesystem itself.&lt;/p&gt;
&lt;h2&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;OCFS2 with Pacemaker integration is supported on Debian
  (&lt;code&gt;squeeze-backports&lt;/code&gt; and up) and Ubuntu (10.04 LTS and up). You'll
  need the &lt;code&gt;dlm-pcmk&lt;/code&gt;, &lt;code&gt;ocfs2-tools&lt;/code&gt;, &lt;code&gt;ocfs2-tools-pacemaker&lt;/code&gt; and
  &lt;code&gt;openais&lt;/code&gt; packages.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fencing is imperative. Get a proper fencing/STONITH configuration
  set up and test it thoroughly.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Running OCFS2/Pacemaker integration requires that you load Corosync
  with the &lt;code&gt;openais_ckpt&lt;/code&gt; service enabled. The service definition is in
  the file &lt;code&gt;/etc/corosync/service.d/ckpt-service&lt;/code&gt; which the &lt;code&gt;openais&lt;/code&gt;
  package installs by default. Make sure you did not accidentally
  delete or disable this file.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Pacemaker configuration&lt;/h2&gt;
&lt;p&gt;The Pacemaker configuration, shown here in crm shell syntax, normally
puts all the required resources into one cloned group. Have a look at
this configuration snippet:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;primitive p_dlm_controld ocf:pacemaker:controld \
  op start interval="0" timeout="90" \
  op stop interval="0" timeout="100" \
  op monitor interval="10"
primitive p_o2cb ocf:pacemaker:o2cb \
  op start interval="0" timeout="90" \
  op stop interval="0" timeout="100" \
  op monitor interval="10"
primitive p_fs_ocfs2 ocf:heartbeat:Filesystem \
  params device="&amp;lt;your device path&amp;gt;" \
    directory="&amp;lt;your mount point&amp;gt;" \
    fstype="ocfs2" \
  meta target-role=Stopped \
  op monitor interval="10"
group g_ocfs2 p_dlm_controld p_o2cb p_fs_ocfs2
clone cl_ocfs2 g_ocfs2 \
  meta interleave="true"
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Why keep the filesystem stopped?&lt;/h2&gt;
&lt;p&gt;Because you probably either don't have a configured OCFS2 filesystem
on your device yet, or your ran mkfs.ocfs2 when the Pacemaker stack
wasn't running. In either of those two cases, mount.ocfs2 will refuse
to mount the filesystem.&lt;/p&gt;
&lt;p&gt;Thus, fire up your DLM and the o2cb process like the above
configuration does, and then:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If you haven't got a filesystem yet, run &lt;code&gt;mkfs.ocfs2&lt;/code&gt; on your device, or&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you do already have one, run
  &lt;code&gt;tunefs.ocfs2 --update-cluster-stack &amp;lt;device&amp;gt;&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then when that's done, run &lt;code&gt;crm resource start p_fs_ocfs2&lt;/code&gt; and your
filesystem should happily mount on all nodes.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="hints-and-kinks"></category><category term="Pacemaker"></category></entry><entry><title>Fencing and Maintaining Sanity in High-Availability Clusters</title><link href="https://xahteiwi.eu/resources/presentations/fencing-and-maintaining-sanity-high-availability-clusters/" rel="alternate"></link><published>2011-11-01T13:45:00+00:00</published><updated>2011-11-01T13:45:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2011-11-01:/resources/presentations/fencing-and-maintaining-sanity-high-availability-clusters/</id><summary type="html">&lt;p&gt;A 45-minute talk I co-presented with &lt;a href="https://alteeve.ca/w/Main_Page"&gt;Madison
Kelly&lt;/a&gt; at Linuxcon Europe 2011 in
Prague. We explain the purpose of fencing, options for implementing
fencing, and common pitfalls.&lt;/p&gt;
&lt;p&gt;This presentation rounded out a series of high-availability talks at
Linuxcon Europe 2011, the first Linuxcon event hosted by the Linux
Foundation in …&lt;/p&gt;</summary><content type="html">&lt;p&gt;A 45-minute talk I co-presented with &lt;a href="https://alteeve.ca/w/Main_Page"&gt;Madison
Kelly&lt;/a&gt; at Linuxcon Europe 2011 in
Prague. We explain the purpose of fencing, options for implementing
fencing, and common pitfalls.&lt;/p&gt;
&lt;p&gt;This presentation rounded out a series of high-availability talks at
Linuxcon Europe 2011, the first Linuxcon event hosted by the Linux
Foundation in Europe. Madison and I presented at the Clarion
Congress hotel, in the main conference track.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Slides: &lt;a href="https://www.slideshare.net/slideshow/embed_code/key/JQdx4FrVorOzkW"&gt;SlideShare&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="Conference"></category></entry><entry><title>MySQL High Availability Sprint: Launch the Pacemaker!</title><link href="https://xahteiwi.eu/resources/presentations/mysql-high-availability-sprint-launch-pacemaker/" rel="alternate"></link><published>2011-11-01T13:45:00+00:00</published><updated>2011-11-01T13:45:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:xahteiwi.eu,2011-11-01:/resources/presentations/mysql-high-availability-sprint-launch-pacemaker/</id><content type="html">&lt;p&gt;This is a very dense tutorial given at Percona Live UK 2011 in London,
England. In three hours, I covered the MySQL HA Stack with
Pacemaker and DRBD, front to back.&lt;/p&gt;
&lt;!--break--&gt;
&lt;ul&gt;
&lt;li&gt;Slides: &lt;a href="https://www.slideshare.net/slideshow/embed_code/key/sz9doig59uDdAC"&gt;SlideShare&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;This article originally appeared on the &lt;code&gt;hastexo.com&lt;/code&gt; website (now defunct).&lt;/p&gt;</content><category term="presentations"></category><category term="Conference"></category><category term="MySQL"></category><category term="Pacemaker"></category></entry></feed>