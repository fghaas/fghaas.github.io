<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>xahteiwi.eu - Stereoscopy</title><link href="https://fghaas.github.io/" rel="alternate"></link><link href="https://fghaas.github.io/feeds/tag/stereoscopy.atom.xml" rel="self"></link><id>https://fghaas.github.io/</id><updated>2020-11-06T00:00:00+00:00</updated><entry><title>Add depth! Stereoscopic imagery for everyone</title><link href="https://fghaas.github.io/talk-submissions/lca-2021-stereoscopy/" rel="alternate"></link><published>2020-11-06T00:00:00+00:00</published><updated>2020-11-06T00:00:00+00:00</updated><author><name>Florian Haas</name></author><id>tag:fghaas.github.io,2020-11-06:/talk-submissions/lca-2021-stereoscopy/</id><summary type="html">&lt;p&gt;A talk I submitted to linux.conf.au 2021.&lt;/p&gt;</summary><content type="html">&lt;p&gt;This is a talk I submitted&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt; to linux.conf.au 2021. It was,
unfortunately, rejected. &lt;/p&gt;
&lt;p&gt;If you run a conference or meetup (on-person or online) where you
think this talk would be a good fit, please let me know! I’d still
love to present it when the opportunity arises.&lt;/p&gt;
&lt;h2&gt;Title&lt;/h2&gt;
&lt;p&gt;Add depth! Stereoscopic imagery for everyone&lt;/p&gt;
&lt;h2&gt;Target Audience&lt;/h2&gt;
&lt;p&gt;User&lt;/p&gt;
&lt;h2&gt;Abstract&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;This will appear in the conference programme. Up to about 500
words. This field is rendered with the monospace font Hack with
whitespace preserved&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Stereoscopic imagery (photography and videography) is a fascinating
way to create 3-dimensional images of landscapes, unmoving and moving
objects, and of course, people.&lt;/p&gt;
&lt;p&gt;In this talk, we'll cover the basics of stereoscopic imagery and
projection, discover how stereoscopic vision works, and how we can
trick our brains into perceiving depth from two flat images.&lt;/p&gt;
&lt;p&gt;We start with the principles of three-dimensional vision in humans:
how our eyes use the combination of focus and vergence to signal two
slightly different images of our surroundings to our brain, and how
our brain then processes these images to give us the perception of
depth. Then, we discuss the techniques available to play tricks on our
brains in which two slightly (but cleverly) distinct &lt;em&gt;two&lt;/em&gt;-dimensional
images are presented to our eyes in such a way that our mind conjures
up depth where there objectively is none.&lt;/p&gt;
&lt;p&gt;These techniques come in various forms, from very high tech (such as
virtual reality goggles) to very low tech (like mechanical
stereoscopic viewers), but some can deal without any projection
technology at all: this is called freeviewing, and for most people it
is a remarkably simple and low-cost way to enjoy stunning
three-dimensional imagery. We'll cover the parallel-view and crossview
freeviewing techniques.&lt;/p&gt;
&lt;p&gt;We'll then dive into the simple but highly effective steps of making
stereoscopic images, using run-of-the-mill cameras (even cell phones),
and some straightforward image processing in the GIMP.&lt;/p&gt;
&lt;p&gt;Finally, we talk about some neat little tricks to make stereoscopic
videos, with minimal cost and investment. We'll look at how we can
make 3D video with just a GoPro, or a simple drone camera — again
using a free software tool, namely the OpenShot video editor, for
processing.&lt;/p&gt;
&lt;h2&gt;Private Abstract&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;This will only be shown to organisers and reviewers. You should
provide any details about your proposal that you don't want to be
public here. This field is rendered with the monospace font Hack
with whitespace preserved&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This talk does not cover a specific software project; the "Project
URL" below is simply a Flickr album containing a set of stereoscopic
images created with the technique I am describing.&lt;/p&gt;
&lt;p&gt;The fact that LCA is an online event this year would suit this talk
particularly well: when I get to the point of explaining freeviewing
to attendees, I would expect novices to have some difficulty with
&lt;em&gt;one&lt;/em&gt; of the freeviewing techniques, and some, with both. The latter
would have the option of simply backing up the stream and re-watching
the instructions and the test images provided, which is an option that
would not exist in a live talk.&lt;/p&gt;
&lt;p&gt;Accessibility note: Regretfully, this talk will have limited
accessibility for people with vision deficiencies. Specifically, the
3D effects presented will be inaccessible to people with complete loss
of vision in one eye (or both), nystagmus, or strabismus. People with
these conditions will still be able to learn from the techniques
presented in the talk, but will likely be unable to perceive the
demonstrated 3D effects themselves. People with intraocular lens (IOL)
implants might also have difficulty following some of the examples in
the talk.&lt;/p&gt;
&lt;h2&gt;Project URL&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://www.flickr.com/gp/77872933@N02/SSzK0w"&gt;https://www.flickr.com/gp/77872933@N02/SSzK0w&lt;/a&gt;&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr/&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;If you’re curious why this is here, please read
&lt;a href="https://fghaas.github.io/blog/2019/04/23/talk-submissions/"&gt;this&lt;/a&gt;. &lt;a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content><category term="talk-submissions"></category><category term="Conference"></category><category term="Stereoscopy"></category></entry></feed>